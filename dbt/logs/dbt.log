[0m17:31:01.458305 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffaa3ae190>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffaa59afd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffaa3ac790>]}


============================== 17:31:01.465289 | fb79e12e-583a-4f38-a76b-08da90e15754 ==============================
[0m17:31:01.465289 [info ] [MainThread]: Running with dbt=1.7.0
[0m17:31:01.465923 [debug] [MainThread]: running dbt with arguments {'write_json': 'True', 'send_anonymous_usage_stats': 'True', 'static_parser': 'True', 'no_print': 'None', 'target_path': 'None', 'log_format': 'default', 'log_cache_events': 'False', 'log_path': '/usr/app/dbt/logs', 'version_check': 'True', 'quiet': 'False', 'invocation_command': 'dbt run --project-dir /usr/app/dbt --profiles-dir /usr/app/dbt --select gold', 'use_colors': 'True', 'use_experimental_parser': 'False', 'debug': 'False', 'warn_error': 'None', 'partial_parse': 'True', 'fail_fast': 'False', 'printer_width': '80', 'introspect': 'True', 'indirect_selection': 'eager', 'cache_selected_only': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'profiles_dir': '/usr/app/dbt'}
[0m17:31:01.467597 [error] [MainThread]: Encountered an error:
Runtime Error
  Could not find profile named 'movie_clickhouse'
[0m17:31:01.468883 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffaa3b7310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffaa3b7390>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffaf9a1150>]}
[0m17:31:01.469138 [debug] [MainThread]: Flushing usage events
[0m17:33:13.841907 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff9829b610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff994d7e10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff9829a850>]}


============================== 17:33:13.844152 | 72d4426f-32fc-4bc2-8435-11d2d0c9aef5 ==============================
[0m17:33:13.844152 [info ] [MainThread]: Running with dbt=1.7.0
[0m17:33:13.844502 [debug] [MainThread]: running dbt with arguments {'version_check': 'True', 'send_anonymous_usage_stats': 'True', 'no_print': 'None', 'quiet': 'False', 'log_path': '/usr/app/dbt/logs', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'indirect_selection': 'eager', 'introspect': 'True', 'log_format': 'default', 'debug': 'False', 'write_json': 'True', 'static_parser': 'True', 'use_experimental_parser': 'False', 'fail_fast': 'False', 'printer_width': '80', 'invocation_command': 'dbt run --project-dir /usr/app/dbt --profiles-dir /usr/app/dbt --select gold', 'profiles_dir': '/usr/app/dbt', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'use_colors': 'True', 'target_path': 'None', 'warn_error': 'None'}
[0m17:33:13.877011 [error] [MainThread]: Encountered an error:
Runtime Error
  Credentials in profile "movie_clickhouse", target "dev" invalid: Runtime Error
        schema: gold 
        database: default 
        cluster: None 
    On Clickhouse, database must be omitted or have the same value as schema.
[0m17:33:13.877804 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff980ada10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff980ac210>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff9d6a12d0>]}
[0m17:33:13.878115 [debug] [MainThread]: Flushing usage events
[0m17:34:36.020504 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa343fb90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa2aa2210>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa245ec50>]}


============================== 17:34:36.026283 | ab8c2c11-ac0e-4fdf-94e1-cd08bfe13b3a ==============================
[0m17:34:36.026283 [info ] [MainThread]: Running with dbt=1.7.0
[0m17:34:36.027144 [debug] [MainThread]: running dbt with arguments {'partial_parse': 'True', 'use_experimental_parser': 'False', 'warn_error': 'None', 'debug': 'False', 'target_path': 'None', 'log_cache_events': 'False', 'printer_width': '80', 'static_parser': 'True', 'introspect': 'True', 'invocation_command': 'dbt run --project-dir /usr/app/dbt --profiles-dir /usr/app/dbt --select gold', 'write_json': 'True', 'profiles_dir': '/usr/app/dbt', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'log_format': 'default', 'version_check': 'True', 'quiet': 'False', 'cache_selected_only': 'False', 'send_anonymous_usage_stats': 'True', 'use_colors': 'True', 'no_print': 'None', 'fail_fast': 'False', 'indirect_selection': 'eager', 'log_path': '/usr/app/dbt/logs'}
[0m17:34:36.206151 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'ab8c2c11-ac0e-4fdf-94e1-cd08bfe13b3a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa25158d0>]}
[0m17:34:36.285378 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'ab8c2c11-ac0e-4fdf-94e1-cd08bfe13b3a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa2386150>]}
[0m17:34:36.287265 [info ] [MainThread]: Registered adapter: clickhouse=1.7.0
[0m17:34:36.296327 [debug] [MainThread]: checksum: 8434eacd4ffdf0ca3ab22bf0e2d55b45306c9599613e842b959405abc489e606, vars: {}, profile: , target: , version: 1.7.0
[0m17:34:36.297491 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m17:34:36.298157 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'ab8c2c11-ac0e-4fdf-94e1-cd08bfe13b3a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa239e050>]}
[0m17:34:37.492495 [error] [MainThread]: Encountered an error:
Compilation Error
  Model 'model.movie_warehouse.fact_movie' (models/gold/fact_movie.sql) depends on a source named 'bronze.imdb_title_crew_raw' which was not found
[0m17:34:37.494054 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa245d8d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa0dd6910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa0e2e090>]}
[0m17:34:37.494639 [debug] [MainThread]: Flushing usage events
[0m18:06:49.274381 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff881b8b80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff86641850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8667a760>]}


============================== 18:06:49.289133 | 6a644bed-a7c4-407c-934e-e899cfb3df33 ==============================
[0m18:06:49.289133 [info ] [MainThread]: Running with dbt=1.8.7
[0m18:06:49.289483 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'debug': 'False', 'log_path': '/opt/airflow/project_root/dbt/logs', 'profiles_dir': '/opt/airflow/project_root/dbt', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'invocation_command': 'dbt run --project-dir /opt/airflow/project_root/dbt --profiles-dir /opt/airflow/project_root/dbt --select gold', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m18:06:49.291814 [info ] [MainThread]: Error importing adapter: No module named 'dbt.adapters.clickhouse'
[0m18:06:49.292136 [error] [MainThread]: Encountered an error:
Runtime Error
  Credentials in profile "movie_clickhouse", target "dev" invalid: Runtime Error
    Could not find adapter type clickhouse!
[0m18:06:49.293466 [debug] [MainThread]: Resource report: {"command_name": "run", "command_wall_clock_time": 0.0496455, "process_user_time": 0.649318, "process_kernel_time": 0.105867, "process_mem_max_rss": "179384", "process_in_blocks": "56768", "process_out_blocks": "115", "command_success": false}
[0m18:06:49.293760 [debug] [MainThread]: Command `dbt run` failed at 18:06:49.293717 after 0.05 seconds
[0m18:06:49.293957 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff881b8b80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff866cf8e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff86632340>]}
[0m18:06:49.294150 [debug] [MainThread]: Flushing usage events
[0m18:12:08.764519 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa231aca0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa1a35400>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa0869340>]}


============================== 18:12:08.769184 | e4a667aa-3c21-4abd-8838-904ad9b46a23 ==============================
[0m18:12:08.769184 [info ] [MainThread]: Running with dbt=1.8.7
[0m18:12:08.769586 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'version_check': 'True', 'log_path': '/opt/airflow/project_root/dbt/logs', 'fail_fast': 'False', 'profiles_dir': '/opt/airflow/project_root/dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'static_parser': 'True', 'introspect': 'True', 'invocation_command': 'dbt run --project-dir /opt/airflow/project_root/dbt --profiles-dir /opt/airflow/project_root/dbt --select gold', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m18:12:08.776475 [error] [MainThread]: Encountered an error:
'type' object is not subscriptable
[0m18:12:08.778040 [error] [MainThread]: Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/dbt/cli/requires.py", line 138, in wrapper
    result, success = func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/dbt/cli/requires.py", line 101, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/dbt/cli/requires.py", line 215, in wrapper
    profile = load_profile(flags.PROJECT_DIR, flags.VARS, flags.PROFILE, flags.TARGET, threads)
  File "/home/airflow/.local/lib/python3.8/site-packages/dbt/config/runtime.py", line 71, in load_profile
    profile = Profile.render(
  File "/home/airflow/.local/lib/python3.8/site-packages/dbt/config/profile.py", line 403, in render
    return cls.from_raw_profiles(
  File "/home/airflow/.local/lib/python3.8/site-packages/dbt/config/profile.py", line 369, in from_raw_profiles
    return cls.from_raw_profile_info(
  File "/home/airflow/.local/lib/python3.8/site-packages/dbt/config/profile.py", line 325, in from_raw_profile_info
    credentials: Credentials = cls._credentials_from_profile(
  File "/home/airflow/.local/lib/python3.8/site-packages/dbt/config/profile.py", line 149, in _credentials_from_profile
    cls = load_plugin(typename)
  File "/home/airflow/.local/lib/python3.8/site-packages/dbt/adapters/factory.py", line 239, in load_plugin
    return FACTORY.load_plugin(name)
  File "/home/airflow/.local/lib/python3.8/site-packages/dbt/adapters/factory.py", line 68, in load_plugin
    mod: Any = import_module("." + name, "dbt.adapters")
  File "/usr/local/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/airflow/.local/lib/python3.8/site-packages/dbt/adapters/clickhouse/__init__.py", line 4, in <module>
    from dbt.adapters.clickhouse.connections import ClickHouseConnectionManager  # noqa
  File "/home/airflow/.local/lib/python3.8/site-packages/dbt/adapters/clickhouse/connections.py", line 10, in <module>
    from dbt.adapters.clickhouse.dbclient import ChRetryableException, get_db_client
  File "/home/airflow/.local/lib/python3.8/site-packages/dbt/adapters/clickhouse/dbclient.py", line 9, in <module>
    from dbt.adapters.clickhouse.credentials import ClickHouseCredentials
  File "/home/airflow/.local/lib/python3.8/site-packages/dbt/adapters/clickhouse/credentials.py", line 9, in <module>
    class ClickHouseCredentials(Credentials):
  File "/home/airflow/.local/lib/python3.8/site-packages/dbt/adapters/clickhouse/credentials.py", line 38, in ClickHouseCredentials
    tcp_keepalive: Union[bool, tuple[int, int, int], list[int]] = False
TypeError: 'type' object is not subscriptable

[0m18:12:08.778868 [debug] [MainThread]: Resource report: {"command_name": "run", "command_wall_clock_time": 0.040379085, "process_user_time": 0.661739, "process_kernel_time": 0.100699, "process_mem_max_rss": "179244", "process_in_blocks": "59120", "process_out_blocks": "9", "command_success": false}
[0m18:12:08.779185 [debug] [MainThread]: Command `dbt run` failed at 18:12:08.779131 after 0.04 seconds
[0m18:12:08.779391 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa231aca0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa08a75b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa06f39a0>]}
[0m18:12:08.779585 [debug] [MainThread]: Flushing usage events
[0m18:20:03.186999 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa87c6c70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa7287190>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa6bb23a0>]}


============================== 18:20:03.203329 | c1d3aec8-6763-4e06-b253-f559aeecea84 ==============================
[0m18:20:03.203329 [info ] [MainThread]: Running with dbt=1.8.7
[0m18:20:03.203705 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'version_check': 'True', 'log_path': '/opt/airflow/project_root/dbt/logs', 'profiles_dir': '/opt/airflow/project_root/dbt', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'introspect': 'True', 'invocation_command': 'dbt run --project-dir /opt/airflow/project_root/dbt --profiles-dir /opt/airflow/project_root/dbt --select gold', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m18:20:03.206185 [info ] [MainThread]: Error importing adapter: No module named 'dbt.adapters.clickhouse'
[0m18:20:03.206499 [error] [MainThread]: Encountered an error:
Runtime Error
  Credentials in profile "movie_clickhouse", target "dev" invalid: Runtime Error
    Could not find adapter type clickhouse!
[0m18:20:03.207278 [debug] [MainThread]: Resource report: {"command_name": "run", "command_wall_clock_time": 0.0494365, "process_user_time": 0.728931, "process_kernel_time": 0.140793, "process_mem_max_rss": "179204", "process_in_blocks": "61632", "process_out_blocks": "2779", "command_success": false}
[0m18:20:03.207591 [debug] [MainThread]: Command `dbt run` failed at 18:20:03.207535 after 0.05 seconds
[0m18:20:03.207815 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa87c6c70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa6c1cc70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa6c1c400>]}
[0m18:20:03.208012 [debug] [MainThread]: Flushing usage events
[0m18:34:31.226630 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff7f7e7ac0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff7f0e5f10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff7dcaa700>]}


============================== 18:34:31.232405 | c7ae6c79-eb4f-4a1d-9986-49ae277e2ae4 ==============================
[0m18:34:31.232405 [info ] [MainThread]: Running with dbt=1.8.7
[0m18:34:31.233239 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/project_root/dbt', 'version_check': 'True', 'warn_error': 'None', 'log_path': '/opt/airflow/project_root/dbt/logs', 'debug': 'False', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run --project-dir /opt/airflow/project_root/dbt --profiles-dir /opt/airflow/project_root/dbt --select gold', 'log_format': 'default', 'static_parser': 'True', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m18:34:31.242318 [info ] [MainThread]: Error importing adapter: No module named 'dbt.adapters.clickhouse'
[0m18:34:31.243302 [error] [MainThread]: Encountered an error:
Runtime Error
  Credentials in profile "movie_clickhouse", target "dev" invalid: Runtime Error
    Could not find adapter type clickhouse!
[0m18:34:31.245142 [debug] [MainThread]: Resource report: {"command_name": "run", "command_wall_clock_time": 0.049812794, "process_user_time": 0.747644, "process_kernel_time": 0.1897, "process_mem_max_rss": "179436", "process_in_blocks": "55824", "process_out_blocks": "3", "command_success": false}
[0m18:34:31.245775 [debug] [MainThread]: Command `dbt run` failed at 18:34:31.245642 after 0.05 seconds
[0m18:34:31.246057 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff7f7e7ac0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff7dccda90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff7dccda00>]}
[0m18:34:31.246373 [debug] [MainThread]: Flushing usage events
[0m18:36:31.962908 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb3a33970>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb412b3a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb4a78910>]}


============================== 18:36:31.973053 | 43a5607a-f377-4ac6-b4c3-572df62380c5 ==============================
[0m18:36:31.973053 [info ] [MainThread]: Running with dbt=1.8.7
[0m18:36:31.974150 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'version_check': 'True', 'log_path': '/opt/airflow/project_root/dbt/logs', 'debug': 'False', 'profiles_dir': '/opt/airflow/project_root/dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'invocation_command': 'dbt run --project-dir /opt/airflow/project_root/dbt --profiles-dir /opt/airflow/project_root/dbt --select gold', 'log_format': 'default', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m18:36:31.984769 [info ] [MainThread]: Error importing adapter: No module named 'dbt.adapters.clickhouse'
[0m18:36:31.986014 [error] [MainThread]: Encountered an error:
Runtime Error
  Credentials in profile "movie_clickhouse", target "dev" invalid: Runtime Error
    Could not find adapter type clickhouse!
[0m18:36:31.988430 [debug] [MainThread]: Resource report: {"command_name": "run", "command_wall_clock_time": 0.100820914, "process_user_time": 2.539708, "process_kernel_time": 0.653315, "process_mem_max_rss": "179224", "process_in_blocks": "41536", "process_out_blocks": "3", "command_success": false}
[0m18:36:31.989490 [debug] [MainThread]: Command `dbt run` failed at 18:36:31.989238 after 0.10 seconds
[0m18:36:31.991243 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb3a33970>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb1f1de50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb1f1d850>]}
[0m18:36:31.992757 [debug] [MainThread]: Flushing usage events
[0m18:40:39.916189 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa5dc9af0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa4ebac70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa5570040>]}


============================== 18:40:39.920009 | abd6f7cd-34f2-444f-bd31-7b550aef8295 ==============================
[0m18:40:39.920009 [info ] [MainThread]: Running with dbt=1.8.7
[0m18:40:39.920332 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/project_root/dbt', 'debug': 'False', 'fail_fast': 'False', 'log_path': '/opt/airflow/project_root/dbt/logs', 'warn_error': 'None', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'invocation_command': 'dbt run --project-dir /opt/airflow/project_root/dbt --profiles-dir /opt/airflow/project_root/dbt --select gold', 'static_parser': 'True', 'introspect': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m18:40:39.922463 [info ] [MainThread]: Error importing adapter: No module named 'dbt.adapters.clickhouse'
[0m18:40:39.922765 [error] [MainThread]: Encountered an error:
Runtime Error
  Credentials in profile "movie_clickhouse", target "dev" invalid: Runtime Error
    Could not find adapter type clickhouse!
[0m18:40:39.923456 [debug] [MainThread]: Resource report: {"command_name": "run", "command_wall_clock_time": 0.032612376, "process_user_time": 0.660812, "process_kernel_time": 0.141026, "process_mem_max_rss": "179360", "process_in_blocks": "59856", "process_out_blocks": "3", "command_success": false}
[0m18:40:39.923735 [debug] [MainThread]: Command `dbt run` failed at 18:40:39.923681 after 0.03 seconds
[0m18:40:39.923925 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa5dc9af0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa42ad9a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa42adb20>]}
[0m18:40:39.924117 [debug] [MainThread]: Flushing usage events
[0m18:47:14.175663 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffadbacaf0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffacc9cc70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffad351040>]}


============================== 18:47:14.179827 | 4acad39a-24c6-43ac-b291-02322f58ee62 ==============================
[0m18:47:14.179827 [info ] [MainThread]: Running with dbt=1.8.7
[0m18:47:14.180178 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/project_root/dbt', 'fail_fast': 'False', 'version_check': 'True', 'log_path': '/opt/airflow/project_root/dbt/logs', 'debug': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'target_path': 'None', 'invocation_command': 'dbt run --project-dir /opt/airflow/project_root/dbt --profiles-dir /opt/airflow/project_root/dbt --select gold', 'send_anonymous_usage_stats': 'True'}
[0m18:47:14.185992 [error] [MainThread]: Encountered an error:
'type' object is not subscriptable
[0m18:47:14.187973 [error] [MainThread]: Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/dbt/cli/requires.py", line 138, in wrapper
    result, success = func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/dbt/cli/requires.py", line 101, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/dbt/cli/requires.py", line 215, in wrapper
    profile = load_profile(flags.PROJECT_DIR, flags.VARS, flags.PROFILE, flags.TARGET, threads)
  File "/home/airflow/.local/lib/python3.8/site-packages/dbt/config/runtime.py", line 71, in load_profile
    profile = Profile.render(
  File "/home/airflow/.local/lib/python3.8/site-packages/dbt/config/profile.py", line 403, in render
    return cls.from_raw_profiles(
  File "/home/airflow/.local/lib/python3.8/site-packages/dbt/config/profile.py", line 369, in from_raw_profiles
    return cls.from_raw_profile_info(
  File "/home/airflow/.local/lib/python3.8/site-packages/dbt/config/profile.py", line 325, in from_raw_profile_info
    credentials: Credentials = cls._credentials_from_profile(
  File "/home/airflow/.local/lib/python3.8/site-packages/dbt/config/profile.py", line 149, in _credentials_from_profile
    cls = load_plugin(typename)
  File "/home/airflow/.local/lib/python3.8/site-packages/dbt/adapters/factory.py", line 239, in load_plugin
    return FACTORY.load_plugin(name)
  File "/home/airflow/.local/lib/python3.8/site-packages/dbt/adapters/factory.py", line 68, in load_plugin
    mod: Any = import_module("." + name, "dbt.adapters")
  File "/usr/local/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/airflow/.local/lib/python3.8/site-packages/dbt/adapters/clickhouse/__init__.py", line 4, in <module>
    from dbt.adapters.clickhouse.connections import ClickHouseConnectionManager  # noqa
  File "/home/airflow/.local/lib/python3.8/site-packages/dbt/adapters/clickhouse/connections.py", line 10, in <module>
    from dbt.adapters.clickhouse.dbclient import ChRetryableException, get_db_client
  File "/home/airflow/.local/lib/python3.8/site-packages/dbt/adapters/clickhouse/dbclient.py", line 9, in <module>
    from dbt.adapters.clickhouse.credentials import ClickHouseCredentials
  File "/home/airflow/.local/lib/python3.8/site-packages/dbt/adapters/clickhouse/credentials.py", line 9, in <module>
    class ClickHouseCredentials(Credentials):
  File "/home/airflow/.local/lib/python3.8/site-packages/dbt/adapters/clickhouse/credentials.py", line 38, in ClickHouseCredentials
    tcp_keepalive: Union[bool, tuple[int, int, int], list[int]] = False
TypeError: 'type' object is not subscriptable

[0m18:47:14.188864 [debug] [MainThread]: Resource report: {"command_name": "run", "command_wall_clock_time": 0.040103126, "process_user_time": 0.685499, "process_kernel_time": 0.109842, "process_mem_max_rss": "179308", "process_in_blocks": "61440", "process_out_blocks": "9", "command_success": false}
[0m18:47:14.189197 [debug] [MainThread]: Command `dbt run` failed at 18:47:14.189134 after 0.04 seconds
[0m18:47:14.189436 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffadbacaf0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffac018dc0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffabef0970>]}
[0m18:47:14.189651 [debug] [MainThread]: Flushing usage events
[0m18:53:22.279773 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb6a97c40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb5af7970>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb4e85bb0>]}


============================== 18:53:22.315091 | af98d37e-31dd-4ece-b737-431980c21b74 ==============================
[0m18:53:22.315091 [info ] [MainThread]: Running with dbt=1.8.7
[0m18:53:22.316078 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/project_root/dbt', 'version_check': 'True', 'debug': 'False', 'log_path': '/opt/airflow/project_root/dbt/logs', 'warn_error': 'None', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'static_parser': 'True', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'invocation_command': 'dbt run --project-dir /opt/airflow/project_root/dbt --profiles-dir /opt/airflow/project_root/dbt --select gold', 'send_anonymous_usage_stats': 'True'}
[0m18:53:22.319884 [info ] [MainThread]: Error importing adapter: No module named 'dbt.adapters.clickhouse'
[0m18:53:22.320363 [error] [MainThread]: Encountered an error:
Runtime Error
  Credentials in profile "movie_clickhouse", target "dev" invalid: Runtime Error
    Could not find adapter type clickhouse!
[0m18:53:22.321878 [debug] [MainThread]: Resource report: {"command_name": "run", "command_wall_clock_time": 0.07787687, "process_user_time": 0.813776, "process_kernel_time": 0.133089, "process_mem_max_rss": "179380", "process_in_blocks": "62656", "process_out_blocks": "2779", "command_success": false}
[0m18:53:22.322567 [debug] [MainThread]: Command `dbt run` failed at 18:53:22.322471 after 0.08 seconds
[0m18:53:22.323447 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb6a97c40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb4eedc70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb4eedac0>]}
[0m18:53:22.324459 [debug] [MainThread]: Flushing usage events
[0m19:29:08.644013 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff9ea19a60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff9f05cf70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff9da772e0>]}


============================== 19:29:08.659769 | 2f872c3d-d4db-48be-b727-3b6c69b22187 ==============================
[0m19:29:08.659769 [info ] [MainThread]: Running with dbt=1.8.7
[0m19:29:08.660181 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'profiles_dir': '/opt/airflow/project_root/dbt', 'log_path': '/opt/airflow/project_root/dbt/logs', 'version_check': 'True', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'invocation_command': 'dbt run --project-dir /opt/airflow/project_root/dbt --profiles-dir /opt/airflow/project_root/dbt --select gold', 'log_format': 'default', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m19:29:08.662487 [info ] [MainThread]: Error importing adapter: No module named 'dbt.adapters.clickhouse'
[0m19:29:08.662786 [error] [MainThread]: Encountered an error:
Runtime Error
  Credentials in profile "movie_clickhouse", target "dev" invalid: Runtime Error
    Could not find adapter type clickhouse!
[0m19:29:08.663522 [debug] [MainThread]: Resource report: {"command_name": "run", "command_wall_clock_time": 0.050519418, "process_user_time": 0.784416, "process_kernel_time": 0.16088, "process_mem_max_rss": "179176", "process_in_blocks": "59136", "process_out_blocks": "2779", "command_success": false}
[0m19:29:08.663829 [debug] [MainThread]: Command `dbt run` failed at 19:29:08.663782 after 0.05 seconds
[0m19:29:08.664700 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff9ea19a60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff9cec6790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff9ce6ddf0>]}
[0m19:29:08.664920 [debug] [MainThread]: Flushing usage events
[0m20:02:33.057209 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa80f6c40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa7157970>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa64e4bb0>]}


============================== 20:02:33.074746 | 428e5fc9-08f8-49cd-9257-6824d486c6dc ==============================
[0m20:02:33.074746 [info ] [MainThread]: Running with dbt=1.8.7
[0m20:02:33.075111 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'version_check': 'True', 'log_path': '/opt/airflow/project_root/dbt/logs', 'debug': 'False', 'profiles_dir': '/opt/airflow/project_root/dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run --project-dir /opt/airflow/project_root/dbt --profiles-dir /opt/airflow/project_root/dbt --select gold', 'log_format': 'default', 'static_parser': 'True', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m20:02:33.077524 [info ] [MainThread]: Error importing adapter: No module named 'dbt.adapters.clickhouse'
[0m20:02:33.077850 [error] [MainThread]: Encountered an error:
Runtime Error
  Credentials in profile "movie_clickhouse", target "dev" invalid: Runtime Error
    Could not find adapter type clickhouse!
[0m20:02:33.078593 [debug] [MainThread]: Resource report: {"command_name": "run", "command_wall_clock_time": 0.051581956, "process_user_time": 0.822909, "process_kernel_time": 0.21265, "process_mem_max_rss": "179216", "process_in_blocks": "63032", "process_out_blocks": "2779", "command_success": false}
[0m20:02:33.078909 [debug] [MainThread]: Command `dbt run` failed at 20:02:33.078849 after 0.05 seconds
[0m20:02:33.079121 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa80f6c40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa659d820>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa657d6d0>]}
[0m20:02:33.079326 [debug] [MainThread]: Flushing usage events
[0m09:10:44.836329 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb8d19c10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb849feb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb7d77340>]}


============================== 09:10:44.853138 | bc83d401-a2fb-41b3-b624-ea1031c3f876 ==============================
[0m09:10:44.853138 [info ] [MainThread]: Running with dbt=1.8.7
[0m09:10:44.853634 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/project_root/dbt', 'version_check': 'True', 'fail_fast': 'False', 'log_path': '/opt/airflow/project_root/dbt/logs', 'warn_error': 'None', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'introspect': 'True', 'log_format': 'default', 'target_path': 'None', 'invocation_command': 'dbt run --project-dir /opt/airflow/project_root/dbt --profiles-dir /opt/airflow/project_root/dbt --select gold', 'send_anonymous_usage_stats': 'True'}
[0m09:10:44.856665 [info ] [MainThread]: Error importing adapter: No module named 'dbt.adapters.clickhouse'
[0m09:10:44.857102 [error] [MainThread]: Encountered an error:
Runtime Error
  Credentials in profile "movie_clickhouse", target "dev" invalid: Runtime Error
    Could not find adapter type clickhouse!
[0m09:10:44.858249 [debug] [MainThread]: Resource report: {"command_name": "run", "command_wall_clock_time": 0.05554829, "process_user_time": 0.77062, "process_kernel_time": 0.200901, "process_mem_max_rss": "179416", "process_in_blocks": "58008", "process_out_blocks": "2779", "command_success": false}
[0m09:10:44.858630 [debug] [MainThread]: Command `dbt run` failed at 09:10:44.858573 after 0.06 seconds
[0m09:10:44.858876 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb8d19c10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb71be640>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb93380d0>]}
[0m09:10:44.859104 [debug] [MainThread]: Flushing usage events
[0m09:25:09.378436 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff85401a50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff85401950>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff85401b90>]}


============================== 09:25:09.397576 | add9c4fc-3cca-45ea-acc6-35987f31a538 ==============================
[0m09:25:09.397576 [info ] [MainThread]: Running with dbt=1.8.9
[0m09:25:09.399846 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/project_root/dbt', 'version_check': 'True', 'debug': 'False', 'log_path': '/opt/airflow/project_root/dbt/logs', 'fail_fast': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'invocation_command': 'dbt run --project-dir /opt/airflow/project_root/dbt --profiles-dir /opt/airflow/project_root/dbt --select gold', 'log_format': 'default', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m09:25:09.603448 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'add9c4fc-3cca-45ea-acc6-35987f31a538', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8543d710>]}
[0m09:25:09.629173 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'add9c4fc-3cca-45ea-acc6-35987f31a538', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff85e2fa10>]}
[0m09:25:09.630043 [info ] [MainThread]: Registered adapter: clickhouse=1.8.9
[0m09:25:09.679494 [debug] [MainThread]: checksum: 132857a23e9d07220246854f7763165174ce9b737cfc7867629ace4294e520b1, vars: {}, profile: , target: , version: 1.8.9
[0m09:25:09.680292 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m09:25:09.680618 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'add9c4fc-3cca-45ea-acc6-35987f31a538', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff85203210>]}
[0m09:25:10.260115 [warn ] [MainThread]: [[33mWARNING[0m]: Deprecated functionality
The `tests` config has been renamed to `data_tests`. Please see
https://docs.getdbt.com/docs/build/data-tests#new-data_tests-syntax for more
information.
[0m09:25:10.260809 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'deprecation', 'label': 'add9c4fc-3cca-45ea-acc6-35987f31a538', 'property_': 'warn', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff857fc990>]}
[0m09:25:10.331329 [error] [MainThread]: Encountered an error:
Compilation Error
  Model 'model.movie_warehouse.fact_movie' (models/gold/fact_movie.sql) depends on a source named 'bronze.tmdb_raw' which was not found
[0m09:25:10.332565 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 0.9998716, "process_in_blocks": "87848", "process_kernel_time": 0.276451, "process_mem_max_rss": "185672", "process_out_blocks": "1462", "process_user_time": 1.682924}
[0m09:25:10.332923 [debug] [MainThread]: Command `dbt run` failed at 09:25:10.332848 after 1.00 seconds
[0m09:25:10.333182 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff85424910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff854269d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff6fd17c50>]}
[0m09:25:10.333408 [debug] [MainThread]: Flushing usage events
[0m09:34:52.807815 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa73dd690>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa73dd250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa73dc990>]}


============================== 09:34:52.811720 | a7f38080-ccc7-487e-94f2-c9c673a45e68 ==============================
[0m09:34:52.811720 [info ] [MainThread]: Running with dbt=1.8.9
[0m09:34:52.812112 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/project_root/dbt', 'fail_fast': 'False', 'version_check': 'True', 'log_path': '/opt/airflow/project_root/dbt/logs', 'debug': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run --project-dir /opt/airflow/project_root/dbt --profiles-dir /opt/airflow/project_root/dbt --select gold', 'log_format': 'default', 'static_parser': 'True', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m09:34:52.835629 [error] [MainThread]: Encountered an error:
Runtime Error
  Credentials in profile "movie_clickhouse", target "dev" invalid: Runtime Error
        schema: default 
        database: gold 
        cluster: None 
    On Clickhouse, database must be omitted or have the same value as schema.
[0m09:34:52.836184 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 0.047615334, "process_in_blocks": "60480", "process_kernel_time": 0.175248, "process_mem_max_rss": "189776", "process_out_blocks": "3", "process_user_time": 0.671447}
[0m09:34:52.836477 [debug] [MainThread]: Command `dbt run` failed at 09:34:52.836421 after 0.05 seconds
[0m09:34:52.836723 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa740f5d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa73de310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffac1a1f10>]}
[0m09:34:52.836951 [debug] [MainThread]: Flushing usage events
[0m09:39:32.143381 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb23dd590>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb23cf010>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb23dd390>]}


============================== 09:39:32.147153 | ff316d60-04cc-45fb-b82c-a332f9535401 ==============================
[0m09:39:32.147153 [info ] [MainThread]: Running with dbt=1.8.9
[0m09:39:32.147528 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'profiles_dir': '/opt/airflow/project_root/dbt', 'log_path': '/opt/airflow/project_root/dbt/logs', 'debug': 'False', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'static_parser': 'True', 'log_format': 'default', 'target_path': 'None', 'invocation_command': 'dbt run --project-dir /opt/airflow/project_root/dbt --profiles-dir /opt/airflow/project_root/dbt --select gold', 'send_anonymous_usage_stats': 'True'}
[0m09:39:32.270655 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'ff316d60-04cc-45fb-b82c-a332f9535401', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb241d710>]}
[0m09:39:32.289486 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'ff316d60-04cc-45fb-b82c-a332f9535401', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb2e0b210>]}
[0m09:39:32.289937 [info ] [MainThread]: Registered adapter: clickhouse=1.8.9
[0m09:39:32.325668 [debug] [MainThread]: checksum: 132857a23e9d07220246854f7763165174ce9b737cfc7867629ace4294e520b1, vars: {}, profile: , target: , version: 1.8.9
[0m09:39:32.326181 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m09:39:32.326430 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'ff316d60-04cc-45fb-b82c-a332f9535401', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb22ef950>]}
[0m09:39:32.815529 [warn ] [MainThread]: [[33mWARNING[0m]: Deprecated functionality
The `tests` config has been renamed to `data_tests`. Please see
https://docs.getdbt.com/docs/build/data-tests#new-data_tests-syntax for more
information.
[0m09:39:32.815935 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'deprecation', 'label': 'ff316d60-04cc-45fb-b82c-a332f9535401', 'property_': 'warn', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb1f816d0>]}
[0m09:39:32.901383 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.movie_warehouse.bronze
[0m09:39:32.905863 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'ff316d60-04cc-45fb-b82c-a332f9535401', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb4321550>]}
[0m09:39:32.965963 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'ff316d60-04cc-45fb-b82c-a332f9535401', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb0cc3f90>]}
[0m09:39:32.966286 [info ] [MainThread]: Found 6 models, 12 data tests, 4 sources, 476 macros
[0m09:39:32.966501 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'ff316d60-04cc-45fb-b82c-a332f9535401', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb1eb9f10>]}
[0m09:39:32.967306 [info ] [MainThread]: 
[0m09:39:32.967616 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m09:39:32.970149 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m09:39:32.974888 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m09:39:33.246747 [info ] [ThreadPool]: dbt_clickhouse adapter: Unexpected server exception dropping table
[0m09:39:33.247255 [debug] [ThreadPool]: dbt_clickhouse adapter: Error running SQL: macro list_schemas
[0m09:39:33.247840 [debug] [MainThread]: Connection 'master' was properly closed.
[0m09:39:33.248071 [debug] [MainThread]: Connection 'list_' was left open.
[0m09:39:33.248269 [debug] [MainThread]: On list_: No close available on handle
[0m09:39:33.248485 [info ] [MainThread]: 
[0m09:39:33.248695 [info ] [MainThread]: Finished running  in 0 hours 0 minutes and 0.28 seconds (0.28s).
[0m09:39:33.248992 [error] [MainThread]: Encountered an error:
Database Error
  'NoneType' object has no attribute 'version_major'
[0m09:39:33.249578 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 1.1255822, "process_in_blocks": "66680", "process_kernel_time": 0.38984, "process_mem_max_rss": "183188", "process_out_blocks": "2242", "process_user_time": 1.465401}
[0m09:39:33.250003 [debug] [MainThread]: Command `dbt run` failed at 09:39:33.249952 after 1.13 seconds
[0m09:39:33.250253 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb243bad0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb243ba50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb243bc10>]}
[0m09:39:33.250498 [debug] [MainThread]: Flushing usage events
[0m09:42:06.176026 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb73ecf50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb73ed250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb73ec890>]}


============================== 09:42:06.179956 | 98f49b0c-4a54-4d95-b914-360679a780ad ==============================
[0m09:42:06.179956 [info ] [MainThread]: Running with dbt=1.8.9
[0m09:42:06.180266 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'debug': 'False', 'log_path': '/opt/airflow/project_root/dbt/logs', 'fail_fast': 'False', 'profiles_dir': '/opt/airflow/project_root/dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'invocation_command': 'dbt run --project-dir /opt/airflow/project_root/dbt --profiles-dir /opt/airflow/project_root/dbt --select gold', 'static_parser': 'True', 'introspect': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m09:42:06.287000 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '98f49b0c-4a54-4d95-b914-360679a780ad', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb742d710>]}
[0m09:42:06.305376 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '98f49b0c-4a54-4d95-b914-360679a780ad', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb7e1b350>]}
[0m09:42:06.305832 [info ] [MainThread]: Registered adapter: clickhouse=1.8.9
[0m09:42:06.338993 [debug] [MainThread]: checksum: 132857a23e9d07220246854f7763165174ce9b737cfc7867629ace4294e520b1, vars: {}, profile: , target: , version: 1.8.9
[0m09:42:06.376694 [info ] [MainThread]: Unable to do partial parsing because profile has changed
[0m09:42:06.377021 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '98f49b0c-4a54-4d95-b914-360679a780ad', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb888d490>]}
[0m09:42:06.807920 [warn ] [MainThread]: [[33mWARNING[0m]: Deprecated functionality
The `tests` config has been renamed to `data_tests`. Please see
https://docs.getdbt.com/docs/build/data-tests#new-data_tests-syntax for more
information.
[0m09:42:06.808341 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'deprecation', 'label': '98f49b0c-4a54-4d95-b914-360679a780ad', 'property_': 'warn', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb72eafd0>]}
[0m09:42:06.890194 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.movie_warehouse.bronze
[0m09:42:06.894848 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '98f49b0c-4a54-4d95-b914-360679a780ad', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb5e80790>]}
[0m09:42:06.946090 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '98f49b0c-4a54-4d95-b914-360679a780ad', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb5ddbf90>]}
[0m09:42:06.946570 [info ] [MainThread]: Found 6 models, 12 data tests, 4 sources, 476 macros
[0m09:42:06.946905 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '98f49b0c-4a54-4d95-b914-360679a780ad', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb5f47350>]}
[0m09:42:06.948150 [info ] [MainThread]: 
[0m09:42:06.948508 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m09:42:06.951762 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m09:42:06.957586 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m09:42:07.271484 [debug] [ThreadPool]: dbt_clickhouse adapter: Error running SQL: macro list_schemas
[0m09:42:07.272013 [debug] [MainThread]: Connection 'master' was properly closed.
[0m09:42:07.272192 [debug] [MainThread]: Connection 'list_' was left open.
[0m09:42:07.272341 [debug] [MainThread]: On list_: No close available on handle
[0m09:42:07.272498 [info ] [MainThread]: 
[0m09:42:07.272689 [info ] [MainThread]: Finished running  in 0 hours 0 minutes and 0.32 seconds (0.32s).
[0m09:42:07.272939 [error] [MainThread]: Encountered an error:
Database Error
  :HTTPDriver for http://clickhouse-server:8123 returned response code 403)
   Code: 516. DB::Exception: analytics: Authentication failed: password is incorrect, or there is no user with such name. (AUTHENTICATION_FAILED) (version 25.9.3.48 (official build))
  
[0m09:42:07.273633 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 1.1186991, "process_in_blocks": "103032", "process_kernel_time": 0.28332, "process_mem_max_rss": "185896", "process_out_blocks": "2226", "process_user_time": 2.058453}
[0m09:42:07.273875 [debug] [MainThread]: Command `dbt run` failed at 09:42:07.273839 after 1.12 seconds
[0m09:42:07.274108 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb73ec890>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb73ee490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffbc1b1f10>]}
[0m09:42:07.274349 [debug] [MainThread]: Flushing usage events
[0m09:46:28.518604 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff920bc6d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff920bd8d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff920bcd10>]}


============================== 09:46:28.524386 | 03907e85-5ecc-4ce4-8110-5368d1efcc03 ==============================
[0m09:46:28.524386 [info ] [MainThread]: Running with dbt=1.8.9
[0m09:46:28.526750 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/project_root/dbt', 'fail_fast': 'False', 'debug': 'False', 'log_path': '/opt/airflow/project_root/dbt/logs', 'version_check': 'True', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'static_parser': 'True', 'introspect': 'True', 'invocation_command': 'dbt run --project-dir /opt/airflow/project_root/dbt --profiles-dir /opt/airflow/project_root/dbt --select gold', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m09:46:28.657367 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '03907e85-5ecc-4ce4-8110-5368d1efcc03', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff920ec9d0>]}
[0m09:46:28.677438 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '03907e85-5ecc-4ce4-8110-5368d1efcc03', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff92aeb390>]}
[0m09:46:28.678076 [info ] [MainThread]: Registered adapter: clickhouse=1.8.9
[0m09:46:28.718394 [debug] [MainThread]: checksum: 132857a23e9d07220246854f7763165174ce9b737cfc7867629ace4294e520b1, vars: {}, profile: , target: , version: 1.8.9
[0m09:46:28.768318 [info ] [MainThread]: Unable to do partial parsing because profile has changed
[0m09:46:28.768741 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '03907e85-5ecc-4ce4-8110-5368d1efcc03', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff935c2310>]}
[0m09:46:29.264069 [warn ] [MainThread]: [[33mWARNING[0m]: Deprecated functionality
The `tests` config has been renamed to `data_tests`. Please see
https://docs.getdbt.com/docs/build/data-tests#new-data_tests-syntax for more
information.
[0m09:46:29.264462 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'deprecation', 'label': '03907e85-5ecc-4ce4-8110-5368d1efcc03', 'property_': 'warn', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff91c69010>]}
[0m09:46:29.350182 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.movie_warehouse.bronze
[0m09:46:29.354935 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '03907e85-5ecc-4ce4-8110-5368d1efcc03', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff91dfce10>]}
[0m09:46:29.409060 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '03907e85-5ecc-4ce4-8110-5368d1efcc03', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff90aabd90>]}
[0m09:46:29.409404 [info ] [MainThread]: Found 6 models, 12 data tests, 4 sources, 476 macros
[0m09:46:29.409620 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '03907e85-5ecc-4ce4-8110-5368d1efcc03', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff91fe1e50>]}
[0m09:46:29.410444 [info ] [MainThread]: 
[0m09:46:29.410748 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m09:46:29.413577 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m09:46:29.418538 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m09:46:29.648359 [info ] [ThreadPool]: dbt_clickhouse adapter: Unexpected server exception dropping table
[0m09:46:29.648979 [debug] [ThreadPool]: dbt_clickhouse adapter: Error running SQL: macro list_schemas
[0m09:46:29.649587 [debug] [MainThread]: Connection 'master' was properly closed.
[0m09:46:29.649817 [debug] [MainThread]: Connection 'list_' was left open.
[0m09:46:29.650063 [debug] [MainThread]: On list_: No close available on handle
[0m09:46:29.650327 [info ] [MainThread]: 
[0m09:46:29.650574 [info ] [MainThread]: Finished running  in 0 hours 0 minutes and 0.24 seconds (0.24s).
[0m09:46:29.650913 [error] [MainThread]: Encountered an error:
Database Error
  'NoneType' object has no attribute 'version_major'
[0m09:46:29.651592 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 1.1613808, "process_in_blocks": "74272", "process_kernel_time": 0.32967, "process_mem_max_rss": "181028", "process_out_blocks": "2225", "process_user_time": 1.520482}
[0m09:46:29.651923 [debug] [MainThread]: Command `dbt run` failed at 09:46:29.651878 after 1.16 seconds
[0m09:46:29.652204 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff920ef5d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff920be250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff96fb9fd0>]}
[0m09:46:29.652467 [debug] [MainThread]: Flushing usage events
[0m09:57:09.963468 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb49bd250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb49e2550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb49ef890>]}


============================== 09:57:09.967751 | 175660b8-b15b-4979-8637-3ff25637a58f ==============================
[0m09:57:09.967751 [info ] [MainThread]: Running with dbt=1.8.9
[0m09:57:09.968069 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'fail_fast': 'False', 'log_path': '/opt/airflow/project_root/dbt/logs', 'version_check': 'True', 'profiles_dir': '/opt/airflow/project_root/dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'invocation_command': 'dbt run --project-dir /opt/airflow/project_root/dbt --profiles-dir /opt/airflow/project_root/dbt --select gold', 'introspect': 'True', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m09:57:10.084392 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '175660b8-b15b-4979-8637-3ff25637a58f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb4a4b0d0>]}
[0m09:57:10.105095 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '175660b8-b15b-4979-8637-3ff25637a58f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb5ebeb10>]}
[0m09:57:10.105556 [info ] [MainThread]: Registered adapter: clickhouse=1.8.9
[0m09:57:10.143113 [debug] [MainThread]: checksum: 132857a23e9d07220246854f7763165174ce9b737cfc7867629ace4294e520b1, vars: {}, profile: , target: , version: 1.8.9
[0m09:57:10.184162 [info ] [MainThread]: Unable to do partial parsing because profile has changed
[0m09:57:10.184586 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '175660b8-b15b-4979-8637-3ff25637a58f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb5ec2590>]}
[0m09:57:10.631352 [warn ] [MainThread]: [[33mWARNING[0m]: Deprecated functionality
The `tests` config has been renamed to `data_tests`. Please see
https://docs.getdbt.com/docs/build/data-tests#new-data_tests-syntax for more
information.
[0m09:57:10.631790 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'deprecation', 'label': '175660b8-b15b-4979-8637-3ff25637a58f', 'property_': 'warn', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb45fe910>]}
[0m09:57:10.713592 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.movie_warehouse.bronze
[0m09:57:10.718356 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '175660b8-b15b-4979-8637-3ff25637a58f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb337eb50>]}
[0m09:57:10.768535 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '175660b8-b15b-4979-8637-3ff25637a58f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb31aa690>]}
[0m09:57:10.768872 [info ] [MainThread]: Found 6 models, 12 data tests, 4 sources, 476 macros
[0m09:57:10.769107 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '175660b8-b15b-4979-8637-3ff25637a58f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb3119510>]}
[0m09:57:10.769938 [info ] [MainThread]: 
[0m09:57:10.770241 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m09:57:10.772925 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m09:57:10.777405 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m09:57:10.927375 [debug] [ThreadPool]: dbt_clickhouse adapter: Error running SQL: macro list_schemas
[0m09:57:10.928066 [debug] [MainThread]: Connection 'master' was properly closed.
[0m09:57:10.928306 [debug] [MainThread]: Connection 'list_' was left open.
[0m09:57:10.928486 [debug] [MainThread]: On list_: No close available on handle
[0m09:57:10.928673 [info ] [MainThread]: 
[0m09:57:10.928896 [info ] [MainThread]: Finished running  in 0 hours 0 minutes and 0.16 seconds (0.16s).
[0m09:57:10.929187 [error] [MainThread]: Encountered an error:
Database Error
  Code: 102. Unexpected packet from server clickhouse-server:8123 (expected Hello or Exception, got Unknown packet)
[0m09:57:10.929799 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 0.9858153, "process_in_blocks": "59728", "process_kernel_time": 0.250569, "process_mem_max_rss": "180176", "process_out_blocks": "2225", "process_user_time": 1.411573}
[0m09:57:10.930165 [debug] [MainThread]: Command `dbt run` failed at 09:57:10.930114 after 0.99 seconds
[0m09:57:10.930430 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb4a1bc10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb4a1b910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb33c4690>]}
[0m09:57:10.930691 [debug] [MainThread]: Flushing usage events
[0m10:00:44.192565 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8e5cdb50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8e5cd8d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8e5ccbd0>]}


============================== 10:00:44.196642 | 0edc0b7d-6bb0-4722-a4ac-90a3b95461b2 ==============================
[0m10:00:44.196642 [info ] [MainThread]: Running with dbt=1.8.9
[0m10:00:44.197075 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'version_check': 'True', 'log_path': '/opt/airflow/project_root/dbt/logs', 'debug': 'False', 'profiles_dir': '/opt/airflow/project_root/dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run --project-dir /opt/airflow/project_root/dbt --profiles-dir /opt/airflow/project_root/dbt --select gold', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m10:00:44.317576 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '0edc0b7d-6bb0-4722-a4ac-90a3b95461b2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8e4f0f50>]}
[0m10:00:44.342217 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '0edc0b7d-6bb0-4722-a4ac-90a3b95461b2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8effb450>]}
[0m10:00:44.342963 [info ] [MainThread]: Registered adapter: clickhouse=1.8.9
[0m10:00:44.381781 [debug] [MainThread]: checksum: 132857a23e9d07220246854f7763165174ce9b737cfc7867629ace4294e520b1, vars: {}, profile: , target: , version: 1.8.9
[0m10:00:44.425302 [info ] [MainThread]: Unable to do partial parsing because profile has changed
[0m10:00:44.425986 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '0edc0b7d-6bb0-4722-a4ac-90a3b95461b2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8fa6d610>]}
[0m10:00:44.915659 [warn ] [MainThread]: [[33mWARNING[0m]: Deprecated functionality
The `tests` config has been renamed to `data_tests`. Please see
https://docs.getdbt.com/docs/build/data-tests#new-data_tests-syntax for more
information.
[0m10:00:44.916163 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'deprecation', 'label': '0edc0b7d-6bb0-4722-a4ac-90a3b95461b2', 'property_': 'warn', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8e2f1a10>]}
[0m10:00:45.003756 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.movie_warehouse.bronze
[0m10:00:45.009636 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '0edc0b7d-6bb0-4722-a4ac-90a3b95461b2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8cff8890>]}
[0m10:00:45.070602 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '0edc0b7d-6bb0-4722-a4ac-90a3b95461b2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8cfa8b90>]}
[0m10:00:45.071027 [info ] [MainThread]: Found 6 models, 12 data tests, 4 sources, 476 macros
[0m10:00:45.071431 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '0edc0b7d-6bb0-4722-a4ac-90a3b95461b2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8e1a9950>]}
[0m10:00:45.072683 [info ] [MainThread]: 
[0m10:00:45.073371 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m10:00:45.077169 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m10:00:45.085454 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:00:45.580396 [info ] [ThreadPool]: dbt_clickhouse adapter: Unexpected server exception dropping table
[0m10:00:45.581182 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m10:00:45.583681 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m10:00:45.609034 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now create__gold_gold)
[0m10:00:45.609648 [debug] [ThreadPool]: Creating schema "schema: "gold_gold"
"
[0m10:00:45.613256 [debug] [ThreadPool]: dbt_clickhouse adapter: On create__gold_gold: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "connection_name": "create__gold_gold"} */
create database if not exists `gold_gold`
        
  
        
  ...
[0m10:00:45.618903 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m10:00:45.621093 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create__gold_gold, now list__gold_gold)
[0m10:00:45.624803 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__gold_gold: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "connection_name": "list__gold_gold"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'gold_gold'
      

  ...
[0m10:00:45.663724 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.04 seconds
[0m10:00:45.665393 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '0edc0b7d-6bb0-4722-a4ac-90a3b95461b2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8cff83d0>]}
[0m10:00:45.665886 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m10:00:45.666212 [info ] [MainThread]: 
[0m10:00:45.672511 [debug] [Thread-1 (]: Began running node model.movie_warehouse.dim_director
[0m10:00:45.673100 [info ] [Thread-1 (]: 1 of 6 START sql table model `gold_gold`.`dim_director` ........................ [RUN]
[0m10:00:45.673500 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list__gold_gold, now model.movie_warehouse.dim_director)
[0m10:00:45.673754 [debug] [Thread-1 (]: Began compiling node model.movie_warehouse.dim_director
[0m10:00:45.679460 [debug] [Thread-1 (]: Writing injected SQL for node "model.movie_warehouse.dim_director"
[0m10:00:45.681528 [debug] [Thread-1 (]: Began executing node model.movie_warehouse.dim_director
[0m10:00:45.690949 [debug] [Thread-1 (]: Creating new relation dim_director
[0m10:00:45.703240 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_director: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_director"} */

            

    
        create table `gold_gold`.`dim_director`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

WITH first_dir AS (
    SELECT
        tconst,
        TRIM(splitByChar(',', directors)[1]) AS director_id
    FROM imdb_title_crew_raw
    WHERE directors IS NOT NULL AND directors != ''
),
deduped AS (
    SELECT DISTINCT director_id
    FROM first_dir
),
joined AS (
    SELECT
        d.director_id AS dir_id,
        n.primaryName AS dir_name
    FROM deduped d
    LEFT JOIN imdb_name_basics_raw n
        ON d.director_id = n.nconst
)
SELECT
    row_number() OVER (ORDER BY dir_id) AS imdb_dir_name_id,
    dir_id,
    dir_name,
    current_date() AS valid_from,
    NULL AS valid_to,
    TRUE AS is_current
FROM joined
WHERE dir_id IS NOT NULL;
          )
        
        ...
[0m10:00:45.710586 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_director"} */

            

    
        create table `gold_gold`.`dim_director`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

WITH first_dir AS (
    SELECT
        tconst,
        TRIM(splitByChar(',', directors)[1]) AS director_id
    FROM imdb_title_crew_raw
    WHERE directors IS NOT NULL AND directors != ''
),
deduped AS (
    SELECT DISTINCT director_id
    FROM first_dir
),
joined AS (
    SELECT
        d.director_id AS dir_id,
        n.primaryName AS dir_name
    FROM deduped d
    LEFT JOIN imdb_name_basics_raw n
        ON d.director_id = n.nconst
)
SELECT
    row_number() OVER (ORDER BY dir_id) AS imdb_dir_name_id,
    dir_id,
    dir_name,
    current_date() AS valid_from,
    NULL AS valid_to,
    TRUE AS is_current
FROM joined
WHERE dir_id IS NOT NULL;
          )
        
        
[0m10:00:45.715873 [debug] [Thread-1 (]: Database Error in model dim_director (models/gold/dim_director.sql)
  :HTTPDriver for http://clickhouse-server:8123 returned response code 400)
   Code: 62. DB::Exception: Syntax error: failed at position 1153 (end of query) (line 52, col 25): ;
            )
          
          . Expected one of: OR, AND, IS NOT DISTINCT FROM, IS NULL, IS NOT NULL, BETWEEN, NOT BETWEEN, LIKE, ILIKE, NOT LIKE, NOT ILIKE, REGEXP, IN, NOT IN, GLOBAL IN, GLOBAL NOT IN, MOD, DIV, alias, AS, GROUP BY, WITH, HAVING, WINDOW, QUALIFY, ORDER BY, LIMIT, OFFSET, FETCH, SETTINGS, UNION, EXCEPT, INTERSECT. (SYNTAX_ERROR) (version 25.9.3.48 (official build))
[0m10:00:45.716946 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0edc0b7d-6bb0-4722-a4ac-90a3b95461b2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff49bcb9d0>]}
[0m10:00:45.717370 [error] [Thread-1 (]: 1 of 6 ERROR creating sql table model `gold_gold`.`dim_director` ............... [[31mERROR[0m in 0.04s]
[0m10:00:45.717706 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.dim_director
[0m10:00:45.717934 [debug] [Thread-1 (]: Began running node model.movie_warehouse.dim_genre
[0m10:00:45.718581 [info ] [Thread-1 (]: 2 of 6 START sql table model `gold_gold`.`dim_genre` ........................... [RUN]
[0m10:00:45.718842 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.movie_warehouse.dim_director, now model.movie_warehouse.dim_genre)
[0m10:00:45.719039 [debug] [Thread-1 (]: Began compiling node model.movie_warehouse.dim_genre
[0m10:00:45.720600 [debug] [Thread-1 (]: Writing injected SQL for node "model.movie_warehouse.dim_genre"
[0m10:00:45.721176 [debug] [Thread-1 (]: Began executing node model.movie_warehouse.dim_genre
[0m10:00:45.724244 [debug] [Thread-1 (]: Creating new relation dim_genre
[0m10:00:45.725453 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_genre: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_genre"} */

            

    
        create table `gold_gold`.`dim_genre`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

SELECT
  ROW_NUMBER() OVER (ORDER BY first_genre) AS genre_id,
  first_genre AS genre_name
FROM (
  SELECT
    TRIM(SPLIT(genres, ',')[0]) AS first_genre
  FROM `bronze`.`tmdb_raw`
  WHERE genres IS NOT NULL
)
GROUP BY first_genre;
          )
        
        ...
[0m10:00:45.728224 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_genre"} */

            

    
        create table `gold_gold`.`dim_genre`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

SELECT
  ROW_NUMBER() OVER (ORDER BY first_genre) AS genre_id,
  first_genre AS genre_name
FROM (
  SELECT
    TRIM(SPLIT(genres, ',')[0]) AS first_genre
  FROM `bronze`.`tmdb_raw`
  WHERE genres IS NOT NULL
)
GROUP BY first_genre;
          )
        
        
[0m10:00:45.730597 [debug] [Thread-1 (]: Database Error in model dim_genre (models/gold/dim_genre.sql)
  :HTTPDriver for http://clickhouse-server:8123 returned response code 400)
   Code: 62. DB::Exception: Syntax error: failed at position 726 (end of query) (line 34, col 21): ;
            )
          
          . Expected one of: token sequence, Dot, token, OR, AND, IS NOT DISTINCT FROM, IS NULL, IS NOT NULL, BETWEEN, NOT BETWEEN, LIKE, ILIKE, NOT LIKE, NOT ILIKE, REGEXP, IN, NOT IN, GLOBAL IN, GLOBAL NOT IN, MOD, DIV, alias, AS, Comma, WITH, HAVING, WINDOW, QUALIFY, ORDER BY, LIMIT, OFFSET, FETCH, SETTINGS, UNION, EXCEPT, INTERSECT. (SYNTAX_ERROR) (version 25.9.3.48 (official build))
[0m10:00:45.731072 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0edc0b7d-6bb0-4722-a4ac-90a3b95461b2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff49c98650>]}
[0m10:00:45.731436 [error] [Thread-1 (]: 2 of 6 ERROR creating sql table model `gold_gold`.`dim_genre` .................. [[31mERROR[0m in 0.01s]
[0m10:00:45.731789 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.dim_genre
[0m10:00:45.732054 [debug] [Thread-1 (]: Began running node model.movie_warehouse.dim_movie
[0m10:00:45.732546 [info ] [Thread-1 (]: 3 of 6 START sql table model `gold_gold`.`dim_movie` ........................... [RUN]
[0m10:00:45.733012 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.movie_warehouse.dim_genre, now model.movie_warehouse.dim_movie)
[0m10:00:45.733281 [debug] [Thread-1 (]: Began compiling node model.movie_warehouse.dim_movie
[0m10:00:45.734924 [debug] [Thread-1 (]: Writing injected SQL for node "model.movie_warehouse.dim_movie"
[0m10:00:45.735485 [debug] [Thread-1 (]: Began executing node model.movie_warehouse.dim_movie
[0m10:00:45.736548 [debug] [Thread-1 (]: Creating new relation dim_movie
[0m10:00:45.737188 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_movie: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_movie"} */

            

    
        create table `gold_gold`.`dim_movie`
        
  
        
  engine = MergeTree()
        order by (movie_id)
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

SELECT
    row_number() OVER (ORDER BY title) AS movie_id,
    imdb_id,
    title AS movie_title,
    release_date,
    runtime AS movie_runtime,
    original_language AS language
FROM `bronze`.`tmdb_raw`
WHERE title IS NOT NULL;
          )
        
        ...
[0m10:00:45.739759 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_movie"} */

            

    
        create table `gold_gold`.`dim_movie`
        
  
        
  engine = MergeTree()
        order by (movie_id)
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

SELECT
    row_number() OVER (ORDER BY title) AS movie_id,
    imdb_id,
    title AS movie_title,
    release_date,
    runtime AS movie_runtime,
    original_language AS language
FROM `bronze`.`tmdb_raw`
WHERE title IS NOT NULL;
          )
        
        
[0m10:00:45.742213 [debug] [Thread-1 (]: Database Error in model dim_movie (models/gold/dim_movie.sql)
  :HTTPDriver for http://clickhouse-server:8123 returned response code 400)
   Code: 62. DB::Exception: Syntax error: failed at position 718 (end of query) (line 32, col 24): ;
            )
          
          . Expected one of: OR, AND, IS NOT DISTINCT FROM, IS NULL, IS NOT NULL, BETWEEN, NOT BETWEEN, LIKE, ILIKE, NOT LIKE, NOT ILIKE, REGEXP, IN, NOT IN, GLOBAL IN, GLOBAL NOT IN, MOD, DIV, alias, AS, GROUP BY, WITH, HAVING, WINDOW, QUALIFY, ORDER BY, LIMIT, OFFSET, FETCH, SETTINGS, UNION, EXCEPT, INTERSECT. (SYNTAX_ERROR) (version 25.9.3.48 (official build))
[0m10:00:45.742552 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0edc0b7d-6bb0-4722-a4ac-90a3b95461b2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8e1aac50>]}
[0m10:00:45.743000 [error] [Thread-1 (]: 3 of 6 ERROR creating sql table model `gold_gold`.`dim_movie` .................. [[31mERROR[0m in 0.01s]
[0m10:00:45.743391 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.dim_movie
[0m10:00:45.743625 [debug] [Thread-1 (]: Began running node model.movie_warehouse.dim_production
[0m10:00:45.743937 [info ] [Thread-1 (]: 4 of 6 START sql table model `gold_gold`.`dim_production` ...................... [RUN]
[0m10:00:45.744199 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.movie_warehouse.dim_movie, now model.movie_warehouse.dim_production)
[0m10:00:45.744397 [debug] [Thread-1 (]: Began compiling node model.movie_warehouse.dim_production
[0m10:00:45.745922 [debug] [Thread-1 (]: Writing injected SQL for node "model.movie_warehouse.dim_production"
[0m10:00:45.746633 [debug] [Thread-1 (]: Began executing node model.movie_warehouse.dim_production
[0m10:00:45.748286 [debug] [Thread-1 (]: Creating new relation dim_production
[0m10:00:45.749013 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_production: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_production"} */

            

    
        create table `gold_gold`.`dim_production`
        
  
        
  engine = MergeTree()
        order by (production_id)
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

WITH first_production AS (
    SELECT
        id AS movie_id,
        trim(splitByChar(',', production_companies)[1]) AS production_name
    FROM `bronze`.`tmdb_raw`
    WHERE production_companies IS NOT NULL AND production_companies != ''
)

SELECT
    row_number() OVER (ORDER BY production_name) AS production_id,
    production_name,
    current_date() AS valid_from,
    NULL AS valid_to,
    TRUE AS is_current
FROM (
    SELECT DISTINCT production_name
    FROM first_production
)
WHERE production_name IS NOT NULL;
          )
        
        ...
[0m10:00:45.751601 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_production"} */

            

    
        create table `gold_gold`.`dim_production`
        
  
        
  engine = MergeTree()
        order by (production_id)
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

WITH first_production AS (
    SELECT
        id AS movie_id,
        trim(splitByChar(',', production_companies)[1]) AS production_name
    FROM `bronze`.`tmdb_raw`
    WHERE production_companies IS NOT NULL AND production_companies != ''
)

SELECT
    row_number() OVER (ORDER BY production_name) AS production_id,
    production_name,
    current_date() AS valid_from,
    NULL AS valid_to,
    TRUE AS is_current
FROM (
    SELECT DISTINCT production_name
    FROM first_production
)
WHERE production_name IS NOT NULL;
          )
        
        
[0m10:00:45.754848 [debug] [Thread-1 (]: Database Error in model dim_production (models/gold/dim_production.sql)
  :HTTPDriver for http://clickhouse-server:8123 returned response code 400)
   Code: 62. DB::Exception: Syntax error: failed at position 1026 (end of query) (line 42, col 34): ;
            )
          
          . Expected one of: OR, AND, IS NOT DISTINCT FROM, IS NULL, IS NOT NULL, BETWEEN, NOT BETWEEN, LIKE, ILIKE, NOT LIKE, NOT ILIKE, REGEXP, IN, NOT IN, GLOBAL IN, GLOBAL NOT IN, MOD, DIV, alias, AS, GROUP BY, WITH, HAVING, WINDOW, QUALIFY, ORDER BY, LIMIT, OFFSET, FETCH, SETTINGS, UNION, EXCEPT, INTERSECT. (SYNTAX_ERROR) (version 25.9.3.48 (official build))
[0m10:00:45.755511 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0edc0b7d-6bb0-4722-a4ac-90a3b95461b2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff5039e450>]}
[0m10:00:45.756634 [error] [Thread-1 (]: 4 of 6 ERROR creating sql table model `gold_gold`.`dim_production` ............. [[31mERROR[0m in 0.01s]
[0m10:00:45.757256 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.dim_production
[0m10:00:45.757501 [debug] [Thread-1 (]: Began running node model.movie_warehouse.dim_release_date
[0m10:00:45.757886 [info ] [Thread-1 (]: 5 of 6 START sql table model `gold_gold`.`dim_release_date` .................... [RUN]
[0m10:00:45.758203 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.movie_warehouse.dim_production, now model.movie_warehouse.dim_release_date)
[0m10:00:45.758454 [debug] [Thread-1 (]: Began compiling node model.movie_warehouse.dim_release_date
[0m10:00:45.760311 [debug] [Thread-1 (]: Writing injected SQL for node "model.movie_warehouse.dim_release_date"
[0m10:00:45.761027 [debug] [Thread-1 (]: Began executing node model.movie_warehouse.dim_release_date
[0m10:00:45.762125 [debug] [Thread-1 (]: Creating new relation dim_release_date
[0m10:00:45.762803 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_release_date: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_release_date"} */

            

    
        create table `gold_gold`.`dim_release_date`
        
  
        
  engine = MergeTree()
        order by (date_id)
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

WITH distinct_dates AS (
    SELECT DISTINCT release_date
    FROM `bronze`.`tmdb_raw`
    WHERE release_date IS NOT NULL
)

SELECT
    row_number() OVER (ORDER BY release_date)                   AS date_id,
    release_date                                                AS full_date,
    toYear(release_date)                                        AS year,
    toMonth(release_date)                                       AS month,
    toDayOfMonth(release_date)                                  AS day,
    toISOWeek(release_date)                                     AS week,
    formatDateTime(release_date, '%A')                          AS weekday,
    CASE
        WHEN toMonth(release_date) IN (12,1,2)  THEN 'Winter'
        WHEN toMonth(release_date) IN (3,4,5)   THEN 'Spring'
        WHEN toMonth(release_date) IN (6,7,8)   THEN 'Summer'
        WHEN toMonth(release_date) IN (9,10,11) THEN 'Autumn'
    END                                                         AS season,
    CASE
        WHEN formatDateTime(release_date, '%A') IN ('Saturday','Sunday') THEN 1
        ELSE 0
    END                                                         AS is_weekend,

    /* ---------- holiday tagging ---------- */
    CASE
        WHEN toMonth(release_date)=1  AND toDayOfMonth(release_date)=1  THEN 'New Year\'s Day'
        WHEN toMonth(release_date)=2  AND toDayOfMonth(release_date)=14 THEN 'Valentine\'s Day'
        WHEN toMonth(release_date)=3  AND toDayOfMonth(release_date)=17 THEN 'St. Patrick\'s Day'
        WHEN toMonth(release_date)=4  AND toDayOfMonth(release_date)=1  THEN 'April Fool\'s Day'
        WHEN toMonth(release_date)=4  AND toDayOfMonth(release_date)=22 THEN 'Earth Day'
        WHEN toMonth(release_date)=5  AND toDayOfMonth(release_date)=1  THEN 'May Day'
        WHEN toMonth(release_date)=5  AND toDayOfMonth(release_date)=5  THEN 'Cinco de Mayo'
        WHEN toMonth(release_date)=6  AND toDayOfMonth(release_date) BETWEEN 19 AND 26 THEN 'Midsummer'
        WHEN toMonth(release_date)=7  AND toDayOfMonth(release_date)=4  THEN 'Independence Day'
        WHEN toMonth(release_date)=9  AND toDayOfMonth(release_date) BETWEEN 1 AND 7 
             AND formatDateTime(release_date,'%A')='Monday'             THEN 'Labor Day (US)'
        WHEN toMonth(release_date)=10 AND toDayOfMonth(release_date)=31 THEN 'Halloween'
        WHEN toMonth(release_date)=11 AND formatDateTime(release_date,'%A')='Thursday'
             AND toISOWeek(release_date) >= 47                           THEN 'Thanksgiving'
        WHEN toMonth(release_date)=12 AND toDayOfMonth(release_date)=24 THEN 'Christmas Eve'
        WHEN toMonth(release_date)=12 AND toDayOfMonth(release_date)=25 THEN 'Christmas Day'
        WHEN toMonth(release_date)=12 AND toDayOfMonth(release_date)=31 THEN 'New Year\'s Eve'
        ELSE NULL
    END                                                         AS holiday_name,
    IF(holiday_name IS NOT NULL, 1, 0)                          AS is_holiday,

    /* placeholders for later enhancement */
    NULL                                                        AS days_until_holiday,
    NULL                                                        AS days_after_holiday
FROM distinct_dates
ORDER BY release_date;
          )
        
        ...
[0m10:00:45.765891 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_release_date"} */

            

    
        create table `gold_gold`.`dim_release_date`
        
  
        
  engine = MergeTree()
        order by (date_id)
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

WITH distinct_dates AS (
    SELECT DISTINCT release_date
    FROM `bronze`.`tmdb_raw`
    WHERE release_date IS NOT NULL
)

SELECT
    row_number() OVER (ORDER BY release_date)                   AS date_id,
    release_date                                                AS full_date,
    toYear(release_date)                                        AS year,
    toMonth(release_date)                                       AS month,
    toDayOfMonth(release_date)                                  AS day,
    toISOWeek(release_date)                                     AS week,
    formatDateTime(release_date, '%A')                          AS weekday,
    CASE
        WHEN toMonth(release_date) IN (12,1,2)  THEN 'Winter'
        WHEN toMonth(release_date) IN (3,4,5)   THEN 'Spring'
        WHEN toMonth(release_date) IN (6,7,8)   THEN 'Summer'
        WHEN toMonth(release_date) IN (9,10,11) THEN 'Autumn'
    END                                                         AS season,
    CASE
        WHEN formatDateTime(release_date, '%A') IN ('Saturday','Sunday') THEN 1
        ELSE 0
    END                                                         AS is_weekend,

    /* ---------- holiday tagging ---------- */
    CASE
        WHEN toMonth(release_date)=1  AND toDayOfMonth(release_date)=1  THEN 'New Year\'s Day'
        WHEN toMonth(release_date)=2  AND toDayOfMonth(release_date)=14 THEN 'Valentine\'s Day'
        WHEN toMonth(release_date)=3  AND toDayOfMonth(release_date)=17 THEN 'St. Patrick\'s Day'
        WHEN toMonth(release_date)=4  AND toDayOfMonth(release_date)=1  THEN 'April Fool\'s Day'
        WHEN toMonth(release_date)=4  AND toDayOfMonth(release_date)=22 THEN 'Earth Day'
        WHEN toMonth(release_date)=5  AND toDayOfMonth(release_date)=1  THEN 'May Day'
        WHEN toMonth(release_date)=5  AND toDayOfMonth(release_date)=5  THEN 'Cinco de Mayo'
        WHEN toMonth(release_date)=6  AND toDayOfMonth(release_date) BETWEEN 19 AND 26 THEN 'Midsummer'
        WHEN toMonth(release_date)=7  AND toDayOfMonth(release_date)=4  THEN 'Independence Day'
        WHEN toMonth(release_date)=9  AND toDayOfMonth(release_date) BETWEEN 1 AND 7 
             AND formatDateTime(release_date,'%A')='Monday'             THEN 'Labor Day (US)'
        WHEN toMonth(release_date)=10 AND toDayOfMonth(release_date)=31 THEN 'Halloween'
        WHEN toMonth(release_date)=11 AND formatDateTime(release_date,'%A')='Thursday'
             AND toISOWeek(release_date) >= 47                           THEN 'Thanksgiving'
        WHEN toMonth(release_date)=12 AND toDayOfMonth(release_date)=24 THEN 'Christmas Eve'
        WHEN toMonth(release_date)=12 AND toDayOfMonth(release_date)=25 THEN 'Christmas Day'
        WHEN toMonth(release_date)=12 AND toDayOfMonth(release_date)=31 THEN 'New Year\'s Eve'
        ELSE NULL
    END                                                         AS holiday_name,
    IF(holiday_name IS NOT NULL, 1, 0)                          AS is_holiday,

    /* placeholders for later enhancement */
    NULL                                                        AS days_until_holiday,
    NULL                                                        AS days_after_holiday
FROM distinct_dates
ORDER BY release_date;
          )
        
        
[0m10:00:45.769094 [debug] [Thread-1 (]: Database Error in model dim_release_date (models/gold/dim_release_date.sql)
  :HTTPDriver for http://clickhouse-server:8123 returned response code 400)
   Code: 62. DB::Exception: Syntax error: failed at position 3753 (end of query) (line 76, col 22): ;
            )
          
          . Expected one of: token sequence, Dot, token, OR, AND, IS NOT DISTINCT FROM, IS NULL, IS NOT NULL, BETWEEN, NOT BETWEEN, LIKE, ILIKE, NOT LIKE, NOT ILIKE, REGEXP, IN, NOT IN, GLOBAL IN, GLOBAL NOT IN, MOD, DIV, alias, AS, DESCENDING, DESC, ASCENDING, ASC, NULLS, COLLATE, WITH FILL, Comma, LIMIT, OFFSET, FETCH, SETTINGS, UNION, EXCEPT, INTERSECT. (SYNTAX_ERROR) (version 25.9.3.48 (official build))
[0m10:00:45.769676 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0edc0b7d-6bb0-4722-a4ac-90a3b95461b2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff49c3ea10>]}
[0m10:00:45.770192 [error] [Thread-1 (]: 5 of 6 ERROR creating sql table model `gold_gold`.`dim_release_date` ........... [[31mERROR[0m in 0.01s]
[0m10:00:45.770677 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.dim_release_date
[0m10:00:45.772174 [debug] [Thread-1 (]: Began running node model.movie_warehouse.fact_movie
[0m10:00:45.772617 [info ] [Thread-1 (]: 6 of 6 SKIP relation gold_gold.fact_movie ...................................... [[33mSKIP[0m]
[0m10:00:45.772920 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.fact_movie
[0m10:00:45.773787 [debug] [MainThread]: Connection 'master' was properly closed.
[0m10:00:45.774018 [debug] [MainThread]: Connection 'model.movie_warehouse.dim_release_date' was left open.
[0m10:00:45.774216 [debug] [MainThread]: On model.movie_warehouse.dim_release_date: Close
[0m10:00:45.774628 [info ] [MainThread]: 
[0m10:00:45.774881 [info ] [MainThread]: Finished running 6 table models in 0 hours 0 minutes and 0.70 seconds (0.70s).
[0m10:00:45.775478 [debug] [MainThread]: Command end result
[0m10:00:45.797979 [info ] [MainThread]: 
[0m10:00:45.798273 [info ] [MainThread]: [31mCompleted with 5 errors and 0 warnings:[0m
[0m10:00:45.798476 [info ] [MainThread]: 
[0m10:00:45.798750 [error] [MainThread]:   Database Error in model dim_director (models/gold/dim_director.sql)
  :HTTPDriver for http://clickhouse-server:8123 returned response code 400)
   Code: 62. DB::Exception: Syntax error: failed at position 1153 (end of query) (line 52, col 25): ;
            )
          
          . Expected one of: OR, AND, IS NOT DISTINCT FROM, IS NULL, IS NOT NULL, BETWEEN, NOT BETWEEN, LIKE, ILIKE, NOT LIKE, NOT ILIKE, REGEXP, IN, NOT IN, GLOBAL IN, GLOBAL NOT IN, MOD, DIV, alias, AS, GROUP BY, WITH, HAVING, WINDOW, QUALIFY, ORDER BY, LIMIT, OFFSET, FETCH, SETTINGS, UNION, EXCEPT, INTERSECT. (SYNTAX_ERROR) (version 25.9.3.48 (official build))
[0m10:00:45.799016 [info ] [MainThread]: 
[0m10:00:45.799237 [error] [MainThread]:   Database Error in model dim_genre (models/gold/dim_genre.sql)
  :HTTPDriver for http://clickhouse-server:8123 returned response code 400)
   Code: 62. DB::Exception: Syntax error: failed at position 726 (end of query) (line 34, col 21): ;
            )
          
          . Expected one of: token sequence, Dot, token, OR, AND, IS NOT DISTINCT FROM, IS NULL, IS NOT NULL, BETWEEN, NOT BETWEEN, LIKE, ILIKE, NOT LIKE, NOT ILIKE, REGEXP, IN, NOT IN, GLOBAL IN, GLOBAL NOT IN, MOD, DIV, alias, AS, Comma, WITH, HAVING, WINDOW, QUALIFY, ORDER BY, LIMIT, OFFSET, FETCH, SETTINGS, UNION, EXCEPT, INTERSECT. (SYNTAX_ERROR) (version 25.9.3.48 (official build))
[0m10:00:45.799438 [info ] [MainThread]: 
[0m10:00:45.799656 [error] [MainThread]:   Database Error in model dim_movie (models/gold/dim_movie.sql)
  :HTTPDriver for http://clickhouse-server:8123 returned response code 400)
   Code: 62. DB::Exception: Syntax error: failed at position 718 (end of query) (line 32, col 24): ;
            )
          
          . Expected one of: OR, AND, IS NOT DISTINCT FROM, IS NULL, IS NOT NULL, BETWEEN, NOT BETWEEN, LIKE, ILIKE, NOT LIKE, NOT ILIKE, REGEXP, IN, NOT IN, GLOBAL IN, GLOBAL NOT IN, MOD, DIV, alias, AS, GROUP BY, WITH, HAVING, WINDOW, QUALIFY, ORDER BY, LIMIT, OFFSET, FETCH, SETTINGS, UNION, EXCEPT, INTERSECT. (SYNTAX_ERROR) (version 25.9.3.48 (official build))
[0m10:00:45.799840 [info ] [MainThread]: 
[0m10:00:45.800039 [error] [MainThread]:   Database Error in model dim_production (models/gold/dim_production.sql)
  :HTTPDriver for http://clickhouse-server:8123 returned response code 400)
   Code: 62. DB::Exception: Syntax error: failed at position 1026 (end of query) (line 42, col 34): ;
            )
          
          . Expected one of: OR, AND, IS NOT DISTINCT FROM, IS NULL, IS NOT NULL, BETWEEN, NOT BETWEEN, LIKE, ILIKE, NOT LIKE, NOT ILIKE, REGEXP, IN, NOT IN, GLOBAL IN, GLOBAL NOT IN, MOD, DIV, alias, AS, GROUP BY, WITH, HAVING, WINDOW, QUALIFY, ORDER BY, LIMIT, OFFSET, FETCH, SETTINGS, UNION, EXCEPT, INTERSECT. (SYNTAX_ERROR) (version 25.9.3.48 (official build))
[0m10:00:45.800246 [info ] [MainThread]: 
[0m10:00:45.800496 [error] [MainThread]:   Database Error in model dim_release_date (models/gold/dim_release_date.sql)
  :HTTPDriver for http://clickhouse-server:8123 returned response code 400)
   Code: 62. DB::Exception: Syntax error: failed at position 3753 (end of query) (line 76, col 22): ;
            )
          
          . Expected one of: token sequence, Dot, token, OR, AND, IS NOT DISTINCT FROM, IS NULL, IS NOT NULL, BETWEEN, NOT BETWEEN, LIKE, ILIKE, NOT LIKE, NOT ILIKE, REGEXP, IN, NOT IN, GLOBAL IN, GLOBAL NOT IN, MOD, DIV, alias, AS, DESCENDING, DESC, ASCENDING, ASC, NULLS, COLLATE, WITH FILL, Comma, LIMIT, OFFSET, FETCH, SETTINGS, UNION, EXCEPT, INTERSECT. (SYNTAX_ERROR) (version 25.9.3.48 (official build))
[0m10:00:45.800683 [info ] [MainThread]: 
[0m10:00:45.800879 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=5 SKIP=1 TOTAL=6
[0m10:00:45.801757 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 1.6314391, "process_in_blocks": "90512", "process_kernel_time": 0.302178, "process_mem_max_rss": "190116", "process_out_blocks": "3422", "process_user_time": 2.232316}
[0m10:00:45.802082 [debug] [MainThread]: Command `dbt run` failed at 10:00:45.802028 after 1.63 seconds
[0m10:00:45.802360 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8e5ff5d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8e62b510>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8e62b6d0>]}
[0m10:00:45.802627 [debug] [MainThread]: Flushing usage events
[0m10:05:20.883509 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff9fb5ced0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff9fb5d150>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff9fb5c250>]}


============================== 10:05:20.887679 | a6749372-6174-47fd-a3f8-8cd2ca71097c ==============================
[0m10:05:20.887679 [info ] [MainThread]: Running with dbt=1.8.9
[0m10:05:20.888015 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/project_root/dbt', 'debug': 'False', 'warn_error': 'None', 'log_path': '/opt/airflow/project_root/dbt/logs', 'fail_fast': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run --project-dir /opt/airflow/project_root/dbt --profiles-dir /opt/airflow/project_root/dbt --select gold', 'introspect': 'True', 'static_parser': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m10:05:20.969810 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'a6749372-6174-47fd-a3f8-8cd2ca71097c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff9fb9d710>]}
[0m10:05:20.989940 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'a6749372-6174-47fd-a3f8-8cd2ca71097c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa058b250>]}
[0m10:05:20.990538 [info ] [MainThread]: Registered adapter: clickhouse=1.8.9
[0m10:05:21.026203 [debug] [MainThread]: checksum: 132857a23e9d07220246854f7763165174ce9b737cfc7867629ace4294e520b1, vars: {}, profile: , target: , version: 1.8.9
[0m10:05:21.095991 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m10:05:21.096376 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m10:05:21.099401 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.movie_warehouse.bronze
[0m10:05:21.115804 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'a6749372-6174-47fd-a3f8-8cd2ca71097c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff9f95e610>]}
[0m10:05:21.167488 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'a6749372-6174-47fd-a3f8-8cd2ca71097c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff9f6c0110>]}
[0m10:05:21.167828 [info ] [MainThread]: Found 6 models, 12 data tests, 4 sources, 476 macros
[0m10:05:21.168159 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a6749372-6174-47fd-a3f8-8cd2ca71097c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa19dc510>]}
[0m10:05:21.169109 [info ] [MainThread]: 
[0m10:05:21.169431 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m10:05:21.172006 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m10:05:21.177243 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:05:21.506283 [info ] [ThreadPool]: dbt_clickhouse adapter: Unexpected server exception dropping table
[0m10:05:21.507416 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m10:05:21.515439 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m10:05:21.547311 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__gold_gold)
[0m10:05:21.551519 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__gold_gold: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "connection_name": "list__gold_gold"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'gold_gold'
      

  ...
[0m10:05:21.561156 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m10:05:21.562516 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a6749372-6174-47fd-a3f8-8cd2ca71097c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff9f846bd0>]}
[0m10:05:21.563044 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m10:05:21.564558 [info ] [MainThread]: 
[0m10:05:21.574365 [debug] [Thread-1 (]: Began running node model.movie_warehouse.dim_director
[0m10:05:21.574869 [info ] [Thread-1 (]: 1 of 6 START sql table model `gold_gold`.`dim_director` ........................ [RUN]
[0m10:05:21.575210 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list__gold_gold, now model.movie_warehouse.dim_director)
[0m10:05:21.575411 [debug] [Thread-1 (]: Began compiling node model.movie_warehouse.dim_director
[0m10:05:21.578874 [debug] [Thread-1 (]: Writing injected SQL for node "model.movie_warehouse.dim_director"
[0m10:05:21.579989 [debug] [Thread-1 (]: Began executing node model.movie_warehouse.dim_director
[0m10:05:21.589201 [debug] [Thread-1 (]: Creating new relation dim_director
[0m10:05:21.606020 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_director: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_director"} */

            

    
        create table `gold_gold`.`dim_director`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

WITH first_dir AS (
    SELECT
        tconst,
        TRIM(splitByChar(',', directors)[1]) AS director_id
    FROM imdb_title_crew_raw
    WHERE directors IS NOT NULL AND directors != ''
),
deduped AS (
    SELECT DISTINCT director_id
    FROM first_dir
),
joined AS (
    SELECT
        d.director_id AS dir_id,
        n.primaryName AS dir_name
    FROM deduped d
    LEFT JOIN imdb_name_basics_raw n
        ON d.director_id = n.nconst
)
SELECT
    row_number() OVER (ORDER BY dir_id) AS imdb_dir_name_id,
    dir_id,
    dir_name,
    current_date() AS valid_from,
    NULL AS valid_to,
    TRUE AS is_current
FROM joined
WHERE dir_id IS NOT NULL;
          )
        
        ...
[0m10:05:21.609386 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_director"} */

            

    
        create table `gold_gold`.`dim_director`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

WITH first_dir AS (
    SELECT
        tconst,
        TRIM(splitByChar(',', directors)[1]) AS director_id
    FROM imdb_title_crew_raw
    WHERE directors IS NOT NULL AND directors != ''
),
deduped AS (
    SELECT DISTINCT director_id
    FROM first_dir
),
joined AS (
    SELECT
        d.director_id AS dir_id,
        n.primaryName AS dir_name
    FROM deduped d
    LEFT JOIN imdb_name_basics_raw n
        ON d.director_id = n.nconst
)
SELECT
    row_number() OVER (ORDER BY dir_id) AS imdb_dir_name_id,
    dir_id,
    dir_name,
    current_date() AS valid_from,
    NULL AS valid_to,
    TRUE AS is_current
FROM joined
WHERE dir_id IS NOT NULL;
          )
        
        
[0m10:05:21.615021 [debug] [Thread-1 (]: Database Error in model dim_director (models/gold/dim_director.sql)
  :HTTPDriver for http://clickhouse-server:8123 returned response code 400)
   Code: 62. DB::Exception: Syntax error: failed at position 1153 (end of query) (line 52, col 25): ;
            )
          
          . Expected one of: OR, AND, IS NOT DISTINCT FROM, IS NULL, IS NOT NULL, BETWEEN, NOT BETWEEN, LIKE, ILIKE, NOT LIKE, NOT ILIKE, REGEXP, IN, NOT IN, GLOBAL IN, GLOBAL NOT IN, MOD, DIV, alias, AS, GROUP BY, WITH, HAVING, WINDOW, QUALIFY, ORDER BY, LIMIT, OFFSET, FETCH, SETTINGS, UNION, EXCEPT, INTERSECT. (SYNTAX_ERROR) (version 25.9.3.48 (official build))
[0m10:05:21.615790 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a6749372-6174-47fd-a3f8-8cd2ca71097c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8079d090>]}
[0m10:05:21.616145 [error] [Thread-1 (]: 1 of 6 ERROR creating sql table model `gold_gold`.`dim_director` ............... [[31mERROR[0m in 0.04s]
[0m10:05:21.616487 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.dim_director
[0m10:05:21.616743 [debug] [Thread-1 (]: Began running node model.movie_warehouse.dim_genre
[0m10:05:21.617329 [info ] [Thread-1 (]: 2 of 6 START sql table model `gold_gold`.`dim_genre` ........................... [RUN]
[0m10:05:21.617551 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.movie_warehouse.dim_director, now model.movie_warehouse.dim_genre)
[0m10:05:21.617744 [debug] [Thread-1 (]: Began compiling node model.movie_warehouse.dim_genre
[0m10:05:21.619258 [debug] [Thread-1 (]: Writing injected SQL for node "model.movie_warehouse.dim_genre"
[0m10:05:21.619956 [debug] [Thread-1 (]: Began executing node model.movie_warehouse.dim_genre
[0m10:05:21.621264 [debug] [Thread-1 (]: Creating new relation dim_genre
[0m10:05:21.621938 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_genre: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_genre"} */

            

    
        create table `gold_gold`.`dim_genre`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

SELECT
  ROW_NUMBER() OVER (ORDER BY first_genre) AS genre_id,
  first_genre AS genre_name
FROM (
  SELECT
    TRIM(SPLIT(genres, ',')[0]) AS first_genre
  FROM `bronze`.`tmdb_raw`
  WHERE genres IS NOT NULL
)
GROUP BY first_genre;
          )
        
        ...
[0m10:05:21.623632 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_genre"} */

            

    
        create table `gold_gold`.`dim_genre`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

SELECT
  ROW_NUMBER() OVER (ORDER BY first_genre) AS genre_id,
  first_genre AS genre_name
FROM (
  SELECT
    TRIM(SPLIT(genres, ',')[0]) AS first_genre
  FROM `bronze`.`tmdb_raw`
  WHERE genres IS NOT NULL
)
GROUP BY first_genre;
          )
        
        
[0m10:05:21.625886 [debug] [Thread-1 (]: Database Error in model dim_genre (models/gold/dim_genre.sql)
  :HTTPDriver for http://clickhouse-server:8123 returned response code 400)
   Code: 62. DB::Exception: Syntax error: failed at position 726 (end of query) (line 34, col 21): ;
            )
          
          . Expected one of: token sequence, Dot, token, OR, AND, IS NOT DISTINCT FROM, IS NULL, IS NOT NULL, BETWEEN, NOT BETWEEN, LIKE, ILIKE, NOT LIKE, NOT ILIKE, REGEXP, IN, NOT IN, GLOBAL IN, GLOBAL NOT IN, MOD, DIV, alias, AS, Comma, WITH, HAVING, WINDOW, QUALIFY, ORDER BY, LIMIT, OFFSET, FETCH, SETTINGS, UNION, EXCEPT, INTERSECT. (SYNTAX_ERROR) (version 25.9.3.48 (official build))
[0m10:05:21.626160 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a6749372-6174-47fd-a3f8-8cd2ca71097c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff80347990>]}
[0m10:05:21.626468 [error] [Thread-1 (]: 2 of 6 ERROR creating sql table model `gold_gold`.`dim_genre` .................. [[31mERROR[0m in 0.01s]
[0m10:05:21.626759 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.dim_genre
[0m10:05:21.626967 [debug] [Thread-1 (]: Began running node model.movie_warehouse.dim_movie
[0m10:05:21.627235 [info ] [Thread-1 (]: 3 of 6 START sql table model `gold_gold`.`dim_movie` ........................... [RUN]
[0m10:05:21.627455 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.movie_warehouse.dim_genre, now model.movie_warehouse.dim_movie)
[0m10:05:21.627628 [debug] [Thread-1 (]: Began compiling node model.movie_warehouse.dim_movie
[0m10:05:21.629060 [debug] [Thread-1 (]: Writing injected SQL for node "model.movie_warehouse.dim_movie"
[0m10:05:21.629549 [debug] [Thread-1 (]: Began executing node model.movie_warehouse.dim_movie
[0m10:05:21.630610 [debug] [Thread-1 (]: Creating new relation dim_movie
[0m10:05:21.632344 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_movie: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_movie"} */

            

    
        create table `gold_gold`.`dim_movie`
        
  
        
  engine = MergeTree()
        order by (movie_id)
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

SELECT
    row_number() OVER (ORDER BY title) AS movie_id,
    imdb_id,
    title AS movie_title,
    release_date,
    runtime AS movie_runtime,
    original_language AS language
FROM `bronze`.`tmdb_raw`
WHERE title IS NOT NULL;
          )
        
        ...
[0m10:05:21.634129 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_movie"} */

            

    
        create table `gold_gold`.`dim_movie`
        
  
        
  engine = MergeTree()
        order by (movie_id)
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

SELECT
    row_number() OVER (ORDER BY title) AS movie_id,
    imdb_id,
    title AS movie_title,
    release_date,
    runtime AS movie_runtime,
    original_language AS language
FROM `bronze`.`tmdb_raw`
WHERE title IS NOT NULL;
          )
        
        
[0m10:05:21.636232 [debug] [Thread-1 (]: Database Error in model dim_movie (models/gold/dim_movie.sql)
  :HTTPDriver for http://clickhouse-server:8123 returned response code 400)
   Code: 62. DB::Exception: Syntax error: failed at position 718 (end of query) (line 32, col 24): ;
            )
          
          . Expected one of: OR, AND, IS NOT DISTINCT FROM, IS NULL, IS NOT NULL, BETWEEN, NOT BETWEEN, LIKE, ILIKE, NOT LIKE, NOT ILIKE, REGEXP, IN, NOT IN, GLOBAL IN, GLOBAL NOT IN, MOD, DIV, alias, AS, GROUP BY, WITH, HAVING, WINDOW, QUALIFY, ORDER BY, LIMIT, OFFSET, FETCH, SETTINGS, UNION, EXCEPT, INTERSECT. (SYNTAX_ERROR) (version 25.9.3.48 (official build))
[0m10:05:21.636464 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a6749372-6174-47fd-a3f8-8cd2ca71097c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8020fb10>]}
[0m10:05:21.636766 [error] [Thread-1 (]: 3 of 6 ERROR creating sql table model `gold_gold`.`dim_movie` .................. [[31mERROR[0m in 0.01s]
[0m10:05:21.637047 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.dim_movie
[0m10:05:21.637245 [debug] [Thread-1 (]: Began running node model.movie_warehouse.dim_production
[0m10:05:21.637496 [info ] [Thread-1 (]: 4 of 6 START sql table model `gold_gold`.`dim_production` ...................... [RUN]
[0m10:05:21.637704 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.movie_warehouse.dim_movie, now model.movie_warehouse.dim_production)
[0m10:05:21.637876 [debug] [Thread-1 (]: Began compiling node model.movie_warehouse.dim_production
[0m10:05:21.639149 [debug] [Thread-1 (]: Writing injected SQL for node "model.movie_warehouse.dim_production"
[0m10:05:21.639629 [debug] [Thread-1 (]: Began executing node model.movie_warehouse.dim_production
[0m10:05:21.640748 [debug] [Thread-1 (]: Creating new relation dim_production
[0m10:05:21.641365 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_production: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_production"} */

            

    
        create table `gold_gold`.`dim_production`
        
  
        
  engine = MergeTree()
        order by (production_id)
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

WITH first_production AS (
    SELECT
        id AS movie_id,
        trim(splitByChar(',', production_companies)[1]) AS production_name
    FROM `bronze`.`tmdb_raw`
    WHERE production_companies IS NOT NULL AND production_companies != ''
)

SELECT
    row_number() OVER (ORDER BY production_name) AS production_id,
    production_name,
    current_date() AS valid_from,
    NULL AS valid_to,
    TRUE AS is_current
FROM (
    SELECT DISTINCT production_name
    FROM first_production
)
WHERE production_name IS NOT NULL;
          )
        
        ...
[0m10:05:21.642996 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_production"} */

            

    
        create table `gold_gold`.`dim_production`
        
  
        
  engine = MergeTree()
        order by (production_id)
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

WITH first_production AS (
    SELECT
        id AS movie_id,
        trim(splitByChar(',', production_companies)[1]) AS production_name
    FROM `bronze`.`tmdb_raw`
    WHERE production_companies IS NOT NULL AND production_companies != ''
)

SELECT
    row_number() OVER (ORDER BY production_name) AS production_id,
    production_name,
    current_date() AS valid_from,
    NULL AS valid_to,
    TRUE AS is_current
FROM (
    SELECT DISTINCT production_name
    FROM first_production
)
WHERE production_name IS NOT NULL;
          )
        
        
[0m10:05:21.645189 [debug] [Thread-1 (]: Database Error in model dim_production (models/gold/dim_production.sql)
  :HTTPDriver for http://clickhouse-server:8123 returned response code 400)
   Code: 62. DB::Exception: Syntax error: failed at position 1026 (end of query) (line 42, col 34): ;
            )
          
          . Expected one of: OR, AND, IS NOT DISTINCT FROM, IS NULL, IS NOT NULL, BETWEEN, NOT BETWEEN, LIKE, ILIKE, NOT LIKE, NOT ILIKE, REGEXP, IN, NOT IN, GLOBAL IN, GLOBAL NOT IN, MOD, DIV, alias, AS, GROUP BY, WITH, HAVING, WINDOW, QUALIFY, ORDER BY, LIMIT, OFFSET, FETCH, SETTINGS, UNION, EXCEPT, INTERSECT. (SYNTAX_ERROR) (version 25.9.3.48 (official build))
[0m10:05:21.645465 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a6749372-6174-47fd-a3f8-8cd2ca71097c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff801f1090>]}
[0m10:05:21.645754 [error] [Thread-1 (]: 4 of 6 ERROR creating sql table model `gold_gold`.`dim_production` ............. [[31mERROR[0m in 0.01s]
[0m10:05:21.646028 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.dim_production
[0m10:05:21.646243 [debug] [Thread-1 (]: Began running node model.movie_warehouse.dim_release_date
[0m10:05:21.646510 [info ] [Thread-1 (]: 5 of 6 START sql table model `gold_gold`.`dim_release_date` .................... [RUN]
[0m10:05:21.646725 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.movie_warehouse.dim_production, now model.movie_warehouse.dim_release_date)
[0m10:05:21.646927 [debug] [Thread-1 (]: Began compiling node model.movie_warehouse.dim_release_date
[0m10:05:21.648501 [debug] [Thread-1 (]: Writing injected SQL for node "model.movie_warehouse.dim_release_date"
[0m10:05:21.648957 [debug] [Thread-1 (]: Began executing node model.movie_warehouse.dim_release_date
[0m10:05:21.649912 [debug] [Thread-1 (]: Creating new relation dim_release_date
[0m10:05:21.650509 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_release_date: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_release_date"} */

            

    
        create table `gold_gold`.`dim_release_date`
        
  
        
  engine = MergeTree()
        order by (date_id)
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

WITH distinct_dates AS (
    SELECT DISTINCT release_date
    FROM `bronze`.`tmdb_raw`
    WHERE release_date IS NOT NULL
)

SELECT
    row_number() OVER (ORDER BY release_date)                   AS date_id,
    release_date                                                AS full_date,
    toYear(release_date)                                        AS year,
    toMonth(release_date)                                       AS month,
    toDayOfMonth(release_date)                                  AS day,
    toISOWeek(release_date)                                     AS week,
    formatDateTime(release_date, '%A')                          AS weekday,
    CASE
        WHEN toMonth(release_date) IN (12,1,2)  THEN 'Winter'
        WHEN toMonth(release_date) IN (3,4,5)   THEN 'Spring'
        WHEN toMonth(release_date) IN (6,7,8)   THEN 'Summer'
        WHEN toMonth(release_date) IN (9,10,11) THEN 'Autumn'
    END                                                         AS season,
    CASE
        WHEN formatDateTime(release_date, '%A') IN ('Saturday','Sunday') THEN 1
        ELSE 0
    END                                                         AS is_weekend,

    /* ---------- holiday tagging ---------- */
    CASE
        WHEN toMonth(release_date)=1  AND toDayOfMonth(release_date)=1  THEN 'New Year\'s Day'
        WHEN toMonth(release_date)=2  AND toDayOfMonth(release_date)=14 THEN 'Valentine\'s Day'
        WHEN toMonth(release_date)=3  AND toDayOfMonth(release_date)=17 THEN 'St. Patrick\'s Day'
        WHEN toMonth(release_date)=4  AND toDayOfMonth(release_date)=1  THEN 'April Fool\'s Day'
        WHEN toMonth(release_date)=4  AND toDayOfMonth(release_date)=22 THEN 'Earth Day'
        WHEN toMonth(release_date)=5  AND toDayOfMonth(release_date)=1  THEN 'May Day'
        WHEN toMonth(release_date)=5  AND toDayOfMonth(release_date)=5  THEN 'Cinco de Mayo'
        WHEN toMonth(release_date)=6  AND toDayOfMonth(release_date) BETWEEN 19 AND 26 THEN 'Midsummer'
        WHEN toMonth(release_date)=7  AND toDayOfMonth(release_date)=4  THEN 'Independence Day'
        WHEN toMonth(release_date)=9  AND toDayOfMonth(release_date) BETWEEN 1 AND 7 
             AND formatDateTime(release_date,'%A')='Monday'             THEN 'Labor Day (US)'
        WHEN toMonth(release_date)=10 AND toDayOfMonth(release_date)=31 THEN 'Halloween'
        WHEN toMonth(release_date)=11 AND formatDateTime(release_date,'%A')='Thursday'
             AND toISOWeek(release_date) >= 47                           THEN 'Thanksgiving'
        WHEN toMonth(release_date)=12 AND toDayOfMonth(release_date)=24 THEN 'Christmas Eve'
        WHEN toMonth(release_date)=12 AND toDayOfMonth(release_date)=25 THEN 'Christmas Day'
        WHEN toMonth(release_date)=12 AND toDayOfMonth(release_date)=31 THEN 'New Year\'s Eve'
        ELSE NULL
    END                                                         AS holiday_name,
    IF(holiday_name IS NOT NULL, 1, 0)                          AS is_holiday,

    /* placeholders for later enhancement */
    NULL                                                        AS days_until_holiday,
    NULL                                                        AS days_after_holiday
FROM distinct_dates
ORDER BY release_date;
          )
        
        ...
[0m10:05:21.652657 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_release_date"} */

            

    
        create table `gold_gold`.`dim_release_date`
        
  
        
  engine = MergeTree()
        order by (date_id)
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

WITH distinct_dates AS (
    SELECT DISTINCT release_date
    FROM `bronze`.`tmdb_raw`
    WHERE release_date IS NOT NULL
)

SELECT
    row_number() OVER (ORDER BY release_date)                   AS date_id,
    release_date                                                AS full_date,
    toYear(release_date)                                        AS year,
    toMonth(release_date)                                       AS month,
    toDayOfMonth(release_date)                                  AS day,
    toISOWeek(release_date)                                     AS week,
    formatDateTime(release_date, '%A')                          AS weekday,
    CASE
        WHEN toMonth(release_date) IN (12,1,2)  THEN 'Winter'
        WHEN toMonth(release_date) IN (3,4,5)   THEN 'Spring'
        WHEN toMonth(release_date) IN (6,7,8)   THEN 'Summer'
        WHEN toMonth(release_date) IN (9,10,11) THEN 'Autumn'
    END                                                         AS season,
    CASE
        WHEN formatDateTime(release_date, '%A') IN ('Saturday','Sunday') THEN 1
        ELSE 0
    END                                                         AS is_weekend,

    /* ---------- holiday tagging ---------- */
    CASE
        WHEN toMonth(release_date)=1  AND toDayOfMonth(release_date)=1  THEN 'New Year\'s Day'
        WHEN toMonth(release_date)=2  AND toDayOfMonth(release_date)=14 THEN 'Valentine\'s Day'
        WHEN toMonth(release_date)=3  AND toDayOfMonth(release_date)=17 THEN 'St. Patrick\'s Day'
        WHEN toMonth(release_date)=4  AND toDayOfMonth(release_date)=1  THEN 'April Fool\'s Day'
        WHEN toMonth(release_date)=4  AND toDayOfMonth(release_date)=22 THEN 'Earth Day'
        WHEN toMonth(release_date)=5  AND toDayOfMonth(release_date)=1  THEN 'May Day'
        WHEN toMonth(release_date)=5  AND toDayOfMonth(release_date)=5  THEN 'Cinco de Mayo'
        WHEN toMonth(release_date)=6  AND toDayOfMonth(release_date) BETWEEN 19 AND 26 THEN 'Midsummer'
        WHEN toMonth(release_date)=7  AND toDayOfMonth(release_date)=4  THEN 'Independence Day'
        WHEN toMonth(release_date)=9  AND toDayOfMonth(release_date) BETWEEN 1 AND 7 
             AND formatDateTime(release_date,'%A')='Monday'             THEN 'Labor Day (US)'
        WHEN toMonth(release_date)=10 AND toDayOfMonth(release_date)=31 THEN 'Halloween'
        WHEN toMonth(release_date)=11 AND formatDateTime(release_date,'%A')='Thursday'
             AND toISOWeek(release_date) >= 47                           THEN 'Thanksgiving'
        WHEN toMonth(release_date)=12 AND toDayOfMonth(release_date)=24 THEN 'Christmas Eve'
        WHEN toMonth(release_date)=12 AND toDayOfMonth(release_date)=25 THEN 'Christmas Day'
        WHEN toMonth(release_date)=12 AND toDayOfMonth(release_date)=31 THEN 'New Year\'s Eve'
        ELSE NULL
    END                                                         AS holiday_name,
    IF(holiday_name IS NOT NULL, 1, 0)                          AS is_holiday,

    /* placeholders for later enhancement */
    NULL                                                        AS days_until_holiday,
    NULL                                                        AS days_after_holiday
FROM distinct_dates
ORDER BY release_date;
          )
        
        
[0m10:05:21.654871 [debug] [Thread-1 (]: Database Error in model dim_release_date (models/gold/dim_release_date.sql)
  :HTTPDriver for http://clickhouse-server:8123 returned response code 400)
   Code: 62. DB::Exception: Syntax error: failed at position 3753 (end of query) (line 76, col 22): ;
            )
          
          . Expected one of: token sequence, Dot, token, OR, AND, IS NOT DISTINCT FROM, IS NULL, IS NOT NULL, BETWEEN, NOT BETWEEN, LIKE, ILIKE, NOT LIKE, NOT ILIKE, REGEXP, IN, NOT IN, GLOBAL IN, GLOBAL NOT IN, MOD, DIV, alias, AS, DESCENDING, DESC, ASCENDING, ASC, NULLS, COLLATE, WITH FILL, Comma, LIMIT, OFFSET, FETCH, SETTINGS, UNION, EXCEPT, INTERSECT. (SYNTAX_ERROR) (version 25.9.3.48 (official build))
[0m10:05:21.655111 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a6749372-6174-47fd-a3f8-8cd2ca71097c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8047e850>]}
[0m10:05:21.655408 [error] [Thread-1 (]: 5 of 6 ERROR creating sql table model `gold_gold`.`dim_release_date` ........... [[31mERROR[0m in 0.01s]
[0m10:05:21.655691 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.dim_release_date
[0m10:05:21.656143 [debug] [Thread-1 (]: Began running node model.movie_warehouse.fact_movie
[0m10:05:21.656333 [info ] [Thread-1 (]: 6 of 6 SKIP relation gold_gold.fact_movie ...................................... [[33mSKIP[0m]
[0m10:05:21.656527 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.fact_movie
[0m10:05:21.657082 [debug] [MainThread]: Connection 'master' was properly closed.
[0m10:05:21.657282 [debug] [MainThread]: Connection 'model.movie_warehouse.dim_release_date' was left open.
[0m10:05:21.657476 [debug] [MainThread]: On model.movie_warehouse.dim_release_date: Close
[0m10:05:21.657733 [info ] [MainThread]: 
[0m10:05:21.657916 [info ] [MainThread]: Finished running 6 table models in 0 hours 0 minutes and 0.49 seconds (0.49s).
[0m10:05:21.658428 [debug] [MainThread]: Command end result
[0m10:05:21.735037 [info ] [MainThread]: 
[0m10:05:21.735352 [info ] [MainThread]: [31mCompleted with 5 errors and 0 warnings:[0m
[0m10:05:21.735525 [info ] [MainThread]: 
[0m10:05:21.735726 [error] [MainThread]:   Database Error in model dim_director (models/gold/dim_director.sql)
  :HTTPDriver for http://clickhouse-server:8123 returned response code 400)
   Code: 62. DB::Exception: Syntax error: failed at position 1153 (end of query) (line 52, col 25): ;
            )
          
          . Expected one of: OR, AND, IS NOT DISTINCT FROM, IS NULL, IS NOT NULL, BETWEEN, NOT BETWEEN, LIKE, ILIKE, NOT LIKE, NOT ILIKE, REGEXP, IN, NOT IN, GLOBAL IN, GLOBAL NOT IN, MOD, DIV, alias, AS, GROUP BY, WITH, HAVING, WINDOW, QUALIFY, ORDER BY, LIMIT, OFFSET, FETCH, SETTINGS, UNION, EXCEPT, INTERSECT. (SYNTAX_ERROR) (version 25.9.3.48 (official build))
[0m10:05:21.735912 [info ] [MainThread]: 
[0m10:05:21.736087 [error] [MainThread]:   Database Error in model dim_genre (models/gold/dim_genre.sql)
  :HTTPDriver for http://clickhouse-server:8123 returned response code 400)
   Code: 62. DB::Exception: Syntax error: failed at position 726 (end of query) (line 34, col 21): ;
            )
          
          . Expected one of: token sequence, Dot, token, OR, AND, IS NOT DISTINCT FROM, IS NULL, IS NOT NULL, BETWEEN, NOT BETWEEN, LIKE, ILIKE, NOT LIKE, NOT ILIKE, REGEXP, IN, NOT IN, GLOBAL IN, GLOBAL NOT IN, MOD, DIV, alias, AS, Comma, WITH, HAVING, WINDOW, QUALIFY, ORDER BY, LIMIT, OFFSET, FETCH, SETTINGS, UNION, EXCEPT, INTERSECT. (SYNTAX_ERROR) (version 25.9.3.48 (official build))
[0m10:05:21.736259 [info ] [MainThread]: 
[0m10:05:21.736492 [error] [MainThread]:   Database Error in model dim_movie (models/gold/dim_movie.sql)
  :HTTPDriver for http://clickhouse-server:8123 returned response code 400)
   Code: 62. DB::Exception: Syntax error: failed at position 718 (end of query) (line 32, col 24): ;
            )
          
          . Expected one of: OR, AND, IS NOT DISTINCT FROM, IS NULL, IS NOT NULL, BETWEEN, NOT BETWEEN, LIKE, ILIKE, NOT LIKE, NOT ILIKE, REGEXP, IN, NOT IN, GLOBAL IN, GLOBAL NOT IN, MOD, DIV, alias, AS, GROUP BY, WITH, HAVING, WINDOW, QUALIFY, ORDER BY, LIMIT, OFFSET, FETCH, SETTINGS, UNION, EXCEPT, INTERSECT. (SYNTAX_ERROR) (version 25.9.3.48 (official build))
[0m10:05:21.736681 [info ] [MainThread]: 
[0m10:05:21.736871 [error] [MainThread]:   Database Error in model dim_production (models/gold/dim_production.sql)
  :HTTPDriver for http://clickhouse-server:8123 returned response code 400)
   Code: 62. DB::Exception: Syntax error: failed at position 1026 (end of query) (line 42, col 34): ;
            )
          
          . Expected one of: OR, AND, IS NOT DISTINCT FROM, IS NULL, IS NOT NULL, BETWEEN, NOT BETWEEN, LIKE, ILIKE, NOT LIKE, NOT ILIKE, REGEXP, IN, NOT IN, GLOBAL IN, GLOBAL NOT IN, MOD, DIV, alias, AS, GROUP BY, WITH, HAVING, WINDOW, QUALIFY, ORDER BY, LIMIT, OFFSET, FETCH, SETTINGS, UNION, EXCEPT, INTERSECT. (SYNTAX_ERROR) (version 25.9.3.48 (official build))
[0m10:05:21.737018 [info ] [MainThread]: 
[0m10:05:21.737186 [error] [MainThread]:   Database Error in model dim_release_date (models/gold/dim_release_date.sql)
  :HTTPDriver for http://clickhouse-server:8123 returned response code 400)
   Code: 62. DB::Exception: Syntax error: failed at position 3753 (end of query) (line 76, col 22): ;
            )
          
          . Expected one of: token sequence, Dot, token, OR, AND, IS NOT DISTINCT FROM, IS NULL, IS NOT NULL, BETWEEN, NOT BETWEEN, LIKE, ILIKE, NOT LIKE, NOT ILIKE, REGEXP, IN, NOT IN, GLOBAL IN, GLOBAL NOT IN, MOD, DIV, alias, AS, DESCENDING, DESC, ASCENDING, ASC, NULLS, COLLATE, WITH FILL, Comma, LIMIT, OFFSET, FETCH, SETTINGS, UNION, EXCEPT, INTERSECT. (SYNTAX_ERROR) (version 25.9.3.48 (official build))
[0m10:05:21.737337 [info ] [MainThread]: 
[0m10:05:21.737488 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=5 SKIP=1 TOTAL=6
[0m10:05:21.738018 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 0.8756918, "process_in_blocks": "70232", "process_kernel_time": 0.309552, "process_mem_max_rss": "189900", "process_out_blocks": "2354", "process_user_time": 1.863385}
[0m10:05:21.738283 [debug] [MainThread]: Command `dbt run` failed at 10:05:21.738246 after 0.88 seconds
[0m10:05:21.738496 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff9fb5e310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff9fb5c890>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa4921e50>]}
[0m10:05:21.738679 [debug] [MainThread]: Flushing usage events
[0m10:08:22.348798 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8853d110>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff886510d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff88821ed0>]}


============================== 10:08:22.353186 | 2f9c2fff-4f8f-42f0-85a6-03b595e4a034 ==============================
[0m10:08:22.353186 [info ] [MainThread]: Running with dbt=1.8.9
[0m10:08:22.353636 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'fail_fast': 'False', 'log_path': '/opt/airflow/project_root/dbt/logs', 'version_check': 'True', 'profiles_dir': '/opt/airflow/project_root/dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'introspect': 'True', 'invocation_command': 'dbt run --project-dir /opt/airflow/project_root/dbt --profiles-dir /opt/airflow/project_root/dbt --select gold', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m10:08:22.460470 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '2f9c2fff-4f8f-42f0-85a6-03b595e4a034', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8a552a90>]}
[0m10:08:22.484635 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '2f9c2fff-4f8f-42f0-85a6-03b595e4a034', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff88f6b210>]}
[0m10:08:22.485380 [info ] [MainThread]: Registered adapter: clickhouse=1.8.9
[0m10:08:22.527262 [debug] [MainThread]: checksum: 132857a23e9d07220246854f7763165174ce9b737cfc7867629ace4294e520b1, vars: {}, profile: , target: , version: 1.8.9
[0m10:08:22.592321 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 2 files changed.
[0m10:08:22.592974 [debug] [MainThread]: Partial parsing: updated file: movie_warehouse://models/gold/dim_director.sql
[0m10:08:22.593273 [debug] [MainThread]: Partial parsing: updated file: movie_warehouse://models/gold/dim_genre.sql
[0m10:08:22.701858 [warn ] [MainThread]: [[33mWARNING[0m]: Deprecated functionality
The `tests` config has been renamed to `data_tests`. Please see
https://docs.getdbt.com/docs/build/data-tests#new-data_tests-syntax for more
information.
[0m10:08:22.702353 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'deprecation', 'label': '2f9c2fff-4f8f-42f0-85a6-03b595e4a034', 'property_': 'warn', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8a39dc10>]}
[0m10:08:22.771039 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.movie_warehouse.bronze
[0m10:08:22.777664 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '2f9c2fff-4f8f-42f0-85a6-03b595e4a034', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff87f064d0>]}
[0m10:08:22.873452 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '2f9c2fff-4f8f-42f0-85a6-03b595e4a034', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff881b3990>]}
[0m10:08:22.873886 [info ] [MainThread]: Found 6 models, 12 data tests, 4 sources, 476 macros
[0m10:08:22.874172 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '2f9c2fff-4f8f-42f0-85a6-03b595e4a034', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff86eb20d0>]}
[0m10:08:22.875181 [info ] [MainThread]: 
[0m10:08:22.875594 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m10:08:22.878833 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m10:08:22.884964 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:08:23.235685 [info ] [ThreadPool]: dbt_clickhouse adapter: Unexpected server exception dropping table
[0m10:08:23.236251 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m10:08:23.239098 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m10:08:23.303751 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__gold_gold)
[0m10:08:23.306871 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__gold_gold: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "connection_name": "list__gold_gold"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'gold_gold'
      

  ...
[0m10:08:23.312812 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m10:08:23.314416 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '2f9c2fff-4f8f-42f0-85a6-03b595e4a034', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff48156d50>]}
[0m10:08:23.314807 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m10:08:23.315087 [info ] [MainThread]: 
[0m10:08:23.320114 [debug] [Thread-1 (]: Began running node model.movie_warehouse.dim_director
[0m10:08:23.320746 [info ] [Thread-1 (]: 1 of 6 START sql table model `gold_gold`.`dim_director` ........................ [RUN]
[0m10:08:23.321229 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list__gold_gold, now model.movie_warehouse.dim_director)
[0m10:08:23.321486 [debug] [Thread-1 (]: Began compiling node model.movie_warehouse.dim_director
[0m10:08:23.325340 [debug] [Thread-1 (]: Writing injected SQL for node "model.movie_warehouse.dim_director"
[0m10:08:23.326721 [debug] [Thread-1 (]: Began executing node model.movie_warehouse.dim_director
[0m10:08:23.336773 [debug] [Thread-1 (]: Creating new relation dim_director
[0m10:08:23.351014 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_director: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_director"} */

            

    
        create table `gold_gold`.`dim_director`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

WITH first_dir AS (
    SELECT
        tconst,
        TRIM(splitByChar(',', directors)[1]) AS director_id
    FROM `bronze`.`imdb_title_crew_raw`
    WHERE directors IS NOT NULL AND directors != ''
),
deduped AS (
    SELECT DISTINCT director_id
    FROM first_dir
),
joined AS (
    SELECT
        d.director_id AS dir_id,
        n.primaryName AS dir_name
    FROM deduped d
    LEFT JOIN `bronze`.`imdb_name_basics_raw` n
        ON d.director_id = n.nconst
)
SELECT
    cityHash64(dir_id) AS imdb_dir_name_id,  -- Use hash instead of row_number
    dir_id,
    dir_name,
    today() AS valid_from,
    CAST(NULL AS Nullable(Date)) AS valid_to,
    1 AS is_current  -- Use 1/0 instead of TRUE/FALSE
FROM joined
WHERE dir_id IS NOT NULL
ORDER BY dir_id
          )
        
        ...
[0m10:08:23.369953 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m10:08:23.376859 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_director: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_director"} */

    select name, type from system.columns where table = 'dim_director'
    
      and database = 'gold_gold'
    
    order by position
  ...
[0m10:08:23.381723 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m10:08:23.385446 [debug] [Thread-1 (]: Writing runtime sql for node "model.movie_warehouse.dim_director"
[0m10:08:23.390511 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_director: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_director"} */

  
    
    
    
        
         


        insert into `gold_gold`.`dim_director`
        ("imdb_dir_name_id", "dir_id", "dir_name", "valid_from", "valid_to", "is_current")

WITH first_dir AS (
    SELECT
        tconst,
        TRIM(splitByChar(',', directors)[1]) AS director_id
    FROM `bronze`.`imdb_title_crew_raw`
    WHERE directors IS NOT NULL AND directors != ''
),
deduped AS (
    SELECT DISTINCT director_id
    FROM first_dir
),
joined AS (
    SELECT
        d.director_id AS dir_id,
        n.primaryName AS dir_name
    FROM deduped d
    LEFT JOIN `bronze`.`imdb_name_basics_raw` n
        ON d.director_id = n.nconst
)
SELECT
    cityHash64(dir_id) AS imdb_dir_name_id,  -- Use hash instead of row_number
    dir_id,
    dir_name,
    today() AS valid_from,
    CAST(NULL AS Nullable(Date)) AS valid_to,
    1 AS is_current  -- Use 1/0 instead of TRUE/FALSE
FROM joined
WHERE dir_id IS NOT NULL
ORDER BY dir_id
  ...
[0m10:08:28.779302 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 5.38 seconds
[0m10:08:28.847259 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2f9c2fff-4f8f-42f0-85a6-03b595e4a034', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff43f203d0>]}
[0m10:08:28.848993 [info ] [Thread-1 (]: 1 of 6 OK created sql table model `gold_gold`.`dim_director` ................... [[32mOK[0m in 5.52s]
[0m10:08:28.850194 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.dim_director
[0m10:08:28.850956 [debug] [Thread-1 (]: Began running node model.movie_warehouse.dim_genre
[0m10:08:28.851836 [info ] [Thread-1 (]: 2 of 6 START sql table model `gold_gold`.`dim_genre` ........................... [RUN]
[0m10:08:28.852301 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.movie_warehouse.dim_director, now model.movie_warehouse.dim_genre)
[0m10:08:28.852576 [debug] [Thread-1 (]: Began compiling node model.movie_warehouse.dim_genre
[0m10:08:28.857014 [debug] [Thread-1 (]: Writing injected SQL for node "model.movie_warehouse.dim_genre"
[0m10:08:28.858212 [debug] [Thread-1 (]: Began executing node model.movie_warehouse.dim_genre
[0m10:08:28.863901 [debug] [Thread-1 (]: Creating new relation dim_genre
[0m10:08:28.865922 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_genre: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_genre"} */

            

    
        create table `gold_gold`.`dim_genre`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

WITH parsed_genres AS (
    SELECT
        TRIM(splitByChar(',', genres)[1]) AS first_genre
    FROM `bronze`.`tmdb_raw`
    WHERE genres IS NOT NULL AND genres != ''
)
SELECT
    cityHash64(first_genre) AS genre_id,
    first_genre AS genre_name
FROM parsed_genres
GROUP BY first_genre
ORDER BY first_genre
          )
        
        ...
[0m10:08:28.886440 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m10:08:28.888599 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_genre: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_genre"} */

    select name, type from system.columns where table = 'dim_genre'
    
      and database = 'gold_gold'
    
    order by position
  ...
[0m10:08:28.893807 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m10:08:28.897529 [debug] [Thread-1 (]: Writing runtime sql for node "model.movie_warehouse.dim_genre"
[0m10:08:28.898798 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_genre: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_genre"} */

  
    
    
    
        
         


        insert into `gold_gold`.`dim_genre`
        ("genre_id", "genre_name")

WITH parsed_genres AS (
    SELECT
        TRIM(splitByChar(',', genres)[1]) AS first_genre
    FROM `bronze`.`tmdb_raw`
    WHERE genres IS NOT NULL AND genres != ''
)
SELECT
    cityHash64(first_genre) AS genre_id,
    first_genre AS genre_name
FROM parsed_genres
GROUP BY first_genre
ORDER BY first_genre
  ...
[0m10:08:28.952688 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m10:08:28.954915 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2f9c2fff-4f8f-42f0-85a6-03b595e4a034', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8829f590>]}
[0m10:08:28.955810 [info ] [Thread-1 (]: 2 of 6 OK created sql table model `gold_gold`.`dim_genre` ...................... [[32mOK[0m in 0.10s]
[0m10:08:28.956322 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.dim_genre
[0m10:08:28.957066 [debug] [Thread-1 (]: Began running node model.movie_warehouse.dim_movie
[0m10:08:28.957905 [info ] [Thread-1 (]: 3 of 6 START sql table model `gold_gold`.`dim_movie` ........................... [RUN]
[0m10:08:28.958609 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.movie_warehouse.dim_genre, now model.movie_warehouse.dim_movie)
[0m10:08:28.959083 [debug] [Thread-1 (]: Began compiling node model.movie_warehouse.dim_movie
[0m10:08:28.964520 [debug] [Thread-1 (]: Writing injected SQL for node "model.movie_warehouse.dim_movie"
[0m10:08:28.966027 [debug] [Thread-1 (]: Began executing node model.movie_warehouse.dim_movie
[0m10:08:28.986826 [debug] [Thread-1 (]: Creating new relation dim_movie
[0m10:08:28.993964 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_movie: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_movie"} */

            

    
        create table `gold_gold`.`dim_movie`
        
  
        
  engine = MergeTree()
        order by (movie_id)
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

SELECT
    row_number() OVER (ORDER BY title) AS movie_id,
    imdb_id,
    title AS movie_title,
    release_date,
    runtime AS movie_runtime,
    original_language AS language
FROM `bronze`.`tmdb_raw`
WHERE title IS NOT NULL;
          )
        
        ...
[0m10:08:29.009781 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_movie"} */

            

    
        create table `gold_gold`.`dim_movie`
        
  
        
  engine = MergeTree()
        order by (movie_id)
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

SELECT
    row_number() OVER (ORDER BY title) AS movie_id,
    imdb_id,
    title AS movie_title,
    release_date,
    runtime AS movie_runtime,
    original_language AS language
FROM `bronze`.`tmdb_raw`
WHERE title IS NOT NULL;
          )
        
        
[0m10:08:29.020692 [debug] [Thread-1 (]: Database Error in model dim_movie (models/gold/dim_movie.sql)
  :HTTPDriver for http://clickhouse-server:8123 returned response code 400)
   Code: 62. DB::Exception: Syntax error: failed at position 718 (end of query) (line 32, col 24): ;
            )
          
          . Expected one of: OR, AND, IS NOT DISTINCT FROM, IS NULL, IS NOT NULL, BETWEEN, NOT BETWEEN, LIKE, ILIKE, NOT LIKE, NOT ILIKE, REGEXP, IN, NOT IN, GLOBAL IN, GLOBAL NOT IN, MOD, DIV, alias, AS, GROUP BY, WITH, HAVING, WINDOW, QUALIFY, ORDER BY, LIMIT, OFFSET, FETCH, SETTINGS, UNION, EXCEPT, INTERSECT. (SYNTAX_ERROR) (version 25.9.3.48 (official build))
[0m10:08:29.021188 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2f9c2fff-4f8f-42f0-85a6-03b595e4a034', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff43944f50>]}
[0m10:08:29.021629 [error] [Thread-1 (]: 3 of 6 ERROR creating sql table model `gold_gold`.`dim_movie` .................. [[31mERROR[0m in 0.06s]
[0m10:08:29.022038 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.dim_movie
[0m10:08:29.022310 [debug] [Thread-1 (]: Began running node model.movie_warehouse.dim_production
[0m10:08:29.023594 [info ] [Thread-1 (]: 4 of 6 START sql table model `gold_gold`.`dim_production` ...................... [RUN]
[0m10:08:29.023867 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.movie_warehouse.dim_movie, now model.movie_warehouse.dim_production)
[0m10:08:29.024082 [debug] [Thread-1 (]: Began compiling node model.movie_warehouse.dim_production
[0m10:08:29.026020 [debug] [Thread-1 (]: Writing injected SQL for node "model.movie_warehouse.dim_production"
[0m10:08:29.026846 [debug] [Thread-1 (]: Began executing node model.movie_warehouse.dim_production
[0m10:08:29.028164 [debug] [Thread-1 (]: Creating new relation dim_production
[0m10:08:29.028881 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_production: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_production"} */

            

    
        create table `gold_gold`.`dim_production`
        
  
        
  engine = MergeTree()
        order by (production_id)
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

WITH first_production AS (
    SELECT
        id AS movie_id,
        trim(splitByChar(',', production_companies)[1]) AS production_name
    FROM `bronze`.`tmdb_raw`
    WHERE production_companies IS NOT NULL AND production_companies != ''
)

SELECT
    row_number() OVER (ORDER BY production_name) AS production_id,
    production_name,
    current_date() AS valid_from,
    NULL AS valid_to,
    TRUE AS is_current
FROM (
    SELECT DISTINCT production_name
    FROM first_production
)
WHERE production_name IS NOT NULL;
          )
        
        ...
[0m10:08:29.031621 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_production"} */

            

    
        create table `gold_gold`.`dim_production`
        
  
        
  engine = MergeTree()
        order by (production_id)
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

WITH first_production AS (
    SELECT
        id AS movie_id,
        trim(splitByChar(',', production_companies)[1]) AS production_name
    FROM `bronze`.`tmdb_raw`
    WHERE production_companies IS NOT NULL AND production_companies != ''
)

SELECT
    row_number() OVER (ORDER BY production_name) AS production_id,
    production_name,
    current_date() AS valid_from,
    NULL AS valid_to,
    TRUE AS is_current
FROM (
    SELECT DISTINCT production_name
    FROM first_production
)
WHERE production_name IS NOT NULL;
          )
        
        
[0m10:08:29.034386 [debug] [Thread-1 (]: Database Error in model dim_production (models/gold/dim_production.sql)
  :HTTPDriver for http://clickhouse-server:8123 returned response code 400)
   Code: 62. DB::Exception: Syntax error: failed at position 1026 (end of query) (line 42, col 34): ;
            )
          
          . Expected one of: OR, AND, IS NOT DISTINCT FROM, IS NULL, IS NOT NULL, BETWEEN, NOT BETWEEN, LIKE, ILIKE, NOT LIKE, NOT ILIKE, REGEXP, IN, NOT IN, GLOBAL IN, GLOBAL NOT IN, MOD, DIV, alias, AS, GROUP BY, WITH, HAVING, WINDOW, QUALIFY, ORDER BY, LIMIT, OFFSET, FETCH, SETTINGS, UNION, EXCEPT, INTERSECT. (SYNTAX_ERROR) (version 25.9.3.48 (official build))
[0m10:08:29.034858 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2f9c2fff-4f8f-42f0-85a6-03b595e4a034', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff7fadb810>]}
[0m10:08:29.035312 [error] [Thread-1 (]: 4 of 6 ERROR creating sql table model `gold_gold`.`dim_production` ............. [[31mERROR[0m in 0.01s]
[0m10:08:29.035669 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.dim_production
[0m10:08:29.035950 [debug] [Thread-1 (]: Began running node model.movie_warehouse.dim_release_date
[0m10:08:29.036298 [info ] [Thread-1 (]: 5 of 6 START sql table model `gold_gold`.`dim_release_date` .................... [RUN]
[0m10:08:29.036560 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.movie_warehouse.dim_production, now model.movie_warehouse.dim_release_date)
[0m10:08:29.036736 [debug] [Thread-1 (]: Began compiling node model.movie_warehouse.dim_release_date
[0m10:08:29.038845 [debug] [Thread-1 (]: Writing injected SQL for node "model.movie_warehouse.dim_release_date"
[0m10:08:29.039692 [debug] [Thread-1 (]: Began executing node model.movie_warehouse.dim_release_date
[0m10:08:29.041014 [debug] [Thread-1 (]: Creating new relation dim_release_date
[0m10:08:29.041822 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_release_date: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_release_date"} */

            

    
        create table `gold_gold`.`dim_release_date`
        
  
        
  engine = MergeTree()
        order by (date_id)
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

WITH distinct_dates AS (
    SELECT DISTINCT release_date
    FROM `bronze`.`tmdb_raw`
    WHERE release_date IS NOT NULL
)

SELECT
    row_number() OVER (ORDER BY release_date)                   AS date_id,
    release_date                                                AS full_date,
    toYear(release_date)                                        AS year,
    toMonth(release_date)                                       AS month,
    toDayOfMonth(release_date)                                  AS day,
    toISOWeek(release_date)                                     AS week,
    formatDateTime(release_date, '%A')                          AS weekday,
    CASE
        WHEN toMonth(release_date) IN (12,1,2)  THEN 'Winter'
        WHEN toMonth(release_date) IN (3,4,5)   THEN 'Spring'
        WHEN toMonth(release_date) IN (6,7,8)   THEN 'Summer'
        WHEN toMonth(release_date) IN (9,10,11) THEN 'Autumn'
    END                                                         AS season,
    CASE
        WHEN formatDateTime(release_date, '%A') IN ('Saturday','Sunday') THEN 1
        ELSE 0
    END                                                         AS is_weekend,

    /* ---------- holiday tagging ---------- */
    CASE
        WHEN toMonth(release_date)=1  AND toDayOfMonth(release_date)=1  THEN 'New Year\'s Day'
        WHEN toMonth(release_date)=2  AND toDayOfMonth(release_date)=14 THEN 'Valentine\'s Day'
        WHEN toMonth(release_date)=3  AND toDayOfMonth(release_date)=17 THEN 'St. Patrick\'s Day'
        WHEN toMonth(release_date)=4  AND toDayOfMonth(release_date)=1  THEN 'April Fool\'s Day'
        WHEN toMonth(release_date)=4  AND toDayOfMonth(release_date)=22 THEN 'Earth Day'
        WHEN toMonth(release_date)=5  AND toDayOfMonth(release_date)=1  THEN 'May Day'
        WHEN toMonth(release_date)=5  AND toDayOfMonth(release_date)=5  THEN 'Cinco de Mayo'
        WHEN toMonth(release_date)=6  AND toDayOfMonth(release_date) BETWEEN 19 AND 26 THEN 'Midsummer'
        WHEN toMonth(release_date)=7  AND toDayOfMonth(release_date)=4  THEN 'Independence Day'
        WHEN toMonth(release_date)=9  AND toDayOfMonth(release_date) BETWEEN 1 AND 7 
             AND formatDateTime(release_date,'%A')='Monday'             THEN 'Labor Day (US)'
        WHEN toMonth(release_date)=10 AND toDayOfMonth(release_date)=31 THEN 'Halloween'
        WHEN toMonth(release_date)=11 AND formatDateTime(release_date,'%A')='Thursday'
             AND toISOWeek(release_date) >= 47                           THEN 'Thanksgiving'
        WHEN toMonth(release_date)=12 AND toDayOfMonth(release_date)=24 THEN 'Christmas Eve'
        WHEN toMonth(release_date)=12 AND toDayOfMonth(release_date)=25 THEN 'Christmas Day'
        WHEN toMonth(release_date)=12 AND toDayOfMonth(release_date)=31 THEN 'New Year\'s Eve'
        ELSE NULL
    END                                                         AS holiday_name,
    IF(holiday_name IS NOT NULL, 1, 0)                          AS is_holiday,

    /* placeholders for later enhancement */
    NULL                                                        AS days_until_holiday,
    NULL                                                        AS days_after_holiday
FROM distinct_dates
ORDER BY release_date;
          )
        
        ...
[0m10:08:29.044875 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_release_date"} */

            

    
        create table `gold_gold`.`dim_release_date`
        
  
        
  engine = MergeTree()
        order by (date_id)
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

WITH distinct_dates AS (
    SELECT DISTINCT release_date
    FROM `bronze`.`tmdb_raw`
    WHERE release_date IS NOT NULL
)

SELECT
    row_number() OVER (ORDER BY release_date)                   AS date_id,
    release_date                                                AS full_date,
    toYear(release_date)                                        AS year,
    toMonth(release_date)                                       AS month,
    toDayOfMonth(release_date)                                  AS day,
    toISOWeek(release_date)                                     AS week,
    formatDateTime(release_date, '%A')                          AS weekday,
    CASE
        WHEN toMonth(release_date) IN (12,1,2)  THEN 'Winter'
        WHEN toMonth(release_date) IN (3,4,5)   THEN 'Spring'
        WHEN toMonth(release_date) IN (6,7,8)   THEN 'Summer'
        WHEN toMonth(release_date) IN (9,10,11) THEN 'Autumn'
    END                                                         AS season,
    CASE
        WHEN formatDateTime(release_date, '%A') IN ('Saturday','Sunday') THEN 1
        ELSE 0
    END                                                         AS is_weekend,

    /* ---------- holiday tagging ---------- */
    CASE
        WHEN toMonth(release_date)=1  AND toDayOfMonth(release_date)=1  THEN 'New Year\'s Day'
        WHEN toMonth(release_date)=2  AND toDayOfMonth(release_date)=14 THEN 'Valentine\'s Day'
        WHEN toMonth(release_date)=3  AND toDayOfMonth(release_date)=17 THEN 'St. Patrick\'s Day'
        WHEN toMonth(release_date)=4  AND toDayOfMonth(release_date)=1  THEN 'April Fool\'s Day'
        WHEN toMonth(release_date)=4  AND toDayOfMonth(release_date)=22 THEN 'Earth Day'
        WHEN toMonth(release_date)=5  AND toDayOfMonth(release_date)=1  THEN 'May Day'
        WHEN toMonth(release_date)=5  AND toDayOfMonth(release_date)=5  THEN 'Cinco de Mayo'
        WHEN toMonth(release_date)=6  AND toDayOfMonth(release_date) BETWEEN 19 AND 26 THEN 'Midsummer'
        WHEN toMonth(release_date)=7  AND toDayOfMonth(release_date)=4  THEN 'Independence Day'
        WHEN toMonth(release_date)=9  AND toDayOfMonth(release_date) BETWEEN 1 AND 7 
             AND formatDateTime(release_date,'%A')='Monday'             THEN 'Labor Day (US)'
        WHEN toMonth(release_date)=10 AND toDayOfMonth(release_date)=31 THEN 'Halloween'
        WHEN toMonth(release_date)=11 AND formatDateTime(release_date,'%A')='Thursday'
             AND toISOWeek(release_date) >= 47                           THEN 'Thanksgiving'
        WHEN toMonth(release_date)=12 AND toDayOfMonth(release_date)=24 THEN 'Christmas Eve'
        WHEN toMonth(release_date)=12 AND toDayOfMonth(release_date)=25 THEN 'Christmas Day'
        WHEN toMonth(release_date)=12 AND toDayOfMonth(release_date)=31 THEN 'New Year\'s Eve'
        ELSE NULL
    END                                                         AS holiday_name,
    IF(holiday_name IS NOT NULL, 1, 0)                          AS is_holiday,

    /* placeholders for later enhancement */
    NULL                                                        AS days_until_holiday,
    NULL                                                        AS days_after_holiday
FROM distinct_dates
ORDER BY release_date;
          )
        
        
[0m10:08:29.047159 [debug] [Thread-1 (]: Database Error in model dim_release_date (models/gold/dim_release_date.sql)
  :HTTPDriver for http://clickhouse-server:8123 returned response code 400)
   Code: 62. DB::Exception: Syntax error: failed at position 3753 (end of query) (line 76, col 22): ;
            )
          
          . Expected one of: token sequence, Dot, token, OR, AND, IS NOT DISTINCT FROM, IS NULL, IS NOT NULL, BETWEEN, NOT BETWEEN, LIKE, ILIKE, NOT LIKE, NOT ILIKE, REGEXP, IN, NOT IN, GLOBAL IN, GLOBAL NOT IN, MOD, DIV, alias, AS, DESCENDING, DESC, ASCENDING, ASC, NULLS, COLLATE, WITH FILL, Comma, LIMIT, OFFSET, FETCH, SETTINGS, UNION, EXCEPT, INTERSECT. (SYNTAX_ERROR) (version 25.9.3.48 (official build))
[0m10:08:29.047436 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2f9c2fff-4f8f-42f0-85a6-03b595e4a034', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff439a7750>]}
[0m10:08:29.047760 [error] [Thread-1 (]: 5 of 6 ERROR creating sql table model `gold_gold`.`dim_release_date` ........... [[31mERROR[0m in 0.01s]
[0m10:08:29.048050 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.dim_release_date
[0m10:08:29.049602 [debug] [Thread-1 (]: Began running node model.movie_warehouse.fact_movie
[0m10:08:29.049891 [info ] [Thread-1 (]: 6 of 6 SKIP relation gold_gold.fact_movie ...................................... [[33mSKIP[0m]
[0m10:08:29.050165 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.fact_movie
[0m10:08:29.051617 [debug] [MainThread]: Connection 'master' was properly closed.
[0m10:08:29.051892 [debug] [MainThread]: Connection 'model.movie_warehouse.dim_release_date' was left open.
[0m10:08:29.052148 [debug] [MainThread]: On model.movie_warehouse.dim_release_date: Close
[0m10:08:29.052994 [info ] [MainThread]: 
[0m10:08:29.053252 [info ] [MainThread]: Finished running 6 table models in 0 hours 0 minutes and 6.18 seconds (6.18s).
[0m10:08:29.053956 [debug] [MainThread]: Command end result
[0m10:08:29.091347 [info ] [MainThread]: 
[0m10:08:29.091817 [info ] [MainThread]: [31mCompleted with 3 errors and 0 warnings:[0m
[0m10:08:29.092038 [info ] [MainThread]: 
[0m10:08:29.092366 [error] [MainThread]:   Database Error in model dim_movie (models/gold/dim_movie.sql)
  :HTTPDriver for http://clickhouse-server:8123 returned response code 400)
   Code: 62. DB::Exception: Syntax error: failed at position 718 (end of query) (line 32, col 24): ;
            )
          
          . Expected one of: OR, AND, IS NOT DISTINCT FROM, IS NULL, IS NOT NULL, BETWEEN, NOT BETWEEN, LIKE, ILIKE, NOT LIKE, NOT ILIKE, REGEXP, IN, NOT IN, GLOBAL IN, GLOBAL NOT IN, MOD, DIV, alias, AS, GROUP BY, WITH, HAVING, WINDOW, QUALIFY, ORDER BY, LIMIT, OFFSET, FETCH, SETTINGS, UNION, EXCEPT, INTERSECT. (SYNTAX_ERROR) (version 25.9.3.48 (official build))
[0m10:08:29.092586 [info ] [MainThread]: 
[0m10:08:29.092832 [error] [MainThread]:   Database Error in model dim_production (models/gold/dim_production.sql)
  :HTTPDriver for http://clickhouse-server:8123 returned response code 400)
   Code: 62. DB::Exception: Syntax error: failed at position 1026 (end of query) (line 42, col 34): ;
            )
          
          . Expected one of: OR, AND, IS NOT DISTINCT FROM, IS NULL, IS NOT NULL, BETWEEN, NOT BETWEEN, LIKE, ILIKE, NOT LIKE, NOT ILIKE, REGEXP, IN, NOT IN, GLOBAL IN, GLOBAL NOT IN, MOD, DIV, alias, AS, GROUP BY, WITH, HAVING, WINDOW, QUALIFY, ORDER BY, LIMIT, OFFSET, FETCH, SETTINGS, UNION, EXCEPT, INTERSECT. (SYNTAX_ERROR) (version 25.9.3.48 (official build))
[0m10:08:29.093109 [info ] [MainThread]: 
[0m10:08:29.093332 [error] [MainThread]:   Database Error in model dim_release_date (models/gold/dim_release_date.sql)
  :HTTPDriver for http://clickhouse-server:8123 returned response code 400)
   Code: 62. DB::Exception: Syntax error: failed at position 3753 (end of query) (line 76, col 22): ;
            )
          
          . Expected one of: token sequence, Dot, token, OR, AND, IS NOT DISTINCT FROM, IS NULL, IS NOT NULL, BETWEEN, NOT BETWEEN, LIKE, ILIKE, NOT LIKE, NOT ILIKE, REGEXP, IN, NOT IN, GLOBAL IN, GLOBAL NOT IN, MOD, DIV, alias, AS, DESCENDING, DESC, ASCENDING, ASC, NULLS, COLLATE, WITH FILL, Comma, LIMIT, OFFSET, FETCH, SETTINGS, UNION, EXCEPT, INTERSECT. (SYNTAX_ERROR) (version 25.9.3.48 (official build))
[0m10:08:29.093550 [info ] [MainThread]: 
[0m10:08:29.093794 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=3 SKIP=1 TOTAL=6
[0m10:08:29.096359 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 6.767777, "process_in_blocks": "736", "process_kernel_time": 0.441627, "process_mem_max_rss": "192588", "process_out_blocks": "3431", "process_user_time": 2.279301}
[0m10:08:29.097280 [debug] [MainThread]: Command `dbt run` failed at 10:08:29.097209 after 6.77 seconds
[0m10:08:29.097906 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8856f5d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8853e490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8853dfd0>]}
[0m10:08:29.098198 [debug] [MainThread]: Flushing usage events
[0m10:22:58.511637 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff999fd610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff99a2f910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff99dbeb90>]}


============================== 10:22:58.515566 | e88a6afc-4e86-4bc9-8500-d10ae251d8f1 ==============================
[0m10:22:58.515566 [info ] [MainThread]: Running with dbt=1.8.9
[0m10:22:58.515919 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'debug': 'False', 'log_path': '/opt/airflow/project_root/dbt/logs', 'fail_fast': 'False', 'profiles_dir': '/opt/airflow/project_root/dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'invocation_command': 'dbt run --project-dir /opt/airflow/project_root/dbt --profiles-dir /opt/airflow/project_root/dbt --select gold', 'static_parser': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m10:22:58.611065 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'e88a6afc-4e86-4bc9-8500-d10ae251d8f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff99a5ba50>]}
[0m10:22:58.633837 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'e88a6afc-4e86-4bc9-8500-d10ae251d8f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff9a42b390>]}
[0m10:22:58.634488 [info ] [MainThread]: Registered adapter: clickhouse=1.8.9
[0m10:22:58.666625 [debug] [MainThread]: checksum: 132857a23e9d07220246854f7763165174ce9b737cfc7867629ace4294e520b1, vars: {}, profile: , target: , version: 1.8.9
[0m10:22:58.721580 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 4 files changed.
[0m10:22:58.721990 [debug] [MainThread]: Partial parsing: updated file: movie_warehouse://models/gold/dim_movie.sql
[0m10:22:58.722247 [debug] [MainThread]: Partial parsing: updated file: movie_warehouse://models/gold/dim_release_date.sql
[0m10:22:58.722471 [debug] [MainThread]: Partial parsing: updated file: movie_warehouse://models/gold/dim_production.sql
[0m10:22:58.722688 [debug] [MainThread]: Partial parsing: updated file: movie_warehouse://models/gold/fact_movie.sql
[0m10:22:58.812797 [warn ] [MainThread]: [[33mWARNING[0m]: Deprecated functionality
The `tests` config has been renamed to `data_tests`. Please see
https://docs.getdbt.com/docs/build/data-tests#new-data_tests-syntax for more
information.
[0m10:22:58.813343 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'deprecation', 'label': 'e88a6afc-4e86-4bc9-8500-d10ae251d8f1', 'property_': 'warn', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff99a39910>]}
[0m10:22:58.882399 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.movie_warehouse.bronze
[0m10:22:58.887510 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'e88a6afc-4e86-4bc9-8500-d10ae251d8f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff993d8750>]}
[0m10:22:58.973000 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'e88a6afc-4e86-4bc9-8500-d10ae251d8f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff9943c050>]}
[0m10:22:58.973424 [info ] [MainThread]: Found 6 models, 12 data tests, 4 sources, 476 macros
[0m10:22:58.973727 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'e88a6afc-4e86-4bc9-8500-d10ae251d8f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff984bca10>]}
[0m10:22:58.974604 [info ] [MainThread]: 
[0m10:22:58.974899 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m10:22:58.977534 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m10:22:58.981900 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:22:59.288933 [info ] [ThreadPool]: dbt_clickhouse adapter: Unexpected server exception dropping table
[0m10:22:59.289513 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m10:22:59.292786 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m10:22:59.319988 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__gold_gold)
[0m10:22:59.323892 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__gold_gold: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "connection_name": "list__gold_gold"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'gold_gold'
      

  ...
[0m10:22:59.337247 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m10:22:59.339150 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'e88a6afc-4e86-4bc9-8500-d10ae251d8f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff90282110>]}
[0m10:22:59.339587 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m10:22:59.339918 [info ] [MainThread]: 
[0m10:22:59.344914 [debug] [Thread-1 (]: Began running node model.movie_warehouse.dim_director
[0m10:22:59.345313 [info ] [Thread-1 (]: 1 of 6 START sql table model `gold_gold`.`dim_director` ........................ [RUN]
[0m10:22:59.345610 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list__gold_gold, now model.movie_warehouse.dim_director)
[0m10:22:59.345838 [debug] [Thread-1 (]: Began compiling node model.movie_warehouse.dim_director
[0m10:22:59.349575 [debug] [Thread-1 (]: Writing injected SQL for node "model.movie_warehouse.dim_director"
[0m10:22:59.350723 [debug] [Thread-1 (]: Began executing node model.movie_warehouse.dim_director
[0m10:22:59.376272 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_director: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_director"} */

            

    
        create table `gold_gold`.`dim_director__dbt_backup`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

WITH first_dir AS (
    SELECT
        tconst,
        TRIM(splitByChar(',', directors)[1]) AS director_id
    FROM `bronze`.`imdb_title_crew_raw`
    WHERE directors IS NOT NULL AND directors != ''
),
deduped AS (
    SELECT DISTINCT director_id
    FROM first_dir
),
joined AS (
    SELECT
        d.director_id AS dir_id,
        n.primaryName AS dir_name
    FROM deduped d
    LEFT JOIN `bronze`.`imdb_name_basics_raw` n
        ON d.director_id = n.nconst
)
SELECT
    cityHash64(dir_id) AS imdb_dir_name_id,  -- Use hash instead of row_number
    dir_id,
    dir_name,
    today() AS valid_from,
    CAST(NULL AS Nullable(Date)) AS valid_to,
    1 AS is_current  -- Use 1/0 instead of TRUE/FALSE
FROM joined
WHERE dir_id IS NOT NULL
ORDER BY dir_id
          )
        
        ...
[0m10:22:59.385583 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m10:22:59.393617 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_director: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_director"} */

    select name, type from system.columns where table = 'dim_director__dbt_backup'
    
      and database = 'gold_gold'
    
    order by position
  ...
[0m10:22:59.396774 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m10:22:59.398564 [debug] [Thread-1 (]: Writing runtime sql for node "model.movie_warehouse.dim_director"
[0m10:22:59.399190 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_director: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_director"} */

  
    
    
    
        
         


        insert into `gold_gold`.`dim_director__dbt_backup`
        ("imdb_dir_name_id", "dir_id", "dir_name", "valid_from", "valid_to", "is_current")

WITH first_dir AS (
    SELECT
        tconst,
        TRIM(splitByChar(',', directors)[1]) AS director_id
    FROM `bronze`.`imdb_title_crew_raw`
    WHERE directors IS NOT NULL AND directors != ''
),
deduped AS (
    SELECT DISTINCT director_id
    FROM first_dir
),
joined AS (
    SELECT
        d.director_id AS dir_id,
        n.primaryName AS dir_name
    FROM deduped d
    LEFT JOIN `bronze`.`imdb_name_basics_raw` n
        ON d.director_id = n.nconst
)
SELECT
    cityHash64(dir_id) AS imdb_dir_name_id,  -- Use hash instead of row_number
    dir_id,
    dir_name,
    today() AS valid_from,
    CAST(NULL AS Nullable(Date)) AS valid_to,
    1 AS is_current  -- Use 1/0 instead of TRUE/FALSE
FROM joined
WHERE dir_id IS NOT NULL
ORDER BY dir_id
  ...
[0m10:23:02.174840 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 2.77 seconds
[0m10:23:02.196820 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_director: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_director"} */
EXCHANGE TABLES `gold_gold`.`dim_director__dbt_backup` AND `gold_gold`.`dim_director` 
  
  ...
[0m10:23:02.222520 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m10:23:02.255409 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_director: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_director"} */

    drop table if exists `gold_gold`.`dim_director__dbt_backup` 
  ...
[0m10:23:02.259024 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_director"} */

    drop table if exists `gold_gold`.`dim_director__dbt_backup` 
  
[0m10:23:02.259450 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: macro drop_relation
[0m10:23:02.265917 [debug] [Thread-1 (]: Database Error in model dim_director (models/gold/dim_director.sql)
  :HTTPDriver for http://clickhouse-server:8123 returned response code 500)
   std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/7ed/7ed8fa57-801a-472b-9299-fbe3e4b13276/dim_director__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/gold_gold.dim_director__dbt_backup.da56fd8b-35dc-4461-9635-41657caaf5c4.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build))
  compiled code at target/run/movie_warehouse/models/gold/dim_director.sql
[0m10:23:02.270063 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e88a6afc-4e86-4bc9-8500-d10ae251d8f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff58e7eed0>]}
[0m10:23:02.271119 [error] [Thread-1 (]: 1 of 6 ERROR creating sql table model `gold_gold`.`dim_director` ............... [[31mERROR[0m in 2.92s]
[0m10:23:02.271850 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.dim_director
[0m10:23:02.272327 [debug] [Thread-1 (]: Began running node model.movie_warehouse.dim_genre
[0m10:23:02.274254 [info ] [Thread-1 (]: 2 of 6 START sql table model `gold_gold`.`dim_genre` ........................... [RUN]
[0m10:23:02.274665 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.movie_warehouse.dim_director, now model.movie_warehouse.dim_genre)
[0m10:23:02.274913 [debug] [Thread-1 (]: Began compiling node model.movie_warehouse.dim_genre
[0m10:23:02.277567 [debug] [Thread-1 (]: Writing injected SQL for node "model.movie_warehouse.dim_genre"
[0m10:23:02.278526 [debug] [Thread-1 (]: Began executing node model.movie_warehouse.dim_genre
[0m10:23:02.280531 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_genre: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_genre"} */

            

    
        create table `gold_gold`.`dim_genre__dbt_backup`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

WITH parsed_genres AS (
    SELECT
        TRIM(splitByChar(',', genres)[1]) AS first_genre
    FROM `bronze`.`tmdb_raw`
    WHERE genres IS NOT NULL AND genres != ''
)
SELECT
    cityHash64(first_genre) AS genre_id,
    first_genre AS genre_name
FROM parsed_genres
GROUP BY first_genre
ORDER BY first_genre
          )
        
        ...
[0m10:23:02.297043 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m10:23:02.298773 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_genre: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_genre"} */

    select name, type from system.columns where table = 'dim_genre__dbt_backup'
    
      and database = 'gold_gold'
    
    order by position
  ...
[0m10:23:02.302570 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m10:23:02.304063 [debug] [Thread-1 (]: Writing runtime sql for node "model.movie_warehouse.dim_genre"
[0m10:23:02.304880 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_genre: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_genre"} */

  
    
    
    
        
         


        insert into `gold_gold`.`dim_genre__dbt_backup`
        ("genre_id", "genre_name")

WITH parsed_genres AS (
    SELECT
        TRIM(splitByChar(',', genres)[1]) AS first_genre
    FROM `bronze`.`tmdb_raw`
    WHERE genres IS NOT NULL AND genres != ''
)
SELECT
    cityHash64(first_genre) AS genre_id,
    first_genre AS genre_name
FROM parsed_genres
GROUP BY first_genre
ORDER BY first_genre
  ...
[0m10:23:02.333845 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.03 seconds
[0m10:23:02.334725 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_genre: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_genre"} */
EXCHANGE TABLES `gold_gold`.`dim_genre__dbt_backup` AND `gold_gold`.`dim_genre` 
  
  ...
[0m10:23:02.337702 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m10:23:02.339625 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_genre: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_genre"} */

    drop table if exists `gold_gold`.`dim_genre__dbt_backup` 
  ...
[0m10:23:02.343223 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_genre"} */

    drop table if exists `gold_gold`.`dim_genre__dbt_backup` 
  
[0m10:23:02.343587 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: macro drop_relation
[0m10:23:02.345940 [debug] [Thread-1 (]: Database Error in model dim_genre (models/gold/dim_genre.sql)
  :HTTPDriver for http://clickhouse-server:8123 returned response code 500)
   std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/7ed/7ed8fa57-801a-472b-9299-fbe3e4b13276/dim_genre__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/gold_gold.dim_genre__dbt_backup.dd7fd47a-7c7e-4b23-ad95-7f11a7bbc5c5.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build))
  compiled code at target/run/movie_warehouse/models/gold/dim_genre.sql
[0m10:23:02.346532 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e88a6afc-4e86-4bc9-8500-d10ae251d8f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff98322ad0>]}
[0m10:23:02.346935 [error] [Thread-1 (]: 2 of 6 ERROR creating sql table model `gold_gold`.`dim_genre` .................. [[31mERROR[0m in 0.07s]
[0m10:23:02.347288 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.dim_genre
[0m10:23:02.347861 [debug] [Thread-1 (]: Began running node model.movie_warehouse.dim_movie
[0m10:23:02.349068 [info ] [Thread-1 (]: 3 of 6 START sql table model `gold_gold`.`dim_movie` ........................... [RUN]
[0m10:23:02.349433 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.movie_warehouse.dim_genre, now model.movie_warehouse.dim_movie)
[0m10:23:02.349687 [debug] [Thread-1 (]: Began compiling node model.movie_warehouse.dim_movie
[0m10:23:02.351898 [debug] [Thread-1 (]: Writing injected SQL for node "model.movie_warehouse.dim_movie"
[0m10:23:02.352628 [debug] [Thread-1 (]: Began executing node model.movie_warehouse.dim_movie
[0m10:23:02.354056 [debug] [Thread-1 (]: Creating new relation dim_movie
[0m10:23:02.354722 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_movie: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_movie"} */

            

    
        create table `gold_gold`.`dim_movie`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            -- ...existing code...


WITH movie_src AS (
    SELECT
        TRIM(title) AS movie_title,
        imdb_id,
        release_date,
        runtime AS movie_runtime,
        original_language AS language
    FROM `bronze`.`tmdb_raw`
    WHERE title IS NOT NULL AND title != ''
)
SELECT
    cityHash64(movie_title) AS movie_id,
    any(imdb_id) AS imdb_id,
    movie_title,
    any(release_date) AS release_date,
    any(movie_runtime) AS movie_runtime,
    any(language) AS language
FROM movie_src
GROUP BY movie_title
ORDER BY movie_title
          )
        
        ...
[0m10:23:02.362527 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m10:23:02.364296 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_movie: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_movie"} */

    select name, type from system.columns where table = 'dim_movie'
    
      and database = 'gold_gold'
    
    order by position
  ...
[0m10:23:02.367740 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m10:23:02.368959 [debug] [Thread-1 (]: Writing runtime sql for node "model.movie_warehouse.dim_movie"
[0m10:23:02.369609 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_movie: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_movie"} */

  
    
    
    
        
         


        insert into `gold_gold`.`dim_movie`
        ("movie_id", "imdb_id", "movie_title", "release_date", "movie_runtime", "language")-- ...existing code...


WITH movie_src AS (
    SELECT
        TRIM(title) AS movie_title,
        imdb_id,
        release_date,
        runtime AS movie_runtime,
        original_language AS language
    FROM `bronze`.`tmdb_raw`
    WHERE title IS NOT NULL AND title != ''
)
SELECT
    cityHash64(movie_title) AS movie_id,
    any(imdb_id) AS imdb_id,
    movie_title,
    any(release_date) AS release_date,
    any(movie_runtime) AS movie_runtime,
    any(language) AS language
FROM movie_src
GROUP BY movie_title
ORDER BY movie_title
  ...
[0m10:23:02.648548 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.28 seconds
[0m10:23:02.650896 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e88a6afc-4e86-4bc9-8500-d10ae251d8f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff58e7c710>]}
[0m10:23:02.651334 [info ] [Thread-1 (]: 3 of 6 OK created sql table model `gold_gold`.`dim_movie` ...................... [[32mOK[0m in 0.30s]
[0m10:23:02.651692 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.dim_movie
[0m10:23:02.651973 [debug] [Thread-1 (]: Began running node model.movie_warehouse.dim_production
[0m10:23:02.652343 [info ] [Thread-1 (]: 4 of 6 START sql table model `gold_gold`.`dim_production` ...................... [RUN]
[0m10:23:02.652597 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.movie_warehouse.dim_movie, now model.movie_warehouse.dim_production)
[0m10:23:02.652818 [debug] [Thread-1 (]: Began compiling node model.movie_warehouse.dim_production
[0m10:23:02.655051 [debug] [Thread-1 (]: Writing injected SQL for node "model.movie_warehouse.dim_production"
[0m10:23:02.655706 [debug] [Thread-1 (]: Began executing node model.movie_warehouse.dim_production
[0m10:23:02.656783 [debug] [Thread-1 (]: Creating new relation dim_production
[0m10:23:02.657485 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_production: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_production"} */

            

    
        create table `gold_gold`.`dim_production`
        
  
        
  engine = MergeTree()
        order by (production_id)
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

WITH first_production AS (
    SELECT
        id AS movie_id,
        trim(splitByChar(',', production_companies)[1]) AS production_name
    FROM `bronze`.`tmdb_raw`
    WHERE production_companies IS NOT NULL AND production_companies != ''
)

SELECT
    cityHash64(production_name) AS production_id,
    production_name,
    current_date() AS valid_from,
    NULL AS valid_to,
    TRUE AS is_current
FROM (
    SELECT DISTINCT production_name
    FROM first_production
)
WHERE production_name IS NOT NULL;
          )
        
        ...
[0m10:23:02.669311 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_production"} */

            

    
        create table `gold_gold`.`dim_production`
        
  
        
  engine = MergeTree()
        order by (production_id)
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

WITH first_production AS (
    SELECT
        id AS movie_id,
        trim(splitByChar(',', production_companies)[1]) AS production_name
    FROM `bronze`.`tmdb_raw`
    WHERE production_companies IS NOT NULL AND production_companies != ''
)

SELECT
    cityHash64(production_name) AS production_id,
    production_name,
    current_date() AS valid_from,
    NULL AS valid_to,
    TRUE AS is_current
FROM (
    SELECT DISTINCT production_name
    FROM first_production
)
WHERE production_name IS NOT NULL;
          )
        
        
[0m10:23:02.671549 [debug] [Thread-1 (]: Database Error in model dim_production (models/gold/dim_production.sql)
  :HTTPDriver for http://clickhouse-server:8123 returned response code 400)
   Code: 62. DB::Exception: Syntax error: failed at position 1009 (end of query) (line 42, col 34): ;
            )
          
          . Expected one of: OR, AND, IS NOT DISTINCT FROM, IS NULL, IS NOT NULL, BETWEEN, NOT BETWEEN, LIKE, ILIKE, NOT LIKE, NOT ILIKE, REGEXP, IN, NOT IN, GLOBAL IN, GLOBAL NOT IN, MOD, DIV, alias, AS, GROUP BY, WITH, HAVING, WINDOW, QUALIFY, ORDER BY, LIMIT, OFFSET, FETCH, SETTINGS, UNION, EXCEPT, INTERSECT. (SYNTAX_ERROR) (version 25.9.3.48 (official build))
[0m10:23:02.671821 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e88a6afc-4e86-4bc9-8500-d10ae251d8f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff58fea4d0>]}
[0m10:23:02.672139 [error] [Thread-1 (]: 4 of 6 ERROR creating sql table model `gold_gold`.`dim_production` ............. [[31mERROR[0m in 0.02s]
[0m10:23:02.672478 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.dim_production
[0m10:23:02.672710 [debug] [Thread-1 (]: Began running node model.movie_warehouse.dim_release_date
[0m10:23:02.673032 [info ] [Thread-1 (]: 5 of 6 START sql table model `gold_gold`.`dim_release_date` .................... [RUN]
[0m10:23:02.673291 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.movie_warehouse.dim_production, now model.movie_warehouse.dim_release_date)
[0m10:23:02.673488 [debug] [Thread-1 (]: Began compiling node model.movie_warehouse.dim_release_date
[0m10:23:02.676227 [debug] [Thread-1 (]: Writing injected SQL for node "model.movie_warehouse.dim_release_date"
[0m10:23:02.676788 [debug] [Thread-1 (]: Began executing node model.movie_warehouse.dim_release_date
[0m10:23:02.677772 [debug] [Thread-1 (]: Creating new relation dim_release_date
[0m10:23:02.678376 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_release_date: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_release_date"} */

            

    
        create table `gold_gold`.`dim_release_date`
        
  
        
  engine = MergeTree()
        order by (date_id)
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

WITH distinct_dates AS (
    SELECT DISTINCT release_date
    FROM `bronze`.`tmdb_raw`
    WHERE release_date IS NOT NULL
)

SELECT
    cityHash64(release_date)                                    AS date_id,
    release_date                                                AS full_date,
    toYear(release_date)                                        AS year,
    toMonth(release_date)                                       AS month,
    toDayOfMonth(release_date)                                  AS day,
    toISOWeek(release_date)                                     AS week,
    formatDateTime(release_date, '%A')                          AS weekday,
    CASE
        WHEN toMonth(release_date) IN (12,1,2)  THEN 'Winter'
        WHEN toMonth(release_date) IN (3,4,5)   THEN 'Spring'
        WHEN toMonth(release_date) IN (6,7,8)   THEN 'Summer'
        WHEN toMonth(release_date) IN (9,10,11) THEN 'Autumn'
    END                                                         AS season,
    CASE
        WHEN formatDateTime(release_date, '%A') IN ('Saturday','Sunday') THEN 1
        ELSE 0
    END                                                         AS is_weekend,

    /* ---------- holiday tagging ---------- */
    CASE
        WHEN toMonth(release_date)=1  AND toDayOfMonth(release_date)=1  THEN 'New Year\'s Day'
        WHEN toMonth(release_date)=2  AND toDayOfMonth(release_date)=14 THEN 'Valentine\'s Day'
        WHEN toMonth(release_date)=3  AND toDayOfMonth(release_date)=17 THEN 'St. Patrick\'s Day'
        WHEN toMonth(release_date)=4  AND toDayOfMonth(release_date)=1  THEN 'April Fool\'s Day'
        WHEN toMonth(release_date)=4  AND toDayOfMonth(release_date)=22 THEN 'Earth Day'
        WHEN toMonth(release_date)=5  AND toDayOfMonth(release_date)=1  THEN 'May Day'
        WHEN toMonth(release_date)=5  AND toDayOfMonth(release_date)=5  THEN 'Cinco de Mayo'
        WHEN toMonth(release_date)=6  AND toDayOfMonth(release_date) BETWEEN 19 AND 26 THEN 'Midsummer'
        WHEN toMonth(release_date)=7  AND toDayOfMonth(release_date)=4  THEN 'Independence Day'
        WHEN toMonth(release_date)=9  AND toDayOfMonth(release_date) BETWEEN 1 AND 7 
             AND formatDateTime(release_date,'%A')='Monday'             THEN 'Labor Day (US)'
        WHEN toMonth(release_date)=10 AND toDayOfMonth(release_date)=31 THEN 'Halloween'
        WHEN toMonth(release_date)=11 AND formatDateTime(release_date,'%A')='Thursday'
             AND toISOWeek(release_date) >= 47                           THEN 'Thanksgiving'
        WHEN toMonth(release_date)=12 AND toDayOfMonth(release_date)=24 THEN 'Christmas Eve'
        WHEN toMonth(release_date)=12 AND toDayOfMonth(release_date)=25 THEN 'Christmas Day'
        WHEN toMonth(release_date)=12 AND toDayOfMonth(release_date)=31 THEN 'New Year\'s Eve'
        ELSE NULL
    END                                                         AS holiday_name,
    IF(holiday_name IS NOT NULL, 1, 0)                          AS is_holiday,

    /* placeholders for later enhancement */
    NULL                                                        AS days_until_holiday,
    NULL                                                        AS days_after_holiday
FROM distinct_dates
ORDER BY release_date;
          )
        
        ...
[0m10:23:02.681618 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_release_date"} */

            

    
        create table `gold_gold`.`dim_release_date`
        
  
        
  engine = MergeTree()
        order by (date_id)
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

WITH distinct_dates AS (
    SELECT DISTINCT release_date
    FROM `bronze`.`tmdb_raw`
    WHERE release_date IS NOT NULL
)

SELECT
    cityHash64(release_date)                                    AS date_id,
    release_date                                                AS full_date,
    toYear(release_date)                                        AS year,
    toMonth(release_date)                                       AS month,
    toDayOfMonth(release_date)                                  AS day,
    toISOWeek(release_date)                                     AS week,
    formatDateTime(release_date, '%A')                          AS weekday,
    CASE
        WHEN toMonth(release_date) IN (12,1,2)  THEN 'Winter'
        WHEN toMonth(release_date) IN (3,4,5)   THEN 'Spring'
        WHEN toMonth(release_date) IN (6,7,8)   THEN 'Summer'
        WHEN toMonth(release_date) IN (9,10,11) THEN 'Autumn'
    END                                                         AS season,
    CASE
        WHEN formatDateTime(release_date, '%A') IN ('Saturday','Sunday') THEN 1
        ELSE 0
    END                                                         AS is_weekend,

    /* ---------- holiday tagging ---------- */
    CASE
        WHEN toMonth(release_date)=1  AND toDayOfMonth(release_date)=1  THEN 'New Year\'s Day'
        WHEN toMonth(release_date)=2  AND toDayOfMonth(release_date)=14 THEN 'Valentine\'s Day'
        WHEN toMonth(release_date)=3  AND toDayOfMonth(release_date)=17 THEN 'St. Patrick\'s Day'
        WHEN toMonth(release_date)=4  AND toDayOfMonth(release_date)=1  THEN 'April Fool\'s Day'
        WHEN toMonth(release_date)=4  AND toDayOfMonth(release_date)=22 THEN 'Earth Day'
        WHEN toMonth(release_date)=5  AND toDayOfMonth(release_date)=1  THEN 'May Day'
        WHEN toMonth(release_date)=5  AND toDayOfMonth(release_date)=5  THEN 'Cinco de Mayo'
        WHEN toMonth(release_date)=6  AND toDayOfMonth(release_date) BETWEEN 19 AND 26 THEN 'Midsummer'
        WHEN toMonth(release_date)=7  AND toDayOfMonth(release_date)=4  THEN 'Independence Day'
        WHEN toMonth(release_date)=9  AND toDayOfMonth(release_date) BETWEEN 1 AND 7 
             AND formatDateTime(release_date,'%A')='Monday'             THEN 'Labor Day (US)'
        WHEN toMonth(release_date)=10 AND toDayOfMonth(release_date)=31 THEN 'Halloween'
        WHEN toMonth(release_date)=11 AND formatDateTime(release_date,'%A')='Thursday'
             AND toISOWeek(release_date) >= 47                           THEN 'Thanksgiving'
        WHEN toMonth(release_date)=12 AND toDayOfMonth(release_date)=24 THEN 'Christmas Eve'
        WHEN toMonth(release_date)=12 AND toDayOfMonth(release_date)=25 THEN 'Christmas Day'
        WHEN toMonth(release_date)=12 AND toDayOfMonth(release_date)=31 THEN 'New Year\'s Eve'
        ELSE NULL
    END                                                         AS holiday_name,
    IF(holiday_name IS NOT NULL, 1, 0)                          AS is_holiday,

    /* placeholders for later enhancement */
    NULL                                                        AS days_until_holiday,
    NULL                                                        AS days_after_holiday
FROM distinct_dates
ORDER BY release_date;
          )
        
        
[0m10:23:02.684027 [debug] [Thread-1 (]: Database Error in model dim_release_date (models/gold/dim_release_date.sql)
  :HTTPDriver for http://clickhouse-server:8123 returned response code 400)
   Code: 62. DB::Exception: Syntax error: failed at position 3753 (end of query) (line 76, col 22): ;
            )
          
          . Expected one of: token sequence, Dot, token, OR, AND, IS NOT DISTINCT FROM, IS NULL, IS NOT NULL, BETWEEN, NOT BETWEEN, LIKE, ILIKE, NOT LIKE, NOT ILIKE, REGEXP, IN, NOT IN, GLOBAL IN, GLOBAL NOT IN, MOD, DIV, alias, AS, DESCENDING, DESC, ASCENDING, ASC, NULLS, COLLATE, WITH FILL, Comma, LIMIT, OFFSET, FETCH, SETTINGS, UNION, EXCEPT, INTERSECT. (SYNTAX_ERROR) (version 25.9.3.48 (official build))
[0m10:23:02.684287 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e88a6afc-4e86-4bc9-8500-d10ae251d8f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff585a0090>]}
[0m10:23:02.684595 [error] [Thread-1 (]: 5 of 6 ERROR creating sql table model `gold_gold`.`dim_release_date` ........... [[31mERROR[0m in 0.01s]
[0m10:23:02.684855 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.dim_release_date
[0m10:23:02.686852 [debug] [Thread-1 (]: Began running node model.movie_warehouse.fact_movie
[0m10:23:02.687235 [info ] [Thread-1 (]: 6 of 6 SKIP relation gold_gold.fact_movie ...................................... [[33mSKIP[0m]
[0m10:23:02.687562 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.fact_movie
[0m10:23:02.688844 [debug] [MainThread]: Connection 'master' was properly closed.
[0m10:23:02.689116 [debug] [MainThread]: Connection 'model.movie_warehouse.dim_release_date' was left open.
[0m10:23:02.689343 [debug] [MainThread]: On model.movie_warehouse.dim_release_date: Close
[0m10:23:02.690034 [info ] [MainThread]: 
[0m10:23:02.690282 [info ] [MainThread]: Finished running 6 table models in 0 hours 0 minutes and 3.72 seconds (3.72s).
[0m10:23:02.690972 [debug] [MainThread]: Command end result
[0m10:23:02.717972 [info ] [MainThread]: 
[0m10:23:02.718355 [info ] [MainThread]: [31mCompleted with 4 errors and 0 warnings:[0m
[0m10:23:02.718570 [info ] [MainThread]: 
[0m10:23:02.718826 [error] [MainThread]:   Database Error in model dim_director (models/gold/dim_director.sql)
  :HTTPDriver for http://clickhouse-server:8123 returned response code 500)
   std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/7ed/7ed8fa57-801a-472b-9299-fbe3e4b13276/dim_director__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/gold_gold.dim_director__dbt_backup.da56fd8b-35dc-4461-9635-41657caaf5c4.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build))
  compiled code at target/run/movie_warehouse/models/gold/dim_director.sql
[0m10:23:02.719014 [info ] [MainThread]: 
[0m10:23:02.719217 [error] [MainThread]:   Database Error in model dim_genre (models/gold/dim_genre.sql)
  :HTTPDriver for http://clickhouse-server:8123 returned response code 500)
   std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/7ed/7ed8fa57-801a-472b-9299-fbe3e4b13276/dim_genre__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/gold_gold.dim_genre__dbt_backup.dd7fd47a-7c7e-4b23-ad95-7f11a7bbc5c5.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build))
  compiled code at target/run/movie_warehouse/models/gold/dim_genre.sql
[0m10:23:02.719382 [info ] [MainThread]: 
[0m10:23:02.719585 [error] [MainThread]:   Database Error in model dim_production (models/gold/dim_production.sql)
  :HTTPDriver for http://clickhouse-server:8123 returned response code 400)
   Code: 62. DB::Exception: Syntax error: failed at position 1009 (end of query) (line 42, col 34): ;
            )
          
          . Expected one of: OR, AND, IS NOT DISTINCT FROM, IS NULL, IS NOT NULL, BETWEEN, NOT BETWEEN, LIKE, ILIKE, NOT LIKE, NOT ILIKE, REGEXP, IN, NOT IN, GLOBAL IN, GLOBAL NOT IN, MOD, DIV, alias, AS, GROUP BY, WITH, HAVING, WINDOW, QUALIFY, ORDER BY, LIMIT, OFFSET, FETCH, SETTINGS, UNION, EXCEPT, INTERSECT. (SYNTAX_ERROR) (version 25.9.3.48 (official build))
[0m10:23:02.719760 [info ] [MainThread]: 
[0m10:23:02.719958 [error] [MainThread]:   Database Error in model dim_release_date (models/gold/dim_release_date.sql)
  :HTTPDriver for http://clickhouse-server:8123 returned response code 400)
   Code: 62. DB::Exception: Syntax error: failed at position 3753 (end of query) (line 76, col 22): ;
            )
          
          . Expected one of: token sequence, Dot, token, OR, AND, IS NOT DISTINCT FROM, IS NULL, IS NOT NULL, BETWEEN, NOT BETWEEN, LIKE, ILIKE, NOT LIKE, NOT ILIKE, REGEXP, IN, NOT IN, GLOBAL IN, GLOBAL NOT IN, MOD, DIV, alias, AS, DESCENDING, DESC, ASCENDING, ASC, NULLS, COLLATE, WITH FILL, Comma, LIMIT, OFFSET, FETCH, SETTINGS, UNION, EXCEPT, INTERSECT. (SYNTAX_ERROR) (version 25.9.3.48 (official build))
[0m10:23:02.720161 [info ] [MainThread]: 
[0m10:23:02.720403 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=4 SKIP=1 TOTAL=6
[0m10:23:02.722859 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 4.2316403, "process_in_blocks": "2320", "process_kernel_time": 0.424924, "process_mem_max_rss": "192604", "process_out_blocks": "3442", "process_user_time": 2.052444}
[0m10:23:02.723547 [debug] [MainThread]: Command `dbt run` failed at 10:23:02.723482 after 4.23 seconds
[0m10:23:02.724016 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff99a5b950>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff99a22110>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff9e8f9fd0>]}
[0m10:23:02.724271 [debug] [MainThread]: Flushing usage events
[0m10:36:48.648872 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffaaef0690>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffaaef1450>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffaaef0150>]}


============================== 10:36:48.653113 | 9f68526b-4be2-4346-9808-4ce4b12becdb ==============================
[0m10:36:48.653113 [info ] [MainThread]: Running with dbt=1.8.9
[0m10:36:48.653613 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/project_root/dbt', 'debug': 'False', 'warn_error': 'None', 'log_path': '/opt/airflow/project_root/dbt/logs', 'fail_fast': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'log_format': 'default', 'static_parser': 'True', 'target_path': 'None', 'invocation_command': 'dbt run --project-dir /opt/airflow/project_root/dbt --profiles-dir /opt/airflow/project_root/dbt --select gold', 'send_anonymous_usage_stats': 'True'}
[0m10:36:48.778330 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '9f68526b-4be2-4346-9808-4ce4b12becdb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffaaddaa90>]}
[0m10:36:48.797389 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '9f68526b-4be2-4346-9808-4ce4b12becdb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffab8dfc50>]}
[0m10:36:48.797934 [info ] [MainThread]: Registered adapter: clickhouse=1.8.9
[0m10:36:48.839337 [debug] [MainThread]: checksum: 132857a23e9d07220246854f7763165174ce9b737cfc7867629ace4294e520b1, vars: {}, profile: , target: , version: 1.8.9
[0m10:36:48.903799 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 2 files changed.
[0m10:36:48.904215 [debug] [MainThread]: Partial parsing: updated file: movie_warehouse://models/gold/dim_production.sql
[0m10:36:48.904447 [debug] [MainThread]: Partial parsing: updated file: movie_warehouse://models/gold/dim_release_date.sql
[0m10:36:48.990472 [warn ] [MainThread]: [[33mWARNING[0m]: Deprecated functionality
The `tests` config has been renamed to `data_tests`. Please see
https://docs.getdbt.com/docs/build/data-tests#new-data_tests-syntax for more
information.
[0m10:36:48.990911 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'deprecation', 'label': '9f68526b-4be2-4346-9808-4ce4b12becdb', 'property_': 'warn', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffacd22090>]}
[0m10:36:49.081977 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.movie_warehouse.bronze
[0m10:36:49.088796 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '9f68526b-4be2-4346-9808-4ce4b12becdb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffaadafed0>]}
[0m10:36:49.174779 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '9f68526b-4be2-4346-9808-4ce4b12becdb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffaa8a4310>]}
[0m10:36:49.175136 [info ] [MainThread]: Found 6 models, 12 data tests, 4 sources, 476 macros
[0m10:36:49.175397 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '9f68526b-4be2-4346-9808-4ce4b12becdb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa98e6790>]}
[0m10:36:49.176234 [info ] [MainThread]: 
[0m10:36:49.176537 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m10:36:49.179201 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m10:36:49.184766 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:36:49.597566 [info ] [ThreadPool]: dbt_clickhouse adapter: Unexpected server exception dropping table
[0m10:36:49.599617 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m10:36:49.605465 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m10:36:49.698203 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__gold_gold)
[0m10:36:49.702275 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__gold_gold: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "connection_name": "list__gold_gold"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'gold_gold'
      

  ...
[0m10:36:49.729927 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.03 seconds
[0m10:36:49.732393 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '9f68526b-4be2-4346-9808-4ce4b12becdb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff67a009d0>]}
[0m10:36:49.732898 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m10:36:49.733226 [info ] [MainThread]: 
[0m10:36:49.739099 [debug] [Thread-1 (]: Began running node model.movie_warehouse.dim_director
[0m10:36:49.739647 [info ] [Thread-1 (]: 1 of 6 START sql table model `gold_gold`.`dim_director` ........................ [RUN]
[0m10:36:49.740078 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list__gold_gold, now model.movie_warehouse.dim_director)
[0m10:36:49.740288 [debug] [Thread-1 (]: Began compiling node model.movie_warehouse.dim_director
[0m10:36:49.744045 [debug] [Thread-1 (]: Writing injected SQL for node "model.movie_warehouse.dim_director"
[0m10:36:49.745001 [debug] [Thread-1 (]: Began executing node model.movie_warehouse.dim_director
[0m10:36:49.769631 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_director: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_director"} */

            

    
        create table `gold_gold`.`dim_director__dbt_backup`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

WITH first_dir AS (
    SELECT
        tconst,
        TRIM(splitByChar(',', directors)[1]) AS director_id
    FROM `bronze`.`imdb_title_crew_raw`
    WHERE directors IS NOT NULL AND directors != ''
),
deduped AS (
    SELECT DISTINCT director_id
    FROM first_dir
),
joined AS (
    SELECT
        d.director_id AS dir_id,
        n.primaryName AS dir_name
    FROM deduped d
    LEFT JOIN `bronze`.`imdb_name_basics_raw` n
        ON d.director_id = n.nconst
)
SELECT
    cityHash64(dir_id) AS imdb_dir_name_id,  -- Use hash instead of row_number
    dir_id,
    dir_name,
    today() AS valid_from,
    CAST(NULL AS Nullable(Date)) AS valid_to,
    1 AS is_current  -- Use 1/0 instead of TRUE/FALSE
FROM joined
WHERE dir_id IS NOT NULL
ORDER BY dir_id
          )
        
        ...
[0m10:36:49.779915 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m10:36:49.787260 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_director: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_director"} */

    select name, type from system.columns where table = 'dim_director__dbt_backup'
    
      and database = 'gold_gold'
    
    order by position
  ...
[0m10:36:49.790872 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m10:36:49.792668 [debug] [Thread-1 (]: Writing runtime sql for node "model.movie_warehouse.dim_director"
[0m10:36:49.793453 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_director: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_director"} */

  
    
    
    
        
         


        insert into `gold_gold`.`dim_director__dbt_backup`
        ("imdb_dir_name_id", "dir_id", "dir_name", "valid_from", "valid_to", "is_current")

WITH first_dir AS (
    SELECT
        tconst,
        TRIM(splitByChar(',', directors)[1]) AS director_id
    FROM `bronze`.`imdb_title_crew_raw`
    WHERE directors IS NOT NULL AND directors != ''
),
deduped AS (
    SELECT DISTINCT director_id
    FROM first_dir
),
joined AS (
    SELECT
        d.director_id AS dir_id,
        n.primaryName AS dir_name
    FROM deduped d
    LEFT JOIN `bronze`.`imdb_name_basics_raw` n
        ON d.director_id = n.nconst
)
SELECT
    cityHash64(dir_id) AS imdb_dir_name_id,  -- Use hash instead of row_number
    dir_id,
    dir_name,
    today() AS valid_from,
    CAST(NULL AS Nullable(Date)) AS valid_to,
    1 AS is_current  -- Use 1/0 instead of TRUE/FALSE
FROM joined
WHERE dir_id IS NOT NULL
ORDER BY dir_id
  ...
[0m10:36:53.842493 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 4.05 seconds
[0m10:36:53.866626 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_director: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_director"} */
EXCHANGE TABLES `gold_gold`.`dim_director__dbt_backup` AND `gold_gold`.`dim_director` 
  
  ...
[0m10:36:53.878433 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m10:36:53.897348 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_director: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_director"} */

    drop table if exists `gold_gold`.`dim_director__dbt_backup` 
  ...
[0m10:36:53.900269 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_director"} */

    drop table if exists `gold_gold`.`dim_director__dbt_backup` 
  
[0m10:36:53.900576 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: macro drop_relation
[0m10:36:53.928393 [debug] [Thread-1 (]: Database Error in model dim_director (models/gold/dim_director.sql)
  :HTTPDriver for http://clickhouse-server:8123 returned response code 500)
   std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/7ed/7ed8fa57-801a-472b-9299-fbe3e4b13276/dim_director__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/gold_gold.dim_director__dbt_backup.a5927d9d-da32-4e3e-90b7-9177b31823d9.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build))
  compiled code at target/run/movie_warehouse/models/gold/dim_director.sql
[0m10:36:53.931603 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9f68526b-4be2-4346-9808-4ce4b12becdb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffaac30ad0>]}
[0m10:36:53.932684 [error] [Thread-1 (]: 1 of 6 ERROR creating sql table model `gold_gold`.`dim_director` ............... [[31mERROR[0m in 4.19s]
[0m10:36:53.933494 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.dim_director
[0m10:36:53.934055 [debug] [Thread-1 (]: Began running node model.movie_warehouse.dim_genre
[0m10:36:53.936138 [info ] [Thread-1 (]: 2 of 6 START sql table model `gold_gold`.`dim_genre` ........................... [RUN]
[0m10:36:53.936586 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.movie_warehouse.dim_director, now model.movie_warehouse.dim_genre)
[0m10:36:53.936842 [debug] [Thread-1 (]: Began compiling node model.movie_warehouse.dim_genre
[0m10:36:53.944383 [debug] [Thread-1 (]: Writing injected SQL for node "model.movie_warehouse.dim_genre"
[0m10:36:53.945464 [debug] [Thread-1 (]: Began executing node model.movie_warehouse.dim_genre
[0m10:36:53.947628 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_genre: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_genre"} */

            

    
        create table `gold_gold`.`dim_genre__dbt_backup`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

WITH parsed_genres AS (
    SELECT
        TRIM(splitByChar(',', genres)[1]) AS first_genre
    FROM `bronze`.`tmdb_raw`
    WHERE genres IS NOT NULL AND genres != ''
)
SELECT
    cityHash64(first_genre) AS genre_id,
    first_genre AS genre_name
FROM parsed_genres
GROUP BY first_genre
ORDER BY first_genre
          )
        
        ...
[0m10:36:53.958017 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m10:36:53.959699 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_genre: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_genre"} */

    select name, type from system.columns where table = 'dim_genre__dbt_backup'
    
      and database = 'gold_gold'
    
    order by position
  ...
[0m10:36:53.963057 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m10:36:53.964301 [debug] [Thread-1 (]: Writing runtime sql for node "model.movie_warehouse.dim_genre"
[0m10:36:53.965040 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_genre: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_genre"} */

  
    
    
    
        
         


        insert into `gold_gold`.`dim_genre__dbt_backup`
        ("genre_id", "genre_name")

WITH parsed_genres AS (
    SELECT
        TRIM(splitByChar(',', genres)[1]) AS first_genre
    FROM `bronze`.`tmdb_raw`
    WHERE genres IS NOT NULL AND genres != ''
)
SELECT
    cityHash64(first_genre) AS genre_id,
    first_genre AS genre_name
FROM parsed_genres
GROUP BY first_genre
ORDER BY first_genre
  ...
[0m10:36:54.010318 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.04 seconds
[0m10:36:54.011574 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_genre: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_genre"} */
EXCHANGE TABLES `gold_gold`.`dim_genre__dbt_backup` AND `gold_gold`.`dim_genre` 
  
  ...
[0m10:36:54.015807 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m10:36:54.017980 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_genre: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_genre"} */

    drop table if exists `gold_gold`.`dim_genre__dbt_backup` 
  ...
[0m10:36:54.021600 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_genre"} */

    drop table if exists `gold_gold`.`dim_genre__dbt_backup` 
  
[0m10:36:54.022004 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: macro drop_relation
[0m10:36:54.024596 [debug] [Thread-1 (]: Database Error in model dim_genre (models/gold/dim_genre.sql)
  :HTTPDriver for http://clickhouse-server:8123 returned response code 500)
   std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/7ed/7ed8fa57-801a-472b-9299-fbe3e4b13276/dim_genre__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/gold_gold.dim_genre__dbt_backup.2f53112f-9bd2-4a8c-8ba9-a98d8fb820c4.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build))
  compiled code at target/run/movie_warehouse/models/gold/dim_genre.sql
[0m10:36:54.025243 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9f68526b-4be2-4346-9808-4ce4b12becdb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffaaa41ed0>]}
[0m10:36:54.026013 [error] [Thread-1 (]: 2 of 6 ERROR creating sql table model `gold_gold`.`dim_genre` .................. [[31mERROR[0m in 0.09s]
[0m10:36:54.026493 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.dim_genre
[0m10:36:54.026975 [debug] [Thread-1 (]: Began running node model.movie_warehouse.dim_movie
[0m10:36:54.028682 [info ] [Thread-1 (]: 3 of 6 START sql table model `gold_gold`.`dim_movie` ........................... [RUN]
[0m10:36:54.029265 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.movie_warehouse.dim_genre, now model.movie_warehouse.dim_movie)
[0m10:36:54.029736 [debug] [Thread-1 (]: Began compiling node model.movie_warehouse.dim_movie
[0m10:36:54.031870 [debug] [Thread-1 (]: Writing injected SQL for node "model.movie_warehouse.dim_movie"
[0m10:36:54.032544 [debug] [Thread-1 (]: Began executing node model.movie_warehouse.dim_movie
[0m10:36:54.034168 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_movie: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_movie"} */

            

    
        create table `gold_gold`.`dim_movie__dbt_backup`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            -- ...existing code...


WITH movie_src AS (
    SELECT
        TRIM(title) AS movie_title,
        imdb_id,
        release_date,
        runtime AS movie_runtime,
        original_language AS language
    FROM `bronze`.`tmdb_raw`
    WHERE title IS NOT NULL AND title != ''
)
SELECT
    cityHash64(movie_title) AS movie_id,
    any(imdb_id) AS imdb_id,
    movie_title,
    any(release_date) AS release_date,
    any(movie_runtime) AS movie_runtime,
    any(language) AS language
FROM movie_src
GROUP BY movie_title
ORDER BY movie_title
          )
        
        ...
[0m10:36:54.040707 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m10:36:54.042212 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_movie: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_movie"} */

    select name, type from system.columns where table = 'dim_movie__dbt_backup'
    
      and database = 'gold_gold'
    
    order by position
  ...
[0m10:36:54.044618 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m10:36:54.045989 [debug] [Thread-1 (]: Writing runtime sql for node "model.movie_warehouse.dim_movie"
[0m10:36:54.046640 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_movie: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_movie"} */

  
    
    
    
        
         


        insert into `gold_gold`.`dim_movie__dbt_backup`
        ("movie_id", "imdb_id", "movie_title", "release_date", "movie_runtime", "language")-- ...existing code...


WITH movie_src AS (
    SELECT
        TRIM(title) AS movie_title,
        imdb_id,
        release_date,
        runtime AS movie_runtime,
        original_language AS language
    FROM `bronze`.`tmdb_raw`
    WHERE title IS NOT NULL AND title != ''
)
SELECT
    cityHash64(movie_title) AS movie_id,
    any(imdb_id) AS imdb_id,
    movie_title,
    any(release_date) AS release_date,
    any(movie_runtime) AS movie_runtime,
    any(language) AS language
FROM movie_src
GROUP BY movie_title
ORDER BY movie_title
  ...
[0m10:36:54.388872 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.34 seconds
[0m10:36:54.389979 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_movie: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_movie"} */
EXCHANGE TABLES `gold_gold`.`dim_movie__dbt_backup` AND `gold_gold`.`dim_movie` 
  
  ...
[0m10:36:54.397362 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m10:36:54.402685 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_movie: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_movie"} */

    drop table if exists `gold_gold`.`dim_movie__dbt_backup` 
  ...
[0m10:36:54.407314 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_movie"} */

    drop table if exists `gold_gold`.`dim_movie__dbt_backup` 
  
[0m10:36:54.408227 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: macro drop_relation
[0m10:36:54.410277 [debug] [Thread-1 (]: Database Error in model dim_movie (models/gold/dim_movie.sql)
  :HTTPDriver for http://clickhouse-server:8123 returned response code 500)
   std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/7ed/7ed8fa57-801a-472b-9299-fbe3e4b13276/dim_movie__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/gold_gold.dim_movie__dbt_backup.21406cd8-db0f-4250-9659-716da7bfa2e9.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build))
  compiled code at target/run/movie_warehouse/models/gold/dim_movie.sql
[0m10:36:54.410632 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9f68526b-4be2-4346-9808-4ce4b12becdb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffaa8e4e90>]}
[0m10:36:54.411056 [error] [Thread-1 (]: 3 of 6 ERROR creating sql table model `gold_gold`.`dim_movie` .................. [[31mERROR[0m in 0.38s]
[0m10:36:54.411407 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.dim_movie
[0m10:36:54.411736 [debug] [Thread-1 (]: Began running node model.movie_warehouse.dim_production
[0m10:36:54.412124 [info ] [Thread-1 (]: 4 of 6 START sql table model `gold_gold`.`dim_production` ...................... [RUN]
[0m10:36:54.412403 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.movie_warehouse.dim_movie, now model.movie_warehouse.dim_production)
[0m10:36:54.412636 [debug] [Thread-1 (]: Began compiling node model.movie_warehouse.dim_production
[0m10:36:54.414871 [debug] [Thread-1 (]: Writing injected SQL for node "model.movie_warehouse.dim_production"
[0m10:36:54.415557 [debug] [Thread-1 (]: Began executing node model.movie_warehouse.dim_production
[0m10:36:54.416794 [debug] [Thread-1 (]: Creating new relation dim_production
[0m10:36:54.417811 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_production: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_production"} */

            

    
        create table `gold_gold`.`dim_production`
        
  
        
  engine = MergeTree()
        order by (production_id)
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

WITH first_production AS (
    SELECT
        id AS movie_id,
        trim(splitByChar(',', production_companies)[1]) AS production_name
    FROM `bronze`.`tmdb_raw`
    WHERE production_companies IS NOT NULL AND production_companies != ''
)

SELECT
    cityHash64(production_name) AS production_id,
    production_name,
    current_date() AS valid_from,
    NULL AS valid_to,
    TRUE AS is_current
FROM (
    SELECT DISTINCT production_name
    FROM first_production
)
WHERE production_name IS NOT NULL
          )
        
        ...
[0m10:36:54.425510 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_production"} */

            

    
        create table `gold_gold`.`dim_production`
        
  
        
  engine = MergeTree()
        order by (production_id)
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

WITH first_production AS (
    SELECT
        id AS movie_id,
        trim(splitByChar(',', production_companies)[1]) AS production_name
    FROM `bronze`.`tmdb_raw`
    WHERE production_companies IS NOT NULL AND production_companies != ''
)

SELECT
    cityHash64(production_name) AS production_id,
    production_name,
    current_date() AS valid_from,
    NULL AS valid_to,
    TRUE AS is_current
FROM (
    SELECT DISTINCT production_name
    FROM first_production
)
WHERE production_name IS NOT NULL
          )
        
        
[0m10:36:54.429125 [debug] [Thread-1 (]: Database Error in model dim_production (models/gold/dim_production.sql)
  :HTTPDriver for http://clickhouse-server:8123 returned response code 404)
   Code: 47. DB::Exception: Unknown expression identifier `id` in scope  first_production. (UNKNOWN_IDENTIFIER) (version 25.9.3.48 (official build))
[0m10:36:54.429427 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9f68526b-4be2-4346-9808-4ce4b12becdb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff64a444d0>]}
[0m10:36:54.429811 [error] [Thread-1 (]: 4 of 6 ERROR creating sql table model `gold_gold`.`dim_production` ............. [[31mERROR[0m in 0.02s]
[0m10:36:54.430151 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.dim_production
[0m10:36:54.430490 [debug] [Thread-1 (]: Began running node model.movie_warehouse.dim_release_date
[0m10:36:54.431313 [info ] [Thread-1 (]: 5 of 6 START sql table model `gold_gold`.`dim_release_date` .................... [RUN]
[0m10:36:54.431598 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.movie_warehouse.dim_production, now model.movie_warehouse.dim_release_date)
[0m10:36:54.431838 [debug] [Thread-1 (]: Began compiling node model.movie_warehouse.dim_release_date
[0m10:36:54.433700 [debug] [Thread-1 (]: Writing injected SQL for node "model.movie_warehouse.dim_release_date"
[0m10:36:54.434236 [debug] [Thread-1 (]: Began executing node model.movie_warehouse.dim_release_date
[0m10:36:54.435264 [debug] [Thread-1 (]: Creating new relation dim_release_date
[0m10:36:54.436054 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_release_date: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_release_date"} */

            

    
        create table `gold_gold`.`dim_release_date`
        
  
        
  engine = MergeTree()
        order by (date_id)
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

WITH distinct_dates AS (
    SELECT DISTINCT release_date
    FROM `bronze`.`tmdb_raw`
    WHERE release_date IS NOT NULL
)

SELECT
    cityHash64(release_date)                                    AS date_id,
    release_date                                                AS full_date,
    toYear(release_date)                                        AS year,
    toMonth(release_date)                                       AS month,
    toDayOfMonth(release_date)                                  AS day,
    toISOWeek(release_date)                                     AS week,
    formatDateTime(release_date, '%A')                          AS weekday,
    CASE
        WHEN toMonth(release_date) IN (12,1,2)  THEN 'Winter'
        WHEN toMonth(release_date) IN (3,4,5)   THEN 'Spring'
        WHEN toMonth(release_date) IN (6,7,8)   THEN 'Summer'
        WHEN toMonth(release_date) IN (9,10,11) THEN 'Autumn'
    END                                                         AS season,
    CASE
        WHEN formatDateTime(release_date, '%A') IN ('Saturday','Sunday') THEN 1
        ELSE 0
    END                                                         AS is_weekend,

    /* ---------- holiday tagging ---------- */
    CASE
        WHEN toMonth(release_date)=1  AND toDayOfMonth(release_date)=1  THEN 'New Years Day'
        WHEN toMonth(release_date)=2  AND toDayOfMonth(release_date)=14 THEN 'Valentines Day'
        WHEN toMonth(release_date)=3  AND toDayOfMonth(release_date)=17 THEN 'St. Patricks Day'
        WHEN toMonth(release_date)=4  AND toDayOfMonth(release_date)=1  THEN 'April Fools Day'
        WHEN toMonth(release_date)=4  AND toDayOfMonth(release_date)=22 THEN 'Earth Day'
        WHEN toMonth(release_date)=5  AND toDayOfMonth(release_date)=1  THEN 'May Day'
        WHEN toMonth(release_date)=5  AND toDayOfMonth(release_date)=5  THEN 'Cinco de Mayo'
        WHEN toMonth(release_date)=6  AND toDayOfMonth(release_date) BETWEEN 19 AND 26 THEN 'Midsummer'
        WHEN toMonth(release_date)=7  AND toDayOfMonth(release_date)=4  THEN 'Independence Day'
        WHEN toMonth(release_date)=9  AND toDayOfMonth(release_date) BETWEEN 1 AND 7 
             AND formatDateTime(release_date,'%A')='Monday'             THEN 'Labor Day (US)'
        WHEN toMonth(release_date)=10 AND toDayOfMonth(release_date)=31 THEN 'Halloween'
        WHEN toMonth(release_date)=11 AND formatDateTime(release_date,'%A')='Thursday'
             AND toISOWeek(release_date) >= 47                           THEN 'Thanksgiving'
        WHEN toMonth(release_date)=12 AND toDayOfMonth(release_date)=24 THEN 'Christmas Eve'
        WHEN toMonth(release_date)=12 AND toDayOfMonth(release_date)=25 THEN 'Christmas Day'
        WHEN toMonth(release_date)=12 AND toDayOfMonth(release_date)=31 THEN 'New Years Eve'
        ELSE NULL
    END                                                         AS holiday_name,
    IF(holiday_name IS NOT NULL, 1, 0)                          AS is_holiday,

    /* placeholders for later enhancement */
    NULL                                                        AS days_until_holiday,
    NULL                                                        AS days_after_holiday
FROM distinct_dates
ORDER BY release_date
          )
        
        ...
[0m10:36:54.451910 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_release_date"} */

            

    
        create table `gold_gold`.`dim_release_date`
        
  
        
  engine = MergeTree()
        order by (date_id)
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

WITH distinct_dates AS (
    SELECT DISTINCT release_date
    FROM `bronze`.`tmdb_raw`
    WHERE release_date IS NOT NULL
)

SELECT
    cityHash64(release_date)                                    AS date_id,
    release_date                                                AS full_date,
    toYear(release_date)                                        AS year,
    toMonth(release_date)                                       AS month,
    toDayOfMonth(release_date)                                  AS day,
    toISOWeek(release_date)                                     AS week,
    formatDateTime(release_date, '%A')                          AS weekday,
    CASE
        WHEN toMonth(release_date) IN (12,1,2)  THEN 'Winter'
        WHEN toMonth(release_date) IN (3,4,5)   THEN 'Spring'
        WHEN toMonth(release_date) IN (6,7,8)   THEN 'Summer'
        WHEN toMonth(release_date) IN (9,10,11) THEN 'Autumn'
    END                                                         AS season,
    CASE
        WHEN formatDateTime(release_date, '%A') IN ('Saturday','Sunday') THEN 1
        ELSE 0
    END                                                         AS is_weekend,

    /* ---------- holiday tagging ---------- */
    CASE
        WHEN toMonth(release_date)=1  AND toDayOfMonth(release_date)=1  THEN 'New Years Day'
        WHEN toMonth(release_date)=2  AND toDayOfMonth(release_date)=14 THEN 'Valentines Day'
        WHEN toMonth(release_date)=3  AND toDayOfMonth(release_date)=17 THEN 'St. Patricks Day'
        WHEN toMonth(release_date)=4  AND toDayOfMonth(release_date)=1  THEN 'April Fools Day'
        WHEN toMonth(release_date)=4  AND toDayOfMonth(release_date)=22 THEN 'Earth Day'
        WHEN toMonth(release_date)=5  AND toDayOfMonth(release_date)=1  THEN 'May Day'
        WHEN toMonth(release_date)=5  AND toDayOfMonth(release_date)=5  THEN 'Cinco de Mayo'
        WHEN toMonth(release_date)=6  AND toDayOfMonth(release_date) BETWEEN 19 AND 26 THEN 'Midsummer'
        WHEN toMonth(release_date)=7  AND toDayOfMonth(release_date)=4  THEN 'Independence Day'
        WHEN toMonth(release_date)=9  AND toDayOfMonth(release_date) BETWEEN 1 AND 7 
             AND formatDateTime(release_date,'%A')='Monday'             THEN 'Labor Day (US)'
        WHEN toMonth(release_date)=10 AND toDayOfMonth(release_date)=31 THEN 'Halloween'
        WHEN toMonth(release_date)=11 AND formatDateTime(release_date,'%A')='Thursday'
             AND toISOWeek(release_date) >= 47                           THEN 'Thanksgiving'
        WHEN toMonth(release_date)=12 AND toDayOfMonth(release_date)=24 THEN 'Christmas Eve'
        WHEN toMonth(release_date)=12 AND toDayOfMonth(release_date)=25 THEN 'Christmas Day'
        WHEN toMonth(release_date)=12 AND toDayOfMonth(release_date)=31 THEN 'New Years Eve'
        ELSE NULL
    END                                                         AS holiday_name,
    IF(holiday_name IS NOT NULL, 1, 0)                          AS is_holiday,

    /* placeholders for later enhancement */
    NULL                                                        AS days_until_holiday,
    NULL                                                        AS days_after_holiday
FROM distinct_dates
ORDER BY release_date
          )
        
        
[0m10:36:54.455012 [debug] [Thread-1 (]: Database Error in model dim_release_date (models/gold/dim_release_date.sql)
  :HTTPDriver for http://clickhouse-server:8123 returned response code 400)
   Code: 36. DB::Exception: Incorrect syntax '%A', symbol is not supported 'A' for function formatDateTime: while executing function formatDateTime on arguments __table1.release_date Date32 Int32(size = 0), '%A'_String String Const(size = 0, String(size = 1)). (BAD_ARGUMENTS) (version 25.9.3.48 (official build))
[0m10:36:54.455537 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9f68526b-4be2-4346-9808-4ce4b12becdb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffaac30e10>]}
[0m10:36:54.456061 [error] [Thread-1 (]: 5 of 6 ERROR creating sql table model `gold_gold`.`dim_release_date` ........... [[31mERROR[0m in 0.02s]
[0m10:36:54.456368 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.dim_release_date
[0m10:36:54.457730 [debug] [Thread-1 (]: Began running node model.movie_warehouse.fact_movie
[0m10:36:54.458005 [info ] [Thread-1 (]: 6 of 6 SKIP relation gold_gold.fact_movie ...................................... [[33mSKIP[0m]
[0m10:36:54.458250 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.fact_movie
[0m10:36:54.459470 [debug] [MainThread]: Connection 'master' was properly closed.
[0m10:36:54.459875 [debug] [MainThread]: Connection 'model.movie_warehouse.dim_release_date' was left open.
[0m10:36:54.460096 [debug] [MainThread]: On model.movie_warehouse.dim_release_date: Close
[0m10:36:54.460995 [info ] [MainThread]: 
[0m10:36:54.464027 [info ] [MainThread]: Finished running 6 table models in 0 hours 0 minutes and 5.28 seconds (5.28s).
[0m10:36:54.469544 [debug] [MainThread]: Command end result
[0m10:36:54.507577 [info ] [MainThread]: 
[0m10:36:54.507893 [info ] [MainThread]: [31mCompleted with 5 errors and 0 warnings:[0m
[0m10:36:54.508150 [info ] [MainThread]: 
[0m10:36:54.508581 [error] [MainThread]:   Database Error in model dim_director (models/gold/dim_director.sql)
  :HTTPDriver for http://clickhouse-server:8123 returned response code 500)
   std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/7ed/7ed8fa57-801a-472b-9299-fbe3e4b13276/dim_director__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/gold_gold.dim_director__dbt_backup.a5927d9d-da32-4e3e-90b7-9177b31823d9.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build))
  compiled code at target/run/movie_warehouse/models/gold/dim_director.sql
[0m10:36:54.508822 [info ] [MainThread]: 
[0m10:36:54.509012 [error] [MainThread]:   Database Error in model dim_genre (models/gold/dim_genre.sql)
  :HTTPDriver for http://clickhouse-server:8123 returned response code 500)
   std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/7ed/7ed8fa57-801a-472b-9299-fbe3e4b13276/dim_genre__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/gold_gold.dim_genre__dbt_backup.2f53112f-9bd2-4a8c-8ba9-a98d8fb820c4.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build))
  compiled code at target/run/movie_warehouse/models/gold/dim_genre.sql
[0m10:36:54.509195 [info ] [MainThread]: 
[0m10:36:54.509393 [error] [MainThread]:   Database Error in model dim_movie (models/gold/dim_movie.sql)
  :HTTPDriver for http://clickhouse-server:8123 returned response code 500)
   std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/7ed/7ed8fa57-801a-472b-9299-fbe3e4b13276/dim_movie__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/gold_gold.dim_movie__dbt_backup.21406cd8-db0f-4250-9659-716da7bfa2e9.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build))
  compiled code at target/run/movie_warehouse/models/gold/dim_movie.sql
[0m10:36:54.509600 [info ] [MainThread]: 
[0m10:36:54.509788 [error] [MainThread]:   Database Error in model dim_production (models/gold/dim_production.sql)
  :HTTPDriver for http://clickhouse-server:8123 returned response code 404)
   Code: 47. DB::Exception: Unknown expression identifier `id` in scope  first_production. (UNKNOWN_IDENTIFIER) (version 25.9.3.48 (official build))
[0m10:36:54.509971 [info ] [MainThread]: 
[0m10:36:54.510213 [error] [MainThread]:   Database Error in model dim_release_date (models/gold/dim_release_date.sql)
  :HTTPDriver for http://clickhouse-server:8123 returned response code 400)
   Code: 36. DB::Exception: Incorrect syntax '%A', symbol is not supported 'A' for function formatDateTime: while executing function formatDateTime on arguments __table1.release_date Date32 Int32(size = 0), '%A'_String String Const(size = 0, String(size = 1)). (BAD_ARGUMENTS) (version 25.9.3.48 (official build))
[0m10:36:54.510388 [info ] [MainThread]: 
[0m10:36:54.510608 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=5 SKIP=1 TOTAL=6
[0m10:36:54.512667 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 5.8951774, "process_in_blocks": "117664", "process_kernel_time": 0.356821, "process_mem_max_rss": "192292", "process_out_blocks": "4903", "process_user_time": 2.269755}
[0m10:36:54.513291 [debug] [MainThread]: Command `dbt run` failed at 10:36:54.513235 after 5.90 seconds
[0m10:36:54.513766 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffaaf0cb50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffafc71f10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffafc71e50>]}
[0m10:36:54.514002 [debug] [MainThread]: Flushing usage events
[0m10:46:29.229096 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff853c2050>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff853feb90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff85853690>]}


============================== 10:46:29.232931 | 7e8b7dce-210c-46e0-ac14-85e1330299e4 ==============================
[0m10:46:29.232931 [info ] [MainThread]: Running with dbt=1.8.9
[0m10:46:29.233243 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'fail_fast': 'False', 'log_path': '/opt/airflow/project_root/dbt/logs', 'profiles_dir': '/opt/airflow/project_root/dbt', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'introspect': 'True', 'invocation_command': 'dbt run --project-dir /opt/airflow/project_root/dbt --profiles-dir /opt/airflow/project_root/dbt --select gold', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m10:46:29.334399 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '7e8b7dce-210c-46e0-ac14-85e1330299e4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff853fd710>]}
[0m10:46:29.353548 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '7e8b7dce-210c-46e0-ac14-85e1330299e4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff868c7090>]}
[0m10:46:29.354027 [info ] [MainThread]: Registered adapter: clickhouse=1.8.9
[0m10:46:29.388745 [debug] [MainThread]: checksum: 132857a23e9d07220246854f7763165174ce9b737cfc7867629ace4294e520b1, vars: {}, profile: , target: , version: 1.8.9
[0m10:46:29.446240 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 2 files changed.
[0m10:46:29.446612 [debug] [MainThread]: Partial parsing: updated file: movie_warehouse://models/gold/dim_release_date.sql
[0m10:46:29.446823 [debug] [MainThread]: Partial parsing: updated file: movie_warehouse://models/gold/dim_production.sql
[0m10:46:29.524724 [warn ] [MainThread]: [[33mWARNING[0m]: Deprecated functionality
The `tests` config has been renamed to `data_tests`. Please see
https://docs.getdbt.com/docs/build/data-tests#new-data_tests-syntax for more
information.
[0m10:46:29.525080 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'deprecation', 'label': '7e8b7dce-210c-46e0-ac14-85e1330299e4', 'property_': 'warn', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff850ba1d0>]}
[0m10:46:29.582857 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.movie_warehouse.bronze
[0m10:46:29.587814 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '7e8b7dce-210c-46e0-ac14-85e1330299e4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff84f48bd0>]}
[0m10:46:29.665680 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '7e8b7dce-210c-46e0-ac14-85e1330299e4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff84d7f090>]}
[0m10:46:29.666161 [info ] [MainThread]: Found 6 models, 12 data tests, 4 sources, 476 macros
[0m10:46:29.666417 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '7e8b7dce-210c-46e0-ac14-85e1330299e4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff7fb75110>]}
[0m10:46:29.667731 [info ] [MainThread]: 
[0m10:46:29.668275 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m10:46:29.671002 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m10:46:29.675229 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:46:29.927628 [info ] [ThreadPool]: dbt_clickhouse adapter: Unexpected server exception dropping table
[0m10:46:29.928385 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m10:46:29.930203 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m10:46:29.978794 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now create__gold_gold)
[0m10:46:29.979157 [debug] [ThreadPool]: Creating schema "schema: "gold_gold"
"
[0m10:46:29.982152 [debug] [ThreadPool]: dbt_clickhouse adapter: On create__gold_gold: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "connection_name": "create__gold_gold"} */
create database if not exists `gold_gold`
        
  
        
  ...
[0m10:46:29.985086 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m10:46:29.986090 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create__gold_gold, now list__gold_gold)
[0m10:46:29.988631 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__gold_gold: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "connection_name": "list__gold_gold"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'gold_gold'
      

  ...
[0m10:46:30.004327 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m10:46:30.005233 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '7e8b7dce-210c-46e0-ac14-85e1330299e4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff44999d90>]}
[0m10:46:30.005571 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m10:46:30.005777 [info ] [MainThread]: 
[0m10:46:30.010389 [debug] [Thread-1 (]: Began running node model.movie_warehouse.dim_director
[0m10:46:30.010725 [info ] [Thread-1 (]: 1 of 6 START sql table model `gold_gold`.`dim_director` ........................ [RUN]
[0m10:46:30.011028 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list__gold_gold, now model.movie_warehouse.dim_director)
[0m10:46:30.011254 [debug] [Thread-1 (]: Began compiling node model.movie_warehouse.dim_director
[0m10:46:30.014695 [debug] [Thread-1 (]: Writing injected SQL for node "model.movie_warehouse.dim_director"
[0m10:46:30.016141 [debug] [Thread-1 (]: Began executing node model.movie_warehouse.dim_director
[0m10:46:30.024258 [debug] [Thread-1 (]: Creating new relation dim_director
[0m10:46:30.036117 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_director: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_director"} */

            

    
        create table `gold_gold`.`dim_director`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

WITH first_dir AS (
    SELECT
        tconst,
        TRIM(splitByChar(',', directors)[1]) AS director_id
    FROM `bronze`.`imdb_title_crew_raw`
    WHERE directors IS NOT NULL AND directors != ''
),
deduped AS (
    SELECT DISTINCT director_id
    FROM first_dir
),
joined AS (
    SELECT
        d.director_id AS dir_id,
        n.primaryName AS dir_name
    FROM deduped d
    LEFT JOIN `bronze`.`imdb_name_basics_raw` n
        ON d.director_id = n.nconst
)
SELECT
    cityHash64(dir_id) AS imdb_dir_name_id,  -- Use hash instead of row_number
    dir_id,
    dir_name,
    today() AS valid_from,
    CAST(NULL AS Nullable(Date)) AS valid_to,
    1 AS is_current  -- Use 1/0 instead of TRUE/FALSE
FROM joined
WHERE dir_id IS NOT NULL
ORDER BY dir_id
          )
        
        ...
[0m10:46:30.045025 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m10:46:30.052057 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_director: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_director"} */

    select name, type from system.columns where table = 'dim_director'
    
      and database = 'gold_gold'
    
    order by position
  ...
[0m10:46:30.055493 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m10:46:30.057112 [debug] [Thread-1 (]: Writing runtime sql for node "model.movie_warehouse.dim_director"
[0m10:46:30.058318 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_director: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_director"} */

  
    
    
    
        
         


        insert into `gold_gold`.`dim_director`
        ("imdb_dir_name_id", "dir_id", "dir_name", "valid_from", "valid_to", "is_current")

WITH first_dir AS (
    SELECT
        tconst,
        TRIM(splitByChar(',', directors)[1]) AS director_id
    FROM `bronze`.`imdb_title_crew_raw`
    WHERE directors IS NOT NULL AND directors != ''
),
deduped AS (
    SELECT DISTINCT director_id
    FROM first_dir
),
joined AS (
    SELECT
        d.director_id AS dir_id,
        n.primaryName AS dir_name
    FROM deduped d
    LEFT JOIN `bronze`.`imdb_name_basics_raw` n
        ON d.director_id = n.nconst
)
SELECT
    cityHash64(dir_id) AS imdb_dir_name_id,  -- Use hash instead of row_number
    dir_id,
    dir_name,
    today() AS valid_from,
    CAST(NULL AS Nullable(Date)) AS valid_to,
    1 AS is_current  -- Use 1/0 instead of TRUE/FALSE
FROM joined
WHERE dir_id IS NOT NULL
ORDER BY dir_id
  ...
[0m10:46:32.237228 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 2.18 seconds
[0m10:46:32.275237 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7e8b7dce-210c-46e0-ac14-85e1330299e4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff44996450>]}
[0m10:46:32.277419 [info ] [Thread-1 (]: 1 of 6 OK created sql table model `gold_gold`.`dim_director` ................... [[32mOK[0m in 2.26s]
[0m10:46:32.278270 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.dim_director
[0m10:46:32.278889 [debug] [Thread-1 (]: Began running node model.movie_warehouse.dim_genre
[0m10:46:32.279686 [info ] [Thread-1 (]: 2 of 6 START sql table model `gold_gold`.`dim_genre` ........................... [RUN]
[0m10:46:32.280092 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.movie_warehouse.dim_director, now model.movie_warehouse.dim_genre)
[0m10:46:32.280364 [debug] [Thread-1 (]: Began compiling node model.movie_warehouse.dim_genre
[0m10:46:32.288121 [debug] [Thread-1 (]: Writing injected SQL for node "model.movie_warehouse.dim_genre"
[0m10:46:32.289132 [debug] [Thread-1 (]: Began executing node model.movie_warehouse.dim_genre
[0m10:46:32.290699 [debug] [Thread-1 (]: Creating new relation dim_genre
[0m10:46:32.291539 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_genre: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_genre"} */

            

    
        create table `gold_gold`.`dim_genre`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

WITH parsed_genres AS (
    SELECT
        TRIM(splitByChar(',', genres)[1]) AS first_genre
    FROM `bronze`.`tmdb_raw`
    WHERE genres IS NOT NULL AND genres != ''
)
SELECT
    cityHash64(first_genre) AS genre_id,
    first_genre AS genre_name
FROM parsed_genres
GROUP BY first_genre
ORDER BY first_genre
          )
        
        ...
[0m10:46:32.303441 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m10:46:32.305365 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_genre: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_genre"} */

    select name, type from system.columns where table = 'dim_genre'
    
      and database = 'gold_gold'
    
    order by position
  ...
[0m10:46:32.308539 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m10:46:32.309753 [debug] [Thread-1 (]: Writing runtime sql for node "model.movie_warehouse.dim_genre"
[0m10:46:32.310759 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_genre: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_genre"} */

  
    
    
    
        
         


        insert into `gold_gold`.`dim_genre`
        ("genre_id", "genre_name")

WITH parsed_genres AS (
    SELECT
        TRIM(splitByChar(',', genres)[1]) AS first_genre
    FROM `bronze`.`tmdb_raw`
    WHERE genres IS NOT NULL AND genres != ''
)
SELECT
    cityHash64(first_genre) AS genre_id,
    first_genre AS genre_name
FROM parsed_genres
GROUP BY first_genre
ORDER BY first_genre
  ...
[0m10:46:32.348171 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.04 seconds
[0m10:46:32.350482 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7e8b7dce-210c-46e0-ac14-85e1330299e4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8531db50>]}
[0m10:46:32.351340 [info ] [Thread-1 (]: 2 of 6 OK created sql table model `gold_gold`.`dim_genre` ...................... [[32mOK[0m in 0.07s]
[0m10:46:32.351806 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.dim_genre
[0m10:46:32.352345 [debug] [Thread-1 (]: Began running node model.movie_warehouse.dim_movie
[0m10:46:32.352911 [info ] [Thread-1 (]: 3 of 6 START sql table model `gold_gold`.`dim_movie` ........................... [RUN]
[0m10:46:32.353216 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.movie_warehouse.dim_genre, now model.movie_warehouse.dim_movie)
[0m10:46:32.353456 [debug] [Thread-1 (]: Began compiling node model.movie_warehouse.dim_movie
[0m10:46:32.356088 [debug] [Thread-1 (]: Writing injected SQL for node "model.movie_warehouse.dim_movie"
[0m10:46:32.356812 [debug] [Thread-1 (]: Began executing node model.movie_warehouse.dim_movie
[0m10:46:32.358369 [debug] [Thread-1 (]: Creating new relation dim_movie
[0m10:46:32.359651 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_movie: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_movie"} */

            

    
        create table `gold_gold`.`dim_movie`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            -- ...existing code...


WITH movie_src AS (
    SELECT
        TRIM(title) AS movie_title,
        imdb_id,
        release_date,
        runtime AS movie_runtime,
        original_language AS language
    FROM `bronze`.`tmdb_raw`
    WHERE title IS NOT NULL AND title != ''
)
SELECT
    cityHash64(movie_title) AS movie_id,
    any(imdb_id) AS imdb_id,
    movie_title,
    any(release_date) AS release_date,
    any(movie_runtime) AS movie_runtime,
    any(language) AS language
FROM movie_src
GROUP BY movie_title
ORDER BY movie_title
          )
        
        ...
[0m10:46:32.370513 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m10:46:32.372322 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_movie: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_movie"} */

    select name, type from system.columns where table = 'dim_movie'
    
      and database = 'gold_gold'
    
    order by position
  ...
[0m10:46:32.375566 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m10:46:32.376765 [debug] [Thread-1 (]: Writing runtime sql for node "model.movie_warehouse.dim_movie"
[0m10:46:32.377579 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_movie: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_movie"} */

  
    
    
    
        
         


        insert into `gold_gold`.`dim_movie`
        ("movie_id", "imdb_id", "movie_title", "release_date", "movie_runtime", "language")-- ...existing code...


WITH movie_src AS (
    SELECT
        TRIM(title) AS movie_title,
        imdb_id,
        release_date,
        runtime AS movie_runtime,
        original_language AS language
    FROM `bronze`.`tmdb_raw`
    WHERE title IS NOT NULL AND title != ''
)
SELECT
    cityHash64(movie_title) AS movie_id,
    any(imdb_id) AS imdb_id,
    movie_title,
    any(release_date) AS release_date,
    any(movie_runtime) AS movie_runtime,
    any(language) AS language
FROM movie_src
GROUP BY movie_title
ORDER BY movie_title
  ...
[0m10:46:32.652000 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.27 seconds
[0m10:46:32.653312 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7e8b7dce-210c-46e0-ac14-85e1330299e4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff44824dd0>]}
[0m10:46:32.653696 [info ] [Thread-1 (]: 3 of 6 OK created sql table model `gold_gold`.`dim_movie` ...................... [[32mOK[0m in 0.30s]
[0m10:46:32.654006 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.dim_movie
[0m10:46:32.654291 [debug] [Thread-1 (]: Began running node model.movie_warehouse.dim_production
[0m10:46:32.655589 [info ] [Thread-1 (]: 4 of 6 START sql table model `gold_gold`.`dim_production` ...................... [RUN]
[0m10:46:32.655864 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.movie_warehouse.dim_movie, now model.movie_warehouse.dim_production)
[0m10:46:32.656094 [debug] [Thread-1 (]: Began compiling node model.movie_warehouse.dim_production
[0m10:46:32.657876 [debug] [Thread-1 (]: Writing injected SQL for node "model.movie_warehouse.dim_production"
[0m10:46:32.658384 [debug] [Thread-1 (]: Began executing node model.movie_warehouse.dim_production
[0m10:46:32.659582 [debug] [Thread-1 (]: Creating new relation dim_production
[0m10:46:32.661085 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_production: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_production"} */

            

    
        create table `gold_gold`.`dim_production`
        
  
        
  engine = MergeTree()
        order by (production_id)
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

WITH first_production AS (
    SELECT
        imdb_id AS movie_id,
        trim(splitByChar(',', production_companies)[1]) AS production_name
    FROM `bronze`.`tmdb_raw`
    WHERE production_companies IS NOT NULL AND production_companies != ''
)

SELECT
    cityHash64(production_name) AS production_id,
    production_name,
    current_date() AS valid_from,
    NULL AS valid_to,
    TRUE AS is_current
FROM (
    SELECT DISTINCT production_name
    FROM first_production
)
WHERE production_name IS NOT NULL
          )
        
        ...
[0m10:46:32.672141 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_production"} */

            

    
        create table `gold_gold`.`dim_production`
        
  
        
  engine = MergeTree()
        order by (production_id)
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

WITH first_production AS (
    SELECT
        imdb_id AS movie_id,
        trim(splitByChar(',', production_companies)[1]) AS production_name
    FROM `bronze`.`tmdb_raw`
    WHERE production_companies IS NOT NULL AND production_companies != ''
)

SELECT
    cityHash64(production_name) AS production_id,
    production_name,
    current_date() AS valid_from,
    NULL AS valid_to,
    TRUE AS is_current
FROM (
    SELECT DISTINCT production_name
    FROM first_production
)
WHERE production_name IS NOT NULL
          )
        
        
[0m10:46:32.680288 [debug] [Thread-1 (]: Database Error in model dim_production (models/gold/dim_production.sql)
  :HTTPDriver for http://clickhouse-server:8123 returned response code 500)
   Code: 370. DB::Exception: Data type Nullable(Nothing) of column 'valid_to' cannot be used in tables. (DATA_TYPE_CANNOT_BE_USED_IN_TABLES) (version 25.9.3.48 (official build))
[0m10:46:32.680745 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7e8b7dce-210c-46e0-ac14-85e1330299e4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff84db5b50>]}
[0m10:46:32.681126 [error] [Thread-1 (]: 4 of 6 ERROR creating sql table model `gold_gold`.`dim_production` ............. [[31mERROR[0m in 0.02s]
[0m10:46:32.681523 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.dim_production
[0m10:46:32.681797 [debug] [Thread-1 (]: Began running node model.movie_warehouse.dim_release_date
[0m10:46:32.683031 [info ] [Thread-1 (]: 5 of 6 START sql table model `gold_gold`.`dim_release_date` .................... [RUN]
[0m10:46:32.683302 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.movie_warehouse.dim_production, now model.movie_warehouse.dim_release_date)
[0m10:46:32.683485 [debug] [Thread-1 (]: Began compiling node model.movie_warehouse.dim_release_date
[0m10:46:32.685534 [debug] [Thread-1 (]: Writing injected SQL for node "model.movie_warehouse.dim_release_date"
[0m10:46:32.686329 [debug] [Thread-1 (]: Began executing node model.movie_warehouse.dim_release_date
[0m10:46:32.687600 [debug] [Thread-1 (]: Creating new relation dim_release_date
[0m10:46:32.688410 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_release_date: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_release_date"} */

            

    
        create table `gold_gold`.`dim_release_date`
        
  
        
  engine = MergeTree()
        order by (date_id)
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

WITH distinct_dates AS (
    SELECT DISTINCT release_date
    FROM `bronze`.`tmdb_raw`
    WHERE release_date IS NOT NULL
)

SELECT
    cityHash64(release_date)                                    AS date_id,
    release_date                                                AS full_date,
    toYear(release_date)                                        AS year,
    toMonth(release_date)                                       AS month,
    toDayOfMonth(release_date)                                  AS day,
    toISOWeek(release_date)                                     AS week,
    formatDateTime(release_date, '%a')                          AS weekday,
    CASE
        WHEN toMonth(release_date) IN (12,1,2)  THEN 'Winter'
        WHEN toMonth(release_date) IN (3,4,5)   THEN 'Spring'
        WHEN toMonth(release_date) IN (6,7,8)   THEN 'Summer'
        WHEN toMonth(release_date) IN (9,10,11) THEN 'Autumn'
    END                                                         AS season,
    CASE
        WHEN formatDateTime(release_date, '%A') IN ('Saturday','Sunday') THEN 1
        ELSE 0
    END                                                         AS is_weekend,

    /* ---------- holiday tagging ---------- */
    CASE
        WHEN toMonth(release_date)=1  AND toDayOfMonth(release_date)=1  THEN 'New Years Day'
        WHEN toMonth(release_date)=2  AND toDayOfMonth(release_date)=14 THEN 'Valentines Day'
        WHEN toMonth(release_date)=3  AND toDayOfMonth(release_date)=17 THEN 'St. Patricks Day'
        WHEN toMonth(release_date)=4  AND toDayOfMonth(release_date)=1  THEN 'April Fools Day'
        WHEN toMonth(release_date)=4  AND toDayOfMonth(release_date)=22 THEN 'Earth Day'
        WHEN toMonth(release_date)=5  AND toDayOfMonth(release_date)=1  THEN 'May Day'
        WHEN toMonth(release_date)=5  AND toDayOfMonth(release_date)=5  THEN 'Cinco de Mayo'
        WHEN toMonth(release_date)=6  AND toDayOfMonth(release_date) BETWEEN 19 AND 26 THEN 'Midsummer'
        WHEN toMonth(release_date)=7  AND toDayOfMonth(release_date)=4  THEN 'Independence Day'
        WHEN toMonth(release_date)=9  AND toDayOfMonth(release_date) BETWEEN 1 AND 7 
             AND formatDateTime(release_date,'%A')='Monday'             THEN 'Labor Day (US)'
        WHEN toMonth(release_date)=10 AND toDayOfMonth(release_date)=31 THEN 'Halloween'
        WHEN toMonth(release_date)=11 AND formatDateTime(release_date,'%A')='Thursday'
             AND toISOWeek(release_date) >= 47                           THEN 'Thanksgiving'
        WHEN toMonth(release_date)=12 AND toDayOfMonth(release_date)=24 THEN 'Christmas Eve'
        WHEN toMonth(release_date)=12 AND toDayOfMonth(release_date)=25 THEN 'Christmas Day'
        WHEN toMonth(release_date)=12 AND toDayOfMonth(release_date)=31 THEN 'New Years Eve'
        ELSE NULL
    END                                                         AS holiday_name,
    IF(holiday_name IS NOT NULL, 1, 0)                          AS is_holiday,

    /* placeholders for later enhancement */
    NULL                                                        AS days_until_holiday,
    NULL                                                        AS days_after_holiday
FROM distinct_dates
ORDER BY release_date
          )
        
        ...
[0m10:46:32.700017 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_release_date"} */

            

    
        create table `gold_gold`.`dim_release_date`
        
  
        
  engine = MergeTree()
        order by (date_id)
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

WITH distinct_dates AS (
    SELECT DISTINCT release_date
    FROM `bronze`.`tmdb_raw`
    WHERE release_date IS NOT NULL
)

SELECT
    cityHash64(release_date)                                    AS date_id,
    release_date                                                AS full_date,
    toYear(release_date)                                        AS year,
    toMonth(release_date)                                       AS month,
    toDayOfMonth(release_date)                                  AS day,
    toISOWeek(release_date)                                     AS week,
    formatDateTime(release_date, '%a')                          AS weekday,
    CASE
        WHEN toMonth(release_date) IN (12,1,2)  THEN 'Winter'
        WHEN toMonth(release_date) IN (3,4,5)   THEN 'Spring'
        WHEN toMonth(release_date) IN (6,7,8)   THEN 'Summer'
        WHEN toMonth(release_date) IN (9,10,11) THEN 'Autumn'
    END                                                         AS season,
    CASE
        WHEN formatDateTime(release_date, '%A') IN ('Saturday','Sunday') THEN 1
        ELSE 0
    END                                                         AS is_weekend,

    /* ---------- holiday tagging ---------- */
    CASE
        WHEN toMonth(release_date)=1  AND toDayOfMonth(release_date)=1  THEN 'New Years Day'
        WHEN toMonth(release_date)=2  AND toDayOfMonth(release_date)=14 THEN 'Valentines Day'
        WHEN toMonth(release_date)=3  AND toDayOfMonth(release_date)=17 THEN 'St. Patricks Day'
        WHEN toMonth(release_date)=4  AND toDayOfMonth(release_date)=1  THEN 'April Fools Day'
        WHEN toMonth(release_date)=4  AND toDayOfMonth(release_date)=22 THEN 'Earth Day'
        WHEN toMonth(release_date)=5  AND toDayOfMonth(release_date)=1  THEN 'May Day'
        WHEN toMonth(release_date)=5  AND toDayOfMonth(release_date)=5  THEN 'Cinco de Mayo'
        WHEN toMonth(release_date)=6  AND toDayOfMonth(release_date) BETWEEN 19 AND 26 THEN 'Midsummer'
        WHEN toMonth(release_date)=7  AND toDayOfMonth(release_date)=4  THEN 'Independence Day'
        WHEN toMonth(release_date)=9  AND toDayOfMonth(release_date) BETWEEN 1 AND 7 
             AND formatDateTime(release_date,'%A')='Monday'             THEN 'Labor Day (US)'
        WHEN toMonth(release_date)=10 AND toDayOfMonth(release_date)=31 THEN 'Halloween'
        WHEN toMonth(release_date)=11 AND formatDateTime(release_date,'%A')='Thursday'
             AND toISOWeek(release_date) >= 47                           THEN 'Thanksgiving'
        WHEN toMonth(release_date)=12 AND toDayOfMonth(release_date)=24 THEN 'Christmas Eve'
        WHEN toMonth(release_date)=12 AND toDayOfMonth(release_date)=25 THEN 'Christmas Day'
        WHEN toMonth(release_date)=12 AND toDayOfMonth(release_date)=31 THEN 'New Years Eve'
        ELSE NULL
    END                                                         AS holiday_name,
    IF(holiday_name IS NOT NULL, 1, 0)                          AS is_holiday,

    /* placeholders for later enhancement */
    NULL                                                        AS days_until_holiday,
    NULL                                                        AS days_after_holiday
FROM distinct_dates
ORDER BY release_date
          )
        
        
[0m10:46:32.702628 [debug] [Thread-1 (]: Database Error in model dim_release_date (models/gold/dim_release_date.sql)
  :HTTPDriver for http://clickhouse-server:8123 returned response code 400)
   Code: 36. DB::Exception: Incorrect syntax '%A', symbol is not supported 'A' for function formatDateTime: while executing function formatDateTime on arguments __table1.release_date Date32 Int32(size = 0), '%A'_String String Const(size = 0, String(size = 1)). (BAD_ARGUMENTS) (version 25.9.3.48 (official build))
[0m10:46:32.703030 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7e8b7dce-210c-46e0-ac14-85e1330299e4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff449c4710>]}
[0m10:46:32.703367 [error] [Thread-1 (]: 5 of 6 ERROR creating sql table model `gold_gold`.`dim_release_date` ........... [[31mERROR[0m in 0.02s]
[0m10:46:32.703791 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.dim_release_date
[0m10:46:32.705061 [debug] [Thread-1 (]: Began running node model.movie_warehouse.fact_movie
[0m10:46:32.705437 [info ] [Thread-1 (]: 6 of 6 SKIP relation gold_gold.fact_movie ...................................... [[33mSKIP[0m]
[0m10:46:32.705771 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.fact_movie
[0m10:46:32.707107 [debug] [MainThread]: Connection 'master' was properly closed.
[0m10:46:32.707396 [debug] [MainThread]: Connection 'model.movie_warehouse.dim_release_date' was left open.
[0m10:46:32.707609 [debug] [MainThread]: On model.movie_warehouse.dim_release_date: Close
[0m10:46:32.708290 [info ] [MainThread]: 
[0m10:46:32.708675 [info ] [MainThread]: Finished running 6 table models in 0 hours 0 minutes and 3.04 seconds (3.04s).
[0m10:46:32.709472 [debug] [MainThread]: Command end result
[0m10:46:32.748679 [info ] [MainThread]: 
[0m10:46:32.749067 [info ] [MainThread]: [31mCompleted with 2 errors and 0 warnings:[0m
[0m10:46:32.749272 [info ] [MainThread]: 
[0m10:46:32.749498 [error] [MainThread]:   Database Error in model dim_production (models/gold/dim_production.sql)
  :HTTPDriver for http://clickhouse-server:8123 returned response code 500)
   Code: 370. DB::Exception: Data type Nullable(Nothing) of column 'valid_to' cannot be used in tables. (DATA_TYPE_CANNOT_BE_USED_IN_TABLES) (version 25.9.3.48 (official build))
[0m10:46:32.749688 [info ] [MainThread]: 
[0m10:46:32.749881 [error] [MainThread]:   Database Error in model dim_release_date (models/gold/dim_release_date.sql)
  :HTTPDriver for http://clickhouse-server:8123 returned response code 400)
   Code: 36. DB::Exception: Incorrect syntax '%A', symbol is not supported 'A' for function formatDateTime: while executing function formatDateTime on arguments __table1.release_date Date32 Int32(size = 0), '%A'_String String Const(size = 0, String(size = 1)). (BAD_ARGUMENTS) (version 25.9.3.48 (official build))
[0m10:46:32.750068 [info ] [MainThread]: 
[0m10:46:32.750311 [info ] [MainThread]: Done. PASS=3 WARN=0 ERROR=2 SKIP=1 TOTAL=6
[0m10:46:32.753220 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 3.5480127, "process_in_blocks": "101576", "process_kernel_time": 0.233993, "process_mem_max_rss": "193124", "process_out_blocks": "4885", "process_user_time": 2.01054}
[0m10:46:32.753880 [debug] [MainThread]: Command `dbt run` failed at 10:46:32.753764 after 3.55 seconds
[0m10:46:32.754402 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8541c950>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8541ea10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff85006090>]}
[0m10:46:32.754625 [debug] [MainThread]: Flushing usage events
[0m10:52:58.047712 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa53adad0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa53df890>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa53df290>]}


============================== 10:52:58.051912 | 5d89a675-36fb-47db-bde2-9a5fd568b0ae ==============================
[0m10:52:58.051912 [info ] [MainThread]: Running with dbt=1.8.9
[0m10:52:58.052234 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/project_root/dbt', 'fail_fast': 'False', 'debug': 'False', 'log_path': '/opt/airflow/project_root/dbt/logs', 'version_check': 'True', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'invocation_command': 'dbt run --project-dir /opt/airflow/project_root/dbt --profiles-dir /opt/airflow/project_root/dbt --select gold', 'log_format': 'default', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m10:52:58.161346 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '5d89a675-36fb-47db-bde2-9a5fd568b0ae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa53ad890>]}
[0m10:52:58.180487 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '5d89a675-36fb-47db-bde2-9a5fd568b0ae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa5ddb450>]}
[0m10:52:58.181098 [info ] [MainThread]: Registered adapter: clickhouse=1.8.9
[0m10:52:58.214066 [debug] [MainThread]: checksum: 132857a23e9d07220246854f7763165174ce9b737cfc7867629ace4294e520b1, vars: {}, profile: , target: , version: 1.8.9
[0m10:52:58.269779 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 2 files changed.
[0m10:52:58.270163 [debug] [MainThread]: Partial parsing: updated file: movie_warehouse://models/gold/dim_release_date.sql
[0m10:52:58.270412 [debug] [MainThread]: Partial parsing: updated file: movie_warehouse://models/gold/dim_production.sql
[0m10:52:58.369989 [warn ] [MainThread]: [[33mWARNING[0m]: Deprecated functionality
The `tests` config has been renamed to `data_tests`. Please see
https://docs.getdbt.com/docs/build/data-tests#new-data_tests-syntax for more
information.
[0m10:52:58.370503 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'deprecation', 'label': '5d89a675-36fb-47db-bde2-9a5fd568b0ae', 'property_': 'warn', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa4dbaf10>]}
[0m10:52:58.440480 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.movie_warehouse.bronze
[0m10:52:58.445560 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '5d89a675-36fb-47db-bde2-9a5fd568b0ae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa4e30850>]}
[0m10:52:58.531990 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '5d89a675-36fb-47db-bde2-9a5fd568b0ae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa4d977d0>]}
[0m10:52:58.532317 [info ] [MainThread]: Found 6 models, 12 data tests, 4 sources, 476 macros
[0m10:52:58.532535 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '5d89a675-36fb-47db-bde2-9a5fd568b0ae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff9fdaded0>]}
[0m10:52:58.533339 [info ] [MainThread]: 
[0m10:52:58.533639 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m10:52:58.536185 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m10:52:58.540372 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:52:58.869705 [info ] [ThreadPool]: dbt_clickhouse adapter: Unexpected server exception dropping table
[0m10:52:58.870417 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m10:52:58.874980 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m10:52:58.947093 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__gold_gold)
[0m10:52:58.949969 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__gold_gold: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "connection_name": "list__gold_gold"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'gold_gold'
      

  ...
[0m10:52:58.955911 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m10:52:58.957123 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '5d89a675-36fb-47db-bde2-9a5fd568b0ae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff665a2010>]}
[0m10:52:58.957458 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m10:52:58.957647 [info ] [MainThread]: 
[0m10:52:58.962739 [debug] [Thread-1 (]: Began running node model.movie_warehouse.dim_director
[0m10:52:58.963191 [info ] [Thread-1 (]: 1 of 6 START sql table model `gold_gold`.`dim_director` ........................ [RUN]
[0m10:52:58.963493 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list__gold_gold, now model.movie_warehouse.dim_director)
[0m10:52:58.963679 [debug] [Thread-1 (]: Began compiling node model.movie_warehouse.dim_director
[0m10:52:58.967282 [debug] [Thread-1 (]: Writing injected SQL for node "model.movie_warehouse.dim_director"
[0m10:52:58.968297 [debug] [Thread-1 (]: Began executing node model.movie_warehouse.dim_director
[0m10:52:58.989666 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_director: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_director"} */

            

    
        create table `gold_gold`.`dim_director__dbt_backup`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

WITH first_dir AS (
    SELECT
        tconst,
        TRIM(splitByChar(',', directors)[1]) AS director_id
    FROM `bronze`.`imdb_title_crew_raw`
    WHERE directors IS NOT NULL AND directors != ''
),
deduped AS (
    SELECT DISTINCT director_id
    FROM first_dir
),
joined AS (
    SELECT
        d.director_id AS dir_id,
        n.primaryName AS dir_name
    FROM deduped d
    LEFT JOIN `bronze`.`imdb_name_basics_raw` n
        ON d.director_id = n.nconst
)
SELECT
    cityHash64(dir_id) AS imdb_dir_name_id,  -- Use hash instead of row_number
    dir_id,
    dir_name,
    today() AS valid_from,
    CAST(NULL AS Nullable(Date)) AS valid_to,
    1 AS is_current  -- Use 1/0 instead of TRUE/FALSE
FROM joined
WHERE dir_id IS NOT NULL
ORDER BY dir_id
          )
        
        ...
[0m10:52:58.999664 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m10:52:59.008088 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_director: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_director"} */

    select name, type from system.columns where table = 'dim_director__dbt_backup'
    
      and database = 'gold_gold'
    
    order by position
  ...
[0m10:52:59.011175 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m10:52:59.013088 [debug] [Thread-1 (]: Writing runtime sql for node "model.movie_warehouse.dim_director"
[0m10:52:59.014101 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_director: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_director"} */

  
    
    
    
        
         


        insert into `gold_gold`.`dim_director__dbt_backup`
        ("imdb_dir_name_id", "dir_id", "dir_name", "valid_from", "valid_to", "is_current")

WITH first_dir AS (
    SELECT
        tconst,
        TRIM(splitByChar(',', directors)[1]) AS director_id
    FROM `bronze`.`imdb_title_crew_raw`
    WHERE directors IS NOT NULL AND directors != ''
),
deduped AS (
    SELECT DISTINCT director_id
    FROM first_dir
),
joined AS (
    SELECT
        d.director_id AS dir_id,
        n.primaryName AS dir_name
    FROM deduped d
    LEFT JOIN `bronze`.`imdb_name_basics_raw` n
        ON d.director_id = n.nconst
)
SELECT
    cityHash64(dir_id) AS imdb_dir_name_id,  -- Use hash instead of row_number
    dir_id,
    dir_name,
    today() AS valid_from,
    CAST(NULL AS Nullable(Date)) AS valid_to,
    1 AS is_current  -- Use 1/0 instead of TRUE/FALSE
FROM joined
WHERE dir_id IS NOT NULL
ORDER BY dir_id
  ...
[0m10:53:01.289146 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 2.27 seconds
[0m10:53:01.302927 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_director: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_director"} */
EXCHANGE TABLES `gold_gold`.`dim_director__dbt_backup` AND `gold_gold`.`dim_director` 
  
  ...
[0m10:53:01.310122 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m10:53:01.345524 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_director: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_director"} */

    drop table if exists `gold_gold`.`dim_director__dbt_backup` 
  ...
[0m10:53:01.350750 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_director"} */

    drop table if exists `gold_gold`.`dim_director__dbt_backup` 
  
[0m10:53:01.351358 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: macro drop_relation
[0m10:53:01.361609 [debug] [Thread-1 (]: Database Error in model dim_director (models/gold/dim_director.sql)
  :HTTPDriver for http://clickhouse-server:8123 returned response code 500)
   std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/8c9/8c9b38bb-5974-4368-97d1-712fe72b58b0/dim_director__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/gold_gold.dim_director__dbt_backup.e138c244-318d-4607-8a2f-5d2e9ee773a5.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build))
  compiled code at target/run/movie_warehouse/models/gold/dim_director.sql
[0m10:53:01.365649 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5d89a675-36fb-47db-bde2-9a5fd568b0ae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff6492ccd0>]}
[0m10:53:01.367141 [error] [Thread-1 (]: 1 of 6 ERROR creating sql table model `gold_gold`.`dim_director` ............... [[31mERROR[0m in 2.40s]
[0m10:53:01.368076 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.dim_director
[0m10:53:01.368662 [debug] [Thread-1 (]: Began running node model.movie_warehouse.dim_genre
[0m10:53:01.370431 [info ] [Thread-1 (]: 2 of 6 START sql table model `gold_gold`.`dim_genre` ........................... [RUN]
[0m10:53:01.371213 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.movie_warehouse.dim_director, now model.movie_warehouse.dim_genre)
[0m10:53:01.371724 [debug] [Thread-1 (]: Began compiling node model.movie_warehouse.dim_genre
[0m10:53:01.378233 [debug] [Thread-1 (]: Writing injected SQL for node "model.movie_warehouse.dim_genre"
[0m10:53:01.379240 [debug] [Thread-1 (]: Began executing node model.movie_warehouse.dim_genre
[0m10:53:01.381660 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_genre: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_genre"} */

            

    
        create table `gold_gold`.`dim_genre__dbt_backup`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

WITH parsed_genres AS (
    SELECT
        TRIM(splitByChar(',', genres)[1]) AS first_genre
    FROM `bronze`.`tmdb_raw`
    WHERE genres IS NOT NULL AND genres != ''
)
SELECT
    cityHash64(first_genre) AS genre_id,
    first_genre AS genre_name
FROM parsed_genres
GROUP BY first_genre
ORDER BY first_genre
          )
        
        ...
[0m10:53:01.389042 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m10:53:01.390671 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_genre: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_genre"} */

    select name, type from system.columns where table = 'dim_genre__dbt_backup'
    
      and database = 'gold_gold'
    
    order by position
  ...
[0m10:53:01.398213 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m10:53:01.400218 [debug] [Thread-1 (]: Writing runtime sql for node "model.movie_warehouse.dim_genre"
[0m10:53:01.401094 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_genre: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_genre"} */

  
    
    
    
        
         


        insert into `gold_gold`.`dim_genre__dbt_backup`
        ("genre_id", "genre_name")

WITH parsed_genres AS (
    SELECT
        TRIM(splitByChar(',', genres)[1]) AS first_genre
    FROM `bronze`.`tmdb_raw`
    WHERE genres IS NOT NULL AND genres != ''
)
SELECT
    cityHash64(first_genre) AS genre_id,
    first_genre AS genre_name
FROM parsed_genres
GROUP BY first_genre
ORDER BY first_genre
  ...
[0m10:53:01.435288 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.03 seconds
[0m10:53:01.436563 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_genre: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_genre"} */
EXCHANGE TABLES `gold_gold`.`dim_genre__dbt_backup` AND `gold_gold`.`dim_genre` 
  
  ...
[0m10:53:01.440640 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m10:53:01.442942 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_genre: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_genre"} */

    drop table if exists `gold_gold`.`dim_genre__dbt_backup` 
  ...
[0m10:53:01.446189 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_genre"} */

    drop table if exists `gold_gold`.`dim_genre__dbt_backup` 
  
[0m10:53:01.446729 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: macro drop_relation
[0m10:53:01.451147 [debug] [Thread-1 (]: Database Error in model dim_genre (models/gold/dim_genre.sql)
  :HTTPDriver for http://clickhouse-server:8123 returned response code 500)
   std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/8c9/8c9b38bb-5974-4368-97d1-712fe72b58b0/dim_genre__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/gold_gold.dim_genre__dbt_backup.1a4c28e4-e09c-47e4-aa23-5e5b4d20e16f.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build))
  compiled code at target/run/movie_warehouse/models/gold/dim_genre.sql
[0m10:53:01.451698 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5d89a675-36fb-47db-bde2-9a5fd568b0ae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa4e12990>]}
[0m10:53:01.452764 [error] [Thread-1 (]: 2 of 6 ERROR creating sql table model `gold_gold`.`dim_genre` .................. [[31mERROR[0m in 0.08s]
[0m10:53:01.453475 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.dim_genre
[0m10:53:01.454054 [debug] [Thread-1 (]: Began running node model.movie_warehouse.dim_movie
[0m10:53:01.454640 [info ] [Thread-1 (]: 3 of 6 START sql table model `gold_gold`.`dim_movie` ........................... [RUN]
[0m10:53:01.454935 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.movie_warehouse.dim_genre, now model.movie_warehouse.dim_movie)
[0m10:53:01.455161 [debug] [Thread-1 (]: Began compiling node model.movie_warehouse.dim_movie
[0m10:53:01.456880 [debug] [Thread-1 (]: Writing injected SQL for node "model.movie_warehouse.dim_movie"
[0m10:53:01.457482 [debug] [Thread-1 (]: Began executing node model.movie_warehouse.dim_movie
[0m10:53:01.459084 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_movie: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_movie"} */

            

    
        create table `gold_gold`.`dim_movie__dbt_backup`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            -- ...existing code...


WITH movie_src AS (
    SELECT
        TRIM(title) AS movie_title,
        imdb_id,
        release_date,
        runtime AS movie_runtime,
        original_language AS language
    FROM `bronze`.`tmdb_raw`
    WHERE title IS NOT NULL AND title != ''
)
SELECT
    cityHash64(movie_title) AS movie_id,
    any(imdb_id) AS imdb_id,
    movie_title,
    any(release_date) AS release_date,
    any(movie_runtime) AS movie_runtime,
    any(language) AS language
FROM movie_src
GROUP BY movie_title
ORDER BY movie_title
          )
        
        ...
[0m10:53:01.466290 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m10:53:01.467789 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_movie: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_movie"} */

    select name, type from system.columns where table = 'dim_movie__dbt_backup'
    
      and database = 'gold_gold'
    
    order by position
  ...
[0m10:53:01.471060 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m10:53:01.472614 [debug] [Thread-1 (]: Writing runtime sql for node "model.movie_warehouse.dim_movie"
[0m10:53:01.473568 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_movie: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_movie"} */

  
    
    
    
        
         


        insert into `gold_gold`.`dim_movie__dbt_backup`
        ("movie_id", "imdb_id", "movie_title", "release_date", "movie_runtime", "language")-- ...existing code...


WITH movie_src AS (
    SELECT
        TRIM(title) AS movie_title,
        imdb_id,
        release_date,
        runtime AS movie_runtime,
        original_language AS language
    FROM `bronze`.`tmdb_raw`
    WHERE title IS NOT NULL AND title != ''
)
SELECT
    cityHash64(movie_title) AS movie_id,
    any(imdb_id) AS imdb_id,
    movie_title,
    any(release_date) AS release_date,
    any(movie_runtime) AS movie_runtime,
    any(language) AS language
FROM movie_src
GROUP BY movie_title
ORDER BY movie_title
  ...
[0m10:53:01.729361 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.26 seconds
[0m10:53:01.730604 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_movie: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_movie"} */
EXCHANGE TABLES `gold_gold`.`dim_movie__dbt_backup` AND `gold_gold`.`dim_movie` 
  
  ...
[0m10:53:01.734625 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m10:53:01.737296 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_movie: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_movie"} */

    drop table if exists `gold_gold`.`dim_movie__dbt_backup` 
  ...
[0m10:53:01.739167 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_movie"} */

    drop table if exists `gold_gold`.`dim_movie__dbt_backup` 
  
[0m10:53:01.739427 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: macro drop_relation
[0m10:53:01.741357 [debug] [Thread-1 (]: Database Error in model dim_movie (models/gold/dim_movie.sql)
  :HTTPDriver for http://clickhouse-server:8123 returned response code 500)
   std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/8c9/8c9b38bb-5974-4368-97d1-712fe72b58b0/dim_movie__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/gold_gold.dim_movie__dbt_backup.cfe16ff3-c081-4abd-964d-4b134361646b.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build))
  compiled code at target/run/movie_warehouse/models/gold/dim_movie.sql
[0m10:53:01.741768 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5d89a675-36fb-47db-bde2-9a5fd568b0ae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff64a8e4d0>]}
[0m10:53:01.742288 [error] [Thread-1 (]: 3 of 6 ERROR creating sql table model `gold_gold`.`dim_movie` .................. [[31mERROR[0m in 0.29s]
[0m10:53:01.742657 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.dim_movie
[0m10:53:01.742937 [debug] [Thread-1 (]: Began running node model.movie_warehouse.dim_production
[0m10:53:01.743337 [info ] [Thread-1 (]: 4 of 6 START sql table model `gold_gold`.`dim_production` ...................... [RUN]
[0m10:53:01.743671 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.movie_warehouse.dim_movie, now model.movie_warehouse.dim_production)
[0m10:53:01.743880 [debug] [Thread-1 (]: Began compiling node model.movie_warehouse.dim_production
[0m10:53:01.745931 [debug] [Thread-1 (]: Writing injected SQL for node "model.movie_warehouse.dim_production"
[0m10:53:01.746827 [debug] [Thread-1 (]: Began executing node model.movie_warehouse.dim_production
[0m10:53:01.748264 [debug] [Thread-1 (]: Creating new relation dim_production
[0m10:53:01.748913 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_production: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_production"} */

            

    
        create table `gold_gold`.`dim_production`
        
  
        
  engine = MergeTree()
        order by (production_id)
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

WITH first_production AS (
    SELECT
        imdb_id AS movie_id,
        trim(splitByChar(',', production_companies)[1]) AS production_name
    FROM `bronze`.`tmdb_raw`
    WHERE production_companies IS NOT NULL AND production_companies != ''
)

SELECT
    cityHash64(production_name) AS production_id,
    production_name,
    current_date() AS valid_from,
    CAST(NULL AS Date) AS valid_to,,
    TRUE AS is_current
FROM (
    SELECT DISTINCT production_name
    FROM first_production
)
WHERE production_name IS NOT NULL
          )
        
        ...
[0m10:53:01.754170 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_production"} */

            

    
        create table `gold_gold`.`dim_production`
        
  
        
  engine = MergeTree()
        order by (production_id)
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

WITH first_production AS (
    SELECT
        imdb_id AS movie_id,
        trim(splitByChar(',', production_companies)[1]) AS production_name
    FROM `bronze`.`tmdb_raw`
    WHERE production_companies IS NOT NULL AND production_companies != ''
)

SELECT
    cityHash64(production_name) AS production_id,
    production_name,
    current_date() AS valid_from,
    CAST(NULL AS Date) AS valid_to,,
    TRUE AS is_current
FROM (
    SELECT DISTINCT production_name
    FROM first_production
)
WHERE production_name IS NOT NULL
          )
        
        
[0m10:53:01.757746 [debug] [Thread-1 (]: Database Error in model dim_production (models/gold/dim_production.sql)
  :HTTPDriver for http://clickhouse-server:8123 returned response code 400)
   Code: 62. DB::Exception: Syntax error: failed at position 906 (TRUE) (line 37, col 5): TRUE AS is_current
  FROM (
      SELECT DISTINCT production_name
      FROM first_production
  )
  WHERE production_name IS NOT NULL
            )
          
          . Expected one of: expression with optional alias, element of expression with optional alias, lambda expression. (SYNTAX_ERROR) (version 25.9.3.48 (official build))
[0m10:53:01.758096 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5d89a675-36fb-47db-bde2-9a5fd568b0ae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff646ff690>]}
[0m10:53:01.758694 [error] [Thread-1 (]: 4 of 6 ERROR creating sql table model `gold_gold`.`dim_production` ............. [[31mERROR[0m in 0.01s]
[0m10:53:01.759135 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.dim_production
[0m10:53:01.759424 [debug] [Thread-1 (]: Began running node model.movie_warehouse.dim_release_date
[0m10:53:01.759764 [info ] [Thread-1 (]: 5 of 6 START sql table model `gold_gold`.`dim_release_date` .................... [RUN]
[0m10:53:01.760001 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.movie_warehouse.dim_production, now model.movie_warehouse.dim_release_date)
[0m10:53:01.760193 [debug] [Thread-1 (]: Began compiling node model.movie_warehouse.dim_release_date
[0m10:53:01.761989 [debug] [Thread-1 (]: Writing injected SQL for node "model.movie_warehouse.dim_release_date"
[0m10:53:01.763615 [debug] [Thread-1 (]: Began executing node model.movie_warehouse.dim_release_date
[0m10:53:01.764840 [debug] [Thread-1 (]: Creating new relation dim_release_date
[0m10:53:01.765553 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_release_date: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_release_date"} */

            

    
        create table `gold_gold`.`dim_release_date`
        
  
        
  engine = MergeTree()
        order by (date_id)
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

WITH distinct_dates AS (
    SELECT DISTINCT release_date
    FROM `bronze`.`tmdb_raw`
    WHERE release_date IS NOT NULL
)

SELECT
    cityHash64(release_date)                                    AS date_id,
    release_date                                                AS full_date,
    toYear(release_date)                                        AS year,
    toMonth(release_date)                                       AS month,
    toDayOfMonth(release_date)                                  AS day,
    toISOWeek(release_date)                                     AS week,
    formatDateTime(release_date, '%a')                          AS weekday,
    CASE
        WHEN toMonth(release_date) IN (12,1,2)  THEN 'Winter'
        WHEN toMonth(release_date) IN (3,4,5)   THEN 'Spring'
        WHEN toMonth(release_date) IN (6,7,8)   THEN 'Summer'
        WHEN toMonth(release_date) IN (9,10,11) THEN 'Autumn'
    END                                                         AS season,
    CASE
        WHEN formatDateTime(release_date, '%a') IN ('Saturday','Sunday') THEN 1
        ELSE 0
    END                                                         AS is_weekend,

    /* ---------- holiday tagging ---------- */
    CASE
        WHEN toMonth(release_date)=1  AND toDayOfMonth(release_date)=1  THEN 'New Years Day'
        WHEN toMonth(release_date)=2  AND toDayOfMonth(release_date)=14 THEN 'Valentines Day'
        WHEN toMonth(release_date)=3  AND toDayOfMonth(release_date)=17 THEN 'St. Patricks Day'
        WHEN toMonth(release_date)=4  AND toDayOfMonth(release_date)=1  THEN 'April Fools Day'
        WHEN toMonth(release_date)=4  AND toDayOfMonth(release_date)=22 THEN 'Earth Day'
        WHEN toMonth(release_date)=5  AND toDayOfMonth(release_date)=1  THEN 'May Day'
        WHEN toMonth(release_date)=5  AND toDayOfMonth(release_date)=5  THEN 'Cinco de Mayo'
        WHEN toMonth(release_date)=6  AND toDayOfMonth(release_date) BETWEEN 19 AND 26 THEN 'Midsummer'
        WHEN toMonth(release_date)=7  AND toDayOfMonth(release_date)=4  THEN 'Independence Day'
        WHEN toMonth(release_date)=9  AND toDayOfMonth(release_date) BETWEEN 1 AND 7 
             AND formatDateTime(release_date,'%a')='Monday'             THEN 'Labor Day (US)'
        WHEN toMonth(release_date)=10 AND toDayOfMonth(release_date)=31 THEN 'Halloween'
        WHEN toMonth(release_date)=11 AND formatDateTime(release_date,'%a')='Thursday'
             AND toISOWeek(release_date) >= 47                           THEN 'Thanksgiving'
        WHEN toMonth(release_date)=12 AND toDayOfMonth(release_date)=24 THEN 'Christmas Eve'
        WHEN toMonth(release_date)=12 AND toDayOfMonth(release_date)=25 THEN 'Christmas Day'
        WHEN toMonth(release_date)=12 AND toDayOfMonth(release_date)=31 THEN 'New Years Eve'
        ELSE NULL
    END                                                         AS holiday_name,
    IF(holiday_name IS NOT NULL, 1, 0)                          AS is_holiday,

    /* placeholders for later enhancement */
    CAST(NULL AS Int32) AS days_until_holiday,
    CAST(NULL AS Int32) AS days_after_holiday
FROM distinct_dates
ORDER BY release_date
          )
        
        ...
[0m10:53:01.779096 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_release_date"} */

            

    
        create table `gold_gold`.`dim_release_date`
        
  
        
  engine = MergeTree()
        order by (date_id)
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

WITH distinct_dates AS (
    SELECT DISTINCT release_date
    FROM `bronze`.`tmdb_raw`
    WHERE release_date IS NOT NULL
)

SELECT
    cityHash64(release_date)                                    AS date_id,
    release_date                                                AS full_date,
    toYear(release_date)                                        AS year,
    toMonth(release_date)                                       AS month,
    toDayOfMonth(release_date)                                  AS day,
    toISOWeek(release_date)                                     AS week,
    formatDateTime(release_date, '%a')                          AS weekday,
    CASE
        WHEN toMonth(release_date) IN (12,1,2)  THEN 'Winter'
        WHEN toMonth(release_date) IN (3,4,5)   THEN 'Spring'
        WHEN toMonth(release_date) IN (6,7,8)   THEN 'Summer'
        WHEN toMonth(release_date) IN (9,10,11) THEN 'Autumn'
    END                                                         AS season,
    CASE
        WHEN formatDateTime(release_date, '%a') IN ('Saturday','Sunday') THEN 1
        ELSE 0
    END                                                         AS is_weekend,

    /* ---------- holiday tagging ---------- */
    CASE
        WHEN toMonth(release_date)=1  AND toDayOfMonth(release_date)=1  THEN 'New Years Day'
        WHEN toMonth(release_date)=2  AND toDayOfMonth(release_date)=14 THEN 'Valentines Day'
        WHEN toMonth(release_date)=3  AND toDayOfMonth(release_date)=17 THEN 'St. Patricks Day'
        WHEN toMonth(release_date)=4  AND toDayOfMonth(release_date)=1  THEN 'April Fools Day'
        WHEN toMonth(release_date)=4  AND toDayOfMonth(release_date)=22 THEN 'Earth Day'
        WHEN toMonth(release_date)=5  AND toDayOfMonth(release_date)=1  THEN 'May Day'
        WHEN toMonth(release_date)=5  AND toDayOfMonth(release_date)=5  THEN 'Cinco de Mayo'
        WHEN toMonth(release_date)=6  AND toDayOfMonth(release_date) BETWEEN 19 AND 26 THEN 'Midsummer'
        WHEN toMonth(release_date)=7  AND toDayOfMonth(release_date)=4  THEN 'Independence Day'
        WHEN toMonth(release_date)=9  AND toDayOfMonth(release_date) BETWEEN 1 AND 7 
             AND formatDateTime(release_date,'%a')='Monday'             THEN 'Labor Day (US)'
        WHEN toMonth(release_date)=10 AND toDayOfMonth(release_date)=31 THEN 'Halloween'
        WHEN toMonth(release_date)=11 AND formatDateTime(release_date,'%a')='Thursday'
             AND toISOWeek(release_date) >= 47                           THEN 'Thanksgiving'
        WHEN toMonth(release_date)=12 AND toDayOfMonth(release_date)=24 THEN 'Christmas Eve'
        WHEN toMonth(release_date)=12 AND toDayOfMonth(release_date)=25 THEN 'Christmas Day'
        WHEN toMonth(release_date)=12 AND toDayOfMonth(release_date)=31 THEN 'New Years Eve'
        ELSE NULL
    END                                                         AS holiday_name,
    IF(holiday_name IS NOT NULL, 1, 0)                          AS is_holiday,

    /* placeholders for later enhancement */
    CAST(NULL AS Int32) AS days_until_holiday,
    CAST(NULL AS Int32) AS days_after_holiday
FROM distinct_dates
ORDER BY release_date
          )
        
        
[0m10:53:01.788327 [debug] [Thread-1 (]: Database Error in model dim_release_date (models/gold/dim_release_date.sql)
  :HTTPDriver for http://clickhouse-server:8123 returned response code 500)
   Code: 70. DB::Exception: Cannot convert NULL to a non-nullable type: In scope WITH distinct_dates AS (SELECT DISTINCT release_date FROM bronze.tmdb_raw WHERE release_date IS NOT NULL) SELECT cityHash64(release_date) AS date_id, release_date AS full_date, toYear(release_date) AS year, toMonth(release_date) AS month, toDayOfMonth(release_date) AS day, toISOWeek(release_date) AS week, formatDateTime(release_date, '%a') AS weekday, multiIf(toMonth(release_date) IN (12, 1, 2), 'Winter', toMonth(release_date) IN (3, 4, 5), 'Spring', toMonth(release_date) IN (6, 7, 8), 'Summer', toMonth(release_date) IN (9, 10, 11), 'Autumn', NULL) AS season, multiIf(formatDateTime(release_date, '%a') IN ('Saturday', 'Sunday'), 1, 0) AS is_weekend, multiIf((toMonth(release_date) = 1) AND (toDayOfMonth(release_date) = 1), 'New Years Day', (toMonth(release_date) = 2) AND (toDayOfMonth(release_date) = 14), 'Valentines Day', (toMonth(release_date) = 3) AND (toDayOfMonth(release_date) = 17), 'St. Patricks Day', (toMonth(release_date) = 4) AND (toDayOfMonth(release_date) = 1), 'April Fools Day', (toMonth(release_date) = 4) AND (toDayOfMonth(release_date) = 22), 'Earth Day', (toMonth(release_date) = 5) AND (toDayOfMonth(release_date) = 1), 'May Day', (toMonth(release_date) = 5) AND (toDayOfMonth(release_date) = 5), 'Cinco de Mayo', (toMonth(release_date) = 6) AND ((toDayOfMonth(release_date) >= 19) AND (toDayOfMonth(release_date) <= 26)), 'Midsummer', (toMonth(release_date) = 7) AND (toDayOfMonth(release_date) = 4), 'Independence Day', (toMonth(release_date) = 9) AND ((toDayOfMonth(release_date) >= 1) AND (toDayOfMonth(release_date) <= 7)) AND (formatDateTime(release_date, '%a') = 'Monday'), 'Labor Day (US)', (toMonth(release_date) = 10) AND (toDayOfMonth(release_date) = 31), 'Halloween', (toMonth(release_date) = 11) AND (formatDateTime(release_date, '%a') = 'Thursday') AND (toISOWeek(release_date) >= 47), 'Thanksgiving', (toMonth(release_date) = 12) AND (toDayOfMonth(release_date) = 24), 'Christmas Eve', (toMonth(release_date) = 12) AND (toDayOfMonth(release_date) = 25), 'Christmas Day', (toMonth(release_date) = 12) AND (toDayOfMonth(release_date) = 31), 'New Years Eve', NULL) AS holiday_name, if(holiday_name IS NOT NULL, 1, 0) AS is_holiday, CAST(NULL, 'Int32') AS days_until_holiday, CAST(NULL, 'Int32') AS days_after_holiday FROM distinct_dates ORDER BY release_date ASC. (CANNOT_CONVERT_TYPE) (version 25.9.3.48 (official build))
[0m10:53:01.789371 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5d89a675-36fb-47db-bde2-9a5fd568b0ae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa51212d0>]}
[0m10:53:01.789979 [error] [Thread-1 (]: 5 of 6 ERROR creating sql table model `gold_gold`.`dim_release_date` ........... [[31mERROR[0m in 0.03s]
[0m10:53:01.790578 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.dim_release_date
[0m10:53:01.793751 [debug] [Thread-1 (]: Began running node model.movie_warehouse.fact_movie
[0m10:53:01.794399 [info ] [Thread-1 (]: 6 of 6 SKIP relation gold_gold.fact_movie ...................................... [[33mSKIP[0m]
[0m10:53:01.795244 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.fact_movie
[0m10:53:01.799078 [debug] [MainThread]: Connection 'master' was properly closed.
[0m10:53:01.799581 [debug] [MainThread]: Connection 'model.movie_warehouse.dim_release_date' was left open.
[0m10:53:01.799909 [debug] [MainThread]: On model.movie_warehouse.dim_release_date: Close
[0m10:53:01.800636 [info ] [MainThread]: 
[0m10:53:01.801107 [info ] [MainThread]: Finished running 6 table models in 0 hours 0 minutes and 3.27 seconds (3.27s).
[0m10:53:01.802684 [debug] [MainThread]: Command end result
[0m10:53:01.853895 [info ] [MainThread]: 
[0m10:53:01.854562 [info ] [MainThread]: [31mCompleted with 5 errors and 0 warnings:[0m
[0m10:53:01.855020 [info ] [MainThread]: 
[0m10:53:01.855429 [error] [MainThread]:   Database Error in model dim_director (models/gold/dim_director.sql)
  :HTTPDriver for http://clickhouse-server:8123 returned response code 500)
   std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/8c9/8c9b38bb-5974-4368-97d1-712fe72b58b0/dim_director__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/gold_gold.dim_director__dbt_backup.e138c244-318d-4607-8a2f-5d2e9ee773a5.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build))
  compiled code at target/run/movie_warehouse/models/gold/dim_director.sql
[0m10:53:01.855671 [info ] [MainThread]: 
[0m10:53:01.855965 [error] [MainThread]:   Database Error in model dim_genre (models/gold/dim_genre.sql)
  :HTTPDriver for http://clickhouse-server:8123 returned response code 500)
   std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/8c9/8c9b38bb-5974-4368-97d1-712fe72b58b0/dim_genre__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/gold_gold.dim_genre__dbt_backup.1a4c28e4-e09c-47e4-aa23-5e5b4d20e16f.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build))
  compiled code at target/run/movie_warehouse/models/gold/dim_genre.sql
[0m10:53:01.856201 [info ] [MainThread]: 
[0m10:53:01.856600 [error] [MainThread]:   Database Error in model dim_movie (models/gold/dim_movie.sql)
  :HTTPDriver for http://clickhouse-server:8123 returned response code 500)
   std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/8c9/8c9b38bb-5974-4368-97d1-712fe72b58b0/dim_movie__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/gold_gold.dim_movie__dbt_backup.cfe16ff3-c081-4abd-964d-4b134361646b.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build))
  compiled code at target/run/movie_warehouse/models/gold/dim_movie.sql
[0m10:53:01.856879 [info ] [MainThread]: 
[0m10:53:01.857120 [error] [MainThread]:   Database Error in model dim_production (models/gold/dim_production.sql)
  :HTTPDriver for http://clickhouse-server:8123 returned response code 400)
   Code: 62. DB::Exception: Syntax error: failed at position 906 (TRUE) (line 37, col 5): TRUE AS is_current
  FROM (
      SELECT DISTINCT production_name
      FROM first_production
  )
  WHERE production_name IS NOT NULL
            )
          
          . Expected one of: expression with optional alias, element of expression with optional alias, lambda expression. (SYNTAX_ERROR) (version 25.9.3.48 (official build))
[0m10:53:01.857339 [info ] [MainThread]: 
[0m10:53:01.857759 [error] [MainThread]:   Database Error in model dim_release_date (models/gold/dim_release_date.sql)
  :HTTPDriver for http://clickhouse-server:8123 returned response code 500)
   Code: 70. DB::Exception: Cannot convert NULL to a non-nullable type: In scope WITH distinct_dates AS (SELECT DISTINCT release_date FROM bronze.tmdb_raw WHERE release_date IS NOT NULL) SELECT cityHash64(release_date) AS date_id, release_date AS full_date, toYear(release_date) AS year, toMonth(release_date) AS month, toDayOfMonth(release_date) AS day, toISOWeek(release_date) AS week, formatDateTime(release_date, '%a') AS weekday, multiIf(toMonth(release_date) IN (12, 1, 2), 'Winter', toMonth(release_date) IN (3, 4, 5), 'Spring', toMonth(release_date) IN (6, 7, 8), 'Summer', toMonth(release_date) IN (9, 10, 11), 'Autumn', NULL) AS season, multiIf(formatDateTime(release_date, '%a') IN ('Saturday', 'Sunday'), 1, 0) AS is_weekend, multiIf((toMonth(release_date) = 1) AND (toDayOfMonth(release_date) = 1), 'New Years Day', (toMonth(release_date) = 2) AND (toDayOfMonth(release_date) = 14), 'Valentines Day', (toMonth(release_date) = 3) AND (toDayOfMonth(release_date) = 17), 'St. Patricks Day', (toMonth(release_date) = 4) AND (toDayOfMonth(release_date) = 1), 'April Fools Day', (toMonth(release_date) = 4) AND (toDayOfMonth(release_date) = 22), 'Earth Day', (toMonth(release_date) = 5) AND (toDayOfMonth(release_date) = 1), 'May Day', (toMonth(release_date) = 5) AND (toDayOfMonth(release_date) = 5), 'Cinco de Mayo', (toMonth(release_date) = 6) AND ((toDayOfMonth(release_date) >= 19) AND (toDayOfMonth(release_date) <= 26)), 'Midsummer', (toMonth(release_date) = 7) AND (toDayOfMonth(release_date) = 4), 'Independence Day', (toMonth(release_date) = 9) AND ((toDayOfMonth(release_date) >= 1) AND (toDayOfMonth(release_date) <= 7)) AND (formatDateTime(release_date, '%a') = 'Monday'), 'Labor Day (US)', (toMonth(release_date) = 10) AND (toDayOfMonth(release_date) = 31), 'Halloween', (toMonth(release_date) = 11) AND (formatDateTime(release_date, '%a') = 'Thursday') AND (toISOWeek(release_date) >= 47), 'Thanksgiving', (toMonth(release_date) = 12) AND (toDayOfMonth(release_date) = 24), 'Christmas Eve', (toMonth(release_date) = 12) AND (toDayOfMonth(release_date) = 25), 'Christmas Day', (toMonth(release_date) = 12) AND (toDayOfMonth(release_date) = 31), 'New Years Eve', NULL) AS holiday_name, if(holiday_name IS NOT NULL, 1, 0) AS is_holiday, CAST(NULL, 'Int32') AS days_until_holiday, CAST(NULL, 'Int32') AS days_after_holiday FROM distinct_dates ORDER BY release_date ASC. (CANNOT_CONVERT_TYPE) (version 25.9.3.48 (official build))
[0m10:53:01.858155 [info ] [MainThread]: 
[0m10:53:01.858505 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=5 SKIP=1 TOTAL=6
[0m10:53:01.861102 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 3.834605, "process_in_blocks": "110440", "process_kernel_time": 0.388437, "process_mem_max_rss": "192356", "process_out_blocks": "3460", "process_user_time": 2.089489}
[0m10:53:01.862089 [debug] [MainThread]: Command `dbt run` failed at 10:53:01.861993 after 3.84 seconds
[0m10:53:01.863998 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa53ae550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa540b890>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa540b490>]}
[0m10:53:01.865596 [debug] [MainThread]: Flushing usage events
[0m11:01:15.483484 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffaa9df210>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffaaa02110>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffaaa0f890>]}


============================== 11:01:15.488173 | a8f99de2-27c3-4cf8-b3c9-b45fe883477d ==============================
[0m11:01:15.488173 [info ] [MainThread]: Running with dbt=1.8.9
[0m11:01:15.488554 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'profiles_dir': '/opt/airflow/project_root/dbt', 'log_path': '/opt/airflow/project_root/dbt/logs', 'debug': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'static_parser': 'True', 'invocation_command': 'dbt run --project-dir /opt/airflow/project_root/dbt --profiles-dir /opt/airflow/project_root/dbt --select gold', 'introspect': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m11:01:15.604133 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'a8f99de2-27c3-4cf8-b3c9-b45fe883477d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffaadfb3d0>]}
[0m11:01:15.630397 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'a8f99de2-27c3-4cf8-b3c9-b45fe883477d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffab40b310>]}
[0m11:01:15.630986 [info ] [MainThread]: Registered adapter: clickhouse=1.8.9
[0m11:01:15.670429 [debug] [MainThread]: checksum: 132857a23e9d07220246854f7763165174ce9b737cfc7867629ace4294e520b1, vars: {}, profile: , target: , version: 1.8.9
[0m11:01:15.797466 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m11:01:15.798203 [debug] [MainThread]: Partial parsing: updated file: movie_warehouse://models/gold/dim_production.sql
[0m11:01:15.910171 [warn ] [MainThread]: [[33mWARNING[0m]: Deprecated functionality
The `tests` config has been renamed to `data_tests`. Please see
https://docs.getdbt.com/docs/build/data-tests#new-data_tests-syntax for more
information.
[0m11:01:15.910668 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'deprecation', 'label': 'a8f99de2-27c3-4cf8-b3c9-b45fe883477d', 'property_': 'warn', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffaa6e4bd0>]}
[0m11:01:15.996733 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.movie_warehouse.bronze
[0m11:01:16.003375 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'a8f99de2-27c3-4cf8-b3c9-b45fe883477d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffaa42e910>]}
[0m11:01:16.100621 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'a8f99de2-27c3-4cf8-b3c9-b45fe883477d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffaa3c4310>]}
[0m11:01:16.101118 [info ] [MainThread]: Found 6 models, 12 data tests, 4 sources, 476 macros
[0m11:01:16.101413 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a8f99de2-27c3-4cf8-b3c9-b45fe883477d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffaa439410>]}
[0m11:01:16.102396 [info ] [MainThread]: 
[0m11:01:16.102780 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m11:01:16.105901 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m11:01:16.110560 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:01:16.460029 [info ] [ThreadPool]: dbt_clickhouse adapter: Unexpected server exception dropping table
[0m11:01:16.460556 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m11:01:16.462960 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:01:16.549049 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__gold_gold)
[0m11:01:16.552477 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__gold_gold: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "connection_name": "list__gold_gold"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'gold_gold'
      

  ...
[0m11:01:16.559391 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m11:01:16.560811 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a8f99de2-27c3-4cf8-b3c9-b45fe883477d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffaa412690>]}
[0m11:01:16.561159 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m11:01:16.561440 [info ] [MainThread]: 
[0m11:01:16.567428 [debug] [Thread-1 (]: Began running node model.movie_warehouse.dim_director
[0m11:01:16.568146 [info ] [Thread-1 (]: 1 of 6 START sql table model `gold_gold`.`dim_director` ........................ [RUN]
[0m11:01:16.568569 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list__gold_gold, now model.movie_warehouse.dim_director)
[0m11:01:16.568944 [debug] [Thread-1 (]: Began compiling node model.movie_warehouse.dim_director
[0m11:01:16.573603 [debug] [Thread-1 (]: Writing injected SQL for node "model.movie_warehouse.dim_director"
[0m11:01:16.574686 [debug] [Thread-1 (]: Began executing node model.movie_warehouse.dim_director
[0m11:01:16.587933 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_director: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_director"} */

    drop table if exists `gold_gold`.`dim_director__dbt_backup` 
  ...
[0m11:01:16.590239 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_director"} */

    drop table if exists `gold_gold`.`dim_director__dbt_backup` 
  
[0m11:01:16.590503 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: macro drop_relation
[0m11:01:16.595922 [debug] [Thread-1 (]: Database Error in model dim_director (models/gold/dim_director.sql)
  :HTTPDriver for http://clickhouse-server:8123 returned response code 500)
   std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/8c9/8c9b38bb-5974-4368-97d1-712fe72b58b0/dim_director__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/gold_gold.dim_director__dbt_backup.e138c244-318d-4607-8a2f-5d2e9ee773a5.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build))
[0m11:01:16.596711 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a8f99de2-27c3-4cf8-b3c9-b45fe883477d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff65f8b750>]}
[0m11:01:16.597087 [error] [Thread-1 (]: 1 of 6 ERROR creating sql table model `gold_gold`.`dim_director` ............... [[31mERROR[0m in 0.03s]
[0m11:01:16.597427 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.dim_director
[0m11:01:16.597670 [debug] [Thread-1 (]: Began running node model.movie_warehouse.dim_genre
[0m11:01:16.598676 [info ] [Thread-1 (]: 2 of 6 START sql table model `gold_gold`.`dim_genre` ........................... [RUN]
[0m11:01:16.599307 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.movie_warehouse.dim_director, now model.movie_warehouse.dim_genre)
[0m11:01:16.599611 [debug] [Thread-1 (]: Began compiling node model.movie_warehouse.dim_genre
[0m11:01:16.601488 [debug] [Thread-1 (]: Writing injected SQL for node "model.movie_warehouse.dim_genre"
[0m11:01:16.602082 [debug] [Thread-1 (]: Began executing node model.movie_warehouse.dim_genre
[0m11:01:16.604291 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_genre: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_genre"} */

    drop table if exists `gold_gold`.`dim_genre__dbt_backup` 
  ...
[0m11:01:16.606538 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_genre"} */

    drop table if exists `gold_gold`.`dim_genre__dbt_backup` 
  
[0m11:01:16.606744 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: macro drop_relation
[0m11:01:16.608420 [debug] [Thread-1 (]: Database Error in model dim_genre (models/gold/dim_genre.sql)
  :HTTPDriver for http://clickhouse-server:8123 returned response code 500)
   std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/8c9/8c9b38bb-5974-4368-97d1-712fe72b58b0/dim_genre__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/gold_gold.dim_genre__dbt_backup.1a4c28e4-e09c-47e4-aa23-5e5b4d20e16f.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build))
[0m11:01:16.608658 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a8f99de2-27c3-4cf8-b3c9-b45fe883477d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff981a0cd0>]}
[0m11:01:16.608977 [error] [Thread-1 (]: 2 of 6 ERROR creating sql table model `gold_gold`.`dim_genre` .................. [[31mERROR[0m in 0.01s]
[0m11:01:16.609276 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.dim_genre
[0m11:01:16.609597 [debug] [Thread-1 (]: Began running node model.movie_warehouse.dim_movie
[0m11:01:16.609945 [info ] [Thread-1 (]: 3 of 6 START sql table model `gold_gold`.`dim_movie` ........................... [RUN]
[0m11:01:16.610161 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.movie_warehouse.dim_genre, now model.movie_warehouse.dim_movie)
[0m11:01:16.610328 [debug] [Thread-1 (]: Began compiling node model.movie_warehouse.dim_movie
[0m11:01:16.611697 [debug] [Thread-1 (]: Writing injected SQL for node "model.movie_warehouse.dim_movie"
[0m11:01:16.612155 [debug] [Thread-1 (]: Began executing node model.movie_warehouse.dim_movie
[0m11:01:16.615220 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_movie: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_movie"} */

    drop table if exists `gold_gold`.`dim_movie__dbt_backup` 
  ...
[0m11:01:16.616831 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_movie"} */

    drop table if exists `gold_gold`.`dim_movie__dbt_backup` 
  
[0m11:01:16.617027 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: macro drop_relation
[0m11:01:16.618704 [debug] [Thread-1 (]: Database Error in model dim_movie (models/gold/dim_movie.sql)
  :HTTPDriver for http://clickhouse-server:8123 returned response code 500)
   std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/8c9/8c9b38bb-5974-4368-97d1-712fe72b58b0/dim_movie__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/gold_gold.dim_movie__dbt_backup.cfe16ff3-c081-4abd-964d-4b134361646b.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build))
[0m11:01:16.618952 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a8f99de2-27c3-4cf8-b3c9-b45fe883477d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff65f09410>]}
[0m11:01:16.619309 [error] [Thread-1 (]: 3 of 6 ERROR creating sql table model `gold_gold`.`dim_movie` .................. [[31mERROR[0m in 0.01s]
[0m11:01:16.619566 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.dim_movie
[0m11:01:16.619751 [debug] [Thread-1 (]: Began running node model.movie_warehouse.dim_production
[0m11:01:16.620031 [info ] [Thread-1 (]: 4 of 6 START sql table model `gold_gold`.`dim_production` ...................... [RUN]
[0m11:01:16.620276 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.movie_warehouse.dim_movie, now model.movie_warehouse.dim_production)
[0m11:01:16.620474 [debug] [Thread-1 (]: Began compiling node model.movie_warehouse.dim_production
[0m11:01:16.621888 [debug] [Thread-1 (]: Writing injected SQL for node "model.movie_warehouse.dim_production"
[0m11:01:16.622374 [debug] [Thread-1 (]: Began executing node model.movie_warehouse.dim_production
[0m11:01:16.623353 [debug] [Thread-1 (]: Creating new relation dim_production
[0m11:01:16.635691 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_production: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_production"} */

            

    
        create table `gold_gold`.`dim_production`
        
  
        
  engine = MergeTree()
        order by (production_id)
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

WITH first_production AS (
    SELECT
        imdb_id AS movie_id,
        trim(splitByChar(',', production_companies)[1]) AS production_name
    FROM `bronze`.`tmdb_raw`
    WHERE production_companies IS NOT NULL AND production_companies != ''
)

SELECT
    cityHash64(production_name) AS production_id,
    production_name,
    current_date() AS valid_from,
    CAST(NULL AS Date) AS valid_to,
    TRUE AS is_current
FROM (
    SELECT DISTINCT production_name
    FROM first_production
)
WHERE production_name IS NOT NULL
          )
        
        ...
[0m11:01:16.640242 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_production"} */

            

    
        create table `gold_gold`.`dim_production`
        
  
        
  engine = MergeTree()
        order by (production_id)
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

WITH first_production AS (
    SELECT
        imdb_id AS movie_id,
        trim(splitByChar(',', production_companies)[1]) AS production_name
    FROM `bronze`.`tmdb_raw`
    WHERE production_companies IS NOT NULL AND production_companies != ''
)

SELECT
    cityHash64(production_name) AS production_id,
    production_name,
    current_date() AS valid_from,
    CAST(NULL AS Date) AS valid_to,
    TRUE AS is_current
FROM (
    SELECT DISTINCT production_name
    FROM first_production
)
WHERE production_name IS NOT NULL
          )
        
        
[0m11:01:16.642541 [debug] [Thread-1 (]: Database Error in model dim_production (models/gold/dim_production.sql)
  :HTTPDriver for http://clickhouse-server:8123 returned response code 500)
   Code: 70. DB::Exception: Cannot convert NULL to a non-nullable type: In scope WITH first_production AS (SELECT imdb_id AS movie_id, trimBoth(splitByChar(',', production_companies)[1]) AS production_name FROM bronze.tmdb_raw WHERE (production_companies IS NOT NULL) AND (production_companies != '')) SELECT cityHash64(production_name) AS production_id, production_name, today() AS valid_from, CAST(NULL, 'Date') AS valid_to, true AS is_current FROM (SELECT DISTINCT production_name FROM first_production) WHERE production_name IS NOT NULL. (CANNOT_CONVERT_TYPE) (version 25.9.3.48 (official build))
[0m11:01:16.642857 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a8f99de2-27c3-4cf8-b3c9-b45fe883477d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff664b4bd0>]}
[0m11:01:16.643200 [error] [Thread-1 (]: 4 of 6 ERROR creating sql table model `gold_gold`.`dim_production` ............. [[31mERROR[0m in 0.02s]
[0m11:01:16.643497 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.dim_production
[0m11:01:16.643746 [debug] [Thread-1 (]: Began running node model.movie_warehouse.dim_release_date
[0m11:01:16.644048 [info ] [Thread-1 (]: 5 of 6 START sql table model `gold_gold`.`dim_release_date` .................... [RUN]
[0m11:01:16.644297 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.movie_warehouse.dim_production, now model.movie_warehouse.dim_release_date)
[0m11:01:16.644468 [debug] [Thread-1 (]: Began compiling node model.movie_warehouse.dim_release_date
[0m11:01:16.646522 [debug] [Thread-1 (]: Writing injected SQL for node "model.movie_warehouse.dim_release_date"
[0m11:01:16.647090 [debug] [Thread-1 (]: Began executing node model.movie_warehouse.dim_release_date
[0m11:01:16.648254 [debug] [Thread-1 (]: Creating new relation dim_release_date
[0m11:01:16.649223 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_release_date: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_release_date"} */

            

    
        create table `gold_gold`.`dim_release_date`
        
  
        
  engine = MergeTree()
        order by (date_id)
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

WITH distinct_dates AS (
    SELECT DISTINCT release_date
    FROM `bronze`.`tmdb_raw`
    WHERE release_date IS NOT NULL
)

SELECT
    cityHash64(release_date)                                    AS date_id,
    release_date                                                AS full_date,
    toYear(release_date)                                        AS year,
    toMonth(release_date)                                       AS month,
    toDayOfMonth(release_date)                                  AS day,
    toISOWeek(release_date)                                     AS week,
    formatDateTime(release_date, '%a')                          AS weekday,
    CASE
        WHEN toMonth(release_date) IN (12,1,2)  THEN 'Winter'
        WHEN toMonth(release_date) IN (3,4,5)   THEN 'Spring'
        WHEN toMonth(release_date) IN (6,7,8)   THEN 'Summer'
        WHEN toMonth(release_date) IN (9,10,11) THEN 'Autumn'
    END                                                         AS season,
    CASE
        WHEN formatDateTime(release_date, '%a') IN ('Saturday','Sunday') THEN 1
        ELSE 0
    END                                                         AS is_weekend,

    /* ---------- holiday tagging ---------- */
    CASE
        WHEN toMonth(release_date)=1  AND toDayOfMonth(release_date)=1  THEN 'New Years Day'
        WHEN toMonth(release_date)=2  AND toDayOfMonth(release_date)=14 THEN 'Valentines Day'
        WHEN toMonth(release_date)=3  AND toDayOfMonth(release_date)=17 THEN 'St. Patricks Day'
        WHEN toMonth(release_date)=4  AND toDayOfMonth(release_date)=1  THEN 'April Fools Day'
        WHEN toMonth(release_date)=4  AND toDayOfMonth(release_date)=22 THEN 'Earth Day'
        WHEN toMonth(release_date)=5  AND toDayOfMonth(release_date)=1  THEN 'May Day'
        WHEN toMonth(release_date)=5  AND toDayOfMonth(release_date)=5  THEN 'Cinco de Mayo'
        WHEN toMonth(release_date)=6  AND toDayOfMonth(release_date) BETWEEN 19 AND 26 THEN 'Midsummer'
        WHEN toMonth(release_date)=7  AND toDayOfMonth(release_date)=4  THEN 'Independence Day'
        WHEN toMonth(release_date)=9  AND toDayOfMonth(release_date) BETWEEN 1 AND 7 
             AND formatDateTime(release_date,'%a')='Monday'             THEN 'Labor Day (US)'
        WHEN toMonth(release_date)=10 AND toDayOfMonth(release_date)=31 THEN 'Halloween'
        WHEN toMonth(release_date)=11 AND formatDateTime(release_date,'%a')='Thursday'
             AND toISOWeek(release_date) >= 47                           THEN 'Thanksgiving'
        WHEN toMonth(release_date)=12 AND toDayOfMonth(release_date)=24 THEN 'Christmas Eve'
        WHEN toMonth(release_date)=12 AND toDayOfMonth(release_date)=25 THEN 'Christmas Day'
        WHEN toMonth(release_date)=12 AND toDayOfMonth(release_date)=31 THEN 'New Years Eve'
        ELSE NULL
    END                                                         AS holiday_name,
    IF(holiday_name IS NOT NULL, 1, 0)                          AS is_holiday,

    /* placeholders for later enhancement */
    CAST(NULL AS Int32) AS days_until_holiday,
    CAST(NULL AS Int32) AS days_after_holiday
FROM distinct_dates
ORDER BY release_date
          )
        
        ...
[0m11:01:16.657135 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_release_date"} */

            

    
        create table `gold_gold`.`dim_release_date`
        
  
        
  engine = MergeTree()
        order by (date_id)
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

WITH distinct_dates AS (
    SELECT DISTINCT release_date
    FROM `bronze`.`tmdb_raw`
    WHERE release_date IS NOT NULL
)

SELECT
    cityHash64(release_date)                                    AS date_id,
    release_date                                                AS full_date,
    toYear(release_date)                                        AS year,
    toMonth(release_date)                                       AS month,
    toDayOfMonth(release_date)                                  AS day,
    toISOWeek(release_date)                                     AS week,
    formatDateTime(release_date, '%a')                          AS weekday,
    CASE
        WHEN toMonth(release_date) IN (12,1,2)  THEN 'Winter'
        WHEN toMonth(release_date) IN (3,4,5)   THEN 'Spring'
        WHEN toMonth(release_date) IN (6,7,8)   THEN 'Summer'
        WHEN toMonth(release_date) IN (9,10,11) THEN 'Autumn'
    END                                                         AS season,
    CASE
        WHEN formatDateTime(release_date, '%a') IN ('Saturday','Sunday') THEN 1
        ELSE 0
    END                                                         AS is_weekend,

    /* ---------- holiday tagging ---------- */
    CASE
        WHEN toMonth(release_date)=1  AND toDayOfMonth(release_date)=1  THEN 'New Years Day'
        WHEN toMonth(release_date)=2  AND toDayOfMonth(release_date)=14 THEN 'Valentines Day'
        WHEN toMonth(release_date)=3  AND toDayOfMonth(release_date)=17 THEN 'St. Patricks Day'
        WHEN toMonth(release_date)=4  AND toDayOfMonth(release_date)=1  THEN 'April Fools Day'
        WHEN toMonth(release_date)=4  AND toDayOfMonth(release_date)=22 THEN 'Earth Day'
        WHEN toMonth(release_date)=5  AND toDayOfMonth(release_date)=1  THEN 'May Day'
        WHEN toMonth(release_date)=5  AND toDayOfMonth(release_date)=5  THEN 'Cinco de Mayo'
        WHEN toMonth(release_date)=6  AND toDayOfMonth(release_date) BETWEEN 19 AND 26 THEN 'Midsummer'
        WHEN toMonth(release_date)=7  AND toDayOfMonth(release_date)=4  THEN 'Independence Day'
        WHEN toMonth(release_date)=9  AND toDayOfMonth(release_date) BETWEEN 1 AND 7 
             AND formatDateTime(release_date,'%a')='Monday'             THEN 'Labor Day (US)'
        WHEN toMonth(release_date)=10 AND toDayOfMonth(release_date)=31 THEN 'Halloween'
        WHEN toMonth(release_date)=11 AND formatDateTime(release_date,'%a')='Thursday'
             AND toISOWeek(release_date) >= 47                           THEN 'Thanksgiving'
        WHEN toMonth(release_date)=12 AND toDayOfMonth(release_date)=24 THEN 'Christmas Eve'
        WHEN toMonth(release_date)=12 AND toDayOfMonth(release_date)=25 THEN 'Christmas Day'
        WHEN toMonth(release_date)=12 AND toDayOfMonth(release_date)=31 THEN 'New Years Eve'
        ELSE NULL
    END                                                         AS holiday_name,
    IF(holiday_name IS NOT NULL, 1, 0)                          AS is_holiday,

    /* placeholders for later enhancement */
    CAST(NULL AS Int32) AS days_until_holiday,
    CAST(NULL AS Int32) AS days_after_holiday
FROM distinct_dates
ORDER BY release_date
          )
        
        
[0m11:01:16.659727 [debug] [Thread-1 (]: Database Error in model dim_release_date (models/gold/dim_release_date.sql)
  :HTTPDriver for http://clickhouse-server:8123 returned response code 500)
   Code: 70. DB::Exception: Cannot convert NULL to a non-nullable type: In scope WITH distinct_dates AS (SELECT DISTINCT release_date FROM bronze.tmdb_raw WHERE release_date IS NOT NULL) SELECT cityHash64(release_date) AS date_id, release_date AS full_date, toYear(release_date) AS year, toMonth(release_date) AS month, toDayOfMonth(release_date) AS day, toISOWeek(release_date) AS week, formatDateTime(release_date, '%a') AS weekday, multiIf(toMonth(release_date) IN (12, 1, 2), 'Winter', toMonth(release_date) IN (3, 4, 5), 'Spring', toMonth(release_date) IN (6, 7, 8), 'Summer', toMonth(release_date) IN (9, 10, 11), 'Autumn', NULL) AS season, multiIf(formatDateTime(release_date, '%a') IN ('Saturday', 'Sunday'), 1, 0) AS is_weekend, multiIf((toMonth(release_date) = 1) AND (toDayOfMonth(release_date) = 1), 'New Years Day', (toMonth(release_date) = 2) AND (toDayOfMonth(release_date) = 14), 'Valentines Day', (toMonth(release_date) = 3) AND (toDayOfMonth(release_date) = 17), 'St. Patricks Day', (toMonth(release_date) = 4) AND (toDayOfMonth(release_date) = 1), 'April Fools Day', (toMonth(release_date) = 4) AND (toDayOfMonth(release_date) = 22), 'Earth Day', (toMonth(release_date) = 5) AND (toDayOfMonth(release_date) = 1), 'May Day', (toMonth(release_date) = 5) AND (toDayOfMonth(release_date) = 5), 'Cinco de Mayo', (toMonth(release_date) = 6) AND ((toDayOfMonth(release_date) >= 19) AND (toDayOfMonth(release_date) <= 26)), 'Midsummer', (toMonth(release_date) = 7) AND (toDayOfMonth(release_date) = 4), 'Independence Day', (toMonth(release_date) = 9) AND ((toDayOfMonth(release_date) >= 1) AND (toDayOfMonth(release_date) <= 7)) AND (formatDateTime(release_date, '%a') = 'Monday'), 'Labor Day (US)', (toMonth(release_date) = 10) AND (toDayOfMonth(release_date) = 31), 'Halloween', (toMonth(release_date) = 11) AND (formatDateTime(release_date, '%a') = 'Thursday') AND (toISOWeek(release_date) >= 47), 'Thanksgiving', (toMonth(release_date) = 12) AND (toDayOfMonth(release_date) = 24), 'Christmas Eve', (toMonth(release_date) = 12) AND (toDayOfMonth(release_date) = 25), 'Christmas Day', (toMonth(release_date) = 12) AND (toDayOfMonth(release_date) = 31), 'New Years Eve', NULL) AS holiday_name, if(holiday_name IS NOT NULL, 1, 0) AS is_holiday, CAST(NULL, 'Int32') AS days_until_holiday, CAST(NULL, 'Int32') AS days_after_holiday FROM distinct_dates ORDER BY release_date ASC. (CANNOT_CONVERT_TYPE) (version 25.9.3.48 (official build))
[0m11:01:16.660261 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a8f99de2-27c3-4cf8-b3c9-b45fe883477d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff6603f1d0>]}
[0m11:01:16.660693 [error] [Thread-1 (]: 5 of 6 ERROR creating sql table model `gold_gold`.`dim_release_date` ........... [[31mERROR[0m in 0.02s]
[0m11:01:16.661090 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.dim_release_date
[0m11:01:16.661550 [debug] [Thread-1 (]: Began running node model.movie_warehouse.fact_movie
[0m11:01:16.661945 [info ] [Thread-1 (]: 6 of 6 SKIP relation gold_gold.fact_movie ...................................... [[33mSKIP[0m]
[0m11:01:16.662401 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.fact_movie
[0m11:01:16.663148 [debug] [MainThread]: Connection 'master' was properly closed.
[0m11:01:16.663370 [debug] [MainThread]: Connection 'model.movie_warehouse.dim_release_date' was left open.
[0m11:01:16.663546 [debug] [MainThread]: On model.movie_warehouse.dim_release_date: Close
[0m11:01:16.663812 [info ] [MainThread]: 
[0m11:01:16.663995 [info ] [MainThread]: Finished running 6 table models in 0 hours 0 minutes and 0.56 seconds (0.56s).
[0m11:01:16.664620 [debug] [MainThread]: Command end result
[0m11:01:16.688684 [info ] [MainThread]: 
[0m11:01:16.689302 [info ] [MainThread]: [31mCompleted with 5 errors and 0 warnings:[0m
[0m11:01:16.689502 [info ] [MainThread]: 
[0m11:01:16.689714 [error] [MainThread]:   Database Error in model dim_director (models/gold/dim_director.sql)
  :HTTPDriver for http://clickhouse-server:8123 returned response code 500)
   std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/8c9/8c9b38bb-5974-4368-97d1-712fe72b58b0/dim_director__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/gold_gold.dim_director__dbt_backup.e138c244-318d-4607-8a2f-5d2e9ee773a5.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build))
[0m11:01:16.689882 [info ] [MainThread]: 
[0m11:01:16.690068 [error] [MainThread]:   Database Error in model dim_genre (models/gold/dim_genre.sql)
  :HTTPDriver for http://clickhouse-server:8123 returned response code 500)
   std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/8c9/8c9b38bb-5974-4368-97d1-712fe72b58b0/dim_genre__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/gold_gold.dim_genre__dbt_backup.1a4c28e4-e09c-47e4-aa23-5e5b4d20e16f.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build))
[0m11:01:16.690221 [info ] [MainThread]: 
[0m11:01:16.690392 [error] [MainThread]:   Database Error in model dim_movie (models/gold/dim_movie.sql)
  :HTTPDriver for http://clickhouse-server:8123 returned response code 500)
   std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/8c9/8c9b38bb-5974-4368-97d1-712fe72b58b0/dim_movie__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/gold_gold.dim_movie__dbt_backup.cfe16ff3-c081-4abd-964d-4b134361646b.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build))
[0m11:01:16.690539 [info ] [MainThread]: 
[0m11:01:16.690744 [error] [MainThread]:   Database Error in model dim_production (models/gold/dim_production.sql)
  :HTTPDriver for http://clickhouse-server:8123 returned response code 500)
   Code: 70. DB::Exception: Cannot convert NULL to a non-nullable type: In scope WITH first_production AS (SELECT imdb_id AS movie_id, trimBoth(splitByChar(',', production_companies)[1]) AS production_name FROM bronze.tmdb_raw WHERE (production_companies IS NOT NULL) AND (production_companies != '')) SELECT cityHash64(production_name) AS production_id, production_name, today() AS valid_from, CAST(NULL, 'Date') AS valid_to, true AS is_current FROM (SELECT DISTINCT production_name FROM first_production) WHERE production_name IS NOT NULL. (CANNOT_CONVERT_TYPE) (version 25.9.3.48 (official build))
[0m11:01:16.691194 [info ] [MainThread]: 
[0m11:01:16.691431 [error] [MainThread]:   Database Error in model dim_release_date (models/gold/dim_release_date.sql)
  :HTTPDriver for http://clickhouse-server:8123 returned response code 500)
   Code: 70. DB::Exception: Cannot convert NULL to a non-nullable type: In scope WITH distinct_dates AS (SELECT DISTINCT release_date FROM bronze.tmdb_raw WHERE release_date IS NOT NULL) SELECT cityHash64(release_date) AS date_id, release_date AS full_date, toYear(release_date) AS year, toMonth(release_date) AS month, toDayOfMonth(release_date) AS day, toISOWeek(release_date) AS week, formatDateTime(release_date, '%a') AS weekday, multiIf(toMonth(release_date) IN (12, 1, 2), 'Winter', toMonth(release_date) IN (3, 4, 5), 'Spring', toMonth(release_date) IN (6, 7, 8), 'Summer', toMonth(release_date) IN (9, 10, 11), 'Autumn', NULL) AS season, multiIf(formatDateTime(release_date, '%a') IN ('Saturday', 'Sunday'), 1, 0) AS is_weekend, multiIf((toMonth(release_date) = 1) AND (toDayOfMonth(release_date) = 1), 'New Years Day', (toMonth(release_date) = 2) AND (toDayOfMonth(release_date) = 14), 'Valentines Day', (toMonth(release_date) = 3) AND (toDayOfMonth(release_date) = 17), 'St. Patricks Day', (toMonth(release_date) = 4) AND (toDayOfMonth(release_date) = 1), 'April Fools Day', (toMonth(release_date) = 4) AND (toDayOfMonth(release_date) = 22), 'Earth Day', (toMonth(release_date) = 5) AND (toDayOfMonth(release_date) = 1), 'May Day', (toMonth(release_date) = 5) AND (toDayOfMonth(release_date) = 5), 'Cinco de Mayo', (toMonth(release_date) = 6) AND ((toDayOfMonth(release_date) >= 19) AND (toDayOfMonth(release_date) <= 26)), 'Midsummer', (toMonth(release_date) = 7) AND (toDayOfMonth(release_date) = 4), 'Independence Day', (toMonth(release_date) = 9) AND ((toDayOfMonth(release_date) >= 1) AND (toDayOfMonth(release_date) <= 7)) AND (formatDateTime(release_date, '%a') = 'Monday'), 'Labor Day (US)', (toMonth(release_date) = 10) AND (toDayOfMonth(release_date) = 31), 'Halloween', (toMonth(release_date) = 11) AND (formatDateTime(release_date, '%a') = 'Thursday') AND (toISOWeek(release_date) >= 47), 'Thanksgiving', (toMonth(release_date) = 12) AND (toDayOfMonth(release_date) = 24), 'Christmas Eve', (toMonth(release_date) = 12) AND (toDayOfMonth(release_date) = 25), 'Christmas Day', (toMonth(release_date) = 12) AND (toDayOfMonth(release_date) = 31), 'New Years Eve', NULL) AS holiday_name, if(holiday_name IS NOT NULL, 1, 0) AS is_holiday, CAST(NULL, 'Int32') AS days_until_holiday, CAST(NULL, 'Int32') AS days_after_holiday FROM distinct_dates ORDER BY release_date ASC. (CANNOT_CONVERT_TYPE) (version 25.9.3.48 (official build))
[0m11:01:16.691671 [info ] [MainThread]: 
[0m11:01:16.691843 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=5 SKIP=1 TOTAL=6
[0m11:01:16.692511 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 1.2301937, "process_in_blocks": "68536", "process_kernel_time": 0.395347, "process_mem_max_rss": "193592", "process_out_blocks": "3436", "process_user_time": 2.144733}
[0m11:01:16.692836 [debug] [MainThread]: Command `dbt run` failed at 11:01:16.692752 after 1.23 seconds
[0m11:01:16.693225 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffaaa181d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffaaa198d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffaaa18d10>]}
[0m11:01:16.693449 [debug] [MainThread]: Flushing usage events
[0m11:06:33.330703 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff79e6e4d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff79e6d910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff79e6ca10>]}


============================== 11:06:33.335726 | 626857d2-26dc-4044-ab31-37a34a87e6de ==============================
[0m11:06:33.335726 [info ] [MainThread]: Running with dbt=1.8.9
[0m11:06:33.336177 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'version_check': 'True', 'log_path': '/opt/airflow/project_root/dbt/logs', 'debug': 'False', 'profiles_dir': '/opt/airflow/project_root/dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'invocation_command': 'dbt run --project-dir /opt/airflow/project_root/dbt --profiles-dir /opt/airflow/project_root/dbt --select gold', 'static_parser': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m11:06:33.459001 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '626857d2-26dc-4044-ab31-37a34a87e6de', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff79ecb7d0>]}
[0m11:06:33.480869 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '626857d2-26dc-4044-ab31-37a34a87e6de', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff7a89b150>]}
[0m11:06:33.481589 [info ] [MainThread]: Registered adapter: clickhouse=1.8.9
[0m11:06:33.529302 [debug] [MainThread]: checksum: 132857a23e9d07220246854f7763165174ce9b737cfc7867629ace4294e520b1, vars: {}, profile: , target: , version: 1.8.9
[0m11:06:33.597992 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 2 files changed.
[0m11:06:33.598452 [debug] [MainThread]: Partial parsing: updated file: movie_warehouse://models/gold/dim_release_date.sql
[0m11:06:33.598694 [debug] [MainThread]: Partial parsing: updated file: movie_warehouse://models/gold/dim_production.sql
[0m11:06:33.685214 [warn ] [MainThread]: [[33mWARNING[0m]: Deprecated functionality
The `tests` config has been renamed to `data_tests`. Please see
https://docs.getdbt.com/docs/build/data-tests#new-data_tests-syntax for more
information.
[0m11:06:33.685652 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'deprecation', 'label': '626857d2-26dc-4044-ab31-37a34a87e6de', 'property_': 'warn', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff79ade890>]}
[0m11:06:33.755218 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.movie_warehouse.bronze
[0m11:06:33.760970 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '626857d2-26dc-4044-ab31-37a34a87e6de', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff798c5ed0>]}
[0m11:06:33.850998 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '626857d2-26dc-4044-ab31-37a34a87e6de', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff798656d0>]}
[0m11:06:33.851338 [info ] [MainThread]: Found 6 models, 12 data tests, 4 sources, 476 macros
[0m11:06:33.851562 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '626857d2-26dc-4044-ab31-37a34a87e6de', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff786a2c90>]}
[0m11:06:33.852415 [info ] [MainThread]: 
[0m11:06:33.852746 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m11:06:33.855649 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m11:06:33.860158 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:06:34.160985 [info ] [ThreadPool]: dbt_clickhouse adapter: Unexpected server exception dropping table
[0m11:06:34.161397 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m11:06:34.163039 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:06:34.223439 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__gold_gold)
[0m11:06:34.227186 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__gold_gold: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "connection_name": "list__gold_gold"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'gold_gold'
      

  ...
[0m11:06:34.231299 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:06:34.232561 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '626857d2-26dc-4044-ab31-37a34a87e6de', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff39489390>]}
[0m11:06:34.232891 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m11:06:34.233121 [info ] [MainThread]: 
[0m11:06:34.238684 [debug] [Thread-1 (]: Began running node model.movie_warehouse.dim_director
[0m11:06:34.238999 [info ] [Thread-1 (]: 1 of 6 START sql table model `gold_gold`.`dim_director` ........................ [RUN]
[0m11:06:34.239266 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list__gold_gold, now model.movie_warehouse.dim_director)
[0m11:06:34.239458 [debug] [Thread-1 (]: Began compiling node model.movie_warehouse.dim_director
[0m11:06:34.243323 [debug] [Thread-1 (]: Writing injected SQL for node "model.movie_warehouse.dim_director"
[0m11:06:34.244302 [debug] [Thread-1 (]: Began executing node model.movie_warehouse.dim_director
[0m11:06:34.256789 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_director: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_director"} */

    drop table if exists `gold_gold`.`dim_director__dbt_backup` 
  ...
[0m11:06:34.259043 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_director"} */

    drop table if exists `gold_gold`.`dim_director__dbt_backup` 
  
[0m11:06:34.259323 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: macro drop_relation
[0m11:06:34.264588 [debug] [Thread-1 (]: Database Error in model dim_director (models/gold/dim_director.sql)
  :HTTPDriver for http://clickhouse-server:8123 returned response code 500)
   std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/8c9/8c9b38bb-5974-4368-97d1-712fe72b58b0/dim_director__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/gold_gold.dim_director__dbt_backup.e138c244-318d-4607-8a2f-5d2e9ee773a5.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build))
[0m11:06:34.265340 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '626857d2-26dc-4044-ab31-37a34a87e6de', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff399a3510>]}
[0m11:06:34.265682 [error] [Thread-1 (]: 1 of 6 ERROR creating sql table model `gold_gold`.`dim_director` ............... [[31mERROR[0m in 0.03s]
[0m11:06:34.266009 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.dim_director
[0m11:06:34.266232 [debug] [Thread-1 (]: Began running node model.movie_warehouse.dim_genre
[0m11:06:34.266796 [info ] [Thread-1 (]: 2 of 6 START sql table model `gold_gold`.`dim_genre` ........................... [RUN]
[0m11:06:34.267042 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.movie_warehouse.dim_director, now model.movie_warehouse.dim_genre)
[0m11:06:34.267257 [debug] [Thread-1 (]: Began compiling node model.movie_warehouse.dim_genre
[0m11:06:34.268698 [debug] [Thread-1 (]: Writing injected SQL for node "model.movie_warehouse.dim_genre"
[0m11:06:34.269476 [debug] [Thread-1 (]: Began executing node model.movie_warehouse.dim_genre
[0m11:06:34.271620 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_genre: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_genre"} */

    drop table if exists `gold_gold`.`dim_genre__dbt_backup` 
  ...
[0m11:06:34.273371 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_genre"} */

    drop table if exists `gold_gold`.`dim_genre__dbt_backup` 
  
[0m11:06:34.273601 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: macro drop_relation
[0m11:06:34.275308 [debug] [Thread-1 (]: Database Error in model dim_genre (models/gold/dim_genre.sql)
  :HTTPDriver for http://clickhouse-server:8123 returned response code 500)
   std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/8c9/8c9b38bb-5974-4368-97d1-712fe72b58b0/dim_genre__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/gold_gold.dim_genre__dbt_backup.1a4c28e4-e09c-47e4-aa23-5e5b4d20e16f.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build))
[0m11:06:34.275660 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '626857d2-26dc-4044-ab31-37a34a87e6de', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff79be2010>]}
[0m11:06:34.275984 [error] [Thread-1 (]: 2 of 6 ERROR creating sql table model `gold_gold`.`dim_genre` .................. [[31mERROR[0m in 0.01s]
[0m11:06:34.276260 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.dim_genre
[0m11:06:34.276481 [debug] [Thread-1 (]: Began running node model.movie_warehouse.dim_movie
[0m11:06:34.276778 [info ] [Thread-1 (]: 3 of 6 START sql table model `gold_gold`.`dim_movie` ........................... [RUN]
[0m11:06:34.277006 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.movie_warehouse.dim_genre, now model.movie_warehouse.dim_movie)
[0m11:06:34.277188 [debug] [Thread-1 (]: Began compiling node model.movie_warehouse.dim_movie
[0m11:06:34.279482 [debug] [Thread-1 (]: Writing injected SQL for node "model.movie_warehouse.dim_movie"
[0m11:06:34.280031 [debug] [Thread-1 (]: Began executing node model.movie_warehouse.dim_movie
[0m11:06:34.282122 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_movie: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_movie"} */

    drop table if exists `gold_gold`.`dim_movie__dbt_backup` 
  ...
[0m11:06:34.283859 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_movie"} */

    drop table if exists `gold_gold`.`dim_movie__dbt_backup` 
  
[0m11:06:34.284093 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: macro drop_relation
[0m11:06:34.285777 [debug] [Thread-1 (]: Database Error in model dim_movie (models/gold/dim_movie.sql)
  :HTTPDriver for http://clickhouse-server:8123 returned response code 500)
   std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/8c9/8c9b38bb-5974-4368-97d1-712fe72b58b0/dim_movie__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/gold_gold.dim_movie__dbt_backup.cfe16ff3-c081-4abd-964d-4b134361646b.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build))
[0m11:06:34.286067 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '626857d2-26dc-4044-ab31-37a34a87e6de', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff39457550>]}
[0m11:06:34.286362 [error] [Thread-1 (]: 3 of 6 ERROR creating sql table model `gold_gold`.`dim_movie` .................. [[31mERROR[0m in 0.01s]
[0m11:06:34.286633 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.dim_movie
[0m11:06:34.286836 [debug] [Thread-1 (]: Began running node model.movie_warehouse.dim_production
[0m11:06:34.287106 [info ] [Thread-1 (]: 4 of 6 START sql table model `gold_gold`.`dim_production` ...................... [RUN]
[0m11:06:34.287316 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.movie_warehouse.dim_movie, now model.movie_warehouse.dim_production)
[0m11:06:34.287494 [debug] [Thread-1 (]: Began compiling node model.movie_warehouse.dim_production
[0m11:06:34.288879 [debug] [Thread-1 (]: Writing injected SQL for node "model.movie_warehouse.dim_production"
[0m11:06:34.289412 [debug] [Thread-1 (]: Began executing node model.movie_warehouse.dim_production
[0m11:06:34.290366 [debug] [Thread-1 (]: Creating new relation dim_production
[0m11:06:34.302657 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_production: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_production"} */

            

    
        create table `gold_gold`.`dim_production`
        
  
        
  engine = MergeTree()
        order by (production_id)
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

WITH first_production AS (
    SELECT
        imdb_id AS movie_id,
        trim(splitByChar(',', production_companies)[1]) AS production_name
    FROM `bronze`.`tmdb_raw`
    WHERE production_companies IS NOT NULL AND production_companies != ''
)

SELECT
    cityHash64(production_name) AS production_id,
    production_name,
    current_date() AS valid_from,
    CAST(NULL AS Nullable(Date)) AS valid_to,
    TRUE AS is_current
FROM (
    SELECT DISTINCT production_name
    FROM first_production
)
WHERE production_name IS NOT NULL
          )
        
        ...
[0m11:06:34.311031 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m11:06:34.318072 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_production: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_production"} */

    select name, type from system.columns where table = 'dim_production'
    
      and database = 'gold_gold'
    
    order by position
  ...
[0m11:06:34.322659 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:06:34.324456 [debug] [Thread-1 (]: Writing runtime sql for node "model.movie_warehouse.dim_production"
[0m11:06:34.325480 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_production: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_production"} */

  
    
    
    
        
         


        insert into `gold_gold`.`dim_production`
        ("production_id", "production_name", "valid_from", "valid_to", "is_current")

WITH first_production AS (
    SELECT
        imdb_id AS movie_id,
        trim(splitByChar(',', production_companies)[1]) AS production_name
    FROM `bronze`.`tmdb_raw`
    WHERE production_companies IS NOT NULL AND production_companies != ''
)

SELECT
    cityHash64(production_name) AS production_id,
    production_name,
    current_date() AS valid_from,
    CAST(NULL AS Nullable(Date)) AS valid_to,
    TRUE AS is_current
FROM (
    SELECT DISTINCT production_name
    FROM first_production
)
WHERE production_name IS NOT NULL
  ...
[0m11:06:34.336819 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m11:06:34.346372 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '626857d2-26dc-4044-ab31-37a34a87e6de', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff3948f410>]}
[0m11:06:34.346941 [info ] [Thread-1 (]: 4 of 6 OK created sql table model `gold_gold`.`dim_production` ................. [[32mOK[0m in 0.06s]
[0m11:06:34.347317 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.dim_production
[0m11:06:34.347667 [debug] [Thread-1 (]: Began running node model.movie_warehouse.dim_release_date
[0m11:06:34.348350 [info ] [Thread-1 (]: 5 of 6 START sql table model `gold_gold`.`dim_release_date` .................... [RUN]
[0m11:06:34.348687 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.movie_warehouse.dim_production, now model.movie_warehouse.dim_release_date)
[0m11:06:34.348936 [debug] [Thread-1 (]: Began compiling node model.movie_warehouse.dim_release_date
[0m11:06:34.351200 [debug] [Thread-1 (]: Writing injected SQL for node "model.movie_warehouse.dim_release_date"
[0m11:06:34.352044 [debug] [Thread-1 (]: Began executing node model.movie_warehouse.dim_release_date
[0m11:06:34.353460 [debug] [Thread-1 (]: Creating new relation dim_release_date
[0m11:06:34.354345 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_release_date: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_release_date"} */

            

    
        create table `gold_gold`.`dim_release_date`
        
  
        
  engine = MergeTree()
        order by (date_id)
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

WITH distinct_dates AS (
    SELECT DISTINCT release_date
    FROM `bronze`.`tmdb_raw`
    WHERE release_date IS NOT NULL
)

SELECT
    cityHash64(release_date)                                    AS date_id,
    release_date                                                AS full_date,
    toYear(release_date)                                        AS year,
    toMonth(release_date)                                       AS month,
    toDayOfMonth(release_date)                                  AS day,
    toISOWeek(release_date)                                     AS week,
    formatDateTime(release_date, '%a')                          AS weekday,
    CASE
        WHEN toMonth(release_date) IN (12,1,2)  THEN 'Winter'
        WHEN toMonth(release_date) IN (3,4,5)   THEN 'Spring'
        WHEN toMonth(release_date) IN (6,7,8)   THEN 'Summer'
        WHEN toMonth(release_date) IN (9,10,11) THEN 'Autumn'
    END                                                         AS season,
    CASE
        WHEN formatDateTime(release_date, '%a') IN ('Saturday','Sunday') THEN 1
        ELSE 0
    END                                                         AS is_weekend,

    /* ---------- holiday tagging ---------- */
    CASE
        WHEN toMonth(release_date)=1  AND toDayOfMonth(release_date)=1  THEN 'New Years Day'
        WHEN toMonth(release_date)=2  AND toDayOfMonth(release_date)=14 THEN 'Valentines Day'
        WHEN toMonth(release_date)=3  AND toDayOfMonth(release_date)=17 THEN 'St. Patricks Day'
        WHEN toMonth(release_date)=4  AND toDayOfMonth(release_date)=1  THEN 'April Fools Day'
        WHEN toMonth(release_date)=4  AND toDayOfMonth(release_date)=22 THEN 'Earth Day'
        WHEN toMonth(release_date)=5  AND toDayOfMonth(release_date)=1  THEN 'May Day'
        WHEN toMonth(release_date)=5  AND toDayOfMonth(release_date)=5  THEN 'Cinco de Mayo'
        WHEN toMonth(release_date)=6  AND toDayOfMonth(release_date) BETWEEN 19 AND 26 THEN 'Midsummer'
        WHEN toMonth(release_date)=7  AND toDayOfMonth(release_date)=4  THEN 'Independence Day'
        WHEN toMonth(release_date)=9  AND toDayOfMonth(release_date) BETWEEN 1 AND 7 
             AND formatDateTime(release_date,'%a')='Monday'             THEN 'Labor Day (US)'
        WHEN toMonth(release_date)=10 AND toDayOfMonth(release_date)=31 THEN 'Halloween'
        WHEN toMonth(release_date)=11 AND formatDateTime(release_date,'%a')='Thursday'
             AND toISOWeek(release_date) >= 47                           THEN 'Thanksgiving'
        WHEN toMonth(release_date)=12 AND toDayOfMonth(release_date)=24 THEN 'Christmas Eve'
        WHEN toMonth(release_date)=12 AND toDayOfMonth(release_date)=25 THEN 'Christmas Day'
        WHEN toMonth(release_date)=12 AND toDayOfMonth(release_date)=31 THEN 'New Years Eve'
        ELSE NULL
    END                                                         AS holiday_name,
    IF(holiday_name IS NOT NULL, 1, 0)                          AS is_holiday,

    /* placeholders for later enhancement */
    CAST(NULL AS Nullable(Int32)) AS days_until_holiday,
    CAST(NULL AS Nullable(Int32)) AS days_after_holiday

FROM distinct_dates
ORDER BY release_date
          )
        
        ...
[0m11:06:34.368488 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m11:06:34.370145 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_release_date: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_release_date"} */

    select name, type from system.columns where table = 'dim_release_date'
    
      and database = 'gold_gold'
    
    order by position
  ...
[0m11:06:34.372488 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:06:34.373607 [debug] [Thread-1 (]: Writing runtime sql for node "model.movie_warehouse.dim_release_date"
[0m11:06:34.374253 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_release_date: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_release_date"} */

  
    
    
    
        
         


        insert into `gold_gold`.`dim_release_date`
        ("date_id", "full_date", "year", "month", "day", "week", "weekday", "season", "is_weekend", "holiday_name", "is_holiday", "days_until_holiday", "days_after_holiday")

WITH distinct_dates AS (
    SELECT DISTINCT release_date
    FROM `bronze`.`tmdb_raw`
    WHERE release_date IS NOT NULL
)

SELECT
    cityHash64(release_date)                                    AS date_id,
    release_date                                                AS full_date,
    toYear(release_date)                                        AS year,
    toMonth(release_date)                                       AS month,
    toDayOfMonth(release_date)                                  AS day,
    toISOWeek(release_date)                                     AS week,
    formatDateTime(release_date, '%a')                          AS weekday,
    CASE
        WHEN toMonth(release_date) IN (12,1,2)  THEN 'Winter'
        WHEN toMonth(release_date) IN (3,4,5)   THEN 'Spring'
        WHEN toMonth(release_date) IN (6,7,8)   THEN 'Summer'
        WHEN toMonth(release_date) IN (9,10,11) THEN 'Autumn'
    END                                                         AS season,
    CASE
        WHEN formatDateTime(release_date, '%a') IN ('Saturday','Sunday') THEN 1
        ELSE 0
    END                                                         AS is_weekend,

    /* ---------- holiday tagging ---------- */
    CASE
        WHEN toMonth(release_date)=1  AND toDayOfMonth(release_date)=1  THEN 'New Years Day'
        WHEN toMonth(release_date)=2  AND toDayOfMonth(release_date)=14 THEN 'Valentines Day'
        WHEN toMonth(release_date)=3  AND toDayOfMonth(release_date)=17 THEN 'St. Patricks Day'
        WHEN toMonth(release_date)=4  AND toDayOfMonth(release_date)=1  THEN 'April Fools Day'
        WHEN toMonth(release_date)=4  AND toDayOfMonth(release_date)=22 THEN 'Earth Day'
        WHEN toMonth(release_date)=5  AND toDayOfMonth(release_date)=1  THEN 'May Day'
        WHEN toMonth(release_date)=5  AND toDayOfMonth(release_date)=5  THEN 'Cinco de Mayo'
        WHEN toMonth(release_date)=6  AND toDayOfMonth(release_date) BETWEEN 19 AND 26 THEN 'Midsummer'
        WHEN toMonth(release_date)=7  AND toDayOfMonth(release_date)=4  THEN 'Independence Day'
        WHEN toMonth(release_date)=9  AND toDayOfMonth(release_date) BETWEEN 1 AND 7 
             AND formatDateTime(release_date,'%a')='Monday'             THEN 'Labor Day (US)'
        WHEN toMonth(release_date)=10 AND toDayOfMonth(release_date)=31 THEN 'Halloween'
        WHEN toMonth(release_date)=11 AND formatDateTime(release_date,'%a')='Thursday'
             AND toISOWeek(release_date) >= 47                           THEN 'Thanksgiving'
        WHEN toMonth(release_date)=12 AND toDayOfMonth(release_date)=24 THEN 'Christmas Eve'
        WHEN toMonth(release_date)=12 AND toDayOfMonth(release_date)=25 THEN 'Christmas Day'
        WHEN toMonth(release_date)=12 AND toDayOfMonth(release_date)=31 THEN 'New Years Eve'
        ELSE NULL
    END                                                         AS holiday_name,
    IF(holiday_name IS NOT NULL, 1, 0)                          AS is_holiday,

    /* placeholders for later enhancement */
    CAST(NULL AS Nullable(Int32)) AS days_until_holiday,
    CAST(NULL AS Nullable(Int32)) AS days_after_holiday

FROM distinct_dates
ORDER BY release_date
  ...
[0m11:06:34.422993 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m11:06:34.424493 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '626857d2-26dc-4044-ab31-37a34a87e6de', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff3820fd90>]}
[0m11:06:34.427507 [info ] [Thread-1 (]: 5 of 6 OK created sql table model `gold_gold`.`dim_release_date` ............... [[32mOK[0m in 0.08s]
[0m11:06:34.428098 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.dim_release_date
[0m11:06:34.428769 [debug] [Thread-1 (]: Began running node model.movie_warehouse.fact_movie
[0m11:06:34.429069 [info ] [Thread-1 (]: 6 of 6 SKIP relation gold_gold.fact_movie ...................................... [[33mSKIP[0m]
[0m11:06:34.429447 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.fact_movie
[0m11:06:34.430234 [debug] [MainThread]: Connection 'master' was properly closed.
[0m11:06:34.430509 [debug] [MainThread]: Connection 'model.movie_warehouse.dim_release_date' was left open.
[0m11:06:34.430723 [debug] [MainThread]: On model.movie_warehouse.dim_release_date: Close
[0m11:06:34.431084 [info ] [MainThread]: 
[0m11:06:34.431536 [info ] [MainThread]: Finished running 6 table models in 0 hours 0 minutes and 0.58 seconds (0.58s).
[0m11:06:34.432235 [debug] [MainThread]: Command end result
[0m11:06:34.454320 [info ] [MainThread]: 
[0m11:06:34.454612 [info ] [MainThread]: [31mCompleted with 3 errors and 0 warnings:[0m
[0m11:06:34.454790 [info ] [MainThread]: 
[0m11:06:34.455026 [error] [MainThread]:   Database Error in model dim_director (models/gold/dim_director.sql)
  :HTTPDriver for http://clickhouse-server:8123 returned response code 500)
   std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/8c9/8c9b38bb-5974-4368-97d1-712fe72b58b0/dim_director__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/gold_gold.dim_director__dbt_backup.e138c244-318d-4607-8a2f-5d2e9ee773a5.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build))
[0m11:06:34.455206 [info ] [MainThread]: 
[0m11:06:34.455393 [error] [MainThread]:   Database Error in model dim_genre (models/gold/dim_genre.sql)
  :HTTPDriver for http://clickhouse-server:8123 returned response code 500)
   std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/8c9/8c9b38bb-5974-4368-97d1-712fe72b58b0/dim_genre__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/gold_gold.dim_genre__dbt_backup.1a4c28e4-e09c-47e4-aa23-5e5b4d20e16f.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build))
[0m11:06:34.455574 [info ] [MainThread]: 
[0m11:06:34.455754 [error] [MainThread]:   Database Error in model dim_movie (models/gold/dim_movie.sql)
  :HTTPDriver for http://clickhouse-server:8123 returned response code 500)
   std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/8c9/8c9b38bb-5974-4368-97d1-712fe72b58b0/dim_movie__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/gold_gold.dim_movie__dbt_backup.cfe16ff3-c081-4abd-964d-4b134361646b.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build))
[0m11:06:34.455920 [info ] [MainThread]: 
[0m11:06:34.456097 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=3 SKIP=1 TOTAL=6
[0m11:06:34.456679 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 1.148187, "process_in_blocks": "81400", "process_kernel_time": 0.297952, "process_mem_max_rss": "189548", "process_out_blocks": "3427", "process_user_time": 1.948714}
[0m11:06:34.456963 [debug] [MainThread]: Command `dbt run` failed at 11:06:34.456916 after 1.15 seconds
[0m11:06:34.457255 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff79ecb850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff79ecba90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff395ff5d0>]}
[0m11:06:34.457476 [debug] [MainThread]: Flushing usage events
[0m11:12:22.050483 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8f54d590>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8f54ca50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8f54c9d0>]}


============================== 11:12:22.056993 | ce68ca17-c0db-48e9-97d6-c0593fdf2226 ==============================
[0m11:12:22.056993 [info ] [MainThread]: Running with dbt=1.8.9
[0m11:12:22.057362 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'profiles_dir': '/opt/airflow/project_root/dbt', 'log_path': '/opt/airflow/project_root/dbt/logs', 'fail_fast': 'False', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'introspect': 'True', 'static_parser': 'True', 'invocation_command': 'dbt run --project-dir /opt/airflow/project_root/dbt --profiles-dir /opt/airflow/project_root/dbt --select gold', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m11:12:22.171656 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'ce68ca17-c0db-48e9-97d6-c0593fdf2226', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff914d9610>]}
[0m11:12:22.193668 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'ce68ca17-c0db-48e9-97d6-c0593fdf2226', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8ff7b250>]}
[0m11:12:22.194328 [info ] [MainThread]: Registered adapter: clickhouse=1.8.9
[0m11:12:22.230926 [debug] [MainThread]: checksum: 132857a23e9d07220246854f7763165174ce9b737cfc7867629ace4294e520b1, vars: {}, profile: , target: , version: 1.8.9
[0m11:12:22.299738 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 3 files changed.
[0m11:12:22.300205 [debug] [MainThread]: Partial parsing: updated file: movie_warehouse://models/gold/dim_movie.sql
[0m11:12:22.300430 [debug] [MainThread]: Partial parsing: updated file: movie_warehouse://models/gold/dim_director.sql
[0m11:12:22.300640 [debug] [MainThread]: Partial parsing: updated file: movie_warehouse://models/gold/dim_genre.sql
[0m11:12:22.390591 [warn ] [MainThread]: [[33mWARNING[0m]: Deprecated functionality
The `tests` config has been renamed to `data_tests`. Please see
https://docs.getdbt.com/docs/build/data-tests#new-data_tests-syntax for more
information.
[0m11:12:22.391055 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'deprecation', 'label': 'ce68ca17-c0db-48e9-97d6-c0593fdf2226', 'property_': 'warn', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8ef7d6d0>]}
[0m11:12:22.451553 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.movie_warehouse.bronze
[0m11:12:22.456762 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'ce68ca17-c0db-48e9-97d6-c0593fdf2226', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8f609610>]}
[0m11:12:22.540942 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'ce68ca17-c0db-48e9-97d6-c0593fdf2226', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8eeefd10>]}
[0m11:12:22.541315 [info ] [MainThread]: Found 6 models, 12 data tests, 4 sources, 476 macros
[0m11:12:22.541599 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'ce68ca17-c0db-48e9-97d6-c0593fdf2226', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8efa1150>]}
[0m11:12:22.542542 [info ] [MainThread]: 
[0m11:12:22.542841 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m11:12:22.545489 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m11:12:22.550210 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:12:22.878234 [info ] [ThreadPool]: dbt_clickhouse adapter: Unexpected server exception dropping table
[0m11:12:22.878760 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m11:12:22.881042 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:12:22.948330 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__gold_gold)
[0m11:12:22.952648 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__gold_gold: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "connection_name": "list__gold_gold"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'gold_gold'
      

  ...
[0m11:12:22.956563 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:12:22.957877 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'ce68ca17-c0db-48e9-97d6-c0593fdf2226', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8ddeb550>]}
[0m11:12:22.958211 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m11:12:22.958401 [info ] [MainThread]: 
[0m11:12:22.963280 [debug] [Thread-1 (]: Began running node model.movie_warehouse.dim_director
[0m11:12:22.963577 [info ] [Thread-1 (]: 1 of 6 START sql table model `gold_gold`.`dim_director` ........................ [RUN]
[0m11:12:22.963817 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list__gold_gold, now model.movie_warehouse.dim_director)
[0m11:12:22.964002 [debug] [Thread-1 (]: Began compiling node model.movie_warehouse.dim_director
[0m11:12:22.967689 [debug] [Thread-1 (]: Writing injected SQL for node "model.movie_warehouse.dim_director"
[0m11:12:22.968642 [debug] [Thread-1 (]: Began executing node model.movie_warehouse.dim_director
[0m11:12:22.981687 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_director: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_director"} */

    drop table if exists `gold_gold`.`dim_director__dbt_backup` 
  ...
[0m11:12:22.983713 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_director"} */

    drop table if exists `gold_gold`.`dim_director__dbt_backup` 
  
[0m11:12:22.983961 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: macro drop_relation
[0m11:12:22.989344 [debug] [Thread-1 (]: Database Error in model dim_director (models/gold/dim_director.sql)
  :HTTPDriver for http://clickhouse-server:8123 returned response code 500)
   std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/8c9/8c9b38bb-5974-4368-97d1-712fe72b58b0/dim_director__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/gold_gold.dim_director__dbt_backup.e138c244-318d-4607-8a2f-5d2e9ee773a5.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build))
[0m11:12:22.990074 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ce68ca17-c0db-48e9-97d6-c0593fdf2226', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8f0db2d0>]}
[0m11:12:22.990434 [error] [Thread-1 (]: 1 of 6 ERROR creating sql table model `gold_gold`.`dim_director` ............... [[31mERROR[0m in 0.03s]
[0m11:12:22.990746 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.dim_director
[0m11:12:22.990963 [debug] [Thread-1 (]: Began running node model.movie_warehouse.dim_genre
[0m11:12:22.991484 [info ] [Thread-1 (]: 2 of 6 START sql table model `gold_gold`.`dim_genre` ........................... [RUN]
[0m11:12:22.991702 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.movie_warehouse.dim_director, now model.movie_warehouse.dim_genre)
[0m11:12:22.991871 [debug] [Thread-1 (]: Began compiling node model.movie_warehouse.dim_genre
[0m11:12:22.993438 [debug] [Thread-1 (]: Writing injected SQL for node "model.movie_warehouse.dim_genre"
[0m11:12:22.993919 [debug] [Thread-1 (]: Began executing node model.movie_warehouse.dim_genre
[0m11:12:22.996235 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_genre: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_genre"} */

    drop table if exists `gold_gold`.`dim_genre__dbt_backup` 
  ...
[0m11:12:22.997867 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_genre"} */

    drop table if exists `gold_gold`.`dim_genre__dbt_backup` 
  
[0m11:12:22.998081 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: macro drop_relation
[0m11:12:22.999776 [debug] [Thread-1 (]: Database Error in model dim_genre (models/gold/dim_genre.sql)
  :HTTPDriver for http://clickhouse-server:8123 returned response code 500)
   std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/8c9/8c9b38bb-5974-4368-97d1-712fe72b58b0/dim_genre__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/gold_gold.dim_genre__dbt_backup.1a4c28e4-e09c-47e4-aa23-5e5b4d20e16f.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build))
[0m11:12:23.000039 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ce68ca17-c0db-48e9-97d6-c0593fdf2226', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff4b01a050>]}
[0m11:12:23.000385 [error] [Thread-1 (]: 2 of 6 ERROR creating sql table model `gold_gold`.`dim_genre` .................. [[31mERROR[0m in 0.01s]
[0m11:12:23.000795 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.dim_genre
[0m11:12:23.001041 [debug] [Thread-1 (]: Began running node model.movie_warehouse.dim_movie
[0m11:12:23.001341 [info ] [Thread-1 (]: 3 of 6 START sql table model `gold_gold`.`dim_movie` ........................... [RUN]
[0m11:12:23.001572 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.movie_warehouse.dim_genre, now model.movie_warehouse.dim_movie)
[0m11:12:23.001755 [debug] [Thread-1 (]: Began compiling node model.movie_warehouse.dim_movie
[0m11:12:23.004175 [debug] [Thread-1 (]: Writing injected SQL for node "model.movie_warehouse.dim_movie"
[0m11:12:23.004703 [debug] [Thread-1 (]: Began executing node model.movie_warehouse.dim_movie
[0m11:12:23.006829 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_movie: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_movie"} */

    drop table if exists `gold_gold`.`dim_movie__dbt_backup` 
  ...
[0m11:12:23.009274 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_movie"} */

    drop table if exists `gold_gold`.`dim_movie__dbt_backup` 
  
[0m11:12:23.009484 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: macro drop_relation
[0m11:12:23.011134 [debug] [Thread-1 (]: Database Error in model dim_movie (models/gold/dim_movie.sql)
  :HTTPDriver for http://clickhouse-server:8123 returned response code 500)
   std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/8c9/8c9b38bb-5974-4368-97d1-712fe72b58b0/dim_movie__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/gold_gold.dim_movie__dbt_backup.cfe16ff3-c081-4abd-964d-4b134361646b.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build))
[0m11:12:23.011391 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ce68ca17-c0db-48e9-97d6-c0593fdf2226', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff4b0b9710>]}
[0m11:12:23.011677 [error] [Thread-1 (]: 3 of 6 ERROR creating sql table model `gold_gold`.`dim_movie` .................. [[31mERROR[0m in 0.01s]
[0m11:12:23.011940 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.dim_movie
[0m11:12:23.012149 [debug] [Thread-1 (]: Began running node model.movie_warehouse.dim_production
[0m11:12:23.012395 [info ] [Thread-1 (]: 4 of 6 START sql table model `gold_gold`.`dim_production` ...................... [RUN]
[0m11:12:23.012636 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.movie_warehouse.dim_movie, now model.movie_warehouse.dim_production)
[0m11:12:23.012842 [debug] [Thread-1 (]: Began compiling node model.movie_warehouse.dim_production
[0m11:12:23.014246 [debug] [Thread-1 (]: Writing injected SQL for node "model.movie_warehouse.dim_production"
[0m11:12:23.014765 [debug] [Thread-1 (]: Began executing node model.movie_warehouse.dim_production
[0m11:12:23.027657 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_production: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_production"} */

            

    
        create table `gold_gold`.`dim_production__dbt_backup`
        
  
        
  engine = MergeTree()
        order by (production_id)
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

WITH first_production AS (
    SELECT
        imdb_id AS movie_id,
        trim(splitByChar(',', production_companies)[1]) AS production_name
    FROM `bronze`.`tmdb_raw`
    WHERE production_companies IS NOT NULL AND production_companies != ''
)

SELECT
    cityHash64(production_name) AS production_id,
    production_name,
    current_date() AS valid_from,
    CAST(NULL AS Nullable(Date)) AS valid_to,
    TRUE AS is_current
FROM (
    SELECT DISTINCT production_name
    FROM first_production
)
WHERE production_name IS NOT NULL
          )
        
        ...
[0m11:12:23.033708 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m11:12:23.040644 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_production: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_production"} */

    select name, type from system.columns where table = 'dim_production__dbt_backup'
    
      and database = 'gold_gold'
    
    order by position
  ...
[0m11:12:23.045416 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:12:23.047591 [debug] [Thread-1 (]: Writing runtime sql for node "model.movie_warehouse.dim_production"
[0m11:12:23.048497 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_production: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_production"} */

  
    
    
    
        
         


        insert into `gold_gold`.`dim_production__dbt_backup`
        ("production_id", "production_name", "valid_from", "valid_to", "is_current")

WITH first_production AS (
    SELECT
        imdb_id AS movie_id,
        trim(splitByChar(',', production_companies)[1]) AS production_name
    FROM `bronze`.`tmdb_raw`
    WHERE production_companies IS NOT NULL AND production_companies != ''
)

SELECT
    cityHash64(production_name) AS production_id,
    production_name,
    current_date() AS valid_from,
    CAST(NULL AS Nullable(Date)) AS valid_to,
    TRUE AS is_current
FROM (
    SELECT DISTINCT production_name
    FROM first_production
)
WHERE production_name IS NOT NULL
  ...
[0m11:12:23.056723 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m11:12:23.059286 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_production: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_production"} */
EXCHANGE TABLES `gold_gold`.`dim_production__dbt_backup` AND `gold_gold`.`dim_production` 
  
  ...
[0m11:12:23.062589 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:12:23.073818 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_production: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_production"} */

    drop table if exists `gold_gold`.`dim_production__dbt_backup` 
  ...
[0m11:12:23.076300 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_production"} */

    drop table if exists `gold_gold`.`dim_production__dbt_backup` 
  
[0m11:12:23.076698 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: macro drop_relation
[0m11:12:23.078720 [debug] [Thread-1 (]: Database Error in model dim_production (models/gold/dim_production.sql)
  :HTTPDriver for http://clickhouse-server:8123 returned response code 500)
   std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/8c9/8c9b38bb-5974-4368-97d1-712fe72b58b0/dim_production__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/gold_gold.dim_production__dbt_backup.83dc598a-5850-477c-9906-3953ea7e88bd.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build))
  compiled code at target/run/movie_warehouse/models/gold/dim_production.sql
[0m11:12:23.079157 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ce68ca17-c0db-48e9-97d6-c0593fdf2226', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8f257810>]}
[0m11:12:23.079601 [error] [Thread-1 (]: 4 of 6 ERROR creating sql table model `gold_gold`.`dim_production` ............. [[31mERROR[0m in 0.07s]
[0m11:12:23.079933 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.dim_production
[0m11:12:23.080208 [debug] [Thread-1 (]: Began running node model.movie_warehouse.dim_release_date
[0m11:12:23.080565 [info ] [Thread-1 (]: 5 of 6 START sql table model `gold_gold`.`dim_release_date` .................... [RUN]
[0m11:12:23.080843 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.movie_warehouse.dim_production, now model.movie_warehouse.dim_release_date)
[0m11:12:23.081068 [debug] [Thread-1 (]: Began compiling node model.movie_warehouse.dim_release_date
[0m11:12:23.082879 [debug] [Thread-1 (]: Writing injected SQL for node "model.movie_warehouse.dim_release_date"
[0m11:12:23.083502 [debug] [Thread-1 (]: Began executing node model.movie_warehouse.dim_release_date
[0m11:12:23.085150 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_release_date: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_release_date"} */

            

    
        create table `gold_gold`.`dim_release_date__dbt_backup`
        
  
        
  engine = MergeTree()
        order by (date_id)
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

WITH distinct_dates AS (
    SELECT DISTINCT release_date
    FROM `bronze`.`tmdb_raw`
    WHERE release_date IS NOT NULL
)

SELECT
    cityHash64(release_date)                                    AS date_id,
    release_date                                                AS full_date,
    toYear(release_date)                                        AS year,
    toMonth(release_date)                                       AS month,
    toDayOfMonth(release_date)                                  AS day,
    toISOWeek(release_date)                                     AS week,
    formatDateTime(release_date, '%a')                          AS weekday,
    CASE
        WHEN toMonth(release_date) IN (12,1,2)  THEN 'Winter'
        WHEN toMonth(release_date) IN (3,4,5)   THEN 'Spring'
        WHEN toMonth(release_date) IN (6,7,8)   THEN 'Summer'
        WHEN toMonth(release_date) IN (9,10,11) THEN 'Autumn'
    END                                                         AS season,
    CASE
        WHEN formatDateTime(release_date, '%a') IN ('Saturday','Sunday') THEN 1
        ELSE 0
    END                                                         AS is_weekend,

    /* ---------- holiday tagging ---------- */
    CASE
        WHEN toMonth(release_date)=1  AND toDayOfMonth(release_date)=1  THEN 'New Years Day'
        WHEN toMonth(release_date)=2  AND toDayOfMonth(release_date)=14 THEN 'Valentines Day'
        WHEN toMonth(release_date)=3  AND toDayOfMonth(release_date)=17 THEN 'St. Patricks Day'
        WHEN toMonth(release_date)=4  AND toDayOfMonth(release_date)=1  THEN 'April Fools Day'
        WHEN toMonth(release_date)=4  AND toDayOfMonth(release_date)=22 THEN 'Earth Day'
        WHEN toMonth(release_date)=5  AND toDayOfMonth(release_date)=1  THEN 'May Day'
        WHEN toMonth(release_date)=5  AND toDayOfMonth(release_date)=5  THEN 'Cinco de Mayo'
        WHEN toMonth(release_date)=6  AND toDayOfMonth(release_date) BETWEEN 19 AND 26 THEN 'Midsummer'
        WHEN toMonth(release_date)=7  AND toDayOfMonth(release_date)=4  THEN 'Independence Day'
        WHEN toMonth(release_date)=9  AND toDayOfMonth(release_date) BETWEEN 1 AND 7 
             AND formatDateTime(release_date,'%a')='Monday'             THEN 'Labor Day (US)'
        WHEN toMonth(release_date)=10 AND toDayOfMonth(release_date)=31 THEN 'Halloween'
        WHEN toMonth(release_date)=11 AND formatDateTime(release_date,'%a')='Thursday'
             AND toISOWeek(release_date) >= 47                           THEN 'Thanksgiving'
        WHEN toMonth(release_date)=12 AND toDayOfMonth(release_date)=24 THEN 'Christmas Eve'
        WHEN toMonth(release_date)=12 AND toDayOfMonth(release_date)=25 THEN 'Christmas Day'
        WHEN toMonth(release_date)=12 AND toDayOfMonth(release_date)=31 THEN 'New Years Eve'
        ELSE NULL
    END                                                         AS holiday_name,
    IF(holiday_name IS NOT NULL, 1, 0)                          AS is_holiday,

    /* placeholders for later enhancement */
    CAST(NULL AS Nullable(Int32)) AS days_until_holiday,
    CAST(NULL AS Nullable(Int32)) AS days_after_holiday

FROM distinct_dates
ORDER BY release_date
          )
        
        ...
[0m11:12:23.095582 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m11:12:23.098102 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_release_date: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_release_date"} */

    select name, type from system.columns where table = 'dim_release_date__dbt_backup'
    
      and database = 'gold_gold'
    
    order by position
  ...
[0m11:12:23.101049 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:12:23.102277 [debug] [Thread-1 (]: Writing runtime sql for node "model.movie_warehouse.dim_release_date"
[0m11:12:23.103028 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_release_date: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_release_date"} */

  
    
    
    
        
         


        insert into `gold_gold`.`dim_release_date__dbt_backup`
        ("date_id", "full_date", "year", "month", "day", "week", "weekday", "season", "is_weekend", "holiday_name", "is_holiday", "days_until_holiday", "days_after_holiday")

WITH distinct_dates AS (
    SELECT DISTINCT release_date
    FROM `bronze`.`tmdb_raw`
    WHERE release_date IS NOT NULL
)

SELECT
    cityHash64(release_date)                                    AS date_id,
    release_date                                                AS full_date,
    toYear(release_date)                                        AS year,
    toMonth(release_date)                                       AS month,
    toDayOfMonth(release_date)                                  AS day,
    toISOWeek(release_date)                                     AS week,
    formatDateTime(release_date, '%a')                          AS weekday,
    CASE
        WHEN toMonth(release_date) IN (12,1,2)  THEN 'Winter'
        WHEN toMonth(release_date) IN (3,4,5)   THEN 'Spring'
        WHEN toMonth(release_date) IN (6,7,8)   THEN 'Summer'
        WHEN toMonth(release_date) IN (9,10,11) THEN 'Autumn'
    END                                                         AS season,
    CASE
        WHEN formatDateTime(release_date, '%a') IN ('Saturday','Sunday') THEN 1
        ELSE 0
    END                                                         AS is_weekend,

    /* ---------- holiday tagging ---------- */
    CASE
        WHEN toMonth(release_date)=1  AND toDayOfMonth(release_date)=1  THEN 'New Years Day'
        WHEN toMonth(release_date)=2  AND toDayOfMonth(release_date)=14 THEN 'Valentines Day'
        WHEN toMonth(release_date)=3  AND toDayOfMonth(release_date)=17 THEN 'St. Patricks Day'
        WHEN toMonth(release_date)=4  AND toDayOfMonth(release_date)=1  THEN 'April Fools Day'
        WHEN toMonth(release_date)=4  AND toDayOfMonth(release_date)=22 THEN 'Earth Day'
        WHEN toMonth(release_date)=5  AND toDayOfMonth(release_date)=1  THEN 'May Day'
        WHEN toMonth(release_date)=5  AND toDayOfMonth(release_date)=5  THEN 'Cinco de Mayo'
        WHEN toMonth(release_date)=6  AND toDayOfMonth(release_date) BETWEEN 19 AND 26 THEN 'Midsummer'
        WHEN toMonth(release_date)=7  AND toDayOfMonth(release_date)=4  THEN 'Independence Day'
        WHEN toMonth(release_date)=9  AND toDayOfMonth(release_date) BETWEEN 1 AND 7 
             AND formatDateTime(release_date,'%a')='Monday'             THEN 'Labor Day (US)'
        WHEN toMonth(release_date)=10 AND toDayOfMonth(release_date)=31 THEN 'Halloween'
        WHEN toMonth(release_date)=11 AND formatDateTime(release_date,'%a')='Thursday'
             AND toISOWeek(release_date) >= 47                           THEN 'Thanksgiving'
        WHEN toMonth(release_date)=12 AND toDayOfMonth(release_date)=24 THEN 'Christmas Eve'
        WHEN toMonth(release_date)=12 AND toDayOfMonth(release_date)=25 THEN 'Christmas Day'
        WHEN toMonth(release_date)=12 AND toDayOfMonth(release_date)=31 THEN 'New Years Eve'
        ELSE NULL
    END                                                         AS holiday_name,
    IF(holiday_name IS NOT NULL, 1, 0)                          AS is_holiday,

    /* placeholders for later enhancement */
    CAST(NULL AS Nullable(Int32)) AS days_until_holiday,
    CAST(NULL AS Nullable(Int32)) AS days_after_holiday

FROM distinct_dates
ORDER BY release_date
  ...
[0m11:12:23.146033 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.04 seconds
[0m11:12:23.146984 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_release_date: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_release_date"} */
EXCHANGE TABLES `gold_gold`.`dim_release_date__dbt_backup` AND `gold_gold`.`dim_release_date` 
  
  ...
[0m11:12:23.150380 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:12:23.152679 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_release_date: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_release_date"} */

    drop table if exists `gold_gold`.`dim_release_date__dbt_backup` 
  ...
[0m11:12:23.155556 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_release_date"} */

    drop table if exists `gold_gold`.`dim_release_date__dbt_backup` 
  
[0m11:12:23.156018 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: macro drop_relation
[0m11:12:23.158029 [debug] [Thread-1 (]: Database Error in model dim_release_date (models/gold/dim_release_date.sql)
  :HTTPDriver for http://clickhouse-server:8123 returned response code 500)
   std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/8c9/8c9b38bb-5974-4368-97d1-712fe72b58b0/dim_release_date__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/gold_gold.dim_release_date__dbt_backup.67a5919a-28ab-4aec-8f6c-05a3753644ed.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build))
  compiled code at target/run/movie_warehouse/models/gold/dim_release_date.sql
[0m11:12:23.158375 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ce68ca17-c0db-48e9-97d6-c0593fdf2226', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff4aa53b90>]}
[0m11:12:23.158715 [error] [Thread-1 (]: 5 of 6 ERROR creating sql table model `gold_gold`.`dim_release_date` ........... [[31mERROR[0m in 0.08s]
[0m11:12:23.159030 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.dim_release_date
[0m11:12:23.159540 [debug] [Thread-1 (]: Began running node model.movie_warehouse.fact_movie
[0m11:12:23.159758 [info ] [Thread-1 (]: 6 of 6 SKIP relation gold_gold.fact_movie ...................................... [[33mSKIP[0m]
[0m11:12:23.159987 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.fact_movie
[0m11:12:23.160660 [debug] [MainThread]: Connection 'master' was properly closed.
[0m11:12:23.160872 [debug] [MainThread]: Connection 'model.movie_warehouse.dim_release_date' was left open.
[0m11:12:23.161058 [debug] [MainThread]: On model.movie_warehouse.dim_release_date: Close
[0m11:12:23.161306 [info ] [MainThread]: 
[0m11:12:23.161507 [info ] [MainThread]: Finished running 6 table models in 0 hours 0 minutes and 0.62 seconds (0.62s).
[0m11:12:23.162043 [debug] [MainThread]: Command end result
[0m11:12:23.181709 [info ] [MainThread]: 
[0m11:12:23.181971 [info ] [MainThread]: [31mCompleted with 5 errors and 0 warnings:[0m
[0m11:12:23.182151 [info ] [MainThread]: 
[0m11:12:23.182339 [error] [MainThread]:   Database Error in model dim_director (models/gold/dim_director.sql)
  :HTTPDriver for http://clickhouse-server:8123 returned response code 500)
   std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/8c9/8c9b38bb-5974-4368-97d1-712fe72b58b0/dim_director__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/gold_gold.dim_director__dbt_backup.e138c244-318d-4607-8a2f-5d2e9ee773a5.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build))
[0m11:12:23.182491 [info ] [MainThread]: 
[0m11:12:23.182659 [error] [MainThread]:   Database Error in model dim_genre (models/gold/dim_genre.sql)
  :HTTPDriver for http://clickhouse-server:8123 returned response code 500)
   std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/8c9/8c9b38bb-5974-4368-97d1-712fe72b58b0/dim_genre__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/gold_gold.dim_genre__dbt_backup.1a4c28e4-e09c-47e4-aa23-5e5b4d20e16f.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build))
[0m11:12:23.182800 [info ] [MainThread]: 
[0m11:12:23.182966 [error] [MainThread]:   Database Error in model dim_movie (models/gold/dim_movie.sql)
  :HTTPDriver for http://clickhouse-server:8123 returned response code 500)
   std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/8c9/8c9b38bb-5974-4368-97d1-712fe72b58b0/dim_movie__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/gold_gold.dim_movie__dbt_backup.cfe16ff3-c081-4abd-964d-4b134361646b.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build))
[0m11:12:23.183123 [info ] [MainThread]: 
[0m11:12:23.183292 [error] [MainThread]:   Database Error in model dim_production (models/gold/dim_production.sql)
  :HTTPDriver for http://clickhouse-server:8123 returned response code 500)
   std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/8c9/8c9b38bb-5974-4368-97d1-712fe72b58b0/dim_production__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/gold_gold.dim_production__dbt_backup.83dc598a-5850-477c-9906-3953ea7e88bd.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build))
  compiled code at target/run/movie_warehouse/models/gold/dim_production.sql
[0m11:12:23.183461 [info ] [MainThread]: 
[0m11:12:23.183633 [error] [MainThread]:   Database Error in model dim_release_date (models/gold/dim_release_date.sql)
  :HTTPDriver for http://clickhouse-server:8123 returned response code 500)
   std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/8c9/8c9b38bb-5974-4368-97d1-712fe72b58b0/dim_release_date__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/gold_gold.dim_release_date__dbt_backup.67a5919a-28ab-4aec-8f6c-05a3753644ed.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build))
  compiled code at target/run/movie_warehouse/models/gold/dim_release_date.sql
[0m11:12:23.183803 [info ] [MainThread]: 
[0m11:12:23.184028 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=5 SKIP=1 TOTAL=6
[0m11:12:23.185156 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 1.1560885, "process_in_blocks": "101240", "process_kernel_time": 0.339095, "process_mem_max_rss": "193832", "process_out_blocks": "3445", "process_user_time": 1.981777}
[0m11:12:23.185418 [debug] [MainThread]: Command `dbt run` failed at 11:12:23.185380 after 1.16 seconds
[0m11:12:23.185617 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8f57f5d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8f54e490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8f54e1d0>]}
[0m11:12:23.185795 [debug] [MainThread]: Flushing usage events
[0m11:14:49.274475 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb94dd250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb94dcbd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb94dcf10>]}


============================== 11:14:49.280323 | c772fa0b-921c-410f-b9ba-f35bd904576c ==============================
[0m11:14:49.280323 [info ] [MainThread]: Running with dbt=1.8.9
[0m11:14:49.280664 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/project_root/dbt', 'version_check': 'True', 'fail_fast': 'False', 'log_path': '/opt/airflow/project_root/dbt/logs', 'debug': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run --project-dir /opt/airflow/project_root/dbt --profiles-dir /opt/airflow/project_root/dbt --select gold', 'introspect': 'True', 'static_parser': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m11:14:49.350797 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'c772fa0b-921c-410f-b9ba-f35bd904576c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb956aa90>]}
[0m11:14:49.370240 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'c772fa0b-921c-410f-b9ba-f35bd904576c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb9f0b4d0>]}
[0m11:14:49.370741 [info ] [MainThread]: Registered adapter: clickhouse=1.8.9
[0m11:14:49.407838 [debug] [MainThread]: checksum: 132857a23e9d07220246854f7763165174ce9b737cfc7867629ace4294e520b1, vars: {}, profile: , target: , version: 1.8.9
[0m11:14:49.462400 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m11:14:49.462824 [debug] [MainThread]: Partial parsing: updated file: movie_warehouse://models/gold/dim_release_date.sql
[0m11:14:49.570742 [warn ] [MainThread]: [[33mWARNING[0m]: Deprecated functionality
The `tests` config has been renamed to `data_tests`. Please see
https://docs.getdbt.com/docs/build/data-tests#new-data_tests-syntax for more
information.
[0m11:14:49.571249 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'deprecation', 'label': 'c772fa0b-921c-410f-b9ba-f35bd904576c', 'property_': 'warn', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb92c9d90>]}
[0m11:14:49.634892 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.movie_warehouse.bronze
[0m11:14:49.640051 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'c772fa0b-921c-410f-b9ba-f35bd904576c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb94dd1d0>]}
[0m11:14:49.730120 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'c772fa0b-921c-410f-b9ba-f35bd904576c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb8f7cb50>]}
[0m11:14:49.730437 [info ] [MainThread]: Found 6 models, 12 data tests, 4 sources, 476 macros
[0m11:14:49.730619 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'c772fa0b-921c-410f-b9ba-f35bd904576c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffabc48650>]}
[0m11:14:49.731420 [info ] [MainThread]: 
[0m11:14:49.731749 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m11:14:49.734401 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m11:14:49.742194 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:14:49.984772 [info ] [ThreadPool]: dbt_clickhouse adapter: Unexpected server exception dropping table
[0m11:14:49.985213 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m11:14:49.987538 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:14:50.052909 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__gold_gold)
[0m11:14:50.056274 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__gold_gold: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "connection_name": "list__gold_gold"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'gold_gold'
      

  ...
[0m11:14:50.061582 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:14:50.063289 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'c772fa0b-921c-410f-b9ba-f35bd904576c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb8e7cad0>]}
[0m11:14:50.063642 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m11:14:50.063838 [info ] [MainThread]: 
[0m11:14:50.069565 [debug] [Thread-1 (]: Began running node model.movie_warehouse.dim_director
[0m11:14:50.070073 [info ] [Thread-1 (]: 1 of 6 START sql table model `gold_gold`.`dim_director` ........................ [RUN]
[0m11:14:50.070421 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list__gold_gold, now model.movie_warehouse.dim_director)
[0m11:14:50.070740 [debug] [Thread-1 (]: Began compiling node model.movie_warehouse.dim_director
[0m11:14:50.074828 [debug] [Thread-1 (]: Writing injected SQL for node "model.movie_warehouse.dim_director"
[0m11:14:50.076275 [debug] [Thread-1 (]: Began executing node model.movie_warehouse.dim_director
[0m11:14:50.089119 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_director: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_director"} */

    drop table if exists `gold_gold`.`dim_director__dbt_backup` 
  ...
[0m11:14:50.091577 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_director"} */

    drop table if exists `gold_gold`.`dim_director__dbt_backup` 
  
[0m11:14:50.091856 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: macro drop_relation
[0m11:14:50.097194 [debug] [Thread-1 (]: Database Error in model dim_director (models/gold/dim_director.sql)
  :HTTPDriver for http://clickhouse-server:8123 returned response code 500)
   std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/8c9/8c9b38bb-5974-4368-97d1-712fe72b58b0/dim_director__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/gold_gold.dim_director__dbt_backup.e138c244-318d-4607-8a2f-5d2e9ee773a5.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build))
[0m11:14:50.097913 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c772fa0b-921c-410f-b9ba-f35bd904576c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff79073510>]}
[0m11:14:50.098222 [error] [Thread-1 (]: 1 of 6 ERROR creating sql table model `gold_gold`.`dim_director` ............... [[31mERROR[0m in 0.03s]
[0m11:14:50.098492 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.dim_director
[0m11:14:50.098708 [debug] [Thread-1 (]: Began running node model.movie_warehouse.dim_genre
[0m11:14:50.099225 [info ] [Thread-1 (]: 2 of 6 START sql table model `gold_gold`.`dim_genre` ........................... [RUN]
[0m11:14:50.099438 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.movie_warehouse.dim_director, now model.movie_warehouse.dim_genre)
[0m11:14:50.099617 [debug] [Thread-1 (]: Began compiling node model.movie_warehouse.dim_genre
[0m11:14:50.101002 [debug] [Thread-1 (]: Writing injected SQL for node "model.movie_warehouse.dim_genre"
[0m11:14:50.101536 [debug] [Thread-1 (]: Began executing node model.movie_warehouse.dim_genre
[0m11:14:50.103539 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_genre: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_genre"} */

    drop table if exists `gold_gold`.`dim_genre__dbt_backup` 
  ...
[0m11:14:50.105078 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_genre"} */

    drop table if exists `gold_gold`.`dim_genre__dbt_backup` 
  
[0m11:14:50.105296 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: macro drop_relation
[0m11:14:50.106892 [debug] [Thread-1 (]: Database Error in model dim_genre (models/gold/dim_genre.sql)
  :HTTPDriver for http://clickhouse-server:8123 returned response code 500)
   std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/8c9/8c9b38bb-5974-4368-97d1-712fe72b58b0/dim_genre__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/gold_gold.dim_genre__dbt_backup.1a4c28e4-e09c-47e4-aa23-5e5b4d20e16f.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build))
[0m11:14:50.107148 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c772fa0b-921c-410f-b9ba-f35bd904576c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff78997050>]}
[0m11:14:50.107432 [error] [Thread-1 (]: 2 of 6 ERROR creating sql table model `gold_gold`.`dim_genre` .................. [[31mERROR[0m in 0.01s]
[0m11:14:50.107700 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.dim_genre
[0m11:14:50.107897 [debug] [Thread-1 (]: Began running node model.movie_warehouse.dim_movie
[0m11:14:50.108154 [info ] [Thread-1 (]: 3 of 6 START sql table model `gold_gold`.`dim_movie` ........................... [RUN]
[0m11:14:50.108358 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.movie_warehouse.dim_genre, now model.movie_warehouse.dim_movie)
[0m11:14:50.108531 [debug] [Thread-1 (]: Began compiling node model.movie_warehouse.dim_movie
[0m11:14:50.109898 [debug] [Thread-1 (]: Writing injected SQL for node "model.movie_warehouse.dim_movie"
[0m11:14:50.110355 [debug] [Thread-1 (]: Began executing node model.movie_warehouse.dim_movie
[0m11:14:50.113252 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_movie: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_movie"} */

    drop table if exists `gold_gold`.`dim_movie__dbt_backup` 
  ...
[0m11:14:50.114941 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_movie"} */

    drop table if exists `gold_gold`.`dim_movie__dbt_backup` 
  
[0m11:14:50.115164 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: macro drop_relation
[0m11:14:50.116781 [debug] [Thread-1 (]: Database Error in model dim_movie (models/gold/dim_movie.sql)
  :HTTPDriver for http://clickhouse-server:8123 returned response code 500)
   std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/8c9/8c9b38bb-5974-4368-97d1-712fe72b58b0/dim_movie__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/gold_gold.dim_movie__dbt_backup.cfe16ff3-c081-4abd-964d-4b134361646b.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build))
[0m11:14:50.117018 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c772fa0b-921c-410f-b9ba-f35bd904576c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff78a23190>]}
[0m11:14:50.117297 [error] [Thread-1 (]: 3 of 6 ERROR creating sql table model `gold_gold`.`dim_movie` .................. [[31mERROR[0m in 0.01s]
[0m11:14:50.117566 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.dim_movie
[0m11:14:50.117762 [debug] [Thread-1 (]: Began running node model.movie_warehouse.dim_production
[0m11:14:50.118033 [info ] [Thread-1 (]: 4 of 6 START sql table model `gold_gold`.`dim_production` ...................... [RUN]
[0m11:14:50.118247 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.movie_warehouse.dim_movie, now model.movie_warehouse.dim_production)
[0m11:14:50.118413 [debug] [Thread-1 (]: Began compiling node model.movie_warehouse.dim_production
[0m11:14:50.119776 [debug] [Thread-1 (]: Writing injected SQL for node "model.movie_warehouse.dim_production"
[0m11:14:50.120253 [debug] [Thread-1 (]: Began executing node model.movie_warehouse.dim_production
[0m11:14:50.122126 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_production: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_production"} */

    drop table if exists `gold_gold`.`dim_production__dbt_backup` 
  ...
[0m11:14:50.123441 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_production"} */

    drop table if exists `gold_gold`.`dim_production__dbt_backup` 
  
[0m11:14:50.123650 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: macro drop_relation
[0m11:14:50.125235 [debug] [Thread-1 (]: Database Error in model dim_production (models/gold/dim_production.sql)
  :HTTPDriver for http://clickhouse-server:8123 returned response code 500)
   std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/8c9/8c9b38bb-5974-4368-97d1-712fe72b58b0/dim_production__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/gold_gold.dim_production__dbt_backup.83dc598a-5850-477c-9906-3953ea7e88bd.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build))
[0m11:14:50.125481 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c772fa0b-921c-410f-b9ba-f35bd904576c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff78a29ad0>]}
[0m11:14:50.125831 [error] [Thread-1 (]: 4 of 6 ERROR creating sql table model `gold_gold`.`dim_production` ............. [[31mERROR[0m in 0.01s]
[0m11:14:50.126262 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.dim_production
[0m11:14:50.126459 [debug] [Thread-1 (]: Began running node model.movie_warehouse.dim_release_date
[0m11:14:50.126786 [info ] [Thread-1 (]: 5 of 6 START sql incremental model `gold_gold`.`dim_release_date` .............. [RUN]
[0m11:14:50.127006 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.movie_warehouse.dim_production, now model.movie_warehouse.dim_release_date)
[0m11:14:50.127176 [debug] [Thread-1 (]: Began compiling node model.movie_warehouse.dim_release_date
[0m11:14:50.128688 [debug] [Thread-1 (]: Writing injected SQL for node "model.movie_warehouse.dim_release_date"
[0m11:14:50.129096 [debug] [Thread-1 (]: Began executing node model.movie_warehouse.dim_release_date
[0m11:14:50.145948 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_release_date: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_release_date"} */

    drop table if exists `gold_gold`.`dim_release_date__dbt_backup` 
  ...
[0m11:14:50.147997 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_release_date"} */

    drop table if exists `gold_gold`.`dim_release_date__dbt_backup` 
  
[0m11:14:50.148223 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: macro drop_relation
[0m11:14:50.149916 [debug] [Thread-1 (]: Database Error in model dim_release_date (models/gold/dim_release_date.sql)
  :HTTPDriver for http://clickhouse-server:8123 returned response code 500)
   std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/8c9/8c9b38bb-5974-4368-97d1-712fe72b58b0/dim_release_date__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/gold_gold.dim_release_date__dbt_backup.67a5919a-28ab-4aec-8f6c-05a3753644ed.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build))
[0m11:14:50.150187 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c772fa0b-921c-410f-b9ba-f35bd904576c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff789f5050>]}
[0m11:14:50.150468 [error] [Thread-1 (]: 5 of 6 ERROR creating sql incremental model `gold_gold`.`dim_release_date` ..... [[31mERROR[0m in 0.02s]
[0m11:14:50.150757 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.dim_release_date
[0m11:14:50.151131 [debug] [Thread-1 (]: Began running node model.movie_warehouse.fact_movie
[0m11:14:50.151391 [info ] [Thread-1 (]: 6 of 6 SKIP relation gold_gold.fact_movie ...................................... [[33mSKIP[0m]
[0m11:14:50.151606 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.fact_movie
[0m11:14:50.152211 [debug] [MainThread]: Connection 'master' was properly closed.
[0m11:14:50.152407 [debug] [MainThread]: Connection 'model.movie_warehouse.dim_release_date' was left open.
[0m11:14:50.152606 [debug] [MainThread]: On model.movie_warehouse.dim_release_date: Close
[0m11:14:50.152844 [info ] [MainThread]: 
[0m11:14:50.153032 [info ] [MainThread]: Finished running 5 table models, 1 incremental model in 0 hours 0 minutes and 0.42 seconds (0.42s).
[0m11:14:50.153566 [debug] [MainThread]: Command end result
[0m11:14:50.175068 [info ] [MainThread]: 
[0m11:14:50.175553 [info ] [MainThread]: [31mCompleted with 5 errors and 0 warnings:[0m
[0m11:14:50.175735 [info ] [MainThread]: 
[0m11:14:50.175937 [error] [MainThread]:   Database Error in model dim_director (models/gold/dim_director.sql)
  :HTTPDriver for http://clickhouse-server:8123 returned response code 500)
   std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/8c9/8c9b38bb-5974-4368-97d1-712fe72b58b0/dim_director__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/gold_gold.dim_director__dbt_backup.e138c244-318d-4607-8a2f-5d2e9ee773a5.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build))
[0m11:14:50.176101 [info ] [MainThread]: 
[0m11:14:50.176274 [error] [MainThread]:   Database Error in model dim_genre (models/gold/dim_genre.sql)
  :HTTPDriver for http://clickhouse-server:8123 returned response code 500)
   std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/8c9/8c9b38bb-5974-4368-97d1-712fe72b58b0/dim_genre__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/gold_gold.dim_genre__dbt_backup.1a4c28e4-e09c-47e4-aa23-5e5b4d20e16f.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build))
[0m11:14:50.176431 [info ] [MainThread]: 
[0m11:14:50.176611 [error] [MainThread]:   Database Error in model dim_movie (models/gold/dim_movie.sql)
  :HTTPDriver for http://clickhouse-server:8123 returned response code 500)
   std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/8c9/8c9b38bb-5974-4368-97d1-712fe72b58b0/dim_movie__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/gold_gold.dim_movie__dbt_backup.cfe16ff3-c081-4abd-964d-4b134361646b.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build))
[0m11:14:50.176760 [info ] [MainThread]: 
[0m11:14:50.176926 [error] [MainThread]:   Database Error in model dim_production (models/gold/dim_production.sql)
  :HTTPDriver for http://clickhouse-server:8123 returned response code 500)
   std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/8c9/8c9b38bb-5974-4368-97d1-712fe72b58b0/dim_production__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/gold_gold.dim_production__dbt_backup.83dc598a-5850-477c-9906-3953ea7e88bd.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build))
[0m11:14:50.177112 [info ] [MainThread]: 
[0m11:14:50.177326 [error] [MainThread]:   Database Error in model dim_release_date (models/gold/dim_release_date.sql)
  :HTTPDriver for http://clickhouse-server:8123 returned response code 500)
   std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/8c9/8c9b38bb-5974-4368-97d1-712fe72b58b0/dim_release_date__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/gold_gold.dim_release_date__dbt_backup.67a5919a-28ab-4aec-8f6c-05a3753644ed.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build))
[0m11:14:50.177639 [info ] [MainThread]: 
[0m11:14:50.177805 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=5 SKIP=1 TOTAL=6
[0m11:14:50.178505 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 0.9244188, "process_in_blocks": "61864", "process_kernel_time": 0.188723, "process_mem_max_rss": "195084", "process_out_blocks": "3413", "process_user_time": 1.95613}
[0m11:14:50.178859 [debug] [MainThread]: Command `dbt run` failed at 11:14:50.178813 after 0.92 seconds
[0m11:14:50.179110 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb950f5d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff78076ad0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffbe3d9e10>]}
[0m11:14:50.179302 [debug] [MainThread]: Flushing usage events
[0m11:26:48.942866 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb29fc890>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb2a2f350>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb29fd310>]}


============================== 11:26:48.948305 | 6dd3a9e5-42cf-4792-9636-04a8bfd45239 ==============================
[0m11:26:48.948305 [info ] [MainThread]: Running with dbt=1.8.9
[0m11:26:48.948706 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'fail_fast': 'False', 'log_path': '/opt/airflow/project_root/dbt/logs', 'profiles_dir': '/opt/airflow/project_root/dbt', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'introspect': 'True', 'invocation_command': 'dbt run --project-dir /opt/airflow/project_root/dbt --profiles-dir /opt/airflow/project_root/dbt --select gold', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m11:26:49.085730 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '6dd3a9e5-42cf-4792-9636-04a8bfd45239', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb2a3d710>]}
[0m11:26:49.104697 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '6dd3a9e5-42cf-4792-9636-04a8bfd45239', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb342b290>]}
[0m11:26:49.105219 [info ] [MainThread]: Registered adapter: clickhouse=1.8.9
[0m11:26:49.143447 [debug] [MainThread]: checksum: 132857a23e9d07220246854f7763165174ce9b737cfc7867629ace4294e520b1, vars: {}, profile: , target: , version: 1.8.9
[0m11:26:49.207066 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m11:26:49.207544 [debug] [MainThread]: Partial parsing: updated file: movie_warehouse://models/gold/dim_release_date.sql
[0m11:26:49.298508 [warn ] [MainThread]: [[33mWARNING[0m]: Deprecated functionality
The `tests` config has been renamed to `data_tests`. Please see
https://docs.getdbt.com/docs/build/data-tests#new-data_tests-syntax for more
information.
[0m11:26:49.298959 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'deprecation', 'label': '6dd3a9e5-42cf-4792-9636-04a8bfd45239', 'property_': 'warn', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb28e2090>]}
[0m11:26:49.382782 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.movie_warehouse.bronze
[0m11:26:49.388735 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '6dd3a9e5-42cf-4792-9636-04a8bfd45239', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb2482d90>]}
[0m11:26:49.476570 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '6dd3a9e5-42cf-4792-9636-04a8bfd45239', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb2498f10>]}
[0m11:26:49.476908 [info ] [MainThread]: Found 6 models, 12 data tests, 4 sources, 476 macros
[0m11:26:49.477107 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '6dd3a9e5-42cf-4792-9636-04a8bfd45239', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb1492b50>]}
[0m11:26:49.477925 [info ] [MainThread]: 
[0m11:26:49.478227 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m11:26:49.480890 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m11:26:49.485227 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:26:49.780703 [info ] [ThreadPool]: dbt_clickhouse adapter: Unexpected server exception dropping table
[0m11:26:49.781113 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m11:26:49.783058 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:26:49.845861 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__gold_gold)
[0m11:26:49.848835 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__gold_gold: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "connection_name": "list__gold_gold"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'gold_gold'
      

  ...
[0m11:26:49.868307 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m11:26:49.869786 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '6dd3a9e5-42cf-4792-9636-04a8bfd45239', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb25b7910>]}
[0m11:26:49.870137 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m11:26:49.870387 [info ] [MainThread]: 
[0m11:26:49.875255 [debug] [Thread-1 (]: Began running node model.movie_warehouse.dim_director
[0m11:26:49.875756 [info ] [Thread-1 (]: 1 of 6 START sql table model `gold_gold`.`dim_director` ........................ [RUN]
[0m11:26:49.876089 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list__gold_gold, now model.movie_warehouse.dim_director)
[0m11:26:49.876539 [debug] [Thread-1 (]: Began compiling node model.movie_warehouse.dim_director
[0m11:26:49.880671 [debug] [Thread-1 (]: Writing injected SQL for node "model.movie_warehouse.dim_director"
[0m11:26:49.881974 [debug] [Thread-1 (]: Began executing node model.movie_warehouse.dim_director
[0m11:26:49.906260 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_director: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_director"} */

            

    
        create table `gold_gold`.`dim_director__dbt_backup`
        
  
        
  engine = MergeTree()
        order by (director_id)
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

WITH first_dir AS (
    SELECT
        tconst,
        TRIM(splitByChar(',', directors)[1]) AS director_id
    FROM `bronze`.`imdb_title_crew_raw`
    WHERE directors IS NOT NULL AND directors != ''
),
deduped AS (
    SELECT DISTINCT director_id
    FROM first_dir
),
joined AS (
    SELECT
        d.director_id AS dir_id,
        n.primaryName AS dir_name
    FROM deduped d
    LEFT JOIN `bronze`.`imdb_name_basics_raw` n
        ON d.director_id = n.nconst
)
SELECT
    cityHash64(dir_id) AS imdb_dir_name_id,  -- Use hash instead of row_number
    dir_id,
    dir_name,
    today() AS valid_from,
    CAST(NULL AS Nullable(Date)) AS valid_to,
    1 AS is_current  -- Use 1/0 instead of TRUE/FALSE
FROM joined
WHERE dir_id IS NOT NULL
ORDER BY dir_id
          )
        
        ...
[0m11:26:49.913787 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_director"} */

            

    
        create table `gold_gold`.`dim_director__dbt_backup`
        
  
        
  engine = MergeTree()
        order by (director_id)
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

WITH first_dir AS (
    SELECT
        tconst,
        TRIM(splitByChar(',', directors)[1]) AS director_id
    FROM `bronze`.`imdb_title_crew_raw`
    WHERE directors IS NOT NULL AND directors != ''
),
deduped AS (
    SELECT DISTINCT director_id
    FROM first_dir
),
joined AS (
    SELECT
        d.director_id AS dir_id,
        n.primaryName AS dir_name
    FROM deduped d
    LEFT JOIN `bronze`.`imdb_name_basics_raw` n
        ON d.director_id = n.nconst
)
SELECT
    cityHash64(dir_id) AS imdb_dir_name_id,  -- Use hash instead of row_number
    dir_id,
    dir_name,
    today() AS valid_from,
    CAST(NULL AS Nullable(Date)) AS valid_to,
    1 AS is_current  -- Use 1/0 instead of TRUE/FALSE
FROM joined
WHERE dir_id IS NOT NULL
ORDER BY dir_id
          )
        
        
[0m11:26:49.920375 [debug] [Thread-1 (]: Database Error in model dim_director (models/gold/dim_director.sql)
  :HTTPDriver for http://clickhouse-server:8123 returned response code 404)
   Code: 47. DB::Exception: Missing columns: 'director_id' while processing: 'director_id', required columns: 'director_id', available columns: 'is_current' 'valid_to' 'valid_from' 'valid_to.null' 'dir_name' 'dir_id' 'imdb_dir_name_id'. (UNKNOWN_IDENTIFIER) (version 25.9.3.48 (official build))
[0m11:26:49.921149 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6dd3a9e5-42cf-4792-9636-04a8bfd45239', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb2706610>]}
[0m11:26:49.921541 [error] [Thread-1 (]: 1 of 6 ERROR creating sql table model `gold_gold`.`dim_director` ............... [[31mERROR[0m in 0.04s]
[0m11:26:49.921882 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.dim_director
[0m11:26:49.922130 [debug] [Thread-1 (]: Began running node model.movie_warehouse.dim_genre
[0m11:26:49.922701 [info ] [Thread-1 (]: 2 of 6 START sql table model `gold_gold`.`dim_genre` ........................... [RUN]
[0m11:26:49.922936 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.movie_warehouse.dim_director, now model.movie_warehouse.dim_genre)
[0m11:26:49.923112 [debug] [Thread-1 (]: Began compiling node model.movie_warehouse.dim_genre
[0m11:26:49.924631 [debug] [Thread-1 (]: Writing injected SQL for node "model.movie_warehouse.dim_genre"
[0m11:26:49.925132 [debug] [Thread-1 (]: Began executing node model.movie_warehouse.dim_genre
[0m11:26:49.926690 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_genre: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_genre"} */

            

    
        create table `gold_gold`.`dim_genre__dbt_backup`
        
  
        
  engine = MergeTree()
        order by (genre_id)
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

WITH parsed_genres AS (
    SELECT
        TRIM(splitByChar(',', genres)[1]) AS first_genre
    FROM `bronze`.`tmdb_raw`
    WHERE genres IS NOT NULL AND genres != ''
)
SELECT
    cityHash64(first_genre) AS genre_id,
    first_genre AS genre_name
FROM parsed_genres
GROUP BY first_genre
ORDER BY first_genre
          )
        
        ...
[0m11:26:49.932777 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m11:26:49.942533 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_genre: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_genre"} */

    select name, type from system.columns where table = 'dim_genre__dbt_backup'
    
      and database = 'gold_gold'
    
    order by position
  ...
[0m11:26:49.947646 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:26:49.949522 [debug] [Thread-1 (]: Writing runtime sql for node "model.movie_warehouse.dim_genre"
[0m11:26:49.950530 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_genre: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_genre"} */

  
    
    
    
        
         


        insert into `gold_gold`.`dim_genre__dbt_backup`
        ("genre_id", "genre_name")

WITH parsed_genres AS (
    SELECT
        TRIM(splitByChar(',', genres)[1]) AS first_genre
    FROM `bronze`.`tmdb_raw`
    WHERE genres IS NOT NULL AND genres != ''
)
SELECT
    cityHash64(first_genre) AS genre_id,
    first_genre AS genre_name
FROM parsed_genres
GROUP BY first_genre
ORDER BY first_genre
  ...
[0m11:26:49.979935 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.03 seconds
[0m11:26:49.982877 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_genre: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_genre"} */
EXCHANGE TABLES `gold_gold`.`dim_genre__dbt_backup` AND `gold_gold`.`dim_genre` 
  
  ...
[0m11:26:49.986835 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:26:49.999017 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_genre: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_genre"} */

    drop table if exists `gold_gold`.`dim_genre__dbt_backup` 
  ...
[0m11:26:50.000997 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_genre"} */

    drop table if exists `gold_gold`.`dim_genre__dbt_backup` 
  
[0m11:26:50.001268 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: macro drop_relation
[0m11:26:50.003298 [debug] [Thread-1 (]: Database Error in model dim_genre (models/gold/dim_genre.sql)
  :HTTPDriver for http://clickhouse-server:8123 returned response code 500)
   std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/8c9/8c9b38bb-5974-4368-97d1-712fe72b58b0/dim_genre__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/gold_gold.dim_genre__dbt_backup.b17917e7-3df3-4eb3-835d-e65347b09e5f.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build))
  compiled code at target/run/movie_warehouse/models/gold/dim_genre.sql
[0m11:26:50.003590 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6dd3a9e5-42cf-4792-9636-04a8bfd45239', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff88020a10>]}
[0m11:26:50.003924 [error] [Thread-1 (]: 2 of 6 ERROR creating sql table model `gold_gold`.`dim_genre` .................. [[31mERROR[0m in 0.08s]
[0m11:26:50.004248 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.dim_genre
[0m11:26:50.004496 [debug] [Thread-1 (]: Began running node model.movie_warehouse.dim_movie
[0m11:26:50.004815 [info ] [Thread-1 (]: 3 of 6 START sql table model `gold_gold`.`dim_movie` ........................... [RUN]
[0m11:26:50.005067 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.movie_warehouse.dim_genre, now model.movie_warehouse.dim_movie)
[0m11:26:50.005264 [debug] [Thread-1 (]: Began compiling node model.movie_warehouse.dim_movie
[0m11:26:50.006684 [debug] [Thread-1 (]: Writing injected SQL for node "model.movie_warehouse.dim_movie"
[0m11:26:50.007574 [debug] [Thread-1 (]: Began executing node model.movie_warehouse.dim_movie
[0m11:26:50.009141 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_movie: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_movie"} */

            

    
        create table `gold_gold`.`dim_movie__dbt_backup`
        
  
        
  engine = MergeTree()
        order by (movie_id)
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            -- ...existing code...


WITH movie_src AS (
    SELECT
        TRIM(title) AS movie_title,
        imdb_id,
        release_date,
        runtime AS movie_runtime,
        original_language AS language
    FROM `bronze`.`tmdb_raw`
    WHERE title IS NOT NULL AND title != ''
)
SELECT
    cityHash64(movie_title) AS movie_id,
    any(imdb_id) AS imdb_id,
    movie_title,
    any(release_date) AS release_date,
    any(movie_runtime) AS movie_runtime,
    any(language) AS language
FROM movie_src
GROUP BY movie_title
ORDER BY movie_title
          )
        
        ...
[0m11:26:50.017529 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m11:26:50.019084 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_movie: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_movie"} */

    select name, type from system.columns where table = 'dim_movie__dbt_backup'
    
      and database = 'gold_gold'
    
    order by position
  ...
[0m11:26:50.021226 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:26:50.022119 [debug] [Thread-1 (]: Writing runtime sql for node "model.movie_warehouse.dim_movie"
[0m11:26:50.022729 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_movie: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_movie"} */

  
    
    
    
        
         


        insert into `gold_gold`.`dim_movie__dbt_backup`
        ("movie_id", "imdb_id", "movie_title", "release_date", "movie_runtime", "language")-- ...existing code...


WITH movie_src AS (
    SELECT
        TRIM(title) AS movie_title,
        imdb_id,
        release_date,
        runtime AS movie_runtime,
        original_language AS language
    FROM `bronze`.`tmdb_raw`
    WHERE title IS NOT NULL AND title != ''
)
SELECT
    cityHash64(movie_title) AS movie_id,
    any(imdb_id) AS imdb_id,
    movie_title,
    any(release_date) AS release_date,
    any(movie_runtime) AS movie_runtime,
    any(language) AS language
FROM movie_src
GROUP BY movie_title
ORDER BY movie_title
  ...
[0m11:26:50.317832 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.29 seconds
[0m11:26:50.318967 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_movie: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_movie"} */
EXCHANGE TABLES `gold_gold`.`dim_movie__dbt_backup` AND `gold_gold`.`dim_movie` 
  
  ...
[0m11:26:50.322537 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:26:50.325132 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_movie: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_movie"} */

    drop table if exists `gold_gold`.`dim_movie__dbt_backup` 
  ...
[0m11:26:50.326721 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_movie"} */

    drop table if exists `gold_gold`.`dim_movie__dbt_backup` 
  
[0m11:26:50.326943 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: macro drop_relation
[0m11:26:50.329024 [debug] [Thread-1 (]: Database Error in model dim_movie (models/gold/dim_movie.sql)
  :HTTPDriver for http://clickhouse-server:8123 returned response code 500)
   std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/8c9/8c9b38bb-5974-4368-97d1-712fe72b58b0/dim_movie__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/gold_gold.dim_movie__dbt_backup.c5bba3bf-6d45-4710-8cc0-79f85b86ff82.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build))
  compiled code at target/run/movie_warehouse/models/gold/dim_movie.sql
[0m11:26:50.329348 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6dd3a9e5-42cf-4792-9636-04a8bfd45239', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb24765d0>]}
[0m11:26:50.329744 [error] [Thread-1 (]: 3 of 6 ERROR creating sql table model `gold_gold`.`dim_movie` .................. [[31mERROR[0m in 0.32s]
[0m11:26:50.330143 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.dim_movie
[0m11:26:50.330423 [debug] [Thread-1 (]: Began running node model.movie_warehouse.dim_production
[0m11:26:50.330788 [info ] [Thread-1 (]: 4 of 6 START sql table model `gold_gold`.`dim_production` ...................... [RUN]
[0m11:26:50.331038 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.movie_warehouse.dim_movie, now model.movie_warehouse.dim_production)
[0m11:26:50.331254 [debug] [Thread-1 (]: Began compiling node model.movie_warehouse.dim_production
[0m11:26:50.333250 [debug] [Thread-1 (]: Writing injected SQL for node "model.movie_warehouse.dim_production"
[0m11:26:50.334079 [debug] [Thread-1 (]: Began executing node model.movie_warehouse.dim_production
[0m11:26:50.336019 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_production: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_production"} */

            

    
        create table `gold_gold`.`dim_production__dbt_backup`
        
  
        
  engine = MergeTree()
        order by (production_id)
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

WITH first_production AS (
    SELECT
        imdb_id AS movie_id,
        trim(splitByChar(',', production_companies)[1]) AS production_name
    FROM `bronze`.`tmdb_raw`
    WHERE production_companies IS NOT NULL AND production_companies != ''
)

SELECT
    cityHash64(production_name) AS production_id,
    production_name,
    current_date() AS valid_from,
    CAST(NULL AS Nullable(Date)) AS valid_to,
    TRUE AS is_current
FROM (
    SELECT DISTINCT production_name
    FROM first_production
)
WHERE production_name IS NOT NULL
          )
        
        ...
[0m11:26:50.341586 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m11:26:50.342864 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_production: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_production"} */

    select name, type from system.columns where table = 'dim_production__dbt_backup'
    
      and database = 'gold_gold'
    
    order by position
  ...
[0m11:26:50.344956 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:26:50.346151 [debug] [Thread-1 (]: Writing runtime sql for node "model.movie_warehouse.dim_production"
[0m11:26:50.346748 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_production: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_production"} */

  
    
    
    
        
         


        insert into `gold_gold`.`dim_production__dbt_backup`
        ("production_id", "production_name", "valid_from", "valid_to", "is_current")

WITH first_production AS (
    SELECT
        imdb_id AS movie_id,
        trim(splitByChar(',', production_companies)[1]) AS production_name
    FROM `bronze`.`tmdb_raw`
    WHERE production_companies IS NOT NULL AND production_companies != ''
)

SELECT
    cityHash64(production_name) AS production_id,
    production_name,
    current_date() AS valid_from,
    CAST(NULL AS Nullable(Date)) AS valid_to,
    TRUE AS is_current
FROM (
    SELECT DISTINCT production_name
    FROM first_production
)
WHERE production_name IS NOT NULL
  ...
[0m11:26:50.351086 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:26:50.351648 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_production: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_production"} */
EXCHANGE TABLES `gold_gold`.`dim_production__dbt_backup` AND `gold_gold`.`dim_production` 
  
  ...
[0m11:26:50.354152 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:26:50.355824 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_production: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_production"} */

    drop table if exists `gold_gold`.`dim_production__dbt_backup` 
  ...
[0m11:26:50.357454 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_production"} */

    drop table if exists `gold_gold`.`dim_production__dbt_backup` 
  
[0m11:26:50.357853 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: macro drop_relation
[0m11:26:50.361555 [debug] [Thread-1 (]: Database Error in model dim_production (models/gold/dim_production.sql)
  :HTTPDriver for http://clickhouse-server:8123 returned response code 500)
   std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/8c9/8c9b38bb-5974-4368-97d1-712fe72b58b0/dim_production__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/gold_gold.dim_production__dbt_backup.eb95a52e-5325-4b40-8b2e-d4782cbc2b9f.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build))
  compiled code at target/run/movie_warehouse/models/gold/dim_production.sql
[0m11:26:50.361935 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6dd3a9e5-42cf-4792-9636-04a8bfd45239', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff6ed589d0>]}
[0m11:26:50.362428 [error] [Thread-1 (]: 4 of 6 ERROR creating sql table model `gold_gold`.`dim_production` ............. [[31mERROR[0m in 0.03s]
[0m11:26:50.362869 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.dim_production
[0m11:26:50.363262 [debug] [Thread-1 (]: Began running node model.movie_warehouse.dim_release_date
[0m11:26:50.363623 [info ] [Thread-1 (]: 5 of 6 START sql table model `gold_gold`.`dim_release_date` .................... [RUN]
[0m11:26:50.363877 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.movie_warehouse.dim_production, now model.movie_warehouse.dim_release_date)
[0m11:26:50.364065 [debug] [Thread-1 (]: Began compiling node model.movie_warehouse.dim_release_date
[0m11:26:50.365892 [debug] [Thread-1 (]: Writing injected SQL for node "model.movie_warehouse.dim_release_date"
[0m11:26:50.366387 [debug] [Thread-1 (]: Began executing node model.movie_warehouse.dim_release_date
[0m11:26:50.368959 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_release_date: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_release_date"} */

            

    
        create table `gold_gold`.`dim_release_date__dbt_backup`
        
  
        
  engine = MergeTree()
        order by (date_id)
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

WITH distinct_dates AS (
    SELECT DISTINCT release_date
    FROM `bronze`.`tmdb_raw`
    WHERE release_date IS NOT NULL
)

SELECT
    cityHash64(release_date)                                    AS date_id,
    release_date                                                AS full_date,
    toYear(release_date)                                        AS year,
    toMonth(release_date)                                       AS month,
    toDayOfMonth(release_date)                                  AS day,
    toISOWeek(release_date)                                     AS week,
    formatDateTime(release_date, '%a')                          AS weekday,
    CASE
        WHEN toMonth(release_date) IN (12,1,2)  THEN 'Winter'
        WHEN toMonth(release_date) IN (3,4,5)   THEN 'Spring'
        WHEN toMonth(release_date) IN (6,7,8)   THEN 'Summer'
        WHEN toMonth(release_date) IN (9,10,11) THEN 'Autumn'
    END                                                         AS season,
    CASE
        WHEN formatDateTime(release_date, '%a') IN ('Saturday','Sunday') THEN 1
        ELSE 0
    END                                                         AS is_weekend,

    /* ---------- holiday tagging ---------- */
    CASE
        WHEN toMonth(release_date)=1  AND toDayOfMonth(release_date)=1  THEN 'New Years Day'
        WHEN toMonth(release_date)=2  AND toDayOfMonth(release_date)=14 THEN 'Valentines Day'
        WHEN toMonth(release_date)=3  AND toDayOfMonth(release_date)=17 THEN 'St. Patricks Day'
        WHEN toMonth(release_date)=4  AND toDayOfMonth(release_date)=1  THEN 'April Fools Day'
        WHEN toMonth(release_date)=4  AND toDayOfMonth(release_date)=22 THEN 'Earth Day'
        WHEN toMonth(release_date)=5  AND toDayOfMonth(release_date)=1  THEN 'May Day'
        WHEN toMonth(release_date)=5  AND toDayOfMonth(release_date)=5  THEN 'Cinco de Mayo'
        WHEN toMonth(release_date)=6  AND toDayOfMonth(release_date) BETWEEN 19 AND 26 THEN 'Midsummer'
        WHEN toMonth(release_date)=7  AND toDayOfMonth(release_date)=4  THEN 'Independence Day'
        WHEN toMonth(release_date)=9  AND toDayOfMonth(release_date) BETWEEN 1 AND 7 
             AND formatDateTime(release_date,'%a')='Monday'             THEN 'Labor Day (US)'
        WHEN toMonth(release_date)=10 AND toDayOfMonth(release_date)=31 THEN 'Halloween'
        WHEN toMonth(release_date)=11 AND formatDateTime(release_date,'%a')='Thursday'
             AND toISOWeek(release_date) >= 47                           THEN 'Thanksgiving'
        WHEN toMonth(release_date)=12 AND toDayOfMonth(release_date)=24 THEN 'Christmas Eve'
        WHEN toMonth(release_date)=12 AND toDayOfMonth(release_date)=25 THEN 'Christmas Day'
        WHEN toMonth(release_date)=12 AND toDayOfMonth(release_date)=31 THEN 'New Years Eve'
        ELSE NULL
    END                                                         AS holiday_name,
    IF(holiday_name IS NOT NULL, 1, 0)                          AS is_holiday,

    /* placeholders for later enhancement */
    CAST(NULL AS Nullable(Int32)) AS days_until_holiday,
    CAST(NULL AS Nullable(Int32)) AS days_after_holiday

FROM distinct_dates
ORDER BY release_date
          )
        
        ...
[0m11:26:50.379816 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m11:26:50.381208 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_release_date: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_release_date"} */

    select name, type from system.columns where table = 'dim_release_date__dbt_backup'
    
      and database = 'gold_gold'
    
    order by position
  ...
[0m11:26:50.383206 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:26:50.384345 [debug] [Thread-1 (]: Writing runtime sql for node "model.movie_warehouse.dim_release_date"
[0m11:26:50.384990 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_release_date: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_release_date"} */

  
    
    
    
        
         


        insert into `gold_gold`.`dim_release_date__dbt_backup`
        ("date_id", "full_date", "year", "month", "day", "week", "weekday", "season", "is_weekend", "holiday_name", "is_holiday", "days_until_holiday", "days_after_holiday")

WITH distinct_dates AS (
    SELECT DISTINCT release_date
    FROM `bronze`.`tmdb_raw`
    WHERE release_date IS NOT NULL
)

SELECT
    cityHash64(release_date)                                    AS date_id,
    release_date                                                AS full_date,
    toYear(release_date)                                        AS year,
    toMonth(release_date)                                       AS month,
    toDayOfMonth(release_date)                                  AS day,
    toISOWeek(release_date)                                     AS week,
    formatDateTime(release_date, '%a')                          AS weekday,
    CASE
        WHEN toMonth(release_date) IN (12,1,2)  THEN 'Winter'
        WHEN toMonth(release_date) IN (3,4,5)   THEN 'Spring'
        WHEN toMonth(release_date) IN (6,7,8)   THEN 'Summer'
        WHEN toMonth(release_date) IN (9,10,11) THEN 'Autumn'
    END                                                         AS season,
    CASE
        WHEN formatDateTime(release_date, '%a') IN ('Saturday','Sunday') THEN 1
        ELSE 0
    END                                                         AS is_weekend,

    /* ---------- holiday tagging ---------- */
    CASE
        WHEN toMonth(release_date)=1  AND toDayOfMonth(release_date)=1  THEN 'New Years Day'
        WHEN toMonth(release_date)=2  AND toDayOfMonth(release_date)=14 THEN 'Valentines Day'
        WHEN toMonth(release_date)=3  AND toDayOfMonth(release_date)=17 THEN 'St. Patricks Day'
        WHEN toMonth(release_date)=4  AND toDayOfMonth(release_date)=1  THEN 'April Fools Day'
        WHEN toMonth(release_date)=4  AND toDayOfMonth(release_date)=22 THEN 'Earth Day'
        WHEN toMonth(release_date)=5  AND toDayOfMonth(release_date)=1  THEN 'May Day'
        WHEN toMonth(release_date)=5  AND toDayOfMonth(release_date)=5  THEN 'Cinco de Mayo'
        WHEN toMonth(release_date)=6  AND toDayOfMonth(release_date) BETWEEN 19 AND 26 THEN 'Midsummer'
        WHEN toMonth(release_date)=7  AND toDayOfMonth(release_date)=4  THEN 'Independence Day'
        WHEN toMonth(release_date)=9  AND toDayOfMonth(release_date) BETWEEN 1 AND 7 
             AND formatDateTime(release_date,'%a')='Monday'             THEN 'Labor Day (US)'
        WHEN toMonth(release_date)=10 AND toDayOfMonth(release_date)=31 THEN 'Halloween'
        WHEN toMonth(release_date)=11 AND formatDateTime(release_date,'%a')='Thursday'
             AND toISOWeek(release_date) >= 47                           THEN 'Thanksgiving'
        WHEN toMonth(release_date)=12 AND toDayOfMonth(release_date)=24 THEN 'Christmas Eve'
        WHEN toMonth(release_date)=12 AND toDayOfMonth(release_date)=25 THEN 'Christmas Day'
        WHEN toMonth(release_date)=12 AND toDayOfMonth(release_date)=31 THEN 'New Years Eve'
        ELSE NULL
    END                                                         AS holiday_name,
    IF(holiday_name IS NOT NULL, 1, 0)                          AS is_holiday,

    /* placeholders for later enhancement */
    CAST(NULL AS Nullable(Int32)) AS days_until_holiday,
    CAST(NULL AS Nullable(Int32)) AS days_after_holiday

FROM distinct_dates
ORDER BY release_date
  ...
[0m11:26:50.409811 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m11:26:50.410770 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_release_date: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_release_date"} */
EXCHANGE TABLES `gold_gold`.`dim_release_date__dbt_backup` AND `gold_gold`.`dim_release_date` 
  
  ...
[0m11:26:50.414353 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:26:50.417115 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_release_date: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_release_date"} */

    drop table if exists `gold_gold`.`dim_release_date__dbt_backup` 
  ...
[0m11:26:50.419429 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_release_date"} */

    drop table if exists `gold_gold`.`dim_release_date__dbt_backup` 
  
[0m11:26:50.419752 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: macro drop_relation
[0m11:26:50.421560 [debug] [Thread-1 (]: Database Error in model dim_release_date (models/gold/dim_release_date.sql)
  :HTTPDriver for http://clickhouse-server:8123 returned response code 500)
   std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/8c9/8c9b38bb-5974-4368-97d1-712fe72b58b0/dim_release_date__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/gold_gold.dim_release_date__dbt_backup.12535e2d-cca5-4c00-bd05-1c22e8aa2738.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build))
  compiled code at target/run/movie_warehouse/models/gold/dim_release_date.sql
[0m11:26:50.421828 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6dd3a9e5-42cf-4792-9636-04a8bfd45239', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff6c57e510>]}
[0m11:26:50.422181 [error] [Thread-1 (]: 5 of 6 ERROR creating sql table model `gold_gold`.`dim_release_date` ........... [[31mERROR[0m in 0.06s]
[0m11:26:50.422448 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.dim_release_date
[0m11:26:50.423089 [debug] [Thread-1 (]: Began running node model.movie_warehouse.fact_movie
[0m11:26:50.423315 [info ] [Thread-1 (]: 6 of 6 SKIP relation gold_gold.fact_movie ...................................... [[33mSKIP[0m]
[0m11:26:50.423545 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.fact_movie
[0m11:26:50.424283 [debug] [MainThread]: Connection 'master' was properly closed.
[0m11:26:50.424528 [debug] [MainThread]: Connection 'model.movie_warehouse.dim_release_date' was left open.
[0m11:26:50.424735 [debug] [MainThread]: On model.movie_warehouse.dim_release_date: Close
[0m11:26:50.425029 [info ] [MainThread]: 
[0m11:26:50.425226 [info ] [MainThread]: Finished running 6 table models in 0 hours 0 minutes and 0.95 seconds (0.95s).
[0m11:26:50.425764 [debug] [MainThread]: Command end result
[0m11:26:50.446890 [info ] [MainThread]: 
[0m11:26:50.447189 [info ] [MainThread]: [31mCompleted with 5 errors and 0 warnings:[0m
[0m11:26:50.447375 [info ] [MainThread]: 
[0m11:26:50.447588 [error] [MainThread]:   Database Error in model dim_director (models/gold/dim_director.sql)
  :HTTPDriver for http://clickhouse-server:8123 returned response code 404)
   Code: 47. DB::Exception: Missing columns: 'director_id' while processing: 'director_id', required columns: 'director_id', available columns: 'is_current' 'valid_to' 'valid_from' 'valid_to.null' 'dir_name' 'dir_id' 'imdb_dir_name_id'. (UNKNOWN_IDENTIFIER) (version 25.9.3.48 (official build))
[0m11:26:50.447749 [info ] [MainThread]: 
[0m11:26:50.447944 [error] [MainThread]:   Database Error in model dim_genre (models/gold/dim_genre.sql)
  :HTTPDriver for http://clickhouse-server:8123 returned response code 500)
   std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/8c9/8c9b38bb-5974-4368-97d1-712fe72b58b0/dim_genre__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/gold_gold.dim_genre__dbt_backup.b17917e7-3df3-4eb3-835d-e65347b09e5f.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build))
  compiled code at target/run/movie_warehouse/models/gold/dim_genre.sql
[0m11:26:50.448140 [info ] [MainThread]: 
[0m11:26:50.448324 [error] [MainThread]:   Database Error in model dim_movie (models/gold/dim_movie.sql)
  :HTTPDriver for http://clickhouse-server:8123 returned response code 500)
   std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/8c9/8c9b38bb-5974-4368-97d1-712fe72b58b0/dim_movie__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/gold_gold.dim_movie__dbt_backup.c5bba3bf-6d45-4710-8cc0-79f85b86ff82.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build))
  compiled code at target/run/movie_warehouse/models/gold/dim_movie.sql
[0m11:26:50.448470 [info ] [MainThread]: 
[0m11:26:50.448637 [error] [MainThread]:   Database Error in model dim_production (models/gold/dim_production.sql)
  :HTTPDriver for http://clickhouse-server:8123 returned response code 500)
   std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/8c9/8c9b38bb-5974-4368-97d1-712fe72b58b0/dim_production__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/gold_gold.dim_production__dbt_backup.eb95a52e-5325-4b40-8b2e-d4782cbc2b9f.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build))
  compiled code at target/run/movie_warehouse/models/gold/dim_production.sql
[0m11:26:50.448820 [info ] [MainThread]: 
[0m11:26:50.449011 [error] [MainThread]:   Database Error in model dim_release_date (models/gold/dim_release_date.sql)
  :HTTPDriver for http://clickhouse-server:8123 returned response code 500)
   std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/8c9/8c9b38bb-5974-4368-97d1-712fe72b58b0/dim_release_date__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/gold_gold.dim_release_date__dbt_backup.12535e2d-cca5-4c00-bd05-1c22e8aa2738.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build))
  compiled code at target/run/movie_warehouse/models/gold/dim_release_date.sql
[0m11:26:50.449191 [info ] [MainThread]: 
[0m11:26:50.449365 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=5 SKIP=1 TOTAL=6
[0m11:26:50.450069 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 1.5273912, "process_in_blocks": "71040", "process_kernel_time": 0.275488, "process_mem_max_rss": "194000", "process_out_blocks": "3465", "process_user_time": 2.012175}
[0m11:26:50.450396 [debug] [MainThread]: Command `dbt run` failed at 11:26:50.450344 after 1.53 seconds
[0m11:26:50.450629 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb29fcad0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb29fe290>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff6dec27d0>]}
[0m11:26:50.450851 [debug] [MainThread]: Flushing usage events
[0m13:30:23.775995 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107e8ba10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1124ef890>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1124efb10>]}


============================== 13:30:23.780891 | 65a9c49e-1425-4eb4-bae6-40ce429791eb ==============================
[0m13:30:23.780891 [info ] [MainThread]: Running with dbt=1.10.13
[0m13:30:23.781175 [debug] [MainThread]: running dbt with arguments {'no_print': 'None', 'partial_parse': 'True', 'send_anonymous_usage_stats': 'True', 'static_parser': 'True', 'log_path': '/Users/kevineriksson/Project-1/dbt/logs', 'write_json': 'True', 'introspect': 'True', 'invocation_command': 'dbt clean', 'log_format': 'default', 'debug': 'False', 'quiet': 'False', 'cache_selected_only': 'False', 'empty': 'None', 'target_path': 'None', 'fail_fast': 'False', 'indirect_selection': 'eager', 'use_colors': 'True', 'printer_width': '80', 'version_check': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'warn_error': 'None', 'log_cache_events': 'False', 'profiles_dir': '/Users/kevineriksson/Project-1/dbt', 'use_experimental_parser': 'False'}
[0m13:30:23.917122 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '65a9c49e-1425-4eb4-bae6-40ce429791eb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1105b3ce0>]}
[0m13:30:24.075883 [debug] [MainThread]: Resource report: {"command_name": "clean", "command_success": true, "command_wall_clock_time": 0.3414701, "process_in_blocks": "0", "process_kernel_time": 0.149734, "process_mem_max_rss": "114524160", "process_out_blocks": "0", "process_user_time": 0.615584}
[0m13:30:24.076339 [debug] [MainThread]: Command `dbt clean` succeeded at 13:30:24.076239 after 0.34 seconds
[0m13:30:24.076592 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11230bac0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112698050>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112675850>]}
[0m13:30:24.076784 [debug] [MainThread]: Flushing usage events
[0m13:30:24.607507 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m13:30:32.376452 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10413ba10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105863890>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105863b10>]}


============================== 13:30:32.378914 | e60d41c5-4a1b-4a51-96b1-08994e09c81c ==============================
[0m13:30:32.378914 [info ] [MainThread]: Running with dbt=1.10.13
[0m13:30:32.379191 [debug] [MainThread]: running dbt with arguments {'profiles_dir': '/Users/kevineriksson/Project-1/dbt', 'partial_parse': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'fail_fast': 'False', 'log_cache_events': 'False', 'cache_selected_only': 'False', 'indirect_selection': 'eager', 'invocation_command': 'dbt run --full-refresh --select dim_director dim_genre dim_movie dim_production dim_release_date', 'debug': 'False', 'introspect': 'True', 'quiet': 'False', 'use_experimental_parser': 'False', 'no_print': 'None', 'static_parser': 'True', 'printer_width': '80', 'log_path': '/Users/kevineriksson/Project-1/dbt/logs', 'send_anonymous_usage_stats': 'True', 'use_colors': 'True', 'log_format': 'default', 'version_check': 'True', 'write_json': 'True', 'target_path': 'None', 'warn_error': 'None', 'empty': 'False'}
[0m13:30:32.467245 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'e60d41c5-4a1b-4a51-96b1-08994e09c81c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104627ce0>]}
[0m13:30:32.490871 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'e60d41c5-4a1b-4a51-96b1-08994e09c81c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10567bce0>]}
[0m13:30:32.492327 [info ] [MainThread]: Registered adapter: clickhouse=1.9.5
[0m13:30:32.543183 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m13:30:32.543783 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m13:30:32.544006 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'e60d41c5-4a1b-4a51-96b1-08994e09c81c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105931150>]}
[0m13:30:33.118630 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.movie_warehouse.bronze
[0m13:30:33.122365 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'e60d41c5-4a1b-4a51-96b1-08994e09c81c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105d186e0>]}
[0m13:30:33.159250 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/kevineriksson/Project-1/dbt/target/manifest.json
[0m13:30:33.160322 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/kevineriksson/Project-1/dbt/target/semantic_manifest.json
[0m13:30:33.172694 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'e60d41c5-4a1b-4a51-96b1-08994e09c81c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106073a10>]}
[0m13:30:33.172894 [info ] [MainThread]: Found 6 models, 12 data tests, 4 sources, 485 macros
[0m13:30:33.173034 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'e60d41c5-4a1b-4a51-96b1-08994e09c81c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105d6ce20>]}
[0m13:30:33.173880 [info ] [MainThread]: 
[0m13:30:33.174013 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m13:30:33.174111 [info ] [MainThread]: 
[0m13:30:33.174296 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m13:30:33.176599 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m13:30:33.180410 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:30:51.034939 [debug] [ThreadPool]: dbt_clickhouse adapter: Got a retryable error when attempting to open a clickhouse connection.
1 attempts remaining. Retrying in 1 seconds.
Error:
Error HTTPConnectionPool(host='clickhouse-server', port=8123): Max retries exceeded with url: /? (Caused by NameResolutionError("<urllib3.connection.HTTPConnection object at 0x119a2f250>: Failed to resolve 'clickhouse-server' ([Errno 8] nodename nor servname provided, or not known)")) executing HTTP request attempt 1 (http://clickhouse-server:8123)
[0m13:30:52.048951 [debug] [ThreadPool]: dbt_clickhouse adapter: Error running SQL: macro list_schemas
[0m13:30:52.051365 [debug] [MainThread]: Connection 'master' was properly closed.
[0m13:30:52.052201 [debug] [MainThread]: Connection 'list_' was left open.
[0m13:30:52.052837 [debug] [MainThread]: On list_: No close available on handle
[0m13:30:52.053438 [info ] [MainThread]: 
[0m13:30:52.054328 [info ] [MainThread]: Finished running  in 0 hours 0 minutes and 18.88 seconds (18.88s).
[0m13:30:52.056316 [error] [MainThread]: Encountered an error:
Database Error
  Error HTTPConnectionPool(host='clickhouse-server', port=8123): Max retries exceeded with url: /? (Caused by NameResolutionError("<urllib3.connection.HTTPConnection object at 0x119a95f30>: Failed to resolve 'clickhouse-server' ([Errno 8] nodename nor servname provided, or not known)")) executing HTTP request attempt 1 (http://clickhouse-server:8123)
[0m13:30:52.065004 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 19.718801, "process_in_blocks": "0", "process_kernel_time": 0.437399, "process_mem_max_rss": "144703488", "process_out_blocks": "0", "process_user_time": 3.374647}
[0m13:30:52.065711 [debug] [MainThread]: Command `dbt run` failed at 13:30:52.065577 after 19.72 seconds
[0m13:30:52.066888 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1056ed9d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x119a26ba0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x119a26c50>]}
[0m13:30:52.070501 [debug] [MainThread]: Flushing usage events
[0m13:30:52.608264 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m11:32:26.585813 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff7cbcd5d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff7cbcd050>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff7cbcc710>]}


============================== 11:32:26.589446 | 322ccf04-866c-4042-9ae4-511405cb3dfe ==============================
[0m11:32:26.589446 [info ] [MainThread]: Running with dbt=1.8.9
[0m11:32:26.589743 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/project_root/dbt', 'debug': 'False', 'warn_error': 'None', 'log_path': '/opt/airflow/project_root/dbt/logs', 'version_check': 'True', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'invocation_command': 'dbt run --project-dir /opt/airflow/project_root/dbt --profiles-dir /opt/airflow/project_root/dbt --select gold', 'static_parser': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m11:32:26.702222 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '322ccf04-866c-4042-9ae4-511405cb3dfe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff7cb46a50>]}
[0m11:32:26.722262 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '322ccf04-866c-4042-9ae4-511405cb3dfe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff7d5fb2d0>]}
[0m11:32:26.722960 [info ] [MainThread]: Registered adapter: clickhouse=1.8.9
[0m11:32:26.756669 [debug] [MainThread]: checksum: 132857a23e9d07220246854f7763165174ce9b737cfc7867629ace4294e520b1, vars: {}, profile: , target: , version: 1.8.9
[0m11:32:26.795599 [info ] [MainThread]: Unable to do partial parsing because of a version mismatch
[0m11:32:26.795966 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '322ccf04-866c-4042-9ae4-511405cb3dfe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff7e0d24d0>]}
[0m11:32:27.420900 [warn ] [MainThread]: [[33mWARNING[0m]: Deprecated functionality
The `tests` config has been renamed to `data_tests`. Please see
https://docs.getdbt.com/docs/build/data-tests#new-data_tests-syntax for more
information.
[0m11:32:27.421461 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'deprecation', 'label': '322ccf04-866c-4042-9ae4-511405cb3dfe', 'property_': 'warn', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff7c73a910>]}
[0m11:32:27.563881 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.movie_warehouse.bronze
[0m11:32:27.569597 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '322ccf04-866c-4042-9ae4-511405cb3dfe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff7777bd90>]}
[0m11:32:27.628826 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '322ccf04-866c-4042-9ae4-511405cb3dfe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff77584190>]}
[0m11:32:27.629195 [info ] [MainThread]: Found 6 models, 12 data tests, 4 sources, 476 macros
[0m11:32:27.629413 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '322ccf04-866c-4042-9ae4-511405cb3dfe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff775c8350>]}
[0m11:32:27.630701 [info ] [MainThread]: 
[0m11:32:27.631241 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m11:32:27.634580 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m11:32:27.640769 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:32:28.038037 [info ] [ThreadPool]: dbt_clickhouse adapter: Unexpected server exception dropping table
[0m11:32:28.038516 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m11:32:28.041453 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:32:28.063233 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__gold_gold)
[0m11:32:28.067118 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__gold_gold: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "connection_name": "list__gold_gold"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'gold_gold'
      

  ...
[0m11:32:28.090722 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m11:32:28.093422 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '322ccf04-866c-4042-9ae4-511405cb3dfe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff3cc96d50>]}
[0m11:32:28.093916 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m11:32:28.094212 [info ] [MainThread]: 
[0m11:32:28.099676 [debug] [Thread-1 (]: Began running node model.movie_warehouse.dim_director
[0m11:32:28.100130 [info ] [Thread-1 (]: 1 of 6 START sql table model `gold_gold`.`dim_director` ........................ [RUN]
[0m11:32:28.100426 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list__gold_gold, now model.movie_warehouse.dim_director)
[0m11:32:28.100640 [debug] [Thread-1 (]: Began compiling node model.movie_warehouse.dim_director
[0m11:32:28.104396 [debug] [Thread-1 (]: Writing injected SQL for node "model.movie_warehouse.dim_director"
[0m11:32:28.105546 [debug] [Thread-1 (]: Began executing node model.movie_warehouse.dim_director
[0m11:32:28.128072 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_director: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_director"} */

            

    
        create table `gold_gold`.`dim_director__dbt_backup`
        
  
        
  engine = MergeTree()
        order by (dir_id)
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

WITH first_dir AS (
    SELECT
        tconst,
        TRIM(splitByChar(',', directors)[1]) AS director_id
    FROM `bronze`.`imdb_title_crew_raw`
    WHERE directors IS NOT NULL AND directors != ''
),
deduped AS (
    SELECT DISTINCT director_id
    FROM first_dir
),
joined AS (
    SELECT
        d.director_id AS dir_id,
        n.primaryName AS dir_name
    FROM deduped d
    LEFT JOIN `bronze`.`imdb_name_basics_raw` n
        ON d.director_id = n.nconst
)
SELECT
    cityHash64(dir_id) AS imdb_dir_name_id,  -- Use hash instead of row_number
    dir_id,
    dir_name,
    today() AS valid_from,
    CAST(NULL AS Nullable(Date)) AS valid_to,
    1 AS is_current  -- Use 1/0 instead of TRUE/FALSE
FROM joined
WHERE dir_id IS NOT NULL
ORDER BY dir_id
          )
        
        ...
[0m11:32:28.145413 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m11:32:28.153263 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_director: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_director"} */

    select name, type from system.columns where table = 'dim_director__dbt_backup'
    
      and database = 'gold_gold'
    
    order by position
  ...
[0m11:32:28.157409 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:32:28.159293 [debug] [Thread-1 (]: Writing runtime sql for node "model.movie_warehouse.dim_director"
[0m11:32:28.160457 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_director: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_director"} */

  
    
    
    
        
         


        insert into `gold_gold`.`dim_director__dbt_backup`
        ("imdb_dir_name_id", "dir_id", "dir_name", "valid_from", "valid_to", "is_current")

WITH first_dir AS (
    SELECT
        tconst,
        TRIM(splitByChar(',', directors)[1]) AS director_id
    FROM `bronze`.`imdb_title_crew_raw`
    WHERE directors IS NOT NULL AND directors != ''
),
deduped AS (
    SELECT DISTINCT director_id
    FROM first_dir
),
joined AS (
    SELECT
        d.director_id AS dir_id,
        n.primaryName AS dir_name
    FROM deduped d
    LEFT JOIN `bronze`.`imdb_name_basics_raw` n
        ON d.director_id = n.nconst
)
SELECT
    cityHash64(dir_id) AS imdb_dir_name_id,  -- Use hash instead of row_number
    dir_id,
    dir_name,
    today() AS valid_from,
    CAST(NULL AS Nullable(Date)) AS valid_to,
    1 AS is_current  -- Use 1/0 instead of TRUE/FALSE
FROM joined
WHERE dir_id IS NOT NULL
ORDER BY dir_id
  ...
[0m11:32:32.217003 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 4.05 seconds
[0m11:32:32.232781 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_director: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_director"} */
EXCHANGE TABLES `gold_gold`.`dim_director__dbt_backup` AND `gold_gold`.`dim_director` 
  
  ...
[0m11:32:32.245720 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m11:32:32.270119 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_director: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_director"} */

    drop table if exists `gold_gold`.`dim_director__dbt_backup` 
  ...
[0m11:32:32.275477 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_director"} */

    drop table if exists `gold_gold`.`dim_director__dbt_backup` 
  
[0m11:32:32.275896 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: macro drop_relation
[0m11:32:32.284325 [debug] [Thread-1 (]: Database Error in model dim_director (models/gold/dim_director.sql)
  :HTTPDriver for http://clickhouse-server:8123 returned response code 500)
   std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/8c9/8c9b38bb-5974-4368-97d1-712fe72b58b0/dim_director__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/gold_gold.dim_director__dbt_backup.a673fee0-4fee-40ce-8a4a-13bd6f9423d1.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build))
  compiled code at target/run/movie_warehouse/models/gold/dim_director.sql
[0m11:32:32.294736 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '322ccf04-866c-4042-9ae4-511405cb3dfe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff776577d0>]}
[0m11:32:32.295990 [error] [Thread-1 (]: 1 of 6 ERROR creating sql table model `gold_gold`.`dim_director` ............... [[31mERROR[0m in 4.18s]
[0m11:32:32.296806 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.dim_director
[0m11:32:32.297222 [debug] [Thread-1 (]: Began running node model.movie_warehouse.dim_genre
[0m11:32:32.298888 [info ] [Thread-1 (]: 2 of 6 START sql table model `gold_gold`.`dim_genre` ........................... [RUN]
[0m11:32:32.299256 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.movie_warehouse.dim_director, now model.movie_warehouse.dim_genre)
[0m11:32:32.299495 [debug] [Thread-1 (]: Began compiling node model.movie_warehouse.dim_genre
[0m11:32:32.302332 [debug] [Thread-1 (]: Writing injected SQL for node "model.movie_warehouse.dim_genre"
[0m11:32:32.303308 [debug] [Thread-1 (]: Began executing node model.movie_warehouse.dim_genre
[0m11:32:32.305811 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_genre: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_genre"} */

            

    
        create table `gold_gold`.`dim_genre__dbt_backup`
        
  
        
  engine = MergeTree()
        order by (genre_id)
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

WITH parsed_genres AS (
    SELECT
        TRIM(splitByChar(',', genres)[1]) AS first_genre
    FROM `bronze`.`tmdb_raw`
    WHERE genres IS NOT NULL AND genres != ''
)
SELECT
    cityHash64(first_genre) AS genre_id,
    first_genre AS genre_name
FROM parsed_genres
GROUP BY first_genre
ORDER BY first_genre
          )
        
        ...
[0m11:32:32.324034 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m11:32:32.331084 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_genre: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_genre"} */

    select name, type from system.columns where table = 'dim_genre__dbt_backup'
    
      and database = 'gold_gold'
    
    order by position
  ...
[0m11:32:32.340524 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m11:32:32.343752 [debug] [Thread-1 (]: Writing runtime sql for node "model.movie_warehouse.dim_genre"
[0m11:32:32.345419 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_genre: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_genre"} */

  
    
    
    
        
         


        insert into `gold_gold`.`dim_genre__dbt_backup`
        ("genre_id", "genre_name")

WITH parsed_genres AS (
    SELECT
        TRIM(splitByChar(',', genres)[1]) AS first_genre
    FROM `bronze`.`tmdb_raw`
    WHERE genres IS NOT NULL AND genres != ''
)
SELECT
    cityHash64(first_genre) AS genre_id,
    first_genre AS genre_name
FROM parsed_genres
GROUP BY first_genre
ORDER BY first_genre
  ...
[0m11:32:32.386308 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.04 seconds
[0m11:32:32.387343 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_genre: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_genre"} */
EXCHANGE TABLES `gold_gold`.`dim_genre__dbt_backup` AND `gold_gold`.`dim_genre` 
  
  ...
[0m11:32:32.391513 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:32:32.394622 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_genre: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_genre"} */

    drop table if exists `gold_gold`.`dim_genre__dbt_backup` 
  ...
[0m11:32:32.398687 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_genre"} */

    drop table if exists `gold_gold`.`dim_genre__dbt_backup` 
  
[0m11:32:32.399188 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: macro drop_relation
[0m11:32:32.402097 [debug] [Thread-1 (]: Database Error in model dim_genre (models/gold/dim_genre.sql)
  :HTTPDriver for http://clickhouse-server:8123 returned response code 500)
   std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/8c9/8c9b38bb-5974-4368-97d1-712fe72b58b0/dim_genre__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/gold_gold.dim_genre__dbt_backup.7bebc36c-fadf-4781-9f64-d627a049af58.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build))
  compiled code at target/run/movie_warehouse/models/gold/dim_genre.sql
[0m11:32:32.402736 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '322ccf04-866c-4042-9ae4-511405cb3dfe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff3c1c6090>]}
[0m11:32:32.403289 [error] [Thread-1 (]: 2 of 6 ERROR creating sql table model `gold_gold`.`dim_genre` .................. [[31mERROR[0m in 0.10s]
[0m11:32:32.403839 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.dim_genre
[0m11:32:32.404243 [debug] [Thread-1 (]: Began running node model.movie_warehouse.dim_movie
[0m11:32:32.404822 [info ] [Thread-1 (]: 3 of 6 START sql table model `gold_gold`.`dim_movie` ........................... [RUN]
[0m11:32:32.405233 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.movie_warehouse.dim_genre, now model.movie_warehouse.dim_movie)
[0m11:32:32.405513 [debug] [Thread-1 (]: Began compiling node model.movie_warehouse.dim_movie
[0m11:32:32.407808 [debug] [Thread-1 (]: Writing injected SQL for node "model.movie_warehouse.dim_movie"
[0m11:32:32.408991 [debug] [Thread-1 (]: Began executing node model.movie_warehouse.dim_movie
[0m11:32:32.411193 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_movie: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_movie"} */

            

    
        create table `gold_gold`.`dim_movie__dbt_backup`
        
  
        
  engine = MergeTree()
        order by (movie_id)
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            -- ...existing code...


WITH movie_src AS (
    SELECT
        TRIM(title) AS movie_title,
        imdb_id,
        release_date,
        runtime AS movie_runtime,
        original_language AS language
    FROM `bronze`.`tmdb_raw`
    WHERE title IS NOT NULL AND title != ''
)
SELECT
    cityHash64(movie_title) AS movie_id,
    any(imdb_id) AS imdb_id,
    movie_title,
    any(release_date) AS release_date,
    any(movie_runtime) AS movie_runtime,
    any(language) AS language
FROM movie_src
GROUP BY movie_title
ORDER BY movie_title
          )
        
        ...
[0m11:32:32.426420 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m11:32:32.428623 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_movie: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_movie"} */

    select name, type from system.columns where table = 'dim_movie__dbt_backup'
    
      and database = 'gold_gold'
    
    order by position
  ...
[0m11:32:32.433078 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:32:32.436714 [debug] [Thread-1 (]: Writing runtime sql for node "model.movie_warehouse.dim_movie"
[0m11:32:32.438014 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_movie: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_movie"} */

  
    
    
    
        
         


        insert into `gold_gold`.`dim_movie__dbt_backup`
        ("movie_id", "imdb_id", "movie_title", "release_date", "movie_runtime", "language")-- ...existing code...


WITH movie_src AS (
    SELECT
        TRIM(title) AS movie_title,
        imdb_id,
        release_date,
        runtime AS movie_runtime,
        original_language AS language
    FROM `bronze`.`tmdb_raw`
    WHERE title IS NOT NULL AND title != ''
)
SELECT
    cityHash64(movie_title) AS movie_id,
    any(imdb_id) AS imdb_id,
    movie_title,
    any(release_date) AS release_date,
    any(movie_runtime) AS movie_runtime,
    any(language) AS language
FROM movie_src
GROUP BY movie_title
ORDER BY movie_title
  ...
[0m11:32:32.809102 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.37 seconds
[0m11:32:32.810436 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_movie: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_movie"} */
EXCHANGE TABLES `gold_gold`.`dim_movie__dbt_backup` AND `gold_gold`.`dim_movie` 
  
  ...
[0m11:32:32.813841 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:32:32.817006 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_movie: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_movie"} */

    drop table if exists `gold_gold`.`dim_movie__dbt_backup` 
  ...
[0m11:32:32.819266 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_movie"} */

    drop table if exists `gold_gold`.`dim_movie__dbt_backup` 
  
[0m11:32:32.819585 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: macro drop_relation
[0m11:32:32.821689 [debug] [Thread-1 (]: Database Error in model dim_movie (models/gold/dim_movie.sql)
  :HTTPDriver for http://clickhouse-server:8123 returned response code 500)
   std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/8c9/8c9b38bb-5974-4368-97d1-712fe72b58b0/dim_movie__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/gold_gold.dim_movie__dbt_backup.d8a108fd-bda1-46fe-b8dd-f9c71728d819.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build))
  compiled code at target/run/movie_warehouse/models/gold/dim_movie.sql
[0m11:32:32.822063 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '322ccf04-866c-4042-9ae4-511405cb3dfe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff7cce8c90>]}
[0m11:32:32.822472 [error] [Thread-1 (]: 3 of 6 ERROR creating sql table model `gold_gold`.`dim_movie` .................. [[31mERROR[0m in 0.42s]
[0m11:32:32.822878 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.dim_movie
[0m11:32:32.823197 [debug] [Thread-1 (]: Began running node model.movie_warehouse.dim_production
[0m11:32:32.823601 [info ] [Thread-1 (]: 4 of 6 START sql table model `gold_gold`.`dim_production` ...................... [RUN]
[0m11:32:32.823882 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.movie_warehouse.dim_movie, now model.movie_warehouse.dim_production)
[0m11:32:32.824106 [debug] [Thread-1 (]: Began compiling node model.movie_warehouse.dim_production
[0m11:32:32.825941 [debug] [Thread-1 (]: Writing injected SQL for node "model.movie_warehouse.dim_production"
[0m11:32:32.826598 [debug] [Thread-1 (]: Began executing node model.movie_warehouse.dim_production
[0m11:32:32.829541 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_production: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_production"} */

            

    
        create table `gold_gold`.`dim_production__dbt_backup`
        
  
        
  engine = MergeTree()
        order by (production_id)
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

WITH first_production AS (
    SELECT
        imdb_id AS movie_id,
        trim(splitByChar(',', production_companies)[1]) AS production_name
    FROM `bronze`.`tmdb_raw`
    WHERE production_companies IS NOT NULL AND production_companies != ''
)

SELECT
    cityHash64(production_name) AS production_id,
    production_name,
    current_date() AS valid_from,
    CAST(NULL AS Nullable(Date)) AS valid_to,
    TRUE AS is_current
FROM (
    SELECT DISTINCT production_name
    FROM first_production
)
WHERE production_name IS NOT NULL
          )
        
        ...
[0m11:32:32.837256 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m11:32:32.839083 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_production: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_production"} */

    select name, type from system.columns where table = 'dim_production__dbt_backup'
    
      and database = 'gold_gold'
    
    order by position
  ...
[0m11:32:32.842129 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:32:32.844253 [debug] [Thread-1 (]: Writing runtime sql for node "model.movie_warehouse.dim_production"
[0m11:32:32.845053 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_production: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_production"} */

  
    
    
    
        
         


        insert into `gold_gold`.`dim_production__dbt_backup`
        ("production_id", "production_name", "valid_from", "valid_to", "is_current")

WITH first_production AS (
    SELECT
        imdb_id AS movie_id,
        trim(splitByChar(',', production_companies)[1]) AS production_name
    FROM `bronze`.`tmdb_raw`
    WHERE production_companies IS NOT NULL AND production_companies != ''
)

SELECT
    cityHash64(production_name) AS production_id,
    production_name,
    current_date() AS valid_from,
    CAST(NULL AS Nullable(Date)) AS valid_to,
    TRUE AS is_current
FROM (
    SELECT DISTINCT production_name
    FROM first_production
)
WHERE production_name IS NOT NULL
  ...
[0m11:32:32.852671 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m11:32:32.854014 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_production: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_production"} */
EXCHANGE TABLES `gold_gold`.`dim_production__dbt_backup` AND `gold_gold`.`dim_production` 
  
  ...
[0m11:32:32.857560 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:32:32.860277 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_production: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_production"} */

    drop table if exists `gold_gold`.`dim_production__dbt_backup` 
  ...
[0m11:32:32.862857 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_production"} */

    drop table if exists `gold_gold`.`dim_production__dbt_backup` 
  
[0m11:32:32.863369 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: macro drop_relation
[0m11:32:32.865680 [debug] [Thread-1 (]: Database Error in model dim_production (models/gold/dim_production.sql)
  :HTTPDriver for http://clickhouse-server:8123 returned response code 500)
   std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/8c9/8c9b38bb-5974-4368-97d1-712fe72b58b0/dim_production__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/gold_gold.dim_production__dbt_backup.b28380b5-87fc-4b0b-a6d9-cde92099be14.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build))
  compiled code at target/run/movie_warehouse/models/gold/dim_production.sql
[0m11:32:32.866197 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '322ccf04-866c-4042-9ae4-511405cb3dfe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff7e0a8850>]}
[0m11:32:32.867165 [error] [Thread-1 (]: 4 of 6 ERROR creating sql table model `gold_gold`.`dim_production` ............. [[31mERROR[0m in 0.04s]
[0m11:32:32.868498 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.dim_production
[0m11:32:32.869196 [debug] [Thread-1 (]: Began running node model.movie_warehouse.dim_release_date
[0m11:32:32.869872 [info ] [Thread-1 (]: 5 of 6 START sql table model `gold_gold`.`dim_release_date` .................... [RUN]
[0m11:32:32.870312 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.movie_warehouse.dim_production, now model.movie_warehouse.dim_release_date)
[0m11:32:32.870615 [debug] [Thread-1 (]: Began compiling node model.movie_warehouse.dim_release_date
[0m11:32:32.873585 [debug] [Thread-1 (]: Writing injected SQL for node "model.movie_warehouse.dim_release_date"
[0m11:32:32.874493 [debug] [Thread-1 (]: Began executing node model.movie_warehouse.dim_release_date
[0m11:32:32.877211 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_release_date: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_release_date"} */

            

    
        create table `gold_gold`.`dim_release_date__dbt_backup`
        
  
        
  engine = MergeTree()
        order by (date_id)
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

WITH distinct_dates AS (
    SELECT DISTINCT release_date
    FROM `bronze`.`tmdb_raw`
    WHERE release_date IS NOT NULL
)

SELECT
    cityHash64(release_date)                                    AS date_id,
    release_date                                                AS full_date,
    toYear(release_date)                                        AS year,
    toMonth(release_date)                                       AS month,
    toDayOfMonth(release_date)                                  AS day,
    toISOWeek(release_date)                                     AS week,
    formatDateTime(release_date, '%a')                          AS weekday,
    CASE
        WHEN toMonth(release_date) IN (12,1,2)  THEN 'Winter'
        WHEN toMonth(release_date) IN (3,4,5)   THEN 'Spring'
        WHEN toMonth(release_date) IN (6,7,8)   THEN 'Summer'
        WHEN toMonth(release_date) IN (9,10,11) THEN 'Autumn'
    END                                                         AS season,
    CASE
        WHEN formatDateTime(release_date, '%a') IN ('Saturday','Sunday') THEN 1
        ELSE 0
    END                                                         AS is_weekend,

    /* ---------- holiday tagging ---------- */
    CASE
        WHEN toMonth(release_date)=1  AND toDayOfMonth(release_date)=1  THEN 'New Years Day'
        WHEN toMonth(release_date)=2  AND toDayOfMonth(release_date)=14 THEN 'Valentines Day'
        WHEN toMonth(release_date)=3  AND toDayOfMonth(release_date)=17 THEN 'St. Patricks Day'
        WHEN toMonth(release_date)=4  AND toDayOfMonth(release_date)=1  THEN 'April Fools Day'
        WHEN toMonth(release_date)=4  AND toDayOfMonth(release_date)=22 THEN 'Earth Day'
        WHEN toMonth(release_date)=5  AND toDayOfMonth(release_date)=1  THEN 'May Day'
        WHEN toMonth(release_date)=5  AND toDayOfMonth(release_date)=5  THEN 'Cinco de Mayo'
        WHEN toMonth(release_date)=6  AND toDayOfMonth(release_date) BETWEEN 19 AND 26 THEN 'Midsummer'
        WHEN toMonth(release_date)=7  AND toDayOfMonth(release_date)=4  THEN 'Independence Day'
        WHEN toMonth(release_date)=9  AND toDayOfMonth(release_date) BETWEEN 1 AND 7 
             AND formatDateTime(release_date,'%a')='Monday'             THEN 'Labor Day (US)'
        WHEN toMonth(release_date)=10 AND toDayOfMonth(release_date)=31 THEN 'Halloween'
        WHEN toMonth(release_date)=11 AND formatDateTime(release_date,'%a')='Thursday'
             AND toISOWeek(release_date) >= 47                           THEN 'Thanksgiving'
        WHEN toMonth(release_date)=12 AND toDayOfMonth(release_date)=24 THEN 'Christmas Eve'
        WHEN toMonth(release_date)=12 AND toDayOfMonth(release_date)=25 THEN 'Christmas Day'
        WHEN toMonth(release_date)=12 AND toDayOfMonth(release_date)=31 THEN 'New Years Eve'
        ELSE NULL
    END                                                         AS holiday_name,
    IF(holiday_name IS NOT NULL, 1, 0)                          AS is_holiday,

    /* placeholders for later enhancement */
    CAST(NULL AS Nullable(Int32)) AS days_until_holiday,
    CAST(NULL AS Nullable(Int32)) AS days_after_holiday

FROM distinct_dates
ORDER BY release_date
          )
        
        ...
[0m11:32:32.898907 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m11:32:32.901075 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_release_date: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_release_date"} */

    select name, type from system.columns where table = 'dim_release_date__dbt_backup'
    
      and database = 'gold_gold'
    
    order by position
  ...
[0m11:32:32.905344 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:32:32.907438 [debug] [Thread-1 (]: Writing runtime sql for node "model.movie_warehouse.dim_release_date"
[0m11:32:32.908638 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_release_date: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_release_date"} */

  
    
    
    
        
         


        insert into `gold_gold`.`dim_release_date__dbt_backup`
        ("date_id", "full_date", "year", "month", "day", "week", "weekday", "season", "is_weekend", "holiday_name", "is_holiday", "days_until_holiday", "days_after_holiday")

WITH distinct_dates AS (
    SELECT DISTINCT release_date
    FROM `bronze`.`tmdb_raw`
    WHERE release_date IS NOT NULL
)

SELECT
    cityHash64(release_date)                                    AS date_id,
    release_date                                                AS full_date,
    toYear(release_date)                                        AS year,
    toMonth(release_date)                                       AS month,
    toDayOfMonth(release_date)                                  AS day,
    toISOWeek(release_date)                                     AS week,
    formatDateTime(release_date, '%a')                          AS weekday,
    CASE
        WHEN toMonth(release_date) IN (12,1,2)  THEN 'Winter'
        WHEN toMonth(release_date) IN (3,4,5)   THEN 'Spring'
        WHEN toMonth(release_date) IN (6,7,8)   THEN 'Summer'
        WHEN toMonth(release_date) IN (9,10,11) THEN 'Autumn'
    END                                                         AS season,
    CASE
        WHEN formatDateTime(release_date, '%a') IN ('Saturday','Sunday') THEN 1
        ELSE 0
    END                                                         AS is_weekend,

    /* ---------- holiday tagging ---------- */
    CASE
        WHEN toMonth(release_date)=1  AND toDayOfMonth(release_date)=1  THEN 'New Years Day'
        WHEN toMonth(release_date)=2  AND toDayOfMonth(release_date)=14 THEN 'Valentines Day'
        WHEN toMonth(release_date)=3  AND toDayOfMonth(release_date)=17 THEN 'St. Patricks Day'
        WHEN toMonth(release_date)=4  AND toDayOfMonth(release_date)=1  THEN 'April Fools Day'
        WHEN toMonth(release_date)=4  AND toDayOfMonth(release_date)=22 THEN 'Earth Day'
        WHEN toMonth(release_date)=5  AND toDayOfMonth(release_date)=1  THEN 'May Day'
        WHEN toMonth(release_date)=5  AND toDayOfMonth(release_date)=5  THEN 'Cinco de Mayo'
        WHEN toMonth(release_date)=6  AND toDayOfMonth(release_date) BETWEEN 19 AND 26 THEN 'Midsummer'
        WHEN toMonth(release_date)=7  AND toDayOfMonth(release_date)=4  THEN 'Independence Day'
        WHEN toMonth(release_date)=9  AND toDayOfMonth(release_date) BETWEEN 1 AND 7 
             AND formatDateTime(release_date,'%a')='Monday'             THEN 'Labor Day (US)'
        WHEN toMonth(release_date)=10 AND toDayOfMonth(release_date)=31 THEN 'Halloween'
        WHEN toMonth(release_date)=11 AND formatDateTime(release_date,'%a')='Thursday'
             AND toISOWeek(release_date) >= 47                           THEN 'Thanksgiving'
        WHEN toMonth(release_date)=12 AND toDayOfMonth(release_date)=24 THEN 'Christmas Eve'
        WHEN toMonth(release_date)=12 AND toDayOfMonth(release_date)=25 THEN 'Christmas Day'
        WHEN toMonth(release_date)=12 AND toDayOfMonth(release_date)=31 THEN 'New Years Eve'
        ELSE NULL
    END                                                         AS holiday_name,
    IF(holiday_name IS NOT NULL, 1, 0)                          AS is_holiday,

    /* placeholders for later enhancement */
    CAST(NULL AS Nullable(Int32)) AS days_until_holiday,
    CAST(NULL AS Nullable(Int32)) AS days_after_holiday

FROM distinct_dates
ORDER BY release_date
  ...
[0m11:32:32.953955 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.04 seconds
[0m11:32:32.955130 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_release_date: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_release_date"} */
EXCHANGE TABLES `gold_gold`.`dim_release_date__dbt_backup` AND `gold_gold`.`dim_release_date` 
  
  ...
[0m11:32:32.959540 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:32:32.961871 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_release_date: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_release_date"} */

    drop table if exists `gold_gold`.`dim_release_date__dbt_backup` 
  ...
[0m11:32:32.963629 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_release_date"} */

    drop table if exists `gold_gold`.`dim_release_date__dbt_backup` 
  
[0m11:32:32.963907 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: macro drop_relation
[0m11:32:32.966703 [debug] [Thread-1 (]: Database Error in model dim_release_date (models/gold/dim_release_date.sql)
  :HTTPDriver for http://clickhouse-server:8123 returned response code 500)
   std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/8c9/8c9b38bb-5974-4368-97d1-712fe72b58b0/dim_release_date__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/gold_gold.dim_release_date__dbt_backup.0d7e9615-6a75-4d8e-b5f5-6a6882af176c.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build))
  compiled code at target/run/movie_warehouse/models/gold/dim_release_date.sql
[0m11:32:32.967082 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '322ccf04-866c-4042-9ae4-511405cb3dfe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff365f6890>]}
[0m11:32:32.967518 [error] [Thread-1 (]: 5 of 6 ERROR creating sql table model `gold_gold`.`dim_release_date` ........... [[31mERROR[0m in 0.10s]
[0m11:32:32.967941 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.dim_release_date
[0m11:32:32.969103 [debug] [Thread-1 (]: Began running node model.movie_warehouse.fact_movie
[0m11:32:32.969375 [info ] [Thread-1 (]: 6 of 6 SKIP relation gold_gold.fact_movie ...................................... [[33mSKIP[0m]
[0m11:32:32.969692 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.fact_movie
[0m11:32:32.971365 [debug] [MainThread]: Connection 'master' was properly closed.
[0m11:32:32.971674 [debug] [MainThread]: Connection 'model.movie_warehouse.dim_release_date' was left open.
[0m11:32:32.971893 [debug] [MainThread]: On model.movie_warehouse.dim_release_date: Close
[0m11:32:32.972435 [info ] [MainThread]: 
[0m11:32:32.972682 [info ] [MainThread]: Finished running 6 table models in 0 hours 0 minutes and 5.34 seconds (5.34s).
[0m11:32:32.973403 [debug] [MainThread]: Command end result
[0m11:32:33.013794 [info ] [MainThread]: 
[0m11:32:33.014230 [info ] [MainThread]: [31mCompleted with 5 errors and 0 warnings:[0m
[0m11:32:33.014456 [info ] [MainThread]: 
[0m11:32:33.014772 [error] [MainThread]:   Database Error in model dim_director (models/gold/dim_director.sql)
  :HTTPDriver for http://clickhouse-server:8123 returned response code 500)
   std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/8c9/8c9b38bb-5974-4368-97d1-712fe72b58b0/dim_director__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/gold_gold.dim_director__dbt_backup.a673fee0-4fee-40ce-8a4a-13bd6f9423d1.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build))
  compiled code at target/run/movie_warehouse/models/gold/dim_director.sql
[0m11:32:33.015032 [info ] [MainThread]: 
[0m11:32:33.015293 [error] [MainThread]:   Database Error in model dim_genre (models/gold/dim_genre.sql)
  :HTTPDriver for http://clickhouse-server:8123 returned response code 500)
   std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/8c9/8c9b38bb-5974-4368-97d1-712fe72b58b0/dim_genre__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/gold_gold.dim_genre__dbt_backup.7bebc36c-fadf-4781-9f64-d627a049af58.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build))
  compiled code at target/run/movie_warehouse/models/gold/dim_genre.sql
[0m11:32:33.015498 [info ] [MainThread]: 
[0m11:32:33.015792 [error] [MainThread]:   Database Error in model dim_movie (models/gold/dim_movie.sql)
  :HTTPDriver for http://clickhouse-server:8123 returned response code 500)
   std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/8c9/8c9b38bb-5974-4368-97d1-712fe72b58b0/dim_movie__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/gold_gold.dim_movie__dbt_backup.d8a108fd-bda1-46fe-b8dd-f9c71728d819.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build))
  compiled code at target/run/movie_warehouse/models/gold/dim_movie.sql
[0m11:32:33.016046 [info ] [MainThread]: 
[0m11:32:33.016291 [error] [MainThread]:   Database Error in model dim_production (models/gold/dim_production.sql)
  :HTTPDriver for http://clickhouse-server:8123 returned response code 500)
   std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/8c9/8c9b38bb-5974-4368-97d1-712fe72b58b0/dim_production__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/gold_gold.dim_production__dbt_backup.b28380b5-87fc-4b0b-a6d9-cde92099be14.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build))
  compiled code at target/run/movie_warehouse/models/gold/dim_production.sql
[0m11:32:33.016510 [info ] [MainThread]: 
[0m11:32:33.016743 [error] [MainThread]:   Database Error in model dim_release_date (models/gold/dim_release_date.sql)
  :HTTPDriver for http://clickhouse-server:8123 returned response code 500)
   std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/8c9/8c9b38bb-5974-4368-97d1-712fe72b58b0/dim_release_date__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/gold_gold.dim_release_date__dbt_backup.0d7e9615-6a75-4d8e-b5f5-6a6882af176c.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build))
  compiled code at target/run/movie_warehouse/models/gold/dim_release_date.sql
[0m11:32:33.017011 [info ] [MainThread]: 
[0m11:32:33.017316 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=5 SKIP=1 TOTAL=6
[0m11:32:33.022692 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 6.4589376, "process_in_blocks": "112024", "process_kernel_time": 0.255057, "process_mem_max_rss": "189012", "process_out_blocks": "3464", "process_user_time": 2.595937}
[0m11:32:33.023508 [debug] [MainThread]: Command `dbt run` failed at 11:32:33.023430 after 6.46 seconds
[0m11:32:33.024008 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff7cc2bdd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff7cc2ba10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff7cc2bd90>]}
[0m11:32:33.024306 [debug] [MainThread]: Flushing usage events
[0m11:37:05.020630 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb8e62390>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb8e9f350>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb8e9ead0>]}


============================== 11:37:05.024434 | 483bace8-7f0d-4b0e-84a1-e03a3a27fc87 ==============================
[0m11:37:05.024434 [info ] [MainThread]: Running with dbt=1.8.9
[0m11:37:05.024807 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'fail_fast': 'False', 'log_path': '/opt/airflow/project_root/dbt/logs', 'profiles_dir': '/opt/airflow/project_root/dbt', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'invocation_command': 'dbt run --project-dir /opt/airflow/project_root/dbt --profiles-dir /opt/airflow/project_root/dbt --select gold', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m11:37:05.133056 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '483bace8-7f0d-4b0e-84a1-e03a3a27fc87', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb9877450>]}
[0m11:37:05.153888 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '483bace8-7f0d-4b0e-84a1-e03a3a27fc87', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb988f910>]}
[0m11:37:05.154515 [info ] [MainThread]: Registered adapter: clickhouse=1.8.9
[0m11:37:05.189625 [debug] [MainThread]: checksum: 132857a23e9d07220246854f7763165174ce9b737cfc7867629ace4294e520b1, vars: {}, profile: , target: , version: 1.8.9
[0m11:37:05.246610 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m11:37:05.247595 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m11:37:05.251684 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.movie_warehouse.bronze
[0m11:37:05.273264 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '483bace8-7f0d-4b0e-84a1-e03a3a27fc87', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb8e05b90>]}
[0m11:37:05.364622 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '483bace8-7f0d-4b0e-84a1-e03a3a27fc87', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb8bbd450>]}
[0m11:37:05.365223 [info ] [MainThread]: Found 6 models, 12 data tests, 4 sources, 476 macros
[0m11:37:05.365552 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '483bace8-7f0d-4b0e-84a1-e03a3a27fc87', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb8e12c90>]}
[0m11:37:05.367108 [info ] [MainThread]: 
[0m11:37:05.367803 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m11:37:05.371726 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m11:37:05.380776 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:37:05.780851 [info ] [ThreadPool]: dbt_clickhouse adapter: Unexpected server exception dropping table
[0m11:37:05.781611 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m11:37:05.784152 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:37:05.804597 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__gold_gold)
[0m11:37:05.808026 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__gold_gold: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "connection_name": "list__gold_gold"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'gold_gold'
      

  ...
[0m11:37:05.832160 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m11:37:05.835588 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '483bace8-7f0d-4b0e-84a1-e03a3a27fc87', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff9a2c50d0>]}
[0m11:37:05.836437 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m11:37:05.836868 [info ] [MainThread]: 
[0m11:37:05.844186 [debug] [Thread-1 (]: Began running node model.movie_warehouse.dim_director
[0m11:37:05.844719 [info ] [Thread-1 (]: 1 of 6 START sql table model `gold_gold`.`dim_director` ........................ [RUN]
[0m11:37:05.845066 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list__gold_gold, now model.movie_warehouse.dim_director)
[0m11:37:05.845311 [debug] [Thread-1 (]: Began compiling node model.movie_warehouse.dim_director
[0m11:37:05.849617 [debug] [Thread-1 (]: Writing injected SQL for node "model.movie_warehouse.dim_director"
[0m11:37:05.850735 [debug] [Thread-1 (]: Began executing node model.movie_warehouse.dim_director
[0m11:37:05.875435 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_director: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_director"} */

            

    
        create table `gold_gold`.`dim_director__dbt_backup`
        
  
        
  engine = MergeTree()
        order by (dir_id)
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

WITH first_dir AS (
    SELECT
        tconst,
        TRIM(splitByChar(',', directors)[1]) AS director_id
    FROM `bronze`.`imdb_title_crew_raw`
    WHERE directors IS NOT NULL AND directors != ''
),
deduped AS (
    SELECT DISTINCT director_id
    FROM first_dir
),
joined AS (
    SELECT
        d.director_id AS dir_id,
        n.primaryName AS dir_name
    FROM deduped d
    LEFT JOIN `bronze`.`imdb_name_basics_raw` n
        ON d.director_id = n.nconst
)
SELECT
    cityHash64(dir_id) AS imdb_dir_name_id,  -- Use hash instead of row_number
    dir_id,
    dir_name,
    today() AS valid_from,
    CAST(NULL AS Nullable(Date)) AS valid_to,
    1 AS is_current  -- Use 1/0 instead of TRUE/FALSE
FROM joined
WHERE dir_id IS NOT NULL
ORDER BY dir_id
          )
        
        ...
[0m11:37:05.891773 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m11:37:05.901028 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_director: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_director"} */

    select name, type from system.columns where table = 'dim_director__dbt_backup'
    
      and database = 'gold_gold'
    
    order by position
  ...
[0m11:37:05.904588 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:37:05.906420 [debug] [Thread-1 (]: Writing runtime sql for node "model.movie_warehouse.dim_director"
[0m11:37:05.907267 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_director: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_director"} */

  
    
    
    
        
         


        insert into `gold_gold`.`dim_director__dbt_backup`
        ("imdb_dir_name_id", "dir_id", "dir_name", "valid_from", "valid_to", "is_current")

WITH first_dir AS (
    SELECT
        tconst,
        TRIM(splitByChar(',', directors)[1]) AS director_id
    FROM `bronze`.`imdb_title_crew_raw`
    WHERE directors IS NOT NULL AND directors != ''
),
deduped AS (
    SELECT DISTINCT director_id
    FROM first_dir
),
joined AS (
    SELECT
        d.director_id AS dir_id,
        n.primaryName AS dir_name
    FROM deduped d
    LEFT JOIN `bronze`.`imdb_name_basics_raw` n
        ON d.director_id = n.nconst
)
SELECT
    cityHash64(dir_id) AS imdb_dir_name_id,  -- Use hash instead of row_number
    dir_id,
    dir_name,
    today() AS valid_from,
    CAST(NULL AS Nullable(Date)) AS valid_to,
    1 AS is_current  -- Use 1/0 instead of TRUE/FALSE
FROM joined
WHERE dir_id IS NOT NULL
ORDER BY dir_id
  ...
[0m11:37:10.035193 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 4.11 seconds
[0m11:37:10.083412 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_director: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_director"} */
EXCHANGE TABLES `gold_gold`.`dim_director__dbt_backup` AND `gold_gold`.`dim_director` 
  
  ...
[0m11:37:10.120744 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.03 seconds
[0m11:37:10.166548 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_director: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_director"} */

    drop table if exists `gold_gold`.`dim_director__dbt_backup` 
  ...
[0m11:37:10.183259 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_director"} */

    drop table if exists `gold_gold`.`dim_director__dbt_backup` 
  
[0m11:37:10.184115 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: macro drop_relation
[0m11:37:10.202367 [debug] [Thread-1 (]: Database Error in model dim_director (models/gold/dim_director.sql)
  :HTTPDriver for http://clickhouse-server:8123 returned response code 500)
   std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/8c9/8c9b38bb-5974-4368-97d1-712fe72b58b0/dim_director__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/gold_gold.dim_director__dbt_backup.2c99c2ef-a08c-480a-8b73-f82e307048ee.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build))
  compiled code at target/run/movie_warehouse/models/gold/dim_director.sql
[0m11:37:10.216005 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '483bace8-7f0d-4b0e-84a1-e03a3a27fc87', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff9ad36c50>]}
[0m11:37:10.222862 [error] [Thread-1 (]: 1 of 6 ERROR creating sql table model `gold_gold`.`dim_director` ............... [[31mERROR[0m in 4.36s]
[0m11:37:10.225146 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.dim_director
[0m11:37:10.227859 [debug] [Thread-1 (]: Began running node model.movie_warehouse.dim_genre
[0m11:37:10.232574 [info ] [Thread-1 (]: 2 of 6 START sql table model `gold_gold`.`dim_genre` ........................... [RUN]
[0m11:37:10.233996 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.movie_warehouse.dim_director, now model.movie_warehouse.dim_genre)
[0m11:37:10.235124 [debug] [Thread-1 (]: Began compiling node model.movie_warehouse.dim_genre
[0m11:37:10.241673 [debug] [Thread-1 (]: Writing injected SQL for node "model.movie_warehouse.dim_genre"
[0m11:37:10.247362 [debug] [Thread-1 (]: Began executing node model.movie_warehouse.dim_genre
[0m11:37:10.257108 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_genre: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_genre"} */

            

    
        create table `gold_gold`.`dim_genre__dbt_backup`
        
  
        
  engine = MergeTree()
        order by (genre_id)
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

WITH parsed_genres AS (
    SELECT
        TRIM(splitByChar(',', genres)[1]) AS first_genre
    FROM `bronze`.`tmdb_raw`
    WHERE genres IS NOT NULL AND genres != ''
)
SELECT
    cityHash64(first_genre) AS genre_id,
    first_genre AS genre_name
FROM parsed_genres
GROUP BY first_genre
ORDER BY first_genre
          )
        
        ...
[0m11:37:10.343337 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.08 seconds
[0m11:37:10.348146 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_genre: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_genre"} */

    select name, type from system.columns where table = 'dim_genre__dbt_backup'
    
      and database = 'gold_gold'
    
    order by position
  ...
[0m11:37:10.392520 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.04 seconds
[0m11:37:10.405857 [debug] [Thread-1 (]: Writing runtime sql for node "model.movie_warehouse.dim_genre"
[0m11:37:10.409461 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_genre: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_genre"} */

  
    
    
    
        
         


        insert into `gold_gold`.`dim_genre__dbt_backup`
        ("genre_id", "genre_name")

WITH parsed_genres AS (
    SELECT
        TRIM(splitByChar(',', genres)[1]) AS first_genre
    FROM `bronze`.`tmdb_raw`
    WHERE genres IS NOT NULL AND genres != ''
)
SELECT
    cityHash64(first_genre) AS genre_id,
    first_genre AS genre_name
FROM parsed_genres
GROUP BY first_genre
ORDER BY first_genre
  ...
[0m11:37:10.496960 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.09 seconds
[0m11:37:10.498277 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_genre: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_genre"} */
EXCHANGE TABLES `gold_gold`.`dim_genre__dbt_backup` AND `gold_gold`.`dim_genre` 
  
  ...
[0m11:37:10.503442 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:37:10.506307 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_genre: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_genre"} */

    drop table if exists `gold_gold`.`dim_genre__dbt_backup` 
  ...
[0m11:37:10.509337 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_genre"} */

    drop table if exists `gold_gold`.`dim_genre__dbt_backup` 
  
[0m11:37:10.509858 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: macro drop_relation
[0m11:37:10.512896 [debug] [Thread-1 (]: Database Error in model dim_genre (models/gold/dim_genre.sql)
  :HTTPDriver for http://clickhouse-server:8123 returned response code 500)
   std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/8c9/8c9b38bb-5974-4368-97d1-712fe72b58b0/dim_genre__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/gold_gold.dim_genre__dbt_backup.2487f1ca-ea22-4281-94ae-ca07070efa81.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build))
  compiled code at target/run/movie_warehouse/models/gold/dim_genre.sql
[0m11:37:10.513824 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '483bace8-7f0d-4b0e-84a1-e03a3a27fc87', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff99a8fa50>]}
[0m11:37:10.514653 [error] [Thread-1 (]: 2 of 6 ERROR creating sql table model `gold_gold`.`dim_genre` .................. [[31mERROR[0m in 0.28s]
[0m11:37:10.515625 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.dim_genre
[0m11:37:10.516005 [debug] [Thread-1 (]: Began running node model.movie_warehouse.dim_movie
[0m11:37:10.516626 [info ] [Thread-1 (]: 3 of 6 START sql table model `gold_gold`.`dim_movie` ........................... [RUN]
[0m11:37:10.517096 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.movie_warehouse.dim_genre, now model.movie_warehouse.dim_movie)
[0m11:37:10.517446 [debug] [Thread-1 (]: Began compiling node model.movie_warehouse.dim_movie
[0m11:37:10.520176 [debug] [Thread-1 (]: Writing injected SQL for node "model.movie_warehouse.dim_movie"
[0m11:37:10.521284 [debug] [Thread-1 (]: Began executing node model.movie_warehouse.dim_movie
[0m11:37:10.523787 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_movie: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_movie"} */

            

    
        create table `gold_gold`.`dim_movie__dbt_backup`
        
  
        
  engine = MergeTree()
        order by (movie_id)
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            -- ...existing code...


WITH movie_src AS (
    SELECT
        TRIM(title) AS movie_title,
        imdb_id,
        release_date,
        runtime AS movie_runtime,
        original_language AS language
    FROM `bronze`.`tmdb_raw`
    WHERE title IS NOT NULL AND title != ''
)
SELECT
    cityHash64(movie_title) AS movie_id,
    any(imdb_id) AS imdb_id,
    movie_title,
    any(release_date) AS release_date,
    any(movie_runtime) AS movie_runtime,
    any(language) AS language
FROM movie_src
GROUP BY movie_title
ORDER BY movie_title
          )
        
        ...
[0m11:37:10.538614 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m11:37:10.540622 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_movie: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_movie"} */

    select name, type from system.columns where table = 'dim_movie__dbt_backup'
    
      and database = 'gold_gold'
    
    order by position
  ...
[0m11:37:10.545601 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:37:10.547670 [debug] [Thread-1 (]: Writing runtime sql for node "model.movie_warehouse.dim_movie"
[0m11:37:10.548529 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_movie: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_movie"} */

  
    
    
    
        
         


        insert into `gold_gold`.`dim_movie__dbt_backup`
        ("movie_id", "imdb_id", "movie_title", "release_date", "movie_runtime", "language")-- ...existing code...


WITH movie_src AS (
    SELECT
        TRIM(title) AS movie_title,
        imdb_id,
        release_date,
        runtime AS movie_runtime,
        original_language AS language
    FROM `bronze`.`tmdb_raw`
    WHERE title IS NOT NULL AND title != ''
)
SELECT
    cityHash64(movie_title) AS movie_id,
    any(imdb_id) AS imdb_id,
    movie_title,
    any(release_date) AS release_date,
    any(movie_runtime) AS movie_runtime,
    any(language) AS language
FROM movie_src
GROUP BY movie_title
ORDER BY movie_title
  ...
[0m11:37:11.115138 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.57 seconds
[0m11:37:11.116457 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_movie: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_movie"} */
EXCHANGE TABLES `gold_gold`.`dim_movie__dbt_backup` AND `gold_gold`.`dim_movie` 
  
  ...
[0m11:37:11.120657 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:37:11.123239 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_movie: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_movie"} */

    drop table if exists `gold_gold`.`dim_movie__dbt_backup` 
  ...
[0m11:37:11.125166 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_movie"} */

    drop table if exists `gold_gold`.`dim_movie__dbt_backup` 
  
[0m11:37:11.125461 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: macro drop_relation
[0m11:37:11.128065 [debug] [Thread-1 (]: Database Error in model dim_movie (models/gold/dim_movie.sql)
  :HTTPDriver for http://clickhouse-server:8123 returned response code 500)
   std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/8c9/8c9b38bb-5974-4368-97d1-712fe72b58b0/dim_movie__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/gold_gold.dim_movie__dbt_backup.1916288c-7695-4a93-8987-f314a281fa5f.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build))
  compiled code at target/run/movie_warehouse/models/gold/dim_movie.sql
[0m11:37:11.128464 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '483bace8-7f0d-4b0e-84a1-e03a3a27fc87', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff995f83d0>]}
[0m11:37:11.128887 [error] [Thread-1 (]: 3 of 6 ERROR creating sql table model `gold_gold`.`dim_movie` .................. [[31mERROR[0m in 0.61s]
[0m11:37:11.129383 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.dim_movie
[0m11:37:11.130011 [debug] [Thread-1 (]: Began running node model.movie_warehouse.dim_production
[0m11:37:11.130407 [info ] [Thread-1 (]: 4 of 6 START sql table model `gold_gold`.`dim_production` ...................... [RUN]
[0m11:37:11.131033 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.movie_warehouse.dim_movie, now model.movie_warehouse.dim_production)
[0m11:37:11.131516 [debug] [Thread-1 (]: Began compiling node model.movie_warehouse.dim_production
[0m11:37:11.134172 [debug] [Thread-1 (]: Writing injected SQL for node "model.movie_warehouse.dim_production"
[0m11:37:11.134876 [debug] [Thread-1 (]: Began executing node model.movie_warehouse.dim_production
[0m11:37:11.136975 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_production: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_production"} */

            

    
        create table `gold_gold`.`dim_production__dbt_backup`
        
  
        
  engine = MergeTree()
        order by (production_id)
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

WITH first_production AS (
    SELECT
        imdb_id AS movie_id,
        trim(splitByChar(',', production_companies)[1]) AS production_name
    FROM `bronze`.`tmdb_raw`
    WHERE production_companies IS NOT NULL AND production_companies != ''
)

SELECT
    cityHash64(production_name) AS production_id,
    production_name,
    current_date() AS valid_from,
    CAST(NULL AS Nullable(Date)) AS valid_to,
    TRUE AS is_current
FROM (
    SELECT DISTINCT production_name
    FROM first_production
)
WHERE production_name IS NOT NULL
          )
        
        ...
[0m11:37:11.149060 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m11:37:11.151778 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_production: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_production"} */

    select name, type from system.columns where table = 'dim_production__dbt_backup'
    
      and database = 'gold_gold'
    
    order by position
  ...
[0m11:37:11.156103 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:37:11.159560 [debug] [Thread-1 (]: Writing runtime sql for node "model.movie_warehouse.dim_production"
[0m11:37:11.160713 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_production: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_production"} */

  
    
    
    
        
         


        insert into `gold_gold`.`dim_production__dbt_backup`
        ("production_id", "production_name", "valid_from", "valid_to", "is_current")

WITH first_production AS (
    SELECT
        imdb_id AS movie_id,
        trim(splitByChar(',', production_companies)[1]) AS production_name
    FROM `bronze`.`tmdb_raw`
    WHERE production_companies IS NOT NULL AND production_companies != ''
)

SELECT
    cityHash64(production_name) AS production_id,
    production_name,
    current_date() AS valid_from,
    CAST(NULL AS Nullable(Date)) AS valid_to,
    TRUE AS is_current
FROM (
    SELECT DISTINCT production_name
    FROM first_production
)
WHERE production_name IS NOT NULL
  ...
[0m11:37:11.172368 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m11:37:11.173853 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_production: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_production"} */
EXCHANGE TABLES `gold_gold`.`dim_production__dbt_backup` AND `gold_gold`.`dim_production` 
  
  ...
[0m11:37:11.178509 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:37:11.318498 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_production: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_production"} */

    drop table if exists `gold_gold`.`dim_production__dbt_backup` 
  ...
[0m11:37:11.321773 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_production"} */

    drop table if exists `gold_gold`.`dim_production__dbt_backup` 
  
[0m11:37:11.322112 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: macro drop_relation
[0m11:37:11.324068 [debug] [Thread-1 (]: Database Error in model dim_production (models/gold/dim_production.sql)
  :HTTPDriver for http://clickhouse-server:8123 returned response code 500)
   std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/8c9/8c9b38bb-5974-4368-97d1-712fe72b58b0/dim_production__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/gold_gold.dim_production__dbt_backup.cb69e4e8-058b-48e7-b13a-77549ddf5902.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build))
  compiled code at target/run/movie_warehouse/models/gold/dim_production.sql
[0m11:37:11.324387 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '483bace8-7f0d-4b0e-84a1-e03a3a27fc87', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb9385b90>]}
[0m11:37:11.324767 [error] [Thread-1 (]: 4 of 6 ERROR creating sql table model `gold_gold`.`dim_production` ............. [[31mERROR[0m in 0.19s]
[0m11:37:11.325149 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.dim_production
[0m11:37:11.325469 [debug] [Thread-1 (]: Began running node model.movie_warehouse.dim_release_date
[0m11:37:11.325833 [info ] [Thread-1 (]: 5 of 6 START sql table model `gold_gold`.`dim_release_date` .................... [RUN]
[0m11:37:11.326116 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.movie_warehouse.dim_production, now model.movie_warehouse.dim_release_date)
[0m11:37:11.326351 [debug] [Thread-1 (]: Began compiling node model.movie_warehouse.dim_release_date
[0m11:37:11.328266 [debug] [Thread-1 (]: Writing injected SQL for node "model.movie_warehouse.dim_release_date"
[0m11:37:11.328898 [debug] [Thread-1 (]: Began executing node model.movie_warehouse.dim_release_date
[0m11:37:11.330664 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_release_date: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_release_date"} */

            

    
        create table `gold_gold`.`dim_release_date__dbt_backup`
        
  
        
  engine = MergeTree()
        order by (date_id)
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

WITH distinct_dates AS (
    SELECT DISTINCT release_date
    FROM `bronze`.`tmdb_raw`
    WHERE release_date IS NOT NULL
)

SELECT
    cityHash64(release_date)                                    AS date_id,
    release_date                                                AS full_date,
    toYear(release_date)                                        AS year,
    toMonth(release_date)                                       AS month,
    toDayOfMonth(release_date)                                  AS day,
    toISOWeek(release_date)                                     AS week,
    formatDateTime(release_date, '%a')                          AS weekday,
    CASE
        WHEN toMonth(release_date) IN (12,1,2)  THEN 'Winter'
        WHEN toMonth(release_date) IN (3,4,5)   THEN 'Spring'
        WHEN toMonth(release_date) IN (6,7,8)   THEN 'Summer'
        WHEN toMonth(release_date) IN (9,10,11) THEN 'Autumn'
    END                                                         AS season,
    CASE
        WHEN formatDateTime(release_date, '%a') IN ('Saturday','Sunday') THEN 1
        ELSE 0
    END                                                         AS is_weekend,

    /* ---------- holiday tagging ---------- */
    CASE
        WHEN toMonth(release_date)=1  AND toDayOfMonth(release_date)=1  THEN 'New Years Day'
        WHEN toMonth(release_date)=2  AND toDayOfMonth(release_date)=14 THEN 'Valentines Day'
        WHEN toMonth(release_date)=3  AND toDayOfMonth(release_date)=17 THEN 'St. Patricks Day'
        WHEN toMonth(release_date)=4  AND toDayOfMonth(release_date)=1  THEN 'April Fools Day'
        WHEN toMonth(release_date)=4  AND toDayOfMonth(release_date)=22 THEN 'Earth Day'
        WHEN toMonth(release_date)=5  AND toDayOfMonth(release_date)=1  THEN 'May Day'
        WHEN toMonth(release_date)=5  AND toDayOfMonth(release_date)=5  THEN 'Cinco de Mayo'
        WHEN toMonth(release_date)=6  AND toDayOfMonth(release_date) BETWEEN 19 AND 26 THEN 'Midsummer'
        WHEN toMonth(release_date)=7  AND toDayOfMonth(release_date)=4  THEN 'Independence Day'
        WHEN toMonth(release_date)=9  AND toDayOfMonth(release_date) BETWEEN 1 AND 7 
             AND formatDateTime(release_date,'%a')='Monday'             THEN 'Labor Day (US)'
        WHEN toMonth(release_date)=10 AND toDayOfMonth(release_date)=31 THEN 'Halloween'
        WHEN toMonth(release_date)=11 AND formatDateTime(release_date,'%a')='Thursday'
             AND toISOWeek(release_date) >= 47                           THEN 'Thanksgiving'
        WHEN toMonth(release_date)=12 AND toDayOfMonth(release_date)=24 THEN 'Christmas Eve'
        WHEN toMonth(release_date)=12 AND toDayOfMonth(release_date)=25 THEN 'Christmas Day'
        WHEN toMonth(release_date)=12 AND toDayOfMonth(release_date)=31 THEN 'New Years Eve'
        ELSE NULL
    END                                                         AS holiday_name,
    IF(holiday_name IS NOT NULL, 1, 0)                          AS is_holiday,

    /* placeholders for later enhancement */
    CAST(NULL AS Nullable(Int32)) AS days_until_holiday,
    CAST(NULL AS Nullable(Int32)) AS days_after_holiday

FROM distinct_dates
ORDER BY release_date
          )
        
        ...
[0m11:37:11.347326 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m11:37:11.350123 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_release_date: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_release_date"} */

    select name, type from system.columns where table = 'dim_release_date__dbt_backup'
    
      and database = 'gold_gold'
    
    order by position
  ...
[0m11:37:11.353351 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:37:11.355710 [debug] [Thread-1 (]: Writing runtime sql for node "model.movie_warehouse.dim_release_date"
[0m11:37:11.356538 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_release_date: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_release_date"} */

  
    
    
    
        
         


        insert into `gold_gold`.`dim_release_date__dbt_backup`
        ("date_id", "full_date", "year", "month", "day", "week", "weekday", "season", "is_weekend", "holiday_name", "is_holiday", "days_until_holiday", "days_after_holiday")

WITH distinct_dates AS (
    SELECT DISTINCT release_date
    FROM `bronze`.`tmdb_raw`
    WHERE release_date IS NOT NULL
)

SELECT
    cityHash64(release_date)                                    AS date_id,
    release_date                                                AS full_date,
    toYear(release_date)                                        AS year,
    toMonth(release_date)                                       AS month,
    toDayOfMonth(release_date)                                  AS day,
    toISOWeek(release_date)                                     AS week,
    formatDateTime(release_date, '%a')                          AS weekday,
    CASE
        WHEN toMonth(release_date) IN (12,1,2)  THEN 'Winter'
        WHEN toMonth(release_date) IN (3,4,5)   THEN 'Spring'
        WHEN toMonth(release_date) IN (6,7,8)   THEN 'Summer'
        WHEN toMonth(release_date) IN (9,10,11) THEN 'Autumn'
    END                                                         AS season,
    CASE
        WHEN formatDateTime(release_date, '%a') IN ('Saturday','Sunday') THEN 1
        ELSE 0
    END                                                         AS is_weekend,

    /* ---------- holiday tagging ---------- */
    CASE
        WHEN toMonth(release_date)=1  AND toDayOfMonth(release_date)=1  THEN 'New Years Day'
        WHEN toMonth(release_date)=2  AND toDayOfMonth(release_date)=14 THEN 'Valentines Day'
        WHEN toMonth(release_date)=3  AND toDayOfMonth(release_date)=17 THEN 'St. Patricks Day'
        WHEN toMonth(release_date)=4  AND toDayOfMonth(release_date)=1  THEN 'April Fools Day'
        WHEN toMonth(release_date)=4  AND toDayOfMonth(release_date)=22 THEN 'Earth Day'
        WHEN toMonth(release_date)=5  AND toDayOfMonth(release_date)=1  THEN 'May Day'
        WHEN toMonth(release_date)=5  AND toDayOfMonth(release_date)=5  THEN 'Cinco de Mayo'
        WHEN toMonth(release_date)=6  AND toDayOfMonth(release_date) BETWEEN 19 AND 26 THEN 'Midsummer'
        WHEN toMonth(release_date)=7  AND toDayOfMonth(release_date)=4  THEN 'Independence Day'
        WHEN toMonth(release_date)=9  AND toDayOfMonth(release_date) BETWEEN 1 AND 7 
             AND formatDateTime(release_date,'%a')='Monday'             THEN 'Labor Day (US)'
        WHEN toMonth(release_date)=10 AND toDayOfMonth(release_date)=31 THEN 'Halloween'
        WHEN toMonth(release_date)=11 AND formatDateTime(release_date,'%a')='Thursday'
             AND toISOWeek(release_date) >= 47                           THEN 'Thanksgiving'
        WHEN toMonth(release_date)=12 AND toDayOfMonth(release_date)=24 THEN 'Christmas Eve'
        WHEN toMonth(release_date)=12 AND toDayOfMonth(release_date)=25 THEN 'Christmas Day'
        WHEN toMonth(release_date)=12 AND toDayOfMonth(release_date)=31 THEN 'New Years Eve'
        ELSE NULL
    END                                                         AS holiday_name,
    IF(holiday_name IS NOT NULL, 1, 0)                          AS is_holiday,

    /* placeholders for later enhancement */
    CAST(NULL AS Nullable(Int32)) AS days_until_holiday,
    CAST(NULL AS Nullable(Int32)) AS days_after_holiday

FROM distinct_dates
ORDER BY release_date
  ...
[0m11:37:11.392889 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.04 seconds
[0m11:37:11.394581 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_release_date: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_release_date"} */
EXCHANGE TABLES `gold_gold`.`dim_release_date__dbt_backup` AND `gold_gold`.`dim_release_date` 
  
  ...
[0m11:37:11.398107 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:37:11.402208 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_release_date: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_release_date"} */

    drop table if exists `gold_gold`.`dim_release_date__dbt_backup` 
  ...
[0m11:37:11.404443 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_release_date"} */

    drop table if exists `gold_gold`.`dim_release_date__dbt_backup` 
  
[0m11:37:11.404766 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: macro drop_relation
[0m11:37:11.407002 [debug] [Thread-1 (]: Database Error in model dim_release_date (models/gold/dim_release_date.sql)
  :HTTPDriver for http://clickhouse-server:8123 returned response code 500)
   std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/8c9/8c9b38bb-5974-4368-97d1-712fe72b58b0/dim_release_date__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/gold_gold.dim_release_date__dbt_backup.f2636bd2-27ea-40bb-be87-ff663458e441.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build))
  compiled code at target/run/movie_warehouse/models/gold/dim_release_date.sql
[0m11:37:11.407406 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '483bace8-7f0d-4b0e-84a1-e03a3a27fc87', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff997223d0>]}
[0m11:37:11.407897 [error] [Thread-1 (]: 5 of 6 ERROR creating sql table model `gold_gold`.`dim_release_date` ........... [[31mERROR[0m in 0.08s]
[0m11:37:11.408469 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.dim_release_date
[0m11:37:11.409767 [debug] [Thread-1 (]: Began running node model.movie_warehouse.fact_movie
[0m11:37:11.410014 [info ] [Thread-1 (]: 6 of 6 SKIP relation gold_gold.fact_movie ...................................... [[33mSKIP[0m]
[0m11:37:11.410261 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.fact_movie
[0m11:37:11.411268 [debug] [MainThread]: Connection 'master' was properly closed.
[0m11:37:11.411661 [debug] [MainThread]: Connection 'model.movie_warehouse.dim_release_date' was left open.
[0m11:37:11.412051 [debug] [MainThread]: On model.movie_warehouse.dim_release_date: Close
[0m11:37:11.412752 [info ] [MainThread]: 
[0m11:37:11.413082 [info ] [MainThread]: Finished running 6 table models in 0 hours 0 minutes and 6.04 seconds (6.04s).
[0m11:37:11.414069 [debug] [MainThread]: Command end result
[0m11:37:11.442022 [info ] [MainThread]: 
[0m11:37:11.442455 [info ] [MainThread]: [31mCompleted with 5 errors and 0 warnings:[0m
[0m11:37:11.442734 [info ] [MainThread]: 
[0m11:37:11.443043 [error] [MainThread]:   Database Error in model dim_director (models/gold/dim_director.sql)
  :HTTPDriver for http://clickhouse-server:8123 returned response code 500)
   std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/8c9/8c9b38bb-5974-4368-97d1-712fe72b58b0/dim_director__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/gold_gold.dim_director__dbt_backup.2c99c2ef-a08c-480a-8b73-f82e307048ee.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build))
  compiled code at target/run/movie_warehouse/models/gold/dim_director.sql
[0m11:37:11.443289 [info ] [MainThread]: 
[0m11:37:11.443568 [error] [MainThread]:   Database Error in model dim_genre (models/gold/dim_genre.sql)
  :HTTPDriver for http://clickhouse-server:8123 returned response code 500)
   std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/8c9/8c9b38bb-5974-4368-97d1-712fe72b58b0/dim_genre__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/gold_gold.dim_genre__dbt_backup.2487f1ca-ea22-4281-94ae-ca07070efa81.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build))
  compiled code at target/run/movie_warehouse/models/gold/dim_genre.sql
[0m11:37:11.443809 [info ] [MainThread]: 
[0m11:37:11.444070 [error] [MainThread]:   Database Error in model dim_movie (models/gold/dim_movie.sql)
  :HTTPDriver for http://clickhouse-server:8123 returned response code 500)
   std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/8c9/8c9b38bb-5974-4368-97d1-712fe72b58b0/dim_movie__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/gold_gold.dim_movie__dbt_backup.1916288c-7695-4a93-8987-f314a281fa5f.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build))
  compiled code at target/run/movie_warehouse/models/gold/dim_movie.sql
[0m11:37:11.444341 [info ] [MainThread]: 
[0m11:37:11.444625 [error] [MainThread]:   Database Error in model dim_production (models/gold/dim_production.sql)
  :HTTPDriver for http://clickhouse-server:8123 returned response code 500)
   std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/8c9/8c9b38bb-5974-4368-97d1-712fe72b58b0/dim_production__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/gold_gold.dim_production__dbt_backup.cb69e4e8-058b-48e7-b13a-77549ddf5902.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build))
  compiled code at target/run/movie_warehouse/models/gold/dim_production.sql
[0m11:37:11.444862 [info ] [MainThread]: 
[0m11:37:11.445123 [error] [MainThread]:   Database Error in model dim_release_date (models/gold/dim_release_date.sql)
  :HTTPDriver for http://clickhouse-server:8123 returned response code 500)
   std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/8c9/8c9b38bb-5974-4368-97d1-712fe72b58b0/dim_release_date__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/gold_gold.dim_release_date__dbt_backup.f2636bd2-27ea-40bb-be87-ff663458e441.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build))
  compiled code at target/run/movie_warehouse/models/gold/dim_release_date.sql
[0m11:37:11.445360 [info ] [MainThread]: 
[0m11:37:11.445665 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=5 SKIP=1 TOTAL=6
[0m11:37:11.448030 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 6.4506245, "process_in_blocks": "117736", "process_kernel_time": 0.289609, "process_mem_max_rss": "188272", "process_out_blocks": "3851", "process_user_time": 2.148782}
[0m11:37:11.448707 [debug] [MainThread]: Command `dbt run` failed at 11:37:11.448617 after 6.45 seconds
[0m11:37:11.449124 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb8ebe990>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb8ebca50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb92f3710>]}
[0m11:37:11.449480 [debug] [MainThread]: Flushing usage events
[0m11:46:09.942499 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa942d810>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffaa834790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa945f890>]}


============================== 11:46:09.946525 | 04144f5e-2d56-4251-997c-9b2c95151325 ==============================
[0m11:46:09.946525 [info ] [MainThread]: Running with dbt=1.8.9
[0m11:46:09.946862 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'profiles_dir': '/opt/airflow/project_root/dbt', 'log_path': '/opt/airflow/project_root/dbt/logs', 'fail_fast': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'static_parser': 'True', 'introspect': 'True', 'invocation_command': 'dbt run --project-dir /opt/airflow/project_root/dbt --profiles-dir /opt/airflow/project_root/dbt --select gold', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m11:46:10.062770 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '04144f5e-2d56-4251-997c-9b2c95151325', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa9386790>]}
[0m11:46:10.082852 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '04144f5e-2d56-4251-997c-9b2c95151325', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa9e5b2d0>]}
[0m11:46:10.083458 [info ] [MainThread]: Registered adapter: clickhouse=1.8.9
[0m11:46:10.122535 [debug] [MainThread]: checksum: 132857a23e9d07220246854f7763165174ce9b737cfc7867629ace4294e520b1, vars: {}, profile: , target: , version: 1.8.9
[0m11:46:10.164268 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m11:46:10.164643 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '04144f5e-2d56-4251-997c-9b2c95151325', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffaa8c9390>]}
[0m11:46:10.727478 [warn ] [MainThread]: [[33mWARNING[0m]: Deprecated functionality
The `tests` config has been renamed to `data_tests`. Please see
https://docs.getdbt.com/docs/build/data-tests#new-data_tests-syntax for more
information.
[0m11:46:10.728164 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'deprecation', 'label': '04144f5e-2d56-4251-997c-9b2c95151325', 'property_': 'warn', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa932ad10>]}
[0m11:46:10.828098 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.movie_warehouse.bronze
[0m11:46:10.834194 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '04144f5e-2d56-4251-997c-9b2c95151325', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa8fbe950>]}
[0m11:46:10.909155 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '04144f5e-2d56-4251-997c-9b2c95151325', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa3dabe90>]}
[0m11:46:10.909542 [info ] [MainThread]: Found 6 models, 12 data tests, 4 sources, 476 macros
[0m11:46:10.909808 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '04144f5e-2d56-4251-997c-9b2c95151325', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa918d710>]}
[0m11:46:10.910712 [info ] [MainThread]: 
[0m11:46:10.911090 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m11:46:10.914066 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m11:46:10.920258 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:46:11.284522 [info ] [ThreadPool]: dbt_clickhouse adapter: Unexpected server exception dropping table
[0m11:46:11.284973 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m11:46:11.287661 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:46:11.313999 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__gold_gold)
[0m11:46:11.317707 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__gold_gold: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "connection_name": "list__gold_gold"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'gold_gold'
      

  ...
[0m11:46:11.326699 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m11:46:11.328377 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '04144f5e-2d56-4251-997c-9b2c95151325', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff698fc250>]}
[0m11:46:11.328739 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m11:46:11.328973 [info ] [MainThread]: 
[0m11:46:11.333791 [debug] [Thread-1 (]: Began running node model.movie_warehouse.dim_director
[0m11:46:11.334127 [info ] [Thread-1 (]: 1 of 6 START sql table model `gold_gold`.`dim_director` ........................ [RUN]
[0m11:46:11.334389 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list__gold_gold, now model.movie_warehouse.dim_director)
[0m11:46:11.334578 [debug] [Thread-1 (]: Began compiling node model.movie_warehouse.dim_director
[0m11:46:11.338269 [debug] [Thread-1 (]: Writing injected SQL for node "model.movie_warehouse.dim_director"
[0m11:46:11.338989 [debug] [Thread-1 (]: Began executing node model.movie_warehouse.dim_director
[0m11:46:11.351366 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_director: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_director"} */

    drop table if exists `gold_gold`.`dim_director__dbt_backup` 
  ...
[0m11:46:11.353327 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_director"} */

    drop table if exists `gold_gold`.`dim_director__dbt_backup` 
  
[0m11:46:11.353575 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: macro drop_relation
[0m11:46:11.358713 [debug] [Thread-1 (]: Database Error in model dim_director (models/gold/dim_director.sql)
  :HTTPDriver for http://clickhouse-server:8123 returned response code 500)
   std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/8c9/8c9b38bb-5974-4368-97d1-712fe72b58b0/dim_director__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/gold_gold.dim_director__dbt_backup.2c99c2ef-a08c-480a-8b73-f82e307048ee.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build))
[0m11:46:11.359518 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '04144f5e-2d56-4251-997c-9b2c95151325', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa3e9e350>]}
[0m11:46:11.359868 [error] [Thread-1 (]: 1 of 6 ERROR creating sql table model `gold_gold`.`dim_director` ............... [[31mERROR[0m in 0.02s]
[0m11:46:11.360205 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.dim_director
[0m11:46:11.360432 [debug] [Thread-1 (]: Began running node model.movie_warehouse.dim_genre
[0m11:46:11.360966 [info ] [Thread-1 (]: 2 of 6 START sql table model `gold_gold`.`dim_genre` ........................... [RUN]
[0m11:46:11.361217 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.movie_warehouse.dim_director, now model.movie_warehouse.dim_genre)
[0m11:46:11.361408 [debug] [Thread-1 (]: Began compiling node model.movie_warehouse.dim_genre
[0m11:46:11.363002 [debug] [Thread-1 (]: Writing injected SQL for node "model.movie_warehouse.dim_genre"
[0m11:46:11.363721 [debug] [Thread-1 (]: Began executing node model.movie_warehouse.dim_genre
[0m11:46:11.366684 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_genre: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_genre"} */

    drop table if exists `gold_gold`.`dim_genre__dbt_backup` 
  ...
[0m11:46:11.368339 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_genre"} */

    drop table if exists `gold_gold`.`dim_genre__dbt_backup` 
  
[0m11:46:11.368564 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: macro drop_relation
[0m11:46:11.370202 [debug] [Thread-1 (]: Database Error in model dim_genre (models/gold/dim_genre.sql)
  :HTTPDriver for http://clickhouse-server:8123 returned response code 500)
   std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/8c9/8c9b38bb-5974-4368-97d1-712fe72b58b0/dim_genre__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/gold_gold.dim_genre__dbt_backup.2487f1ca-ea22-4281-94ae-ca07070efa81.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build))
[0m11:46:11.370486 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '04144f5e-2d56-4251-997c-9b2c95151325', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff68989dd0>]}
[0m11:46:11.370820 [error] [Thread-1 (]: 2 of 6 ERROR creating sql table model `gold_gold`.`dim_genre` .................. [[31mERROR[0m in 0.01s]
[0m11:46:11.371107 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.dim_genre
[0m11:46:11.371314 [debug] [Thread-1 (]: Began running node model.movie_warehouse.dim_movie
[0m11:46:11.371579 [info ] [Thread-1 (]: 3 of 6 START sql table model `gold_gold`.`dim_movie` ........................... [RUN]
[0m11:46:11.371793 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.movie_warehouse.dim_genre, now model.movie_warehouse.dim_movie)
[0m11:46:11.371966 [debug] [Thread-1 (]: Began compiling node model.movie_warehouse.dim_movie
[0m11:46:11.373358 [debug] [Thread-1 (]: Writing injected SQL for node "model.movie_warehouse.dim_movie"
[0m11:46:11.374449 [debug] [Thread-1 (]: Began executing node model.movie_warehouse.dim_movie
[0m11:46:11.376772 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_movie: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_movie"} */

    drop table if exists `gold_gold`.`dim_movie__dbt_backup` 
  ...
[0m11:46:11.379311 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_movie"} */

    drop table if exists `gold_gold`.`dim_movie__dbt_backup` 
  
[0m11:46:11.379652 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: macro drop_relation
[0m11:46:11.381799 [debug] [Thread-1 (]: Database Error in model dim_movie (models/gold/dim_movie.sql)
  :HTTPDriver for http://clickhouse-server:8123 returned response code 500)
   std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/8c9/8c9b38bb-5974-4368-97d1-712fe72b58b0/dim_movie__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/gold_gold.dim_movie__dbt_backup.1916288c-7695-4a93-8987-f314a281fa5f.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build))
[0m11:46:11.382234 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '04144f5e-2d56-4251-997c-9b2c95151325', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff80019610>]}
[0m11:46:11.382861 [error] [Thread-1 (]: 3 of 6 ERROR creating sql table model `gold_gold`.`dim_movie` .................. [[31mERROR[0m in 0.01s]
[0m11:46:11.383252 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.dim_movie
[0m11:46:11.383494 [debug] [Thread-1 (]: Began running node model.movie_warehouse.dim_production
[0m11:46:11.383796 [info ] [Thread-1 (]: 4 of 6 START sql table model `gold_gold`.`dim_production` ...................... [RUN]
[0m11:46:11.384111 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.movie_warehouse.dim_movie, now model.movie_warehouse.dim_production)
[0m11:46:11.384344 [debug] [Thread-1 (]: Began compiling node model.movie_warehouse.dim_production
[0m11:46:11.385984 [debug] [Thread-1 (]: Writing injected SQL for node "model.movie_warehouse.dim_production"
[0m11:46:11.386780 [debug] [Thread-1 (]: Began executing node model.movie_warehouse.dim_production
[0m11:46:11.389141 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_production: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_production"} */

    drop table if exists `gold_gold`.`dim_production__dbt_backup` 
  ...
[0m11:46:11.390914 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_production"} */

    drop table if exists `gold_gold`.`dim_production__dbt_backup` 
  
[0m11:46:11.391148 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: macro drop_relation
[0m11:46:11.392824 [debug] [Thread-1 (]: Database Error in model dim_production (models/gold/dim_production.sql)
  :HTTPDriver for http://clickhouse-server:8123 returned response code 500)
   std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/8c9/8c9b38bb-5974-4368-97d1-712fe72b58b0/dim_production__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/gold_gold.dim_production__dbt_backup.cb69e4e8-058b-48e7-b13a-77549ddf5902.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build))
[0m11:46:11.393101 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '04144f5e-2d56-4251-997c-9b2c95151325', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff689c7110>]}
[0m11:46:11.393398 [error] [Thread-1 (]: 4 of 6 ERROR creating sql table model `gold_gold`.`dim_production` ............. [[31mERROR[0m in 0.01s]
[0m11:46:11.393687 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.dim_production
[0m11:46:11.393908 [debug] [Thread-1 (]: Began running node model.movie_warehouse.dim_release_date
[0m11:46:11.394172 [info ] [Thread-1 (]: 5 of 6 START sql table model `gold_gold`.`dim_release_date` .................... [RUN]
[0m11:46:11.394385 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.movie_warehouse.dim_production, now model.movie_warehouse.dim_release_date)
[0m11:46:11.394560 [debug] [Thread-1 (]: Began compiling node model.movie_warehouse.dim_release_date
[0m11:46:11.396197 [debug] [Thread-1 (]: Writing injected SQL for node "model.movie_warehouse.dim_release_date"
[0m11:46:11.396940 [debug] [Thread-1 (]: Began executing node model.movie_warehouse.dim_release_date
[0m11:46:11.398931 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_release_date: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_release_date"} */

    drop table if exists `gold_gold`.`dim_release_date__dbt_backup` 
  ...
[0m11:46:11.400528 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_release_date"} */

    drop table if exists `gold_gold`.`dim_release_date__dbt_backup` 
  
[0m11:46:11.400813 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: macro drop_relation
[0m11:46:11.402449 [debug] [Thread-1 (]: Database Error in model dim_release_date (models/gold/dim_release_date.sql)
  :HTTPDriver for http://clickhouse-server:8123 returned response code 500)
   std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/8c9/8c9b38bb-5974-4368-97d1-712fe72b58b0/dim_release_date__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/gold_gold.dim_release_date__dbt_backup.f2636bd2-27ea-40bb-be87-ff663458e441.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build))
[0m11:46:11.402686 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '04144f5e-2d56-4251-997c-9b2c95151325', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff68a73750>]}
[0m11:46:11.402981 [error] [Thread-1 (]: 5 of 6 ERROR creating sql table model `gold_gold`.`dim_release_date` ........... [[31mERROR[0m in 0.01s]
[0m11:46:11.403249 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.dim_release_date
[0m11:46:11.403630 [debug] [Thread-1 (]: Began running node model.movie_warehouse.fact_movie
[0m11:46:11.403932 [info ] [Thread-1 (]: 6 of 6 SKIP relation gold_gold.fact_movie ...................................... [[33mSKIP[0m]
[0m11:46:11.404150 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.fact_movie
[0m11:46:11.404749 [debug] [MainThread]: Connection 'master' was properly closed.
[0m11:46:11.404949 [debug] [MainThread]: Connection 'model.movie_warehouse.dim_release_date' was left open.
[0m11:46:11.405149 [debug] [MainThread]: On model.movie_warehouse.dim_release_date: Close
[0m11:46:11.405414 [info ] [MainThread]: 
[0m11:46:11.405613 [info ] [MainThread]: Finished running 6 table models in 0 hours 0 minutes and 0.49 seconds (0.49s).
[0m11:46:11.406152 [debug] [MainThread]: Command end result
[0m11:46:11.427676 [info ] [MainThread]: 
[0m11:46:11.427971 [info ] [MainThread]: [31mCompleted with 5 errors and 0 warnings:[0m
[0m11:46:11.428160 [info ] [MainThread]: 
[0m11:46:11.428365 [error] [MainThread]:   Database Error in model dim_director (models/gold/dim_director.sql)
  :HTTPDriver for http://clickhouse-server:8123 returned response code 500)
   std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/8c9/8c9b38bb-5974-4368-97d1-712fe72b58b0/dim_director__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/gold_gold.dim_director__dbt_backup.2c99c2ef-a08c-480a-8b73-f82e307048ee.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build))
[0m11:46:11.428550 [info ] [MainThread]: 
[0m11:46:11.428746 [error] [MainThread]:   Database Error in model dim_genre (models/gold/dim_genre.sql)
  :HTTPDriver for http://clickhouse-server:8123 returned response code 500)
   std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/8c9/8c9b38bb-5974-4368-97d1-712fe72b58b0/dim_genre__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/gold_gold.dim_genre__dbt_backup.2487f1ca-ea22-4281-94ae-ca07070efa81.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build))
[0m11:46:11.428923 [info ] [MainThread]: 
[0m11:46:11.429131 [error] [MainThread]:   Database Error in model dim_movie (models/gold/dim_movie.sql)
  :HTTPDriver for http://clickhouse-server:8123 returned response code 500)
   std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/8c9/8c9b38bb-5974-4368-97d1-712fe72b58b0/dim_movie__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/gold_gold.dim_movie__dbt_backup.1916288c-7695-4a93-8987-f314a281fa5f.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build))
[0m11:46:11.429326 [info ] [MainThread]: 
[0m11:46:11.429514 [error] [MainThread]:   Database Error in model dim_production (models/gold/dim_production.sql)
  :HTTPDriver for http://clickhouse-server:8123 returned response code 500)
   std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/8c9/8c9b38bb-5974-4368-97d1-712fe72b58b0/dim_production__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/gold_gold.dim_production__dbt_backup.cb69e4e8-058b-48e7-b13a-77549ddf5902.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build))
[0m11:46:11.429678 [info ] [MainThread]: 
[0m11:46:11.429865 [error] [MainThread]:   Database Error in model dim_release_date (models/gold/dim_release_date.sql)
  :HTTPDriver for http://clickhouse-server:8123 returned response code 500)
   std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/8c9/8c9b38bb-5974-4368-97d1-712fe72b58b0/dim_release_date__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/gold_gold.dim_release_date__dbt_backup.f2636bd2-27ea-40bb-be87-ff663458e441.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build))
[0m11:46:11.430030 [info ] [MainThread]: 
[0m11:46:11.430208 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=5 SKIP=1 TOTAL=6
[0m11:46:11.431033 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 1.5115054, "process_in_blocks": "109904", "process_kernel_time": 0.312245, "process_mem_max_rss": "189792", "process_out_blocks": "3408", "process_user_time": 2.377554}
[0m11:46:11.431313 [debug] [MainThread]: Command `dbt run` failed at 11:46:11.431275 after 1.51 seconds
[0m11:46:11.431532 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa945f5d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa946b910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa9469490>]}
[0m11:46:11.431730 [debug] [MainThread]: Flushing usage events
[0m11:51:26.022304 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff9f04d290>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff9f40eb10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff9f04d950>]}


============================== 11:51:26.026201 | d9bab753-cdab-4108-ace2-4af36ea39984 ==============================
[0m11:51:26.026201 [info ] [MainThread]: Running with dbt=1.8.9
[0m11:51:26.026539 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'profiles_dir': '/opt/airflow/project_root/dbt', 'log_path': '/opt/airflow/project_root/dbt/logs', 'debug': 'False', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'static_parser': 'True', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'invocation_command': 'dbt run --project-dir /opt/airflow/project_root/dbt --profiles-dir /opt/airflow/project_root/dbt --select gold', 'send_anonymous_usage_stats': 'True'}
[0m11:51:26.112679 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'd9bab753-cdab-4108-ace2-4af36ea39984', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff9fade950>]}
[0m11:51:26.143609 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'd9bab753-cdab-4108-ace2-4af36ea39984', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa054e750>]}
[0m11:51:26.144295 [info ] [MainThread]: Registered adapter: clickhouse=1.8.9
[0m11:51:26.185444 [debug] [MainThread]: checksum: 132857a23e9d07220246854f7763165174ce9b737cfc7867629ace4294e520b1, vars: {}, profile: , target: , version: 1.8.9
[0m11:51:26.246975 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 1 files added, 0 files changed.
[0m11:51:26.248001 [debug] [MainThread]: Partial parsing: added file: movie_warehouse://macros/no_backup_table.sql
[0m11:51:26.302118 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.movie_warehouse.bronze
[0m11:51:26.308322 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd9bab753-cdab-4108-ace2-4af36ea39984', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff9ec77810>]}
[0m11:51:26.372674 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd9bab753-cdab-4108-ace2-4af36ea39984', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff9e9ef410>]}
[0m11:51:26.373379 [info ] [MainThread]: Found 6 models, 12 data tests, 4 sources, 477 macros
[0m11:51:26.373664 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'd9bab753-cdab-4108-ace2-4af36ea39984', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff9f08a850>]}
[0m11:51:26.374834 [info ] [MainThread]: 
[0m11:51:26.375295 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m11:51:26.378401 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m11:51:26.385340 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:51:26.730544 [info ] [ThreadPool]: dbt_clickhouse adapter: Unexpected server exception dropping table
[0m11:51:26.731087 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m11:51:26.733672 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:51:26.755374 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__gold_gold)
[0m11:51:26.758424 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__gold_gold: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "connection_name": "list__gold_gold"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'gold_gold'
      

  ...
[0m11:51:26.762739 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:51:26.764213 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'd9bab753-cdab-4108-ace2-4af36ea39984', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff82138ed0>]}
[0m11:51:26.764555 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m11:51:26.764784 [info ] [MainThread]: 
[0m11:51:26.769699 [debug] [Thread-1 (]: Began running node model.movie_warehouse.dim_director
[0m11:51:26.770069 [info ] [Thread-1 (]: 1 of 6 START sql table model `gold_gold`.`dim_director` ........................ [RUN]
[0m11:51:26.770388 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list__gold_gold, now model.movie_warehouse.dim_director)
[0m11:51:26.770593 [debug] [Thread-1 (]: Began compiling node model.movie_warehouse.dim_director
[0m11:51:26.774248 [debug] [Thread-1 (]: Writing injected SQL for node "model.movie_warehouse.dim_director"
[0m11:51:26.775029 [debug] [Thread-1 (]: Began executing node model.movie_warehouse.dim_director
[0m11:51:26.787971 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_director: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_director"} */

    drop table if exists `gold_gold`.`dim_director__dbt_backup` 
  ...
[0m11:51:26.789914 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_director"} */

    drop table if exists `gold_gold`.`dim_director__dbt_backup` 
  
[0m11:51:26.790206 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: macro drop_relation
[0m11:51:26.792803 [debug] [Thread-1 (]: Database Error in model dim_director (models/gold/dim_director.sql)
  :HTTPDriver for http://clickhouse-server:8123 returned response code 500)
   std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/8c9/8c9b38bb-5974-4368-97d1-712fe72b58b0/dim_director__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/gold_gold.dim_director__dbt_backup.2c99c2ef-a08c-480a-8b73-f82e307048ee.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build))
[0m11:51:26.793629 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd9bab753-cdab-4108-ace2-4af36ea39984', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff7bd028d0>]}
[0m11:51:26.793997 [error] [Thread-1 (]: 1 of 6 ERROR creating sql table model `gold_gold`.`dim_director` ............... [[31mERROR[0m in 0.02s]
[0m11:51:26.794359 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.dim_director
[0m11:51:26.794634 [debug] [Thread-1 (]: Began running node model.movie_warehouse.dim_genre
[0m11:51:26.795177 [info ] [Thread-1 (]: 2 of 6 START sql table model `gold_gold`.`dim_genre` ........................... [RUN]
[0m11:51:26.795464 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.movie_warehouse.dim_director, now model.movie_warehouse.dim_genre)
[0m11:51:26.795692 [debug] [Thread-1 (]: Began compiling node model.movie_warehouse.dim_genre
[0m11:51:26.797374 [debug] [Thread-1 (]: Writing injected SQL for node "model.movie_warehouse.dim_genre"
[0m11:51:26.798115 [debug] [Thread-1 (]: Began executing node model.movie_warehouse.dim_genre
[0m11:51:26.800733 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_genre: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_genre"} */

    drop table if exists `gold_gold`.`dim_genre__dbt_backup` 
  ...
[0m11:51:26.802413 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_genre"} */

    drop table if exists `gold_gold`.`dim_genre__dbt_backup` 
  
[0m11:51:26.802655 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: macro drop_relation
[0m11:51:26.804284 [debug] [Thread-1 (]: Database Error in model dim_genre (models/gold/dim_genre.sql)
  :HTTPDriver for http://clickhouse-server:8123 returned response code 500)
   std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/8c9/8c9b38bb-5974-4368-97d1-712fe72b58b0/dim_genre__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/gold_gold.dim_genre__dbt_backup.2487f1ca-ea22-4281-94ae-ca07070efa81.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build))
[0m11:51:26.804595 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd9bab753-cdab-4108-ace2-4af36ea39984', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff800f3a90>]}
[0m11:51:26.804917 [error] [Thread-1 (]: 2 of 6 ERROR creating sql table model `gold_gold`.`dim_genre` .................. [[31mERROR[0m in 0.01s]
[0m11:51:26.805230 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.dim_genre
[0m11:51:26.805447 [debug] [Thread-1 (]: Began running node model.movie_warehouse.dim_movie
[0m11:51:26.805733 [info ] [Thread-1 (]: 3 of 6 START sql table model `gold_gold`.`dim_movie` ........................... [RUN]
[0m11:51:26.805970 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.movie_warehouse.dim_genre, now model.movie_warehouse.dim_movie)
[0m11:51:26.806170 [debug] [Thread-1 (]: Began compiling node model.movie_warehouse.dim_movie
[0m11:51:26.807544 [debug] [Thread-1 (]: Writing injected SQL for node "model.movie_warehouse.dim_movie"
[0m11:51:26.808171 [debug] [Thread-1 (]: Began executing node model.movie_warehouse.dim_movie
[0m11:51:26.810063 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_movie: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_movie"} */

    drop table if exists `gold_gold`.`dim_movie__dbt_backup` 
  ...
[0m11:51:26.811484 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_movie"} */

    drop table if exists `gold_gold`.`dim_movie__dbt_backup` 
  
[0m11:51:26.811713 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: macro drop_relation
[0m11:51:26.813330 [debug] [Thread-1 (]: Database Error in model dim_movie (models/gold/dim_movie.sql)
  :HTTPDriver for http://clickhouse-server:8123 returned response code 500)
   std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/8c9/8c9b38bb-5974-4368-97d1-712fe72b58b0/dim_movie__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/gold_gold.dim_movie__dbt_backup.1916288c-7695-4a93-8987-f314a281fa5f.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build))
[0m11:51:26.813569 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd9bab753-cdab-4108-ace2-4af36ea39984', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff9ed348d0>]}
[0m11:51:26.813928 [error] [Thread-1 (]: 3 of 6 ERROR creating sql table model `gold_gold`.`dim_movie` .................. [[31mERROR[0m in 0.01s]
[0m11:51:26.814384 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.dim_movie
[0m11:51:26.814599 [debug] [Thread-1 (]: Began running node model.movie_warehouse.dim_production
[0m11:51:26.814857 [info ] [Thread-1 (]: 4 of 6 START sql table model `gold_gold`.`dim_production` ...................... [RUN]
[0m11:51:26.815069 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.movie_warehouse.dim_movie, now model.movie_warehouse.dim_production)
[0m11:51:26.815286 [debug] [Thread-1 (]: Began compiling node model.movie_warehouse.dim_production
[0m11:51:26.816654 [debug] [Thread-1 (]: Writing injected SQL for node "model.movie_warehouse.dim_production"
[0m11:51:26.817466 [debug] [Thread-1 (]: Began executing node model.movie_warehouse.dim_production
[0m11:51:26.819406 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_production: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_production"} */

    drop table if exists `gold_gold`.`dim_production__dbt_backup` 
  ...
[0m11:51:26.820858 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_production"} */

    drop table if exists `gold_gold`.`dim_production__dbt_backup` 
  
[0m11:51:26.821089 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: macro drop_relation
[0m11:51:26.822992 [debug] [Thread-1 (]: Database Error in model dim_production (models/gold/dim_production.sql)
  :HTTPDriver for http://clickhouse-server:8123 returned response code 500)
   std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/8c9/8c9b38bb-5974-4368-97d1-712fe72b58b0/dim_production__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/gold_gold.dim_production__dbt_backup.cb69e4e8-058b-48e7-b13a-77549ddf5902.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build))
[0m11:51:26.823386 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd9bab753-cdab-4108-ace2-4af36ea39984', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff7b687b50>]}
[0m11:51:26.823957 [error] [Thread-1 (]: 4 of 6 ERROR creating sql table model `gold_gold`.`dim_production` ............. [[31mERROR[0m in 0.01s]
[0m11:51:26.824379 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.dim_production
[0m11:51:26.824614 [debug] [Thread-1 (]: Began running node model.movie_warehouse.dim_release_date
[0m11:51:26.824918 [info ] [Thread-1 (]: 5 of 6 START sql table model `gold_gold`.`dim_release_date` .................... [RUN]
[0m11:51:26.825185 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.movie_warehouse.dim_production, now model.movie_warehouse.dim_release_date)
[0m11:51:26.825402 [debug] [Thread-1 (]: Began compiling node model.movie_warehouse.dim_release_date
[0m11:51:26.827551 [debug] [Thread-1 (]: Writing injected SQL for node "model.movie_warehouse.dim_release_date"
[0m11:51:26.828247 [debug] [Thread-1 (]: Began executing node model.movie_warehouse.dim_release_date
[0m11:51:26.830664 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_release_date: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_release_date"} */

    drop table if exists `gold_gold`.`dim_release_date__dbt_backup` 
  ...
[0m11:51:26.832587 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_release_date"} */

    drop table if exists `gold_gold`.`dim_release_date__dbt_backup` 
  
[0m11:51:26.832847 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: macro drop_relation
[0m11:51:26.834589 [debug] [Thread-1 (]: Database Error in model dim_release_date (models/gold/dim_release_date.sql)
  :HTTPDriver for http://clickhouse-server:8123 returned response code 500)
   std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/8c9/8c9b38bb-5974-4368-97d1-712fe72b58b0/dim_release_date__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/gold_gold.dim_release_date__dbt_backup.f2636bd2-27ea-40bb-be87-ff663458e441.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build))
[0m11:51:26.834949 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd9bab753-cdab-4108-ace2-4af36ea39984', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff7bd1c890>]}
[0m11:51:26.835347 [error] [Thread-1 (]: 5 of 6 ERROR creating sql table model `gold_gold`.`dim_release_date` ........... [[31mERROR[0m in 0.01s]
[0m11:51:26.835668 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.dim_release_date
[0m11:51:26.836103 [debug] [Thread-1 (]: Began running node model.movie_warehouse.fact_movie
[0m11:51:26.836482 [info ] [Thread-1 (]: 6 of 6 SKIP relation gold_gold.fact_movie ...................................... [[33mSKIP[0m]
[0m11:51:26.836727 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.fact_movie
[0m11:51:26.837385 [debug] [MainThread]: Connection 'master' was properly closed.
[0m11:51:26.837580 [debug] [MainThread]: Connection 'model.movie_warehouse.dim_release_date' was left open.
[0m11:51:26.837747 [debug] [MainThread]: On model.movie_warehouse.dim_release_date: Close
[0m11:51:26.838006 [info ] [MainThread]: 
[0m11:51:26.838219 [info ] [MainThread]: Finished running 6 table models in 0 hours 0 minutes and 0.46 seconds (0.46s).
[0m11:51:26.838768 [debug] [MainThread]: Command end result
[0m11:51:26.898725 [info ] [MainThread]: 
[0m11:51:26.899012 [info ] [MainThread]: [31mCompleted with 5 errors and 0 warnings:[0m
[0m11:51:26.899208 [info ] [MainThread]: 
[0m11:51:26.899439 [error] [MainThread]:   Database Error in model dim_director (models/gold/dim_director.sql)
  :HTTPDriver for http://clickhouse-server:8123 returned response code 500)
   std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/8c9/8c9b38bb-5974-4368-97d1-712fe72b58b0/dim_director__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/gold_gold.dim_director__dbt_backup.2c99c2ef-a08c-480a-8b73-f82e307048ee.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build))
[0m11:51:26.899651 [info ] [MainThread]: 
[0m11:51:26.899848 [error] [MainThread]:   Database Error in model dim_genre (models/gold/dim_genre.sql)
  :HTTPDriver for http://clickhouse-server:8123 returned response code 500)
   std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/8c9/8c9b38bb-5974-4368-97d1-712fe72b58b0/dim_genre__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/gold_gold.dim_genre__dbt_backup.2487f1ca-ea22-4281-94ae-ca07070efa81.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build))
[0m11:51:26.900012 [info ] [MainThread]: 
[0m11:51:26.900202 [error] [MainThread]:   Database Error in model dim_movie (models/gold/dim_movie.sql)
  :HTTPDriver for http://clickhouse-server:8123 returned response code 500)
   std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/8c9/8c9b38bb-5974-4368-97d1-712fe72b58b0/dim_movie__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/gold_gold.dim_movie__dbt_backup.1916288c-7695-4a93-8987-f314a281fa5f.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build))
[0m11:51:26.900361 [info ] [MainThread]: 
[0m11:51:26.900541 [error] [MainThread]:   Database Error in model dim_production (models/gold/dim_production.sql)
  :HTTPDriver for http://clickhouse-server:8123 returned response code 500)
   std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/8c9/8c9b38bb-5974-4368-97d1-712fe72b58b0/dim_production__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/gold_gold.dim_production__dbt_backup.cb69e4e8-058b-48e7-b13a-77549ddf5902.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build))
[0m11:51:26.900718 [info ] [MainThread]: 
[0m11:51:26.900912 [error] [MainThread]:   Database Error in model dim_release_date (models/gold/dim_release_date.sql)
  :HTTPDriver for http://clickhouse-server:8123 returned response code 500)
   std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/8c9/8c9b38bb-5974-4368-97d1-712fe72b58b0/dim_release_date__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/gold_gold.dim_release_date__dbt_backup.f2636bd2-27ea-40bb-be87-ff663458e441.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build))
[0m11:51:26.901109 [info ] [MainThread]: 
[0m11:51:26.901324 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=5 SKIP=1 TOTAL=6
[0m11:51:26.901819 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 0.9000849, "process_in_blocks": "0", "process_kernel_time": 0.348386, "process_mem_max_rss": "190672", "process_out_blocks": "3420", "process_user_time": 1.946611}
[0m11:51:26.902081 [debug] [MainThread]: Command `dbt run` failed at 11:51:26.902044 after 0.90 seconds
[0m11:51:26.902354 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff9f07f5d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff9f40eb90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa1348b10>]}
[0m11:51:26.902560 [debug] [MainThread]: Flushing usage events
[0m11:53:43.929248 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff9388ce90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff9388d210>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff9388c810>]}


============================== 11:53:43.932575 | e6767653-a2e2-440d-b246-32b7b51cbc97 ==============================
[0m11:53:43.932575 [info ] [MainThread]: Running with dbt=1.8.9
[0m11:53:43.932930 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/project_root/dbt', 'version_check': 'True', 'warn_error': 'None', 'log_path': '/opt/airflow/project_root/dbt/logs', 'fail_fast': 'False', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'introspect': 'True', 'log_format': 'default', 'target_path': 'None', 'invocation_command': 'dbt run --project-dir /opt/airflow/project_root/dbt --profiles-dir /opt/airflow/project_root/dbt --select gold', 'send_anonymous_usage_stats': 'True'}
[0m11:53:43.997625 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'e6767653-a2e2-440d-b246-32b7b51cbc97', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff93815910>]}
[0m11:53:44.015995 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'e6767653-a2e2-440d-b246-32b7b51cbc97', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff942bb390>]}
[0m11:53:44.016474 [info ] [MainThread]: Registered adapter: clickhouse=1.8.9
[0m11:53:44.047050 [debug] [MainThread]: checksum: 132857a23e9d07220246854f7763165174ce9b737cfc7867629ace4294e520b1, vars: {}, profile: , target: , version: 1.8.9
[0m11:53:44.096880 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m11:53:44.097165 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m11:53:44.099859 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.movie_warehouse.bronze
[0m11:53:44.115250 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'e6767653-a2e2-440d-b246-32b7b51cbc97', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff93686e90>]}
[0m11:53:44.166550 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'e6767653-a2e2-440d-b246-32b7b51cbc97', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff93572a90>]}
[0m11:53:44.166896 [info ] [MainThread]: Found 6 models, 12 data tests, 4 sources, 477 macros
[0m11:53:44.167098 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'e6767653-a2e2-440d-b246-32b7b51cbc97', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff938c8b90>]}
[0m11:53:44.167887 [info ] [MainThread]: 
[0m11:53:44.168207 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m11:53:44.170991 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m11:53:44.176012 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:53:44.413496 [info ] [ThreadPool]: dbt_clickhouse adapter: Unexpected server exception dropping table
[0m11:53:44.413885 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m11:53:44.415548 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:53:44.436278 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__gold_gold)
[0m11:53:44.439680 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__gold_gold: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "connection_name": "list__gold_gold"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'gold_gold'
      

  ...
[0m11:53:44.446394 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m11:53:44.448018 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'e6767653-a2e2-440d-b246-32b7b51cbc97', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff95f876d0>]}
[0m11:53:44.448454 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m11:53:44.448726 [info ] [MainThread]: 
[0m11:53:44.453561 [debug] [Thread-1 (]: Began running node model.movie_warehouse.dim_director
[0m11:53:44.453947 [info ] [Thread-1 (]: 1 of 6 START sql table model `gold_gold`.`dim_director` ........................ [RUN]
[0m11:53:44.454249 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list__gold_gold, now model.movie_warehouse.dim_director)
[0m11:53:44.454499 [debug] [Thread-1 (]: Began compiling node model.movie_warehouse.dim_director
[0m11:53:44.458070 [debug] [Thread-1 (]: Writing injected SQL for node "model.movie_warehouse.dim_director"
[0m11:53:44.458913 [debug] [Thread-1 (]: Began executing node model.movie_warehouse.dim_director
[0m11:53:44.467137 [debug] [Thread-1 (]: Creating new relation dim_director
[0m11:53:44.479248 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_director: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_director"} */

            

    
        create table `gold_gold`.`dim_director`
        
  
        
  engine = MergeTree()
        order by (dir_id)
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

WITH first_dir AS (
    SELECT
        tconst,
        TRIM(splitByChar(',', directors)[1]) AS director_id
    FROM `bronze`.`imdb_title_crew_raw`
    WHERE directors IS NOT NULL AND directors != ''
),
deduped AS (
    SELECT DISTINCT director_id
    FROM first_dir
),
joined AS (
    SELECT
        d.director_id AS dir_id,
        n.primaryName AS dir_name
    FROM deduped d
    LEFT JOIN `bronze`.`imdb_name_basics_raw` n
        ON d.director_id = n.nconst
)
SELECT
    cityHash64(dir_id) AS imdb_dir_name_id,  -- Use hash instead of row_number
    dir_id,
    dir_name,
    today() AS valid_from,
    CAST(NULL AS Nullable(Date)) AS valid_to,
    1 AS is_current  -- Use 1/0 instead of TRUE/FALSE
FROM joined
WHERE dir_id IS NOT NULL
ORDER BY dir_id
          )
        
        ...
[0m11:53:44.487921 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m11:53:44.494803 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_director: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_director"} */

    select name, type from system.columns where table = 'dim_director'
    
      and database = 'gold_gold'
    
    order by position
  ...
[0m11:53:44.497966 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:53:44.499612 [debug] [Thread-1 (]: Writing runtime sql for node "model.movie_warehouse.dim_director"
[0m11:53:44.500677 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_director: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_director"} */

  
    
    
    
        
         


        insert into `gold_gold`.`dim_director`
        ("imdb_dir_name_id", "dir_id", "dir_name", "valid_from", "valid_to", "is_current")

WITH first_dir AS (
    SELECT
        tconst,
        TRIM(splitByChar(',', directors)[1]) AS director_id
    FROM `bronze`.`imdb_title_crew_raw`
    WHERE directors IS NOT NULL AND directors != ''
),
deduped AS (
    SELECT DISTINCT director_id
    FROM first_dir
),
joined AS (
    SELECT
        d.director_id AS dir_id,
        n.primaryName AS dir_name
    FROM deduped d
    LEFT JOIN `bronze`.`imdb_name_basics_raw` n
        ON d.director_id = n.nconst
)
SELECT
    cityHash64(dir_id) AS imdb_dir_name_id,  -- Use hash instead of row_number
    dir_id,
    dir_name,
    today() AS valid_from,
    CAST(NULL AS Nullable(Date)) AS valid_to,
    1 AS is_current  -- Use 1/0 instead of TRUE/FALSE
FROM joined
WHERE dir_id IS NOT NULL
ORDER BY dir_id
  ...
[0m11:53:47.313723 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 2.81 seconds
[0m11:53:47.343866 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e6767653-a2e2-440d-b246-32b7b51cbc97', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff937ce6d0>]}
[0m11:53:47.345413 [info ] [Thread-1 (]: 1 of 6 OK created sql table model `gold_gold`.`dim_director` ................... [[32mOK[0m in 2.89s]
[0m11:53:47.346287 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.dim_director
[0m11:53:47.346878 [debug] [Thread-1 (]: Began running node model.movie_warehouse.dim_genre
[0m11:53:47.347643 [info ] [Thread-1 (]: 2 of 6 START sql table model `gold_gold`.`dim_genre` ........................... [RUN]
[0m11:53:47.348040 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.movie_warehouse.dim_director, now model.movie_warehouse.dim_genre)
[0m11:53:47.348314 [debug] [Thread-1 (]: Began compiling node model.movie_warehouse.dim_genre
[0m11:53:47.352441 [debug] [Thread-1 (]: Writing injected SQL for node "model.movie_warehouse.dim_genre"
[0m11:53:47.353526 [debug] [Thread-1 (]: Began executing node model.movie_warehouse.dim_genre
[0m11:53:47.355054 [debug] [Thread-1 (]: Creating new relation dim_genre
[0m11:53:47.355893 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_genre: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_genre"} */

            

    
        create table `gold_gold`.`dim_genre`
        
  
        
  engine = MergeTree()
        order by (genre_id)
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

WITH parsed_genres AS (
    SELECT
        TRIM(splitByChar(',', genres)[1]) AS first_genre
    FROM `bronze`.`tmdb_raw`
    WHERE genres IS NOT NULL AND genres != ''
)
SELECT
    cityHash64(first_genre) AS genre_id,
    first_genre AS genre_name
FROM parsed_genres
GROUP BY first_genre
ORDER BY first_genre
          )
        
        ...
[0m11:53:47.373557 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m11:53:47.377868 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_genre: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_genre"} */

    select name, type from system.columns where table = 'dim_genre'
    
      and database = 'gold_gold'
    
    order by position
  ...
[0m11:53:47.382180 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:53:47.383912 [debug] [Thread-1 (]: Writing runtime sql for node "model.movie_warehouse.dim_genre"
[0m11:53:47.384856 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_genre: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_genre"} */

  
    
    
    
        
         


        insert into `gold_gold`.`dim_genre`
        ("genre_id", "genre_name")

WITH parsed_genres AS (
    SELECT
        TRIM(splitByChar(',', genres)[1]) AS first_genre
    FROM `bronze`.`tmdb_raw`
    WHERE genres IS NOT NULL AND genres != ''
)
SELECT
    cityHash64(first_genre) AS genre_id,
    first_genre AS genre_name
FROM parsed_genres
GROUP BY first_genre
ORDER BY first_genre
  ...
[0m11:53:47.426850 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.04 seconds
[0m11:53:47.428822 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e6767653-a2e2-440d-b246-32b7b51cbc97', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff93771710>]}
[0m11:53:47.429271 [info ] [Thread-1 (]: 2 of 6 OK created sql table model `gold_gold`.`dim_genre` ...................... [[32mOK[0m in 0.08s]
[0m11:53:47.429614 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.dim_genre
[0m11:53:47.429869 [debug] [Thread-1 (]: Began running node model.movie_warehouse.dim_movie
[0m11:53:47.430272 [info ] [Thread-1 (]: 3 of 6 START sql table model `gold_gold`.`dim_movie` ........................... [RUN]
[0m11:53:47.430615 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.movie_warehouse.dim_genre, now model.movie_warehouse.dim_movie)
[0m11:53:47.430864 [debug] [Thread-1 (]: Began compiling node model.movie_warehouse.dim_movie
[0m11:53:47.432695 [debug] [Thread-1 (]: Writing injected SQL for node "model.movie_warehouse.dim_movie"
[0m11:53:47.433365 [debug] [Thread-1 (]: Began executing node model.movie_warehouse.dim_movie
[0m11:53:47.434567 [debug] [Thread-1 (]: Creating new relation dim_movie
[0m11:53:47.435117 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_movie: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_movie"} */

            

    
        create table `gold_gold`.`dim_movie`
        
  
        
  engine = MergeTree()
        order by (movie_id)
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            -- ...existing code...


WITH movie_src AS (
    SELECT
        TRIM(title) AS movie_title,
        imdb_id,
        release_date,
        runtime AS movie_runtime,
        original_language AS language
    FROM `bronze`.`tmdb_raw`
    WHERE title IS NOT NULL AND title != ''
)
SELECT
    cityHash64(movie_title) AS movie_id,
    any(imdb_id) AS imdb_id,
    movie_title,
    any(release_date) AS release_date,
    any(movie_runtime) AS movie_runtime,
    any(language) AS language
FROM movie_src
GROUP BY movie_title
ORDER BY movie_title
          )
        
        ...
[0m11:53:47.446474 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m11:53:47.449080 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_movie: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_movie"} */

    select name, type from system.columns where table = 'dim_movie'
    
      and database = 'gold_gold'
    
    order by position
  ...
[0m11:53:47.452691 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:53:47.454207 [debug] [Thread-1 (]: Writing runtime sql for node "model.movie_warehouse.dim_movie"
[0m11:53:47.455072 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_movie: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_movie"} */

  
    
    
    
        
         


        insert into `gold_gold`.`dim_movie`
        ("movie_id", "imdb_id", "movie_title", "release_date", "movie_runtime", "language")-- ...existing code...


WITH movie_src AS (
    SELECT
        TRIM(title) AS movie_title,
        imdb_id,
        release_date,
        runtime AS movie_runtime,
        original_language AS language
    FROM `bronze`.`tmdb_raw`
    WHERE title IS NOT NULL AND title != ''
)
SELECT
    cityHash64(movie_title) AS movie_id,
    any(imdb_id) AS imdb_id,
    movie_title,
    any(release_date) AS release_date,
    any(movie_runtime) AS movie_runtime,
    any(language) AS language
FROM movie_src
GROUP BY movie_title
ORDER BY movie_title
  ...
[0m11:53:47.813142 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.36 seconds
[0m11:53:47.816006 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e6767653-a2e2-440d-b246-32b7b51cbc97', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff6ff09450>]}
[0m11:53:47.821919 [info ] [Thread-1 (]: 3 of 6 OK created sql table model `gold_gold`.`dim_movie` ...................... [[32mOK[0m in 0.39s]
[0m11:53:47.822399 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.dim_movie
[0m11:53:47.822756 [debug] [Thread-1 (]: Began running node model.movie_warehouse.dim_production
[0m11:53:47.823117 [info ] [Thread-1 (]: 4 of 6 START sql table model `gold_gold`.`dim_production` ...................... [RUN]
[0m11:53:47.823405 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.movie_warehouse.dim_movie, now model.movie_warehouse.dim_production)
[0m11:53:47.823648 [debug] [Thread-1 (]: Began compiling node model.movie_warehouse.dim_production
[0m11:53:47.827060 [debug] [Thread-1 (]: Writing injected SQL for node "model.movie_warehouse.dim_production"
[0m11:53:47.827723 [debug] [Thread-1 (]: Began executing node model.movie_warehouse.dim_production
[0m11:53:47.828816 [debug] [Thread-1 (]: Creating new relation dim_production
[0m11:53:47.829398 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_production: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_production"} */

            

    
        create table `gold_gold`.`dim_production`
        
  
        
  engine = MergeTree()
        order by (production_id)
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

WITH first_production AS (
    SELECT
        imdb_id AS movie_id,
        trim(splitByChar(',', production_companies)[1]) AS production_name
    FROM `bronze`.`tmdb_raw`
    WHERE production_companies IS NOT NULL AND production_companies != ''
)

SELECT
    cityHash64(production_name) AS production_id,
    production_name,
    current_date() AS valid_from,
    CAST(NULL AS Nullable(Date)) AS valid_to,
    TRUE AS is_current
FROM (
    SELECT DISTINCT production_name
    FROM first_production
)
WHERE production_name IS NOT NULL
          )
        
        ...
[0m11:53:47.837633 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m11:53:47.839173 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_production: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_production"} */

    select name, type from system.columns where table = 'dim_production'
    
      and database = 'gold_gold'
    
    order by position
  ...
[0m11:53:47.841816 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:53:47.842775 [debug] [Thread-1 (]: Writing runtime sql for node "model.movie_warehouse.dim_production"
[0m11:53:47.844988 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_production: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_production"} */

  
    
    
    
        
         


        insert into `gold_gold`.`dim_production`
        ("production_id", "production_name", "valid_from", "valid_to", "is_current")

WITH first_production AS (
    SELECT
        imdb_id AS movie_id,
        trim(splitByChar(',', production_companies)[1]) AS production_name
    FROM `bronze`.`tmdb_raw`
    WHERE production_companies IS NOT NULL AND production_companies != ''
)

SELECT
    cityHash64(production_name) AS production_id,
    production_name,
    current_date() AS valid_from,
    CAST(NULL AS Nullable(Date)) AS valid_to,
    TRUE AS is_current
FROM (
    SELECT DISTINCT production_name
    FROM first_production
)
WHERE production_name IS NOT NULL
  ...
[0m11:53:47.853653 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m11:53:47.854662 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e6767653-a2e2-440d-b246-32b7b51cbc97', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff93771710>]}
[0m11:53:47.855011 [info ] [Thread-1 (]: 4 of 6 OK created sql table model `gold_gold`.`dim_production` ................. [[32mOK[0m in 0.03s]
[0m11:53:47.855327 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.dim_production
[0m11:53:47.855587 [debug] [Thread-1 (]: Began running node model.movie_warehouse.dim_release_date
[0m11:53:47.855881 [info ] [Thread-1 (]: 5 of 6 START sql table model `gold_gold`.`dim_release_date` .................... [RUN]
[0m11:53:47.856139 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.movie_warehouse.dim_production, now model.movie_warehouse.dim_release_date)
[0m11:53:47.856333 [debug] [Thread-1 (]: Began compiling node model.movie_warehouse.dim_release_date
[0m11:53:47.858117 [debug] [Thread-1 (]: Writing injected SQL for node "model.movie_warehouse.dim_release_date"
[0m11:53:47.858730 [debug] [Thread-1 (]: Began executing node model.movie_warehouse.dim_release_date
[0m11:53:47.859944 [debug] [Thread-1 (]: Creating new relation dim_release_date
[0m11:53:47.860607 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_release_date: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_release_date"} */

            

    
        create table `gold_gold`.`dim_release_date`
        
  
        
  engine = MergeTree()
        order by (date_id)
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

WITH distinct_dates AS (
    SELECT DISTINCT release_date
    FROM `bronze`.`tmdb_raw`
    WHERE release_date IS NOT NULL
)

SELECT
    cityHash64(release_date)                                    AS date_id,
    release_date                                                AS full_date,
    toYear(release_date)                                        AS year,
    toMonth(release_date)                                       AS month,
    toDayOfMonth(release_date)                                  AS day,
    toISOWeek(release_date)                                     AS week,
    formatDateTime(release_date, '%a')                          AS weekday,
    CASE
        WHEN toMonth(release_date) IN (12,1,2)  THEN 'Winter'
        WHEN toMonth(release_date) IN (3,4,5)   THEN 'Spring'
        WHEN toMonth(release_date) IN (6,7,8)   THEN 'Summer'
        WHEN toMonth(release_date) IN (9,10,11) THEN 'Autumn'
    END                                                         AS season,
    CASE
        WHEN formatDateTime(release_date, '%a') IN ('Saturday','Sunday') THEN 1
        ELSE 0
    END                                                         AS is_weekend,

    /* ---------- holiday tagging ---------- */
    CASE
        WHEN toMonth(release_date)=1  AND toDayOfMonth(release_date)=1  THEN 'New Years Day'
        WHEN toMonth(release_date)=2  AND toDayOfMonth(release_date)=14 THEN 'Valentines Day'
        WHEN toMonth(release_date)=3  AND toDayOfMonth(release_date)=17 THEN 'St. Patricks Day'
        WHEN toMonth(release_date)=4  AND toDayOfMonth(release_date)=1  THEN 'April Fools Day'
        WHEN toMonth(release_date)=4  AND toDayOfMonth(release_date)=22 THEN 'Earth Day'
        WHEN toMonth(release_date)=5  AND toDayOfMonth(release_date)=1  THEN 'May Day'
        WHEN toMonth(release_date)=5  AND toDayOfMonth(release_date)=5  THEN 'Cinco de Mayo'
        WHEN toMonth(release_date)=6  AND toDayOfMonth(release_date) BETWEEN 19 AND 26 THEN 'Midsummer'
        WHEN toMonth(release_date)=7  AND toDayOfMonth(release_date)=4  THEN 'Independence Day'
        WHEN toMonth(release_date)=9  AND toDayOfMonth(release_date) BETWEEN 1 AND 7 
             AND formatDateTime(release_date,'%a')='Monday'             THEN 'Labor Day (US)'
        WHEN toMonth(release_date)=10 AND toDayOfMonth(release_date)=31 THEN 'Halloween'
        WHEN toMonth(release_date)=11 AND formatDateTime(release_date,'%a')='Thursday'
             AND toISOWeek(release_date) >= 47                           THEN 'Thanksgiving'
        WHEN toMonth(release_date)=12 AND toDayOfMonth(release_date)=24 THEN 'Christmas Eve'
        WHEN toMonth(release_date)=12 AND toDayOfMonth(release_date)=25 THEN 'Christmas Day'
        WHEN toMonth(release_date)=12 AND toDayOfMonth(release_date)=31 THEN 'New Years Eve'
        ELSE NULL
    END                                                         AS holiday_name,
    IF(holiday_name IS NOT NULL, 1, 0)                          AS is_holiday,

    /* placeholders for later enhancement */
    CAST(NULL AS Nullable(Int32)) AS days_until_holiday,
    CAST(NULL AS Nullable(Int32)) AS days_after_holiday

FROM distinct_dates
ORDER BY release_date
          )
        
        ...
[0m11:53:47.874735 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m11:53:47.876352 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_release_date: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_release_date"} */

    select name, type from system.columns where table = 'dim_release_date'
    
      and database = 'gold_gold'
    
    order by position
  ...
[0m11:53:47.880233 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:53:47.881720 [debug] [Thread-1 (]: Writing runtime sql for node "model.movie_warehouse.dim_release_date"
[0m11:53:47.882398 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_release_date: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_release_date"} */

  
    
    
    
        
         


        insert into `gold_gold`.`dim_release_date`
        ("date_id", "full_date", "year", "month", "day", "week", "weekday", "season", "is_weekend", "holiday_name", "is_holiday", "days_until_holiday", "days_after_holiday")

WITH distinct_dates AS (
    SELECT DISTINCT release_date
    FROM `bronze`.`tmdb_raw`
    WHERE release_date IS NOT NULL
)

SELECT
    cityHash64(release_date)                                    AS date_id,
    release_date                                                AS full_date,
    toYear(release_date)                                        AS year,
    toMonth(release_date)                                       AS month,
    toDayOfMonth(release_date)                                  AS day,
    toISOWeek(release_date)                                     AS week,
    formatDateTime(release_date, '%a')                          AS weekday,
    CASE
        WHEN toMonth(release_date) IN (12,1,2)  THEN 'Winter'
        WHEN toMonth(release_date) IN (3,4,5)   THEN 'Spring'
        WHEN toMonth(release_date) IN (6,7,8)   THEN 'Summer'
        WHEN toMonth(release_date) IN (9,10,11) THEN 'Autumn'
    END                                                         AS season,
    CASE
        WHEN formatDateTime(release_date, '%a') IN ('Saturday','Sunday') THEN 1
        ELSE 0
    END                                                         AS is_weekend,

    /* ---------- holiday tagging ---------- */
    CASE
        WHEN toMonth(release_date)=1  AND toDayOfMonth(release_date)=1  THEN 'New Years Day'
        WHEN toMonth(release_date)=2  AND toDayOfMonth(release_date)=14 THEN 'Valentines Day'
        WHEN toMonth(release_date)=3  AND toDayOfMonth(release_date)=17 THEN 'St. Patricks Day'
        WHEN toMonth(release_date)=4  AND toDayOfMonth(release_date)=1  THEN 'April Fools Day'
        WHEN toMonth(release_date)=4  AND toDayOfMonth(release_date)=22 THEN 'Earth Day'
        WHEN toMonth(release_date)=5  AND toDayOfMonth(release_date)=1  THEN 'May Day'
        WHEN toMonth(release_date)=5  AND toDayOfMonth(release_date)=5  THEN 'Cinco de Mayo'
        WHEN toMonth(release_date)=6  AND toDayOfMonth(release_date) BETWEEN 19 AND 26 THEN 'Midsummer'
        WHEN toMonth(release_date)=7  AND toDayOfMonth(release_date)=4  THEN 'Independence Day'
        WHEN toMonth(release_date)=9  AND toDayOfMonth(release_date) BETWEEN 1 AND 7 
             AND formatDateTime(release_date,'%a')='Monday'             THEN 'Labor Day (US)'
        WHEN toMonth(release_date)=10 AND toDayOfMonth(release_date)=31 THEN 'Halloween'
        WHEN toMonth(release_date)=11 AND formatDateTime(release_date,'%a')='Thursday'
             AND toISOWeek(release_date) >= 47                           THEN 'Thanksgiving'
        WHEN toMonth(release_date)=12 AND toDayOfMonth(release_date)=24 THEN 'Christmas Eve'
        WHEN toMonth(release_date)=12 AND toDayOfMonth(release_date)=25 THEN 'Christmas Day'
        WHEN toMonth(release_date)=12 AND toDayOfMonth(release_date)=31 THEN 'New Years Eve'
        ELSE NULL
    END                                                         AS holiday_name,
    IF(holiday_name IS NOT NULL, 1, 0)                          AS is_holiday,

    /* placeholders for later enhancement */
    CAST(NULL AS Nullable(Int32)) AS days_until_holiday,
    CAST(NULL AS Nullable(Int32)) AS days_after_holiday

FROM distinct_dates
ORDER BY release_date
  ...
[0m11:53:47.915094 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.03 seconds
[0m11:53:47.916105 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e6767653-a2e2-440d-b246-32b7b51cbc97', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff6ffd7850>]}
[0m11:53:47.916473 [info ] [Thread-1 (]: 5 of 6 OK created sql table model `gold_gold`.`dim_release_date` ............... [[32mOK[0m in 0.06s]
[0m11:53:47.916819 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.dim_release_date
[0m11:53:47.918054 [debug] [Thread-1 (]: Began running node model.movie_warehouse.fact_movie
[0m11:53:47.918344 [info ] [Thread-1 (]: 6 of 6 START sql table model `gold_gold`.`fact_movie` .......................... [RUN]
[0m11:53:47.918704 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.movie_warehouse.dim_release_date, now model.movie_warehouse.fact_movie)
[0m11:53:47.918947 [debug] [Thread-1 (]: Began compiling node model.movie_warehouse.fact_movie
[0m11:53:47.922383 [debug] [Thread-1 (]: Writing injected SQL for node "model.movie_warehouse.fact_movie"
[0m11:53:47.922929 [debug] [Thread-1 (]: Began executing node model.movie_warehouse.fact_movie
[0m11:53:48.088414 [debug] [Thread-1 (]: Creating new relation fact_movie
[0m11:53:48.089489 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.fact_movie: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.fact_movie"} */

            

    
        create table `gold_gold`.`fact_movie`
        
  
        
  engine = MergeTree()
        order by (fact_id)
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

WITH latest_tmdb AS (
    SELECT
        *,
        row_number() OVER (PARTITION BY id ORDER BY ingestion_date DESC) AS rn
    FROM `bronze`.`tmdb_raw`
),

filtered_tmdb AS (
    SELECT *
    FROM latest_tmdb
    WHERE rn = 1
),

-- First genre
first_genre AS (
    SELECT
        id AS movie_id,
        trim(splitByChar(',', genres)[1]) AS genre_name
    FROM filtered_tmdb
),

-- First director
first_director AS (
    SELECT
        t.id AS movie_id,
        trim(splitByChar(',', c.directors)[1]) AS director_id
    FROM `bronze`.`tmdb_raw` t
    LEFT JOIN `bronze`.`imdb_title_crew_raw` c
        ON t.imdb_id = c.tconst
),

-- Join to dim_production to get production_id
movie_production AS (
    SELECT
        t.id AS movie_id,
        p.production_id
    FROM filtered_tmdb t
    LEFT JOIN `gold_gold`.`dim_production` p
        ON trim(splitByChar(',', t.production_companies)[1]) = p.production_name
),

-- Map genre_name to dim_genre to get genre_id
movie_genre AS (
    SELECT
        fg.movie_id,
        g.genre_id
    FROM first_genre fg
    LEFT JOIN `gold_gold`.`dim_genre` g
        ON fg.genre_name = g.genre_name
),

base AS (
    SELECT
        t.id                                      AS movie_id,
        d.director_id,
        mg.genre_id,
        mp.production_id,
        dr.date_id                                AS date_id,
        t.vote_average                            AS vote_avg,
        t.vote_count,
        t.revenue,
        t.budget,
        t.popularity                              AS movie_popularity,
        toYear(t.release_date)                    AS release_year
    FROM filtered_tmdb t
    LEFT JOIN movie_genre mg       ON mg.movie_id = t.id
    LEFT JOIN first_director d     ON d.movie_id = t.id
    LEFT JOIN movie_production mp  ON mp.movie_id = t.id
    LEFT JOIN `gold_gold`.`dim_release_date` dr
        ON dr.full_date = t.release_date
),

metrics AS (
    SELECT
        b.*,
        b.revenue - lag(b.revenue, 1) OVER (PARTITION BY b.movie_id ORDER BY b.release_year) AS revenue_growth,
        b.movie_popularity - lag(b.movie_popularity, 1) OVER (PARTITION BY b.movie_id ORDER BY b.release_year) AS popularity_change,
        b.vote_avg - lag(b.vote_avg, 1) OVER (PARTITION BY b.movie_id ORDER BY b.release_year) AS vote_avg_change
    FROM base b
)

SELECT
    cityHash64(concat(toString(movie_id), '-', toString(date_id))) AS fact_id,
    movie_id,
    director_id,
    genre_id,
    production_id,
    date_id,
    vote_avg,
    vote_count,
    revenue,
    budget,
    movie_popularity,
    revenue_growth,
    popularity_change,
    vote_avg_change
FROM metrics;
          )
        
        ...
[0m11:53:48.101705 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.fact_movie"} */

            

    
        create table `gold_gold`.`fact_movie`
        
  
        
  engine = MergeTree()
        order by (fact_id)
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

WITH latest_tmdb AS (
    SELECT
        *,
        row_number() OVER (PARTITION BY id ORDER BY ingestion_date DESC) AS rn
    FROM `bronze`.`tmdb_raw`
),

filtered_tmdb AS (
    SELECT *
    FROM latest_tmdb
    WHERE rn = 1
),

-- First genre
first_genre AS (
    SELECT
        id AS movie_id,
        trim(splitByChar(',', genres)[1]) AS genre_name
    FROM filtered_tmdb
),

-- First director
first_director AS (
    SELECT
        t.id AS movie_id,
        trim(splitByChar(',', c.directors)[1]) AS director_id
    FROM `bronze`.`tmdb_raw` t
    LEFT JOIN `bronze`.`imdb_title_crew_raw` c
        ON t.imdb_id = c.tconst
),

-- Join to dim_production to get production_id
movie_production AS (
    SELECT
        t.id AS movie_id,
        p.production_id
    FROM filtered_tmdb t
    LEFT JOIN `gold_gold`.`dim_production` p
        ON trim(splitByChar(',', t.production_companies)[1]) = p.production_name
),

-- Map genre_name to dim_genre to get genre_id
movie_genre AS (
    SELECT
        fg.movie_id,
        g.genre_id
    FROM first_genre fg
    LEFT JOIN `gold_gold`.`dim_genre` g
        ON fg.genre_name = g.genre_name
),

base AS (
    SELECT
        t.id                                      AS movie_id,
        d.director_id,
        mg.genre_id,
        mp.production_id,
        dr.date_id                                AS date_id,
        t.vote_average                            AS vote_avg,
        t.vote_count,
        t.revenue,
        t.budget,
        t.popularity                              AS movie_popularity,
        toYear(t.release_date)                    AS release_year
    FROM filtered_tmdb t
    LEFT JOIN movie_genre mg       ON mg.movie_id = t.id
    LEFT JOIN first_director d     ON d.movie_id = t.id
    LEFT JOIN movie_production mp  ON mp.movie_id = t.id
    LEFT JOIN `gold_gold`.`dim_release_date` dr
        ON dr.full_date = t.release_date
),

metrics AS (
    SELECT
        b.*,
        b.revenue - lag(b.revenue, 1) OVER (PARTITION BY b.movie_id ORDER BY b.release_year) AS revenue_growth,
        b.movie_popularity - lag(b.movie_popularity, 1) OVER (PARTITION BY b.movie_id ORDER BY b.release_year) AS popularity_change,
        b.vote_avg - lag(b.vote_avg, 1) OVER (PARTITION BY b.movie_id ORDER BY b.release_year) AS vote_avg_change
    FROM base b
)

SELECT
    cityHash64(concat(toString(movie_id), '-', toString(date_id))) AS fact_id,
    movie_id,
    director_id,
    genre_id,
    production_id,
    date_id,
    vote_avg,
    vote_count,
    revenue,
    budget,
    movie_popularity,
    revenue_growth,
    popularity_change,
    vote_avg_change
FROM metrics;
          )
        
        
[0m11:53:48.111206 [debug] [Thread-1 (]: Database Error in model fact_movie (models/gold/fact_movie.sql)
  :HTTPDriver for http://clickhouse-server:8123 returned response code 400)
   Code: 62. DB::Exception: Syntax error: failed at position 3123 (end of query) (line 120, col 13): ;
            )
          
          . Expected one of: token sequence, Dot, token, OpeningRoundBracket, UUID, alias, AS, identifier, FINAL, SAMPLE, table, table function, subquery or list of joined tables, array join, LEFT ARRAY JOIN, INNER, ARRAY JOIN, GLOBAL, LOCAL, ANY, ALL, ASOF, SEMI, ANTI, ONLY, LEFT, RIGHT, FULL, CROSS, PASTE, JOIN, PREWHERE, WHERE, GROUP BY, WITH, HAVING, WINDOW, QUALIFY, ORDER BY, LIMIT, OFFSET, FETCH, SETTINGS, UNION, EXCEPT, INTERSECT. (SYNTAX_ERROR) (version 25.9.3.48 (official build))
[0m11:53:48.111989 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e6767653-a2e2-440d-b246-32b7b51cbc97', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff6feaf850>]}
[0m11:53:48.112503 [error] [Thread-1 (]: 6 of 6 ERROR creating sql table model `gold_gold`.`fact_movie` ................. [[31mERROR[0m in 0.19s]
[0m11:53:48.113407 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.fact_movie
[0m11:53:48.117196 [debug] [MainThread]: Connection 'master' was properly closed.
[0m11:53:48.117713 [debug] [MainThread]: Connection 'model.movie_warehouse.fact_movie' was left open.
[0m11:53:48.118051 [debug] [MainThread]: On model.movie_warehouse.fact_movie: Close
[0m11:53:48.118525 [info ] [MainThread]: 
[0m11:53:48.118859 [info ] [MainThread]: Finished running 6 table models in 0 hours 0 minutes and 3.95 seconds (3.95s).
[0m11:53:48.119843 [debug] [MainThread]: Command end result
[0m11:53:48.165510 [info ] [MainThread]: 
[0m11:53:48.166462 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m11:53:48.166920 [info ] [MainThread]: 
[0m11:53:48.167567 [error] [MainThread]:   Database Error in model fact_movie (models/gold/fact_movie.sql)
  :HTTPDriver for http://clickhouse-server:8123 returned response code 400)
   Code: 62. DB::Exception: Syntax error: failed at position 3123 (end of query) (line 120, col 13): ;
            )
          
          . Expected one of: token sequence, Dot, token, OpeningRoundBracket, UUID, alias, AS, identifier, FINAL, SAMPLE, table, table function, subquery or list of joined tables, array join, LEFT ARRAY JOIN, INNER, ARRAY JOIN, GLOBAL, LOCAL, ANY, ALL, ASOF, SEMI, ANTI, ONLY, LEFT, RIGHT, FULL, CROSS, PASTE, JOIN, PREWHERE, WHERE, GROUP BY, WITH, HAVING, WINDOW, QUALIFY, ORDER BY, LIMIT, OFFSET, FETCH, SETTINGS, UNION, EXCEPT, INTERSECT. (SYNTAX_ERROR) (version 25.9.3.48 (official build))
[0m11:53:48.167837 [info ] [MainThread]: 
[0m11:53:48.168133 [info ] [MainThread]: Done. PASS=5 WARN=0 ERROR=1 SKIP=0 TOTAL=6
[0m11:53:48.171132 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 4.2598224, "process_in_blocks": "0", "process_kernel_time": 0.209977, "process_mem_max_rss": "189612", "process_out_blocks": "2404", "process_user_time": 1.95979}
[0m11:53:48.172699 [debug] [MainThread]: Command `dbt run` failed at 11:53:48.172626 after 4.26 seconds
[0m11:53:48.173073 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff938b5dd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff938eb650>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff938eb750>]}
[0m11:53:48.173390 [debug] [MainThread]: Flushing usage events
[0m11:55:16.274640 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff7f46d510>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff7f46cd10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff7f46cad0>]}


============================== 11:55:16.279900 | 756ba710-ace1-48e8-81f3-3ea3a40d6c06 ==============================
[0m11:55:16.279900 [info ] [MainThread]: Running with dbt=1.8.9
[0m11:55:16.280322 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'profiles_dir': '/opt/airflow/project_root/dbt', 'log_path': '/opt/airflow/project_root/dbt/logs', 'version_check': 'True', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'log_format': 'default', 'introspect': 'True', 'target_path': 'None', 'invocation_command': 'dbt run --project-dir /opt/airflow/project_root/dbt --profiles-dir /opt/airflow/project_root/dbt --select gold', 'send_anonymous_usage_stats': 'True'}
[0m11:55:16.349355 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '756ba710-ace1-48e8-81f3-3ea3a40d6c06', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff7f589c10>]}
[0m11:55:16.367729 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '756ba710-ace1-48e8-81f3-3ea3a40d6c06', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff7fe9b350>]}
[0m11:55:16.368173 [info ] [MainThread]: Registered adapter: clickhouse=1.8.9
[0m11:55:16.403662 [debug] [MainThread]: checksum: 132857a23e9d07220246854f7763165174ce9b737cfc7867629ace4294e520b1, vars: {}, profile: , target: , version: 1.8.9
[0m11:55:16.465744 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m11:55:16.466432 [debug] [MainThread]: Partial parsing: updated file: movie_warehouse://models/gold/fact_movie.sql
[0m11:55:16.569776 [warn ] [MainThread]: [[33mWARNING[0m]: Deprecated functionality
The `tests` config has been renamed to `data_tests`. Please see
https://docs.getdbt.com/docs/build/data-tests#new-data_tests-syntax for more
information.
[0m11:55:16.572161 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'deprecation', 'label': '756ba710-ace1-48e8-81f3-3ea3a40d6c06', 'property_': 'warn', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff7ee023d0>]}
[0m11:55:16.636371 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.movie_warehouse.bronze
[0m11:55:16.641749 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '756ba710-ace1-48e8-81f3-3ea3a40d6c06', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff7eeb3450>]}
[0m11:55:16.721281 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '756ba710-ace1-48e8-81f3-3ea3a40d6c06', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff7f0c55d0>]}
[0m11:55:16.721609 [info ] [MainThread]: Found 6 models, 12 data tests, 4 sources, 477 macros
[0m11:55:16.721803 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '756ba710-ace1-48e8-81f3-3ea3a40d6c06', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff7decb390>]}
[0m11:55:16.722633 [info ] [MainThread]: 
[0m11:55:16.722972 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m11:55:16.725814 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m11:55:16.733279 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:55:16.958016 [info ] [ThreadPool]: dbt_clickhouse adapter: Unexpected server exception dropping table
[0m11:55:16.958431 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m11:55:16.960123 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:55:17.016174 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__gold_gold)
[0m11:55:17.019023 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__gold_gold: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "connection_name": "list__gold_gold"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'gold_gold'
      

  ...
[0m11:55:17.023012 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:55:17.024199 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '756ba710-ace1-48e8-81f3-3ea3a40d6c06', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff7f04c110>]}
[0m11:55:17.024560 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m11:55:17.024846 [info ] [MainThread]: 
[0m11:55:17.028926 [debug] [Thread-1 (]: Began running node model.movie_warehouse.dim_director
[0m11:55:17.029265 [info ] [Thread-1 (]: 1 of 6 START sql table model `gold_gold`.`dim_director` ........................ [RUN]
[0m11:55:17.029515 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list__gold_gold, now model.movie_warehouse.dim_director)
[0m11:55:17.029707 [debug] [Thread-1 (]: Began compiling node model.movie_warehouse.dim_director
[0m11:55:17.033175 [debug] [Thread-1 (]: Writing injected SQL for node "model.movie_warehouse.dim_director"
[0m11:55:17.033991 [debug] [Thread-1 (]: Began executing node model.movie_warehouse.dim_director
[0m11:55:17.042006 [debug] [Thread-1 (]: Creating new relation dim_director
[0m11:55:17.054311 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_director: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_director"} */

            

    
        create table `gold_gold`.`dim_director`
        
  
        
  engine = MergeTree()
        order by (dir_id)
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

WITH first_dir AS (
    SELECT
        tconst,
        TRIM(splitByChar(',', directors)[1]) AS director_id
    FROM `bronze`.`imdb_title_crew_raw`
    WHERE directors IS NOT NULL AND directors != ''
),
deduped AS (
    SELECT DISTINCT director_id
    FROM first_dir
),
joined AS (
    SELECT
        d.director_id AS dir_id,
        n.primaryName AS dir_name
    FROM deduped d
    LEFT JOIN `bronze`.`imdb_name_basics_raw` n
        ON d.director_id = n.nconst
)
SELECT
    cityHash64(dir_id) AS imdb_dir_name_id,  -- Use hash instead of row_number
    dir_id,
    dir_name,
    today() AS valid_from,
    CAST(NULL AS Nullable(Date)) AS valid_to,
    1 AS is_current  -- Use 1/0 instead of TRUE/FALSE
FROM joined
WHERE dir_id IS NOT NULL
ORDER BY dir_id
          )
        
        ...
[0m11:55:17.061131 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m11:55:17.067678 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_director: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_director"} */

    select name, type from system.columns where table = 'dim_director'
    
      and database = 'gold_gold'
    
    order by position
  ...
[0m11:55:17.070248 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:55:17.072011 [debug] [Thread-1 (]: Writing runtime sql for node "model.movie_warehouse.dim_director"
[0m11:55:17.072928 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_director: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_director"} */

  
    
    
    
        
         


        insert into `gold_gold`.`dim_director`
        ("imdb_dir_name_id", "dir_id", "dir_name", "valid_from", "valid_to", "is_current")

WITH first_dir AS (
    SELECT
        tconst,
        TRIM(splitByChar(',', directors)[1]) AS director_id
    FROM `bronze`.`imdb_title_crew_raw`
    WHERE directors IS NOT NULL AND directors != ''
),
deduped AS (
    SELECT DISTINCT director_id
    FROM first_dir
),
joined AS (
    SELECT
        d.director_id AS dir_id,
        n.primaryName AS dir_name
    FROM deduped d
    LEFT JOIN `bronze`.`imdb_name_basics_raw` n
        ON d.director_id = n.nconst
)
SELECT
    cityHash64(dir_id) AS imdb_dir_name_id,  -- Use hash instead of row_number
    dir_id,
    dir_name,
    today() AS valid_from,
    CAST(NULL AS Nullable(Date)) AS valid_to,
    1 AS is_current  -- Use 1/0 instead of TRUE/FALSE
FROM joined
WHERE dir_id IS NOT NULL
ORDER BY dir_id
  ...
[0m11:55:18.971694 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 1.90 seconds
[0m11:55:18.996552 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '756ba710-ace1-48e8-81f3-3ea3a40d6c06', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff3aa56150>]}
[0m11:55:18.997640 [info ] [Thread-1 (]: 1 of 6 OK created sql table model `gold_gold`.`dim_director` ................... [[32mOK[0m in 1.97s]
[0m11:55:18.998295 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.dim_director
[0m11:55:18.998741 [debug] [Thread-1 (]: Began running node model.movie_warehouse.dim_genre
[0m11:55:18.999311 [info ] [Thread-1 (]: 2 of 6 START sql table model `gold_gold`.`dim_genre` ........................... [RUN]
[0m11:55:18.999602 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.movie_warehouse.dim_director, now model.movie_warehouse.dim_genre)
[0m11:55:18.999847 [debug] [Thread-1 (]: Began compiling node model.movie_warehouse.dim_genre
[0m11:55:19.003708 [debug] [Thread-1 (]: Writing injected SQL for node "model.movie_warehouse.dim_genre"
[0m11:55:19.004721 [debug] [Thread-1 (]: Began executing node model.movie_warehouse.dim_genre
[0m11:55:19.006001 [debug] [Thread-1 (]: Creating new relation dim_genre
[0m11:55:19.006706 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_genre: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_genre"} */

            

    
        create table `gold_gold`.`dim_genre`
        
  
        
  engine = MergeTree()
        order by (genre_id)
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

WITH parsed_genres AS (
    SELECT
        TRIM(splitByChar(',', genres)[1]) AS first_genre
    FROM `bronze`.`tmdb_raw`
    WHERE genres IS NOT NULL AND genres != ''
)
SELECT
    cityHash64(first_genre) AS genre_id,
    first_genre AS genre_name
FROM parsed_genres
GROUP BY first_genre
ORDER BY first_genre
          )
        
        ...
[0m11:55:19.023460 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m11:55:19.025281 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_genre: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_genre"} */

    select name, type from system.columns where table = 'dim_genre'
    
      and database = 'gold_gold'
    
    order by position
  ...
[0m11:55:19.028756 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:55:19.030097 [debug] [Thread-1 (]: Writing runtime sql for node "model.movie_warehouse.dim_genre"
[0m11:55:19.030956 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_genre: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_genre"} */

  
    
    
    
        
         


        insert into `gold_gold`.`dim_genre`
        ("genre_id", "genre_name")

WITH parsed_genres AS (
    SELECT
        TRIM(splitByChar(',', genres)[1]) AS first_genre
    FROM `bronze`.`tmdb_raw`
    WHERE genres IS NOT NULL AND genres != ''
)
SELECT
    cityHash64(first_genre) AS genre_id,
    first_genre AS genre_name
FROM parsed_genres
GROUP BY first_genre
ORDER BY first_genre
  ...
[0m11:55:19.054429 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m11:55:19.055888 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '756ba710-ace1-48e8-81f3-3ea3a40d6c06', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff3aa54290>]}
[0m11:55:19.056288 [info ] [Thread-1 (]: 2 of 6 OK created sql table model `gold_gold`.`dim_genre` ...................... [[32mOK[0m in 0.06s]
[0m11:55:19.056573 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.dim_genre
[0m11:55:19.056815 [debug] [Thread-1 (]: Began running node model.movie_warehouse.dim_movie
[0m11:55:19.057174 [info ] [Thread-1 (]: 3 of 6 START sql table model `gold_gold`.`dim_movie` ........................... [RUN]
[0m11:55:19.057436 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.movie_warehouse.dim_genre, now model.movie_warehouse.dim_movie)
[0m11:55:19.057652 [debug] [Thread-1 (]: Began compiling node model.movie_warehouse.dim_movie
[0m11:55:19.061070 [debug] [Thread-1 (]: Writing injected SQL for node "model.movie_warehouse.dim_movie"
[0m11:55:19.061999 [debug] [Thread-1 (]: Began executing node model.movie_warehouse.dim_movie
[0m11:55:19.063638 [debug] [Thread-1 (]: Creating new relation dim_movie
[0m11:55:19.064267 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_movie: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_movie"} */

            

    
        create table `gold_gold`.`dim_movie`
        
  
        
  engine = MergeTree()
        order by (movie_id)
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            -- ...existing code...


WITH movie_src AS (
    SELECT
        TRIM(title) AS movie_title,
        imdb_id,
        release_date,
        runtime AS movie_runtime,
        original_language AS language
    FROM `bronze`.`tmdb_raw`
    WHERE title IS NOT NULL AND title != ''
)
SELECT
    cityHash64(movie_title) AS movie_id,
    any(imdb_id) AS imdb_id,
    movie_title,
    any(release_date) AS release_date,
    any(movie_runtime) AS movie_runtime,
    any(language) AS language
FROM movie_src
GROUP BY movie_title
ORDER BY movie_title
          )
        
        ...
[0m11:55:19.071443 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m11:55:19.073097 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_movie: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_movie"} */

    select name, type from system.columns where table = 'dim_movie'
    
      and database = 'gold_gold'
    
    order by position
  ...
[0m11:55:19.076713 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:55:19.077994 [debug] [Thread-1 (]: Writing runtime sql for node "model.movie_warehouse.dim_movie"
[0m11:55:19.078714 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_movie: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_movie"} */

  
    
    
    
        
         


        insert into `gold_gold`.`dim_movie`
        ("movie_id", "imdb_id", "movie_title", "release_date", "movie_runtime", "language")-- ...existing code...


WITH movie_src AS (
    SELECT
        TRIM(title) AS movie_title,
        imdb_id,
        release_date,
        runtime AS movie_runtime,
        original_language AS language
    FROM `bronze`.`tmdb_raw`
    WHERE title IS NOT NULL AND title != ''
)
SELECT
    cityHash64(movie_title) AS movie_id,
    any(imdb_id) AS imdb_id,
    movie_title,
    any(release_date) AS release_date,
    any(movie_runtime) AS movie_runtime,
    any(language) AS language
FROM movie_src
GROUP BY movie_title
ORDER BY movie_title
  ...
[0m11:55:19.306439 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.23 seconds
[0m11:55:19.307647 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '756ba710-ace1-48e8-81f3-3ea3a40d6c06', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff3a9711d0>]}
[0m11:55:19.307977 [info ] [Thread-1 (]: 3 of 6 OK created sql table model `gold_gold`.`dim_movie` ...................... [[32mOK[0m in 0.25s]
[0m11:55:19.308261 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.dim_movie
[0m11:55:19.308465 [debug] [Thread-1 (]: Began running node model.movie_warehouse.dim_production
[0m11:55:19.308738 [info ] [Thread-1 (]: 4 of 6 START sql table model `gold_gold`.`dim_production` ...................... [RUN]
[0m11:55:19.308945 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.movie_warehouse.dim_movie, now model.movie_warehouse.dim_production)
[0m11:55:19.309112 [debug] [Thread-1 (]: Began compiling node model.movie_warehouse.dim_production
[0m11:55:19.310653 [debug] [Thread-1 (]: Writing injected SQL for node "model.movie_warehouse.dim_production"
[0m11:55:19.311364 [debug] [Thread-1 (]: Began executing node model.movie_warehouse.dim_production
[0m11:55:19.312735 [debug] [Thread-1 (]: Creating new relation dim_production
[0m11:55:19.313379 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_production: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_production"} */

            

    
        create table `gold_gold`.`dim_production`
        
  
        
  engine = MergeTree()
        order by (production_id)
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

WITH first_production AS (
    SELECT
        imdb_id AS movie_id,
        trim(splitByChar(',', production_companies)[1]) AS production_name
    FROM `bronze`.`tmdb_raw`
    WHERE production_companies IS NOT NULL AND production_companies != ''
)

SELECT
    cityHash64(production_name) AS production_id,
    production_name,
    current_date() AS valid_from,
    CAST(NULL AS Nullable(Date)) AS valid_to,
    TRUE AS is_current
FROM (
    SELECT DISTINCT production_name
    FROM first_production
)
WHERE production_name IS NOT NULL
          )
        
        ...
[0m11:55:19.319565 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m11:55:19.321492 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_production: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_production"} */

    select name, type from system.columns where table = 'dim_production'
    
      and database = 'gold_gold'
    
    order by position
  ...
[0m11:55:19.323961 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:55:19.325445 [debug] [Thread-1 (]: Writing runtime sql for node "model.movie_warehouse.dim_production"
[0m11:55:19.326195 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_production: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_production"} */

  
    
    
    
        
         


        insert into `gold_gold`.`dim_production`
        ("production_id", "production_name", "valid_from", "valid_to", "is_current")

WITH first_production AS (
    SELECT
        imdb_id AS movie_id,
        trim(splitByChar(',', production_companies)[1]) AS production_name
    FROM `bronze`.`tmdb_raw`
    WHERE production_companies IS NOT NULL AND production_companies != ''
)

SELECT
    cityHash64(production_name) AS production_id,
    production_name,
    current_date() AS valid_from,
    CAST(NULL AS Nullable(Date)) AS valid_to,
    TRUE AS is_current
FROM (
    SELECT DISTINCT production_name
    FROM first_production
)
WHERE production_name IS NOT NULL
  ...
[0m11:55:19.329795 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:55:19.330720 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '756ba710-ace1-48e8-81f3-3ea3a40d6c06', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff3ab04990>]}
[0m11:55:19.331115 [info ] [Thread-1 (]: 4 of 6 OK created sql table model `gold_gold`.`dim_production` ................. [[32mOK[0m in 0.02s]
[0m11:55:19.331864 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.dim_production
[0m11:55:19.332355 [debug] [Thread-1 (]: Began running node model.movie_warehouse.dim_release_date
[0m11:55:19.332783 [info ] [Thread-1 (]: 5 of 6 START sql table model `gold_gold`.`dim_release_date` .................... [RUN]
[0m11:55:19.333520 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.movie_warehouse.dim_production, now model.movie_warehouse.dim_release_date)
[0m11:55:19.333854 [debug] [Thread-1 (]: Began compiling node model.movie_warehouse.dim_release_date
[0m11:55:19.336157 [debug] [Thread-1 (]: Writing injected SQL for node "model.movie_warehouse.dim_release_date"
[0m11:55:19.336970 [debug] [Thread-1 (]: Began executing node model.movie_warehouse.dim_release_date
[0m11:55:19.338084 [debug] [Thread-1 (]: Creating new relation dim_release_date
[0m11:55:19.339322 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_release_date: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_release_date"} */

            

    
        create table `gold_gold`.`dim_release_date`
        
  
        
  engine = MergeTree()
        order by (date_id)
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

WITH distinct_dates AS (
    SELECT DISTINCT release_date
    FROM `bronze`.`tmdb_raw`
    WHERE release_date IS NOT NULL
)

SELECT
    cityHash64(release_date)                                    AS date_id,
    release_date                                                AS full_date,
    toYear(release_date)                                        AS year,
    toMonth(release_date)                                       AS month,
    toDayOfMonth(release_date)                                  AS day,
    toISOWeek(release_date)                                     AS week,
    formatDateTime(release_date, '%a')                          AS weekday,
    CASE
        WHEN toMonth(release_date) IN (12,1,2)  THEN 'Winter'
        WHEN toMonth(release_date) IN (3,4,5)   THEN 'Spring'
        WHEN toMonth(release_date) IN (6,7,8)   THEN 'Summer'
        WHEN toMonth(release_date) IN (9,10,11) THEN 'Autumn'
    END                                                         AS season,
    CASE
        WHEN formatDateTime(release_date, '%a') IN ('Saturday','Sunday') THEN 1
        ELSE 0
    END                                                         AS is_weekend,

    /* ---------- holiday tagging ---------- */
    CASE
        WHEN toMonth(release_date)=1  AND toDayOfMonth(release_date)=1  THEN 'New Years Day'
        WHEN toMonth(release_date)=2  AND toDayOfMonth(release_date)=14 THEN 'Valentines Day'
        WHEN toMonth(release_date)=3  AND toDayOfMonth(release_date)=17 THEN 'St. Patricks Day'
        WHEN toMonth(release_date)=4  AND toDayOfMonth(release_date)=1  THEN 'April Fools Day'
        WHEN toMonth(release_date)=4  AND toDayOfMonth(release_date)=22 THEN 'Earth Day'
        WHEN toMonth(release_date)=5  AND toDayOfMonth(release_date)=1  THEN 'May Day'
        WHEN toMonth(release_date)=5  AND toDayOfMonth(release_date)=5  THEN 'Cinco de Mayo'
        WHEN toMonth(release_date)=6  AND toDayOfMonth(release_date) BETWEEN 19 AND 26 THEN 'Midsummer'
        WHEN toMonth(release_date)=7  AND toDayOfMonth(release_date)=4  THEN 'Independence Day'
        WHEN toMonth(release_date)=9  AND toDayOfMonth(release_date) BETWEEN 1 AND 7 
             AND formatDateTime(release_date,'%a')='Monday'             THEN 'Labor Day (US)'
        WHEN toMonth(release_date)=10 AND toDayOfMonth(release_date)=31 THEN 'Halloween'
        WHEN toMonth(release_date)=11 AND formatDateTime(release_date,'%a')='Thursday'
             AND toISOWeek(release_date) >= 47                           THEN 'Thanksgiving'
        WHEN toMonth(release_date)=12 AND toDayOfMonth(release_date)=24 THEN 'Christmas Eve'
        WHEN toMonth(release_date)=12 AND toDayOfMonth(release_date)=25 THEN 'Christmas Day'
        WHEN toMonth(release_date)=12 AND toDayOfMonth(release_date)=31 THEN 'New Years Eve'
        ELSE NULL
    END                                                         AS holiday_name,
    IF(holiday_name IS NOT NULL, 1, 0)                          AS is_holiday,

    /* placeholders for later enhancement */
    CAST(NULL AS Nullable(Int32)) AS days_until_holiday,
    CAST(NULL AS Nullable(Int32)) AS days_after_holiday

FROM distinct_dates
ORDER BY release_date
          )
        
        ...
[0m11:55:19.351061 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m11:55:19.352430 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_release_date: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_release_date"} */

    select name, type from system.columns where table = 'dim_release_date'
    
      and database = 'gold_gold'
    
    order by position
  ...
[0m11:55:19.354417 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:55:19.355511 [debug] [Thread-1 (]: Writing runtime sql for node "model.movie_warehouse.dim_release_date"
[0m11:55:19.356034 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_release_date: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_release_date"} */

  
    
    
    
        
         


        insert into `gold_gold`.`dim_release_date`
        ("date_id", "full_date", "year", "month", "day", "week", "weekday", "season", "is_weekend", "holiday_name", "is_holiday", "days_until_holiday", "days_after_holiday")

WITH distinct_dates AS (
    SELECT DISTINCT release_date
    FROM `bronze`.`tmdb_raw`
    WHERE release_date IS NOT NULL
)

SELECT
    cityHash64(release_date)                                    AS date_id,
    release_date                                                AS full_date,
    toYear(release_date)                                        AS year,
    toMonth(release_date)                                       AS month,
    toDayOfMonth(release_date)                                  AS day,
    toISOWeek(release_date)                                     AS week,
    formatDateTime(release_date, '%a')                          AS weekday,
    CASE
        WHEN toMonth(release_date) IN (12,1,2)  THEN 'Winter'
        WHEN toMonth(release_date) IN (3,4,5)   THEN 'Spring'
        WHEN toMonth(release_date) IN (6,7,8)   THEN 'Summer'
        WHEN toMonth(release_date) IN (9,10,11) THEN 'Autumn'
    END                                                         AS season,
    CASE
        WHEN formatDateTime(release_date, '%a') IN ('Saturday','Sunday') THEN 1
        ELSE 0
    END                                                         AS is_weekend,

    /* ---------- holiday tagging ---------- */
    CASE
        WHEN toMonth(release_date)=1  AND toDayOfMonth(release_date)=1  THEN 'New Years Day'
        WHEN toMonth(release_date)=2  AND toDayOfMonth(release_date)=14 THEN 'Valentines Day'
        WHEN toMonth(release_date)=3  AND toDayOfMonth(release_date)=17 THEN 'St. Patricks Day'
        WHEN toMonth(release_date)=4  AND toDayOfMonth(release_date)=1  THEN 'April Fools Day'
        WHEN toMonth(release_date)=4  AND toDayOfMonth(release_date)=22 THEN 'Earth Day'
        WHEN toMonth(release_date)=5  AND toDayOfMonth(release_date)=1  THEN 'May Day'
        WHEN toMonth(release_date)=5  AND toDayOfMonth(release_date)=5  THEN 'Cinco de Mayo'
        WHEN toMonth(release_date)=6  AND toDayOfMonth(release_date) BETWEEN 19 AND 26 THEN 'Midsummer'
        WHEN toMonth(release_date)=7  AND toDayOfMonth(release_date)=4  THEN 'Independence Day'
        WHEN toMonth(release_date)=9  AND toDayOfMonth(release_date) BETWEEN 1 AND 7 
             AND formatDateTime(release_date,'%a')='Monday'             THEN 'Labor Day (US)'
        WHEN toMonth(release_date)=10 AND toDayOfMonth(release_date)=31 THEN 'Halloween'
        WHEN toMonth(release_date)=11 AND formatDateTime(release_date,'%a')='Thursday'
             AND toISOWeek(release_date) >= 47                           THEN 'Thanksgiving'
        WHEN toMonth(release_date)=12 AND toDayOfMonth(release_date)=24 THEN 'Christmas Eve'
        WHEN toMonth(release_date)=12 AND toDayOfMonth(release_date)=25 THEN 'Christmas Day'
        WHEN toMonth(release_date)=12 AND toDayOfMonth(release_date)=31 THEN 'New Years Eve'
        ELSE NULL
    END                                                         AS holiday_name,
    IF(holiday_name IS NOT NULL, 1, 0)                          AS is_holiday,

    /* placeholders for later enhancement */
    CAST(NULL AS Nullable(Int32)) AS days_until_holiday,
    CAST(NULL AS Nullable(Int32)) AS days_after_holiday

FROM distinct_dates
ORDER BY release_date
  ...
[0m11:55:19.381983 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.03 seconds
[0m11:55:19.383244 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '756ba710-ace1-48e8-81f3-3ea3a40d6c06', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff3a917310>]}
[0m11:55:19.383641 [info ] [Thread-1 (]: 5 of 6 OK created sql table model `gold_gold`.`dim_release_date` ............... [[32mOK[0m in 0.05s]
[0m11:55:19.383930 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.dim_release_date
[0m11:55:19.385081 [debug] [Thread-1 (]: Began running node model.movie_warehouse.fact_movie
[0m11:55:19.385434 [info ] [Thread-1 (]: 6 of 6 START sql table model `gold_gold`.`fact_movie` .......................... [RUN]
[0m11:55:19.385733 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.movie_warehouse.dim_release_date, now model.movie_warehouse.fact_movie)
[0m11:55:19.386055 [debug] [Thread-1 (]: Began compiling node model.movie_warehouse.fact_movie
[0m11:55:19.389167 [debug] [Thread-1 (]: Writing injected SQL for node "model.movie_warehouse.fact_movie"
[0m11:55:19.389976 [debug] [Thread-1 (]: Began executing node model.movie_warehouse.fact_movie
[0m11:55:19.392393 [debug] [Thread-1 (]: Creating new relation fact_movie
[0m11:55:19.393493 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.fact_movie: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.fact_movie"} */

            

    
        create table `gold_gold`.`fact_movie`
        
  
        
  engine = MergeTree()
        order by (fact_id)
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

WITH latest_tmdb AS (
    SELECT
        *,
        row_number() OVER (PARTITION BY id ORDER BY ingestion_date DESC) AS rn
    FROM `bronze`.`tmdb_raw`
),

filtered_tmdb AS (
    SELECT *
    FROM latest_tmdb
    WHERE rn = 1
),

-- First genre
first_genre AS (
    SELECT
        id AS movie_id,
        trim(splitByChar(',', genres)[1]) AS genre_name
    FROM filtered_tmdb
),

-- First director
first_director AS (
    SELECT
        t.id AS movie_id,
        trim(splitByChar(',', c.directors)[1]) AS director_id
    FROM `bronze`.`tmdb_raw` t
    LEFT JOIN `bronze`.`imdb_title_crew_raw` c
        ON t.imdb_id = c.tconst
),

-- Join to dim_production to get production_id
movie_production AS (
    SELECT
        t.id AS movie_id,
        p.production_id
    FROM filtered_tmdb t
    LEFT JOIN `gold_gold`.`dim_production` p
        ON trim(splitByChar(',', t.production_companies)[1]) = p.production_name
),

-- Map genre_name to dim_genre to get genre_id
movie_genre AS (
    SELECT
        fg.movie_id,
        g.genre_id
    FROM first_genre fg
    LEFT JOIN `gold_gold`.`dim_genre` g
        ON fg.genre_name = g.genre_name
),

base AS (
    SELECT
        t.id                                      AS movie_id,
        d.director_id,
        mg.genre_id,
        mp.production_id,
        dr.date_id                                AS date_id,
        t.vote_average                            AS vote_avg,
        t.vote_count,
        t.revenue,
        t.budget,
        t.popularity                              AS movie_popularity,
        toYear(t.release_date)                    AS release_year
    FROM filtered_tmdb t
    LEFT JOIN movie_genre mg       ON mg.movie_id = t.id
    LEFT JOIN first_director d     ON d.movie_id = t.id
    LEFT JOIN movie_production mp  ON mp.movie_id = t.id
    LEFT JOIN `gold_gold`.`dim_release_date` dr
        ON dr.full_date = t.release_date
),

metrics AS (
    SELECT
        b.*,
        b.revenue - lag(b.revenue, 1) OVER (PARTITION BY b.movie_id ORDER BY b.release_year) AS revenue_growth,
        b.movie_popularity - lag(b.movie_popularity, 1) OVER (PARTITION BY b.movie_id ORDER BY b.release_year) AS popularity_change,
        b.vote_avg - lag(b.vote_avg, 1) OVER (PARTITION BY b.movie_id ORDER BY b.release_year) AS vote_avg_change
    FROM base b
)

SELECT
    cityHash64(concat(toString(movie_id), '-', toString(date_id))) AS fact_id,
    movie_id,
    director_id,
    genre_id,
    production_id,
    date_id,
    vote_avg,
    vote_count,
    revenue,
    budget,
    movie_popularity,
    revenue_growth,
    popularity_change,
    vote_avg_change
FROM metrics
          )
        
        ...
[0m11:55:19.401976 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.fact_movie"} */

            

    
        create table `gold_gold`.`fact_movie`
        
  
        
  engine = MergeTree()
        order by (fact_id)
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

WITH latest_tmdb AS (
    SELECT
        *,
        row_number() OVER (PARTITION BY id ORDER BY ingestion_date DESC) AS rn
    FROM `bronze`.`tmdb_raw`
),

filtered_tmdb AS (
    SELECT *
    FROM latest_tmdb
    WHERE rn = 1
),

-- First genre
first_genre AS (
    SELECT
        id AS movie_id,
        trim(splitByChar(',', genres)[1]) AS genre_name
    FROM filtered_tmdb
),

-- First director
first_director AS (
    SELECT
        t.id AS movie_id,
        trim(splitByChar(',', c.directors)[1]) AS director_id
    FROM `bronze`.`tmdb_raw` t
    LEFT JOIN `bronze`.`imdb_title_crew_raw` c
        ON t.imdb_id = c.tconst
),

-- Join to dim_production to get production_id
movie_production AS (
    SELECT
        t.id AS movie_id,
        p.production_id
    FROM filtered_tmdb t
    LEFT JOIN `gold_gold`.`dim_production` p
        ON trim(splitByChar(',', t.production_companies)[1]) = p.production_name
),

-- Map genre_name to dim_genre to get genre_id
movie_genre AS (
    SELECT
        fg.movie_id,
        g.genre_id
    FROM first_genre fg
    LEFT JOIN `gold_gold`.`dim_genre` g
        ON fg.genre_name = g.genre_name
),

base AS (
    SELECT
        t.id                                      AS movie_id,
        d.director_id,
        mg.genre_id,
        mp.production_id,
        dr.date_id                                AS date_id,
        t.vote_average                            AS vote_avg,
        t.vote_count,
        t.revenue,
        t.budget,
        t.popularity                              AS movie_popularity,
        toYear(t.release_date)                    AS release_year
    FROM filtered_tmdb t
    LEFT JOIN movie_genre mg       ON mg.movie_id = t.id
    LEFT JOIN first_director d     ON d.movie_id = t.id
    LEFT JOIN movie_production mp  ON mp.movie_id = t.id
    LEFT JOIN `gold_gold`.`dim_release_date` dr
        ON dr.full_date = t.release_date
),

metrics AS (
    SELECT
        b.*,
        b.revenue - lag(b.revenue, 1) OVER (PARTITION BY b.movie_id ORDER BY b.release_year) AS revenue_growth,
        b.movie_popularity - lag(b.movie_popularity, 1) OVER (PARTITION BY b.movie_id ORDER BY b.release_year) AS popularity_change,
        b.vote_avg - lag(b.vote_avg, 1) OVER (PARTITION BY b.movie_id ORDER BY b.release_year) AS vote_avg_change
    FROM base b
)

SELECT
    cityHash64(concat(toString(movie_id), '-', toString(date_id))) AS fact_id,
    movie_id,
    director_id,
    genre_id,
    production_id,
    date_id,
    vote_avg,
    vote_count,
    revenue,
    budget,
    movie_popularity,
    revenue_growth,
    popularity_change,
    vote_avg_change
FROM metrics
          )
        
        
[0m11:55:19.406255 [debug] [Thread-1 (]: Database Error in model fact_movie (models/gold/fact_movie.sql)
  :HTTPDriver for http://clickhouse-server:8123 returned response code 404)
   Code: 47. DB::Exception: Unknown expression identifier `id` in scope  latest_tmdb. (UNKNOWN_IDENTIFIER) (version 25.9.3.48 (official build))
[0m11:55:19.406542 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '756ba710-ace1-48e8-81f3-3ea3a40d6c06', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff3a9dad90>]}
[0m11:55:19.406861 [error] [Thread-1 (]: 6 of 6 ERROR creating sql table model `gold_gold`.`fact_movie` ................. [[31mERROR[0m in 0.02s]
[0m11:55:19.407161 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.fact_movie
[0m11:55:19.408952 [debug] [MainThread]: Connection 'master' was properly closed.
[0m11:55:19.409199 [debug] [MainThread]: Connection 'model.movie_warehouse.fact_movie' was left open.
[0m11:55:19.409425 [debug] [MainThread]: On model.movie_warehouse.fact_movie: Close
[0m11:55:19.409855 [info ] [MainThread]: 
[0m11:55:19.410094 [info ] [MainThread]: Finished running 6 table models in 0 hours 0 minutes and 2.69 seconds (2.69s).
[0m11:55:19.410730 [debug] [MainThread]: Command end result
[0m11:55:19.433454 [info ] [MainThread]: 
[0m11:55:19.433732 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m11:55:19.433895 [info ] [MainThread]: 
[0m11:55:19.434087 [error] [MainThread]:   Database Error in model fact_movie (models/gold/fact_movie.sql)
  :HTTPDriver for http://clickhouse-server:8123 returned response code 404)
   Code: 47. DB::Exception: Unknown expression identifier `id` in scope  latest_tmdb. (UNKNOWN_IDENTIFIER) (version 25.9.3.48 (official build))
[0m11:55:19.434290 [info ] [MainThread]: 
[0m11:55:19.434530 [info ] [MainThread]: Done. PASS=5 WARN=0 ERROR=1 SKIP=0 TOTAL=6
[0m11:55:19.435958 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 3.1832592, "process_in_blocks": "0", "process_kernel_time": 0.257334, "process_mem_max_rss": "192864", "process_out_blocks": "3478", "process_user_time": 2.032019}
[0m11:55:19.436464 [debug] [MainThread]: Command `dbt run` failed at 11:55:19.436414 after 3.18 seconds
[0m11:55:19.436783 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff7f49f5d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff7f46e490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff7f46e410>]}
[0m11:55:19.436975 [debug] [MainThread]: Flushing usage events
[0m11:56:23.935496 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff7f27cf50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff7f2a9d90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff7f2af350>]}


============================== 11:56:23.938998 | ee902c7f-afa1-4269-9286-e429cb182412 ==============================
[0m11:56:23.938998 [info ] [MainThread]: Running with dbt=1.8.9
[0m11:56:23.939346 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/project_root/dbt', 'fail_fast': 'False', 'version_check': 'True', 'log_path': '/opt/airflow/project_root/dbt/logs', 'debug': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'log_format': 'default', 'introspect': 'True', 'target_path': 'None', 'invocation_command': 'dbt run --project-dir /opt/airflow/project_root/dbt --profiles-dir /opt/airflow/project_root/dbt --select gold', 'send_anonymous_usage_stats': 'True'}
[0m11:56:24.005152 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'ee902c7f-afa1-4269-9286-e429cb182412', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff7f2bd710>]}
[0m11:56:24.023817 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'ee902c7f-afa1-4269-9286-e429cb182412', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff7fcab350>]}
[0m11:56:24.024343 [info ] [MainThread]: Registered adapter: clickhouse=1.8.9
[0m11:56:24.055610 [debug] [MainThread]: checksum: 132857a23e9d07220246854f7763165174ce9b737cfc7867629ace4294e520b1, vars: {}, profile: , target: , version: 1.8.9
[0m11:56:24.108669 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m11:56:24.109093 [debug] [MainThread]: Partial parsing: updated file: movie_warehouse://models/gold/fact_movie.sql
[0m11:56:24.186030 [warn ] [MainThread]: [[33mWARNING[0m]: Deprecated functionality
The `tests` config has been renamed to `data_tests`. Please see
https://docs.getdbt.com/docs/build/data-tests#new-data_tests-syntax for more
information.
[0m11:56:24.186442 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'deprecation', 'label': 'ee902c7f-afa1-4269-9286-e429cb182412', 'property_': 'warn', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff7f2bc1d0>]}
[0m11:56:24.245969 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.movie_warehouse.bronze
[0m11:56:24.251181 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'ee902c7f-afa1-4269-9286-e429cb182412', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff7eefadd0>]}
[0m11:56:24.327054 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'ee902c7f-afa1-4269-9286-e429cb182412', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff7ecbf550>]}
[0m11:56:24.327368 [info ] [MainThread]: Found 6 models, 12 data tests, 4 sources, 477 macros
[0m11:56:24.327576 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'ee902c7f-afa1-4269-9286-e429cb182412', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff7dcfe090>]}
[0m11:56:24.328403 [info ] [MainThread]: 
[0m11:56:24.328718 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m11:56:24.331615 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m11:56:24.335809 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:56:24.672352 [info ] [ThreadPool]: dbt_clickhouse adapter: Unexpected server exception dropping table
[0m11:56:24.676078 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m11:56:24.688876 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m11:56:24.784995 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__gold_gold)
[0m11:56:24.788520 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__gold_gold: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "connection_name": "list__gold_gold"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'gold_gold'
      

  ...
[0m11:56:24.794181 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m11:56:24.795727 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'ee902c7f-afa1-4269-9286-e429cb182412', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff541226d0>]}
[0m11:56:24.796118 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m11:56:24.796415 [info ] [MainThread]: 
[0m11:56:24.801918 [debug] [Thread-1 (]: Began running node model.movie_warehouse.dim_director
[0m11:56:24.802409 [info ] [Thread-1 (]: 1 of 6 START sql table model `gold_gold`.`dim_director` ........................ [RUN]
[0m11:56:24.802757 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list__gold_gold, now model.movie_warehouse.dim_director)
[0m11:56:24.803006 [debug] [Thread-1 (]: Began compiling node model.movie_warehouse.dim_director
[0m11:56:24.806782 [debug] [Thread-1 (]: Writing injected SQL for node "model.movie_warehouse.dim_director"
[0m11:56:24.807660 [debug] [Thread-1 (]: Began executing node model.movie_warehouse.dim_director
[0m11:56:24.816271 [debug] [Thread-1 (]: Creating new relation dim_director
[0m11:56:24.831850 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_director: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_director"} */

            

    
        create table `gold_gold`.`dim_director`
        
  
        
  engine = MergeTree()
        order by (dir_id)
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

WITH first_dir AS (
    SELECT
        tconst,
        TRIM(splitByChar(',', directors)[1]) AS director_id
    FROM `bronze`.`imdb_title_crew_raw`
    WHERE directors IS NOT NULL AND directors != ''
),
deduped AS (
    SELECT DISTINCT director_id
    FROM first_dir
),
joined AS (
    SELECT
        d.director_id AS dir_id,
        n.primaryName AS dir_name
    FROM deduped d
    LEFT JOIN `bronze`.`imdb_name_basics_raw` n
        ON d.director_id = n.nconst
)
SELECT
    cityHash64(dir_id) AS imdb_dir_name_id,  -- Use hash instead of row_number
    dir_id,
    dir_name,
    today() AS valid_from,
    CAST(NULL AS Nullable(Date)) AS valid_to,
    1 AS is_current  -- Use 1/0 instead of TRUE/FALSE
FROM joined
WHERE dir_id IS NOT NULL
ORDER BY dir_id
          )
        
        ...
[0m11:56:24.840285 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m11:56:24.847857 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_director: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_director"} */

    select name, type from system.columns where table = 'dim_director'
    
      and database = 'gold_gold'
    
    order by position
  ...
[0m11:56:24.851133 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:56:24.853093 [debug] [Thread-1 (]: Writing runtime sql for node "model.movie_warehouse.dim_director"
[0m11:56:24.853837 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_director: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_director"} */

  
    
    
    
        
         


        insert into `gold_gold`.`dim_director`
        ("imdb_dir_name_id", "dir_id", "dir_name", "valid_from", "valid_to", "is_current")

WITH first_dir AS (
    SELECT
        tconst,
        TRIM(splitByChar(',', directors)[1]) AS director_id
    FROM `bronze`.`imdb_title_crew_raw`
    WHERE directors IS NOT NULL AND directors != ''
),
deduped AS (
    SELECT DISTINCT director_id
    FROM first_dir
),
joined AS (
    SELECT
        d.director_id AS dir_id,
        n.primaryName AS dir_name
    FROM deduped d
    LEFT JOIN `bronze`.`imdb_name_basics_raw` n
        ON d.director_id = n.nconst
)
SELECT
    cityHash64(dir_id) AS imdb_dir_name_id,  -- Use hash instead of row_number
    dir_id,
    dir_name,
    today() AS valid_from,
    CAST(NULL AS Nullable(Date)) AS valid_to,
    1 AS is_current  -- Use 1/0 instead of TRUE/FALSE
FROM joined
WHERE dir_id IS NOT NULL
ORDER BY dir_id
  ...
[0m11:56:27.052901 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 2.20 seconds
[0m11:56:27.091477 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ee902c7f-afa1-4269-9286-e429cb182412', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff3a86a350>]}
[0m11:56:27.093869 [info ] [Thread-1 (]: 1 of 6 OK created sql table model `gold_gold`.`dim_director` ................... [[32mOK[0m in 2.29s]
[0m11:56:27.095264 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.dim_director
[0m11:56:27.096943 [debug] [Thread-1 (]: Began running node model.movie_warehouse.dim_genre
[0m11:56:27.099564 [info ] [Thread-1 (]: 2 of 6 START sql table model `gold_gold`.`dim_genre` ........................... [RUN]
[0m11:56:27.100455 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.movie_warehouse.dim_director, now model.movie_warehouse.dim_genre)
[0m11:56:27.100793 [debug] [Thread-1 (]: Began compiling node model.movie_warehouse.dim_genre
[0m11:56:27.107583 [debug] [Thread-1 (]: Writing injected SQL for node "model.movie_warehouse.dim_genre"
[0m11:56:27.108892 [debug] [Thread-1 (]: Began executing node model.movie_warehouse.dim_genre
[0m11:56:27.110423 [debug] [Thread-1 (]: Creating new relation dim_genre
[0m11:56:27.111262 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_genre: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_genre"} */

            

    
        create table `gold_gold`.`dim_genre`
        
  
        
  engine = MergeTree()
        order by (genre_id)
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

WITH parsed_genres AS (
    SELECT
        TRIM(splitByChar(',', genres)[1]) AS first_genre
    FROM `bronze`.`tmdb_raw`
    WHERE genres IS NOT NULL AND genres != ''
)
SELECT
    cityHash64(first_genre) AS genre_id,
    first_genre AS genre_name
FROM parsed_genres
GROUP BY first_genre
ORDER BY first_genre
          )
        
        ...
[0m11:56:27.142639 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.03 seconds
[0m11:56:27.145620 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_genre: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_genre"} */

    select name, type from system.columns where table = 'dim_genre'
    
      and database = 'gold_gold'
    
    order by position
  ...
[0m11:56:27.153237 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m11:56:27.156801 [debug] [Thread-1 (]: Writing runtime sql for node "model.movie_warehouse.dim_genre"
[0m11:56:27.158303 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_genre: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_genre"} */

  
    
    
    
        
         


        insert into `gold_gold`.`dim_genre`
        ("genre_id", "genre_name")

WITH parsed_genres AS (
    SELECT
        TRIM(splitByChar(',', genres)[1]) AS first_genre
    FROM `bronze`.`tmdb_raw`
    WHERE genres IS NOT NULL AND genres != ''
)
SELECT
    cityHash64(first_genre) AS genre_id,
    first_genre AS genre_name
FROM parsed_genres
GROUP BY first_genre
ORDER BY first_genre
  ...
[0m11:56:27.204259 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m11:56:27.207981 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ee902c7f-afa1-4269-9286-e429cb182412', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff7ee47150>]}
[0m11:56:27.208572 [info ] [Thread-1 (]: 2 of 6 OK created sql table model `gold_gold`.`dim_genre` ...................... [[32mOK[0m in 0.11s]
[0m11:56:27.208921 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.dim_genre
[0m11:56:27.209513 [debug] [Thread-1 (]: Began running node model.movie_warehouse.dim_movie
[0m11:56:27.210136 [info ] [Thread-1 (]: 3 of 6 START sql table model `gold_gold`.`dim_movie` ........................... [RUN]
[0m11:56:27.210935 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.movie_warehouse.dim_genre, now model.movie_warehouse.dim_movie)
[0m11:56:27.211352 [debug] [Thread-1 (]: Began compiling node model.movie_warehouse.dim_movie
[0m11:56:27.216983 [debug] [Thread-1 (]: Writing injected SQL for node "model.movie_warehouse.dim_movie"
[0m11:56:27.217824 [debug] [Thread-1 (]: Began executing node model.movie_warehouse.dim_movie
[0m11:56:27.220431 [debug] [Thread-1 (]: Creating new relation dim_movie
[0m11:56:27.221514 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_movie: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_movie"} */

            

    
        create table `gold_gold`.`dim_movie`
        
  
        
  engine = MergeTree()
        order by (movie_id)
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            -- ...existing code...


WITH movie_src AS (
    SELECT
        TRIM(title) AS movie_title,
        imdb_id,
        release_date,
        runtime AS movie_runtime,
        original_language AS language
    FROM `bronze`.`tmdb_raw`
    WHERE title IS NOT NULL AND title != ''
)
SELECT
    cityHash64(movie_title) AS movie_id,
    any(imdb_id) AS imdb_id,
    movie_title,
    any(release_date) AS release_date,
    any(movie_runtime) AS movie_runtime,
    any(language) AS language
FROM movie_src
GROUP BY movie_title
ORDER BY movie_title
          )
        
        ...
[0m11:56:27.231264 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m11:56:27.234605 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_movie: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_movie"} */

    select name, type from system.columns where table = 'dim_movie'
    
      and database = 'gold_gold'
    
    order by position
  ...
[0m11:56:27.237524 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:56:27.238437 [debug] [Thread-1 (]: Writing runtime sql for node "model.movie_warehouse.dim_movie"
[0m11:56:27.238977 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_movie: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_movie"} */

  
    
    
    
        
         


        insert into `gold_gold`.`dim_movie`
        ("movie_id", "imdb_id", "movie_title", "release_date", "movie_runtime", "language")-- ...existing code...


WITH movie_src AS (
    SELECT
        TRIM(title) AS movie_title,
        imdb_id,
        release_date,
        runtime AS movie_runtime,
        original_language AS language
    FROM `bronze`.`tmdb_raw`
    WHERE title IS NOT NULL AND title != ''
)
SELECT
    cityHash64(movie_title) AS movie_id,
    any(imdb_id) AS imdb_id,
    movie_title,
    any(release_date) AS release_date,
    any(movie_runtime) AS movie_runtime,
    any(language) AS language
FROM movie_src
GROUP BY movie_title
ORDER BY movie_title
  ...
[0m11:56:27.675130 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.44 seconds
[0m11:56:27.676530 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ee902c7f-afa1-4269-9286-e429cb182412', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff7ec13d10>]}
[0m11:56:27.676927 [info ] [Thread-1 (]: 3 of 6 OK created sql table model `gold_gold`.`dim_movie` ...................... [[32mOK[0m in 0.47s]
[0m11:56:27.677254 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.dim_movie
[0m11:56:27.677553 [debug] [Thread-1 (]: Began running node model.movie_warehouse.dim_production
[0m11:56:27.677929 [info ] [Thread-1 (]: 4 of 6 START sql table model `gold_gold`.`dim_production` ...................... [RUN]
[0m11:56:27.678215 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.movie_warehouse.dim_movie, now model.movie_warehouse.dim_production)
[0m11:56:27.678458 [debug] [Thread-1 (]: Began compiling node model.movie_warehouse.dim_production
[0m11:56:27.680352 [debug] [Thread-1 (]: Writing injected SQL for node "model.movie_warehouse.dim_production"
[0m11:56:27.681022 [debug] [Thread-1 (]: Began executing node model.movie_warehouse.dim_production
[0m11:56:27.682659 [debug] [Thread-1 (]: Creating new relation dim_production
[0m11:56:27.683555 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_production: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_production"} */

            

    
        create table `gold_gold`.`dim_production`
        
  
        
  engine = MergeTree()
        order by (production_id)
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

WITH first_production AS (
    SELECT
        imdb_id AS movie_id,
        trim(splitByChar(',', production_companies)[1]) AS production_name
    FROM `bronze`.`tmdb_raw`
    WHERE production_companies IS NOT NULL AND production_companies != ''
)

SELECT
    cityHash64(production_name) AS production_id,
    production_name,
    current_date() AS valid_from,
    CAST(NULL AS Nullable(Date)) AS valid_to,
    TRUE AS is_current
FROM (
    SELECT DISTINCT production_name
    FROM first_production
)
WHERE production_name IS NOT NULL
          )
        
        ...
[0m11:56:27.690402 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m11:56:27.691782 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_production: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_production"} */

    select name, type from system.columns where table = 'dim_production'
    
      and database = 'gold_gold'
    
    order by position
  ...
[0m11:56:27.695923 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:56:27.697237 [debug] [Thread-1 (]: Writing runtime sql for node "model.movie_warehouse.dim_production"
[0m11:56:27.697919 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_production: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_production"} */

  
    
    
    
        
         


        insert into `gold_gold`.`dim_production`
        ("production_id", "production_name", "valid_from", "valid_to", "is_current")

WITH first_production AS (
    SELECT
        imdb_id AS movie_id,
        trim(splitByChar(',', production_companies)[1]) AS production_name
    FROM `bronze`.`tmdb_raw`
    WHERE production_companies IS NOT NULL AND production_companies != ''
)

SELECT
    cityHash64(production_name) AS production_id,
    production_name,
    current_date() AS valid_from,
    CAST(NULL AS Nullable(Date)) AS valid_to,
    TRUE AS is_current
FROM (
    SELECT DISTINCT production_name
    FROM first_production
)
WHERE production_name IS NOT NULL
  ...
[0m11:56:27.701997 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:56:27.703158 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ee902c7f-afa1-4269-9286-e429cb182412', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff3a85ae10>]}
[0m11:56:27.703562 [info ] [Thread-1 (]: 4 of 6 OK created sql table model `gold_gold`.`dim_production` ................. [[32mOK[0m in 0.02s]
[0m11:56:27.703863 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.dim_production
[0m11:56:27.704092 [debug] [Thread-1 (]: Began running node model.movie_warehouse.dim_release_date
[0m11:56:27.704380 [info ] [Thread-1 (]: 5 of 6 START sql table model `gold_gold`.`dim_release_date` .................... [RUN]
[0m11:56:27.704589 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.movie_warehouse.dim_production, now model.movie_warehouse.dim_release_date)
[0m11:56:27.704757 [debug] [Thread-1 (]: Began compiling node model.movie_warehouse.dim_release_date
[0m11:56:27.706533 [debug] [Thread-1 (]: Writing injected SQL for node "model.movie_warehouse.dim_release_date"
[0m11:56:27.706992 [debug] [Thread-1 (]: Began executing node model.movie_warehouse.dim_release_date
[0m11:56:27.708036 [debug] [Thread-1 (]: Creating new relation dim_release_date
[0m11:56:27.708607 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_release_date: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_release_date"} */

            

    
        create table `gold_gold`.`dim_release_date`
        
  
        
  engine = MergeTree()
        order by (date_id)
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

WITH distinct_dates AS (
    SELECT DISTINCT release_date
    FROM `bronze`.`tmdb_raw`
    WHERE release_date IS NOT NULL
)

SELECT
    cityHash64(release_date)                                    AS date_id,
    release_date                                                AS full_date,
    toYear(release_date)                                        AS year,
    toMonth(release_date)                                       AS month,
    toDayOfMonth(release_date)                                  AS day,
    toISOWeek(release_date)                                     AS week,
    formatDateTime(release_date, '%a')                          AS weekday,
    CASE
        WHEN toMonth(release_date) IN (12,1,2)  THEN 'Winter'
        WHEN toMonth(release_date) IN (3,4,5)   THEN 'Spring'
        WHEN toMonth(release_date) IN (6,7,8)   THEN 'Summer'
        WHEN toMonth(release_date) IN (9,10,11) THEN 'Autumn'
    END                                                         AS season,
    CASE
        WHEN formatDateTime(release_date, '%a') IN ('Saturday','Sunday') THEN 1
        ELSE 0
    END                                                         AS is_weekend,

    /* ---------- holiday tagging ---------- */
    CASE
        WHEN toMonth(release_date)=1  AND toDayOfMonth(release_date)=1  THEN 'New Years Day'
        WHEN toMonth(release_date)=2  AND toDayOfMonth(release_date)=14 THEN 'Valentines Day'
        WHEN toMonth(release_date)=3  AND toDayOfMonth(release_date)=17 THEN 'St. Patricks Day'
        WHEN toMonth(release_date)=4  AND toDayOfMonth(release_date)=1  THEN 'April Fools Day'
        WHEN toMonth(release_date)=4  AND toDayOfMonth(release_date)=22 THEN 'Earth Day'
        WHEN toMonth(release_date)=5  AND toDayOfMonth(release_date)=1  THEN 'May Day'
        WHEN toMonth(release_date)=5  AND toDayOfMonth(release_date)=5  THEN 'Cinco de Mayo'
        WHEN toMonth(release_date)=6  AND toDayOfMonth(release_date) BETWEEN 19 AND 26 THEN 'Midsummer'
        WHEN toMonth(release_date)=7  AND toDayOfMonth(release_date)=4  THEN 'Independence Day'
        WHEN toMonth(release_date)=9  AND toDayOfMonth(release_date) BETWEEN 1 AND 7 
             AND formatDateTime(release_date,'%a')='Monday'             THEN 'Labor Day (US)'
        WHEN toMonth(release_date)=10 AND toDayOfMonth(release_date)=31 THEN 'Halloween'
        WHEN toMonth(release_date)=11 AND formatDateTime(release_date,'%a')='Thursday'
             AND toISOWeek(release_date) >= 47                           THEN 'Thanksgiving'
        WHEN toMonth(release_date)=12 AND toDayOfMonth(release_date)=24 THEN 'Christmas Eve'
        WHEN toMonth(release_date)=12 AND toDayOfMonth(release_date)=25 THEN 'Christmas Day'
        WHEN toMonth(release_date)=12 AND toDayOfMonth(release_date)=31 THEN 'New Years Eve'
        ELSE NULL
    END                                                         AS holiday_name,
    IF(holiday_name IS NOT NULL, 1, 0)                          AS is_holiday,

    /* placeholders for later enhancement */
    CAST(NULL AS Nullable(Int32)) AS days_until_holiday,
    CAST(NULL AS Nullable(Int32)) AS days_after_holiday

FROM distinct_dates
ORDER BY release_date
          )
        
        ...
[0m11:56:27.730888 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m11:56:27.734376 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_release_date: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_release_date"} */

    select name, type from system.columns where table = 'dim_release_date'
    
      and database = 'gold_gold'
    
    order by position
  ...
[0m11:56:27.743221 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m11:56:27.744900 [debug] [Thread-1 (]: Writing runtime sql for node "model.movie_warehouse.dim_release_date"
[0m11:56:27.745617 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_release_date: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_release_date"} */

  
    
    
    
        
         


        insert into `gold_gold`.`dim_release_date`
        ("date_id", "full_date", "year", "month", "day", "week", "weekday", "season", "is_weekend", "holiday_name", "is_holiday", "days_until_holiday", "days_after_holiday")

WITH distinct_dates AS (
    SELECT DISTINCT release_date
    FROM `bronze`.`tmdb_raw`
    WHERE release_date IS NOT NULL
)

SELECT
    cityHash64(release_date)                                    AS date_id,
    release_date                                                AS full_date,
    toYear(release_date)                                        AS year,
    toMonth(release_date)                                       AS month,
    toDayOfMonth(release_date)                                  AS day,
    toISOWeek(release_date)                                     AS week,
    formatDateTime(release_date, '%a')                          AS weekday,
    CASE
        WHEN toMonth(release_date) IN (12,1,2)  THEN 'Winter'
        WHEN toMonth(release_date) IN (3,4,5)   THEN 'Spring'
        WHEN toMonth(release_date) IN (6,7,8)   THEN 'Summer'
        WHEN toMonth(release_date) IN (9,10,11) THEN 'Autumn'
    END                                                         AS season,
    CASE
        WHEN formatDateTime(release_date, '%a') IN ('Saturday','Sunday') THEN 1
        ELSE 0
    END                                                         AS is_weekend,

    /* ---------- holiday tagging ---------- */
    CASE
        WHEN toMonth(release_date)=1  AND toDayOfMonth(release_date)=1  THEN 'New Years Day'
        WHEN toMonth(release_date)=2  AND toDayOfMonth(release_date)=14 THEN 'Valentines Day'
        WHEN toMonth(release_date)=3  AND toDayOfMonth(release_date)=17 THEN 'St. Patricks Day'
        WHEN toMonth(release_date)=4  AND toDayOfMonth(release_date)=1  THEN 'April Fools Day'
        WHEN toMonth(release_date)=4  AND toDayOfMonth(release_date)=22 THEN 'Earth Day'
        WHEN toMonth(release_date)=5  AND toDayOfMonth(release_date)=1  THEN 'May Day'
        WHEN toMonth(release_date)=5  AND toDayOfMonth(release_date)=5  THEN 'Cinco de Mayo'
        WHEN toMonth(release_date)=6  AND toDayOfMonth(release_date) BETWEEN 19 AND 26 THEN 'Midsummer'
        WHEN toMonth(release_date)=7  AND toDayOfMonth(release_date)=4  THEN 'Independence Day'
        WHEN toMonth(release_date)=9  AND toDayOfMonth(release_date) BETWEEN 1 AND 7 
             AND formatDateTime(release_date,'%a')='Monday'             THEN 'Labor Day (US)'
        WHEN toMonth(release_date)=10 AND toDayOfMonth(release_date)=31 THEN 'Halloween'
        WHEN toMonth(release_date)=11 AND formatDateTime(release_date,'%a')='Thursday'
             AND toISOWeek(release_date) >= 47                           THEN 'Thanksgiving'
        WHEN toMonth(release_date)=12 AND toDayOfMonth(release_date)=24 THEN 'Christmas Eve'
        WHEN toMonth(release_date)=12 AND toDayOfMonth(release_date)=25 THEN 'Christmas Day'
        WHEN toMonth(release_date)=12 AND toDayOfMonth(release_date)=31 THEN 'New Years Eve'
        ELSE NULL
    END                                                         AS holiday_name,
    IF(holiday_name IS NOT NULL, 1, 0)                          AS is_holiday,

    /* placeholders for later enhancement */
    CAST(NULL AS Nullable(Int32)) AS days_until_holiday,
    CAST(NULL AS Nullable(Int32)) AS days_after_holiday

FROM distinct_dates
ORDER BY release_date
  ...
[0m11:56:27.776679 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.03 seconds
[0m11:56:27.778176 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ee902c7f-afa1-4269-9286-e429cb182412', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff7ec13d10>]}
[0m11:56:27.778624 [info ] [Thread-1 (]: 5 of 6 OK created sql table model `gold_gold`.`dim_release_date` ............... [[32mOK[0m in 0.07s]
[0m11:56:27.779015 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.dim_release_date
[0m11:56:27.780136 [debug] [Thread-1 (]: Began running node model.movie_warehouse.fact_movie
[0m11:56:27.780396 [info ] [Thread-1 (]: 6 of 6 START sql table model `gold_gold`.`fact_movie` .......................... [RUN]
[0m11:56:27.780618 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.movie_warehouse.dim_release_date, now model.movie_warehouse.fact_movie)
[0m11:56:27.780790 [debug] [Thread-1 (]: Began compiling node model.movie_warehouse.fact_movie
[0m11:56:27.783159 [debug] [Thread-1 (]: Writing injected SQL for node "model.movie_warehouse.fact_movie"
[0m11:56:27.783667 [debug] [Thread-1 (]: Began executing node model.movie_warehouse.fact_movie
[0m11:56:27.785699 [debug] [Thread-1 (]: Creating new relation fact_movie
[0m11:56:27.786305 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.fact_movie: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.fact_movie"} */

            

    
        create table `gold_gold`.`fact_movie`
        
  
        
  engine = MergeTree()
        order by (fact_id)
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

WITH latest_tmdb AS (
    SELECT
        id,
        imdb_id,
        title,
        release_date,
        genres,
        production_companies,
        vote_average,
        vote_count,
        revenue,
        budget,
        popularity,
        ingestion_date,
        row_number() OVER (PARTITION BY id ORDER BY ingestion_date DESC) AS rn
    FROM `bronze`.`tmdb_raw`
),

filtered_tmdb AS (
    SELECT 
        id,
        imdb_id,
        title,
        release_date,
        genres,
        production_companies,
        vote_average,
        vote_count,
        revenue,
        budget,
        popularity
    FROM latest_tmdb
    WHERE rn = 1
),

-- First genre
first_genre AS (
    SELECT
        id AS movie_id,
        trim(splitByChar(',', genres)[1]) AS genre_name
    FROM filtered_tmdb
),

-- First director
first_director AS (
    SELECT
        t.id AS movie_id,
        trim(splitByChar(',', c.directors)[1]) AS director_id
    FROM filtered_tmdb t
    LEFT JOIN `bronze`.`imdb_title_crew_raw` c
        ON t.imdb_id = c.tconst
),

-- Join to dim_production to get production_id
movie_production AS (
    SELECT
        t.id AS movie_id,
        p.production_id
    FROM filtered_tmdb t
    LEFT JOIN `gold_gold`.`dim_production` p
        ON trim(splitByChar(',', t.production_companies)[1]) = p.production_name
),

-- Map genre_name to dim_genre to get genre_id
movie_genre AS (
    SELECT
        fg.movie_id,
        g.genre_id
    FROM first_genre fg
    LEFT JOIN `gold_gold`.`dim_genre` g
        ON fg.genre_name = g.genre_name
),

base AS (
    SELECT
        t.id                                      AS movie_id,
        d.director_id,
        mg.genre_id,
        mp.production_id,
        dr.date_id                                AS date_id,
        t.vote_average                            AS vote_avg,
        t.vote_count,
        t.revenue,
        t.budget,
        t.popularity                              AS movie_popularity,
        toYear(t.release_date)                    AS release_year
    FROM filtered_tmdb t
    LEFT JOIN movie_genre mg       ON mg.movie_id = t.id
    LEFT JOIN first_director d     ON d.movie_id = t.id
    LEFT JOIN movie_production mp  ON mp.movie_id = t.id
    LEFT JOIN `gold_gold`.`dim_release_date` dr
        ON dr.full_date = t.release_date
),

metrics AS (
    SELECT
        b.*,
        b.revenue - lag(b.revenue, 1) OVER (PARTITION BY b.movie_id ORDER BY b.release_year) AS revenue_growth,
        b.movie_popularity - lag(b.movie_popularity, 1) OVER (PARTITION BY b.movie_id ORDER BY b.release_year) AS popularity_change,
        b.vote_avg - lag(b.vote_avg, 1) OVER (PARTITION BY b.movie_id ORDER BY b.release_year) AS vote_avg_change
    FROM base b
)

SELECT
    cityHash64(concat(toString(movie_id), '-', toString(date_id))) AS fact_id,
    movie_id,
    director_id,
    genre_id,
    production_id,
    date_id,
    vote_avg,
    vote_count,
    revenue,
    budget,
    movie_popularity,
    revenue_growth,
    popularity_change,
    vote_avg_change
FROM metrics
          )
        
        ...
[0m11:56:27.791217 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.fact_movie"} */

            

    
        create table `gold_gold`.`fact_movie`
        
  
        
  engine = MergeTree()
        order by (fact_id)
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

WITH latest_tmdb AS (
    SELECT
        id,
        imdb_id,
        title,
        release_date,
        genres,
        production_companies,
        vote_average,
        vote_count,
        revenue,
        budget,
        popularity,
        ingestion_date,
        row_number() OVER (PARTITION BY id ORDER BY ingestion_date DESC) AS rn
    FROM `bronze`.`tmdb_raw`
),

filtered_tmdb AS (
    SELECT 
        id,
        imdb_id,
        title,
        release_date,
        genres,
        production_companies,
        vote_average,
        vote_count,
        revenue,
        budget,
        popularity
    FROM latest_tmdb
    WHERE rn = 1
),

-- First genre
first_genre AS (
    SELECT
        id AS movie_id,
        trim(splitByChar(',', genres)[1]) AS genre_name
    FROM filtered_tmdb
),

-- First director
first_director AS (
    SELECT
        t.id AS movie_id,
        trim(splitByChar(',', c.directors)[1]) AS director_id
    FROM filtered_tmdb t
    LEFT JOIN `bronze`.`imdb_title_crew_raw` c
        ON t.imdb_id = c.tconst
),

-- Join to dim_production to get production_id
movie_production AS (
    SELECT
        t.id AS movie_id,
        p.production_id
    FROM filtered_tmdb t
    LEFT JOIN `gold_gold`.`dim_production` p
        ON trim(splitByChar(',', t.production_companies)[1]) = p.production_name
),

-- Map genre_name to dim_genre to get genre_id
movie_genre AS (
    SELECT
        fg.movie_id,
        g.genre_id
    FROM first_genre fg
    LEFT JOIN `gold_gold`.`dim_genre` g
        ON fg.genre_name = g.genre_name
),

base AS (
    SELECT
        t.id                                      AS movie_id,
        d.director_id,
        mg.genre_id,
        mp.production_id,
        dr.date_id                                AS date_id,
        t.vote_average                            AS vote_avg,
        t.vote_count,
        t.revenue,
        t.budget,
        t.popularity                              AS movie_popularity,
        toYear(t.release_date)                    AS release_year
    FROM filtered_tmdb t
    LEFT JOIN movie_genre mg       ON mg.movie_id = t.id
    LEFT JOIN first_director d     ON d.movie_id = t.id
    LEFT JOIN movie_production mp  ON mp.movie_id = t.id
    LEFT JOIN `gold_gold`.`dim_release_date` dr
        ON dr.full_date = t.release_date
),

metrics AS (
    SELECT
        b.*,
        b.revenue - lag(b.revenue, 1) OVER (PARTITION BY b.movie_id ORDER BY b.release_year) AS revenue_growth,
        b.movie_popularity - lag(b.movie_popularity, 1) OVER (PARTITION BY b.movie_id ORDER BY b.release_year) AS popularity_change,
        b.vote_avg - lag(b.vote_avg, 1) OVER (PARTITION BY b.movie_id ORDER BY b.release_year) AS vote_avg_change
    FROM base b
)

SELECT
    cityHash64(concat(toString(movie_id), '-', toString(date_id))) AS fact_id,
    movie_id,
    director_id,
    genre_id,
    production_id,
    date_id,
    vote_avg,
    vote_count,
    revenue,
    budget,
    movie_popularity,
    revenue_growth,
    popularity_change,
    vote_avg_change
FROM metrics
          )
        
        
[0m11:56:27.796193 [debug] [Thread-1 (]: Database Error in model fact_movie (models/gold/fact_movie.sql)
  :HTTPDriver for http://clickhouse-server:8123 returned response code 404)
   Code: 47. DB::Exception: Unknown expression identifier `id` in scope  latest_tmdb. (UNKNOWN_IDENTIFIER) (version 25.9.3.48 (official build))
[0m11:56:27.796572 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ee902c7f-afa1-4269-9286-e429cb182412', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff3a7d0d50>]}
[0m11:56:27.796905 [error] [Thread-1 (]: 6 of 6 ERROR creating sql table model `gold_gold`.`fact_movie` ................. [[31mERROR[0m in 0.02s]
[0m11:56:27.797237 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.fact_movie
[0m11:56:27.805385 [debug] [MainThread]: Connection 'master' was properly closed.
[0m11:56:27.805811 [debug] [MainThread]: Connection 'model.movie_warehouse.fact_movie' was left open.
[0m11:56:27.806033 [debug] [MainThread]: On model.movie_warehouse.fact_movie: Close
[0m11:56:27.806700 [info ] [MainThread]: 
[0m11:56:27.806982 [info ] [MainThread]: Finished running 6 table models in 0 hours 0 minutes and 3.48 seconds (3.48s).
[0m11:56:27.807775 [debug] [MainThread]: Command end result
[0m11:56:27.835935 [info ] [MainThread]: 
[0m11:56:27.836298 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m11:56:27.836490 [info ] [MainThread]: 
[0m11:56:27.836716 [error] [MainThread]:   Database Error in model fact_movie (models/gold/fact_movie.sql)
  :HTTPDriver for http://clickhouse-server:8123 returned response code 404)
   Code: 47. DB::Exception: Unknown expression identifier `id` in scope  latest_tmdb. (UNKNOWN_IDENTIFIER) (version 25.9.3.48 (official build))
[0m11:56:27.836890 [info ] [MainThread]: 
[0m11:56:27.837129 [info ] [MainThread]: Done. PASS=5 WARN=0 ERROR=1 SKIP=0 TOTAL=6
[0m11:56:27.846892 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 3.9301188, "process_in_blocks": "0", "process_kernel_time": 0.354438, "process_mem_max_rss": "192960", "process_out_blocks": "3486", "process_user_time": 2.033721}
[0m11:56:27.847799 [debug] [MainThread]: Command `dbt run` failed at 11:56:27.847729 after 3.93 seconds
[0m11:56:27.848302 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff7f2dbad0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff7f2db450>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff7f63e610>]}
[0m11:56:27.848546 [debug] [MainThread]: Flushing usage events
[0m11:58:35.770566 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff851fd1d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff86604750>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff851fce10>]}


============================== 11:58:35.774333 | de882833-8dbe-4eae-8ad1-339680c83224 ==============================
[0m11:58:35.774333 [info ] [MainThread]: Running with dbt=1.8.9
[0m11:58:35.774658 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/project_root/dbt', 'version_check': 'True', 'warn_error': 'None', 'log_path': '/opt/airflow/project_root/dbt/logs', 'debug': 'False', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'invocation_command': 'dbt run --project-dir /opt/airflow/project_root/dbt --profiles-dir /opt/airflow/project_root/dbt --select gold', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m11:58:35.845457 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'de882833-8dbe-4eae-8ad1-339680c83224', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff851784d0>]}
[0m11:58:35.863971 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'de882833-8dbe-4eae-8ad1-339680c83224', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff866fea90>]}
[0m11:58:35.864423 [info ] [MainThread]: Registered adapter: clickhouse=1.8.9
[0m11:58:35.896942 [debug] [MainThread]: checksum: 132857a23e9d07220246854f7763165174ce9b737cfc7867629ace4294e520b1, vars: {}, profile: , target: , version: 1.8.9
[0m11:58:35.951180 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m11:58:35.951580 [debug] [MainThread]: Partial parsing: updated file: movie_warehouse://models/gold/fact_movie.sql
[0m11:58:36.033267 [warn ] [MainThread]: [[33mWARNING[0m]: Deprecated functionality
The `tests` config has been renamed to `data_tests`. Please see
https://docs.getdbt.com/docs/build/data-tests#new-data_tests-syntax for more
information.
[0m11:58:36.033690 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'deprecation', 'label': 'de882833-8dbe-4eae-8ad1-339680c83224', 'property_': 'warn', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff84d51dd0>]}
[0m11:58:36.112235 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.movie_warehouse.bronze
[0m11:58:36.118009 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'de882833-8dbe-4eae-8ad1-339680c83224', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff84c52dd0>]}
[0m11:58:36.199959 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'de882833-8dbe-4eae-8ad1-339680c83224', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff84bbbe10>]}
[0m11:58:36.200298 [info ] [MainThread]: Found 6 models, 12 data tests, 4 sources, 477 macros
[0m11:58:36.200527 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'de882833-8dbe-4eae-8ad1-339680c83224', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff840b3490>]}
[0m11:58:36.201372 [info ] [MainThread]: 
[0m11:58:36.201750 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m11:58:36.204577 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m11:58:36.209231 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:58:36.482523 [info ] [ThreadPool]: dbt_clickhouse adapter: Unexpected server exception dropping table
[0m11:58:36.483019 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m11:58:36.485162 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:58:36.544750 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__gold_gold)
[0m11:58:36.547820 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__gold_gold: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "connection_name": "list__gold_gold"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'gold_gold'
      

  ...
[0m11:58:36.552720 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:58:36.553983 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'de882833-8dbe-4eae-8ad1-339680c83224', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff45d3ccd0>]}
[0m11:58:36.554319 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m11:58:36.554515 [info ] [MainThread]: 
[0m11:58:36.559753 [debug] [Thread-1 (]: Began running node model.movie_warehouse.dim_director
[0m11:58:36.560114 [info ] [Thread-1 (]: 1 of 6 START sql table model `gold_gold`.`dim_director` ........................ [RUN]
[0m11:58:36.560472 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list__gold_gold, now model.movie_warehouse.dim_director)
[0m11:58:36.560801 [debug] [Thread-1 (]: Began compiling node model.movie_warehouse.dim_director
[0m11:58:36.564424 [debug] [Thread-1 (]: Writing injected SQL for node "model.movie_warehouse.dim_director"
[0m11:58:36.566392 [debug] [Thread-1 (]: Began executing node model.movie_warehouse.dim_director
[0m11:58:36.575700 [debug] [Thread-1 (]: Creating new relation dim_director
[0m11:58:36.588369 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_director: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_director"} */

            

    
        create table `gold_gold`.`dim_director`
        
  
        
  engine = MergeTree()
        order by (dir_id)
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

WITH first_dir AS (
    SELECT
        tconst,
        TRIM(splitByChar(',', directors)[1]) AS director_id
    FROM `bronze`.`imdb_title_crew_raw`
    WHERE directors IS NOT NULL AND directors != ''
),
deduped AS (
    SELECT DISTINCT director_id
    FROM first_dir
),
joined AS (
    SELECT
        d.director_id AS dir_id,
        n.primaryName AS dir_name
    FROM deduped d
    LEFT JOIN `bronze`.`imdb_name_basics_raw` n
        ON d.director_id = n.nconst
)
SELECT
    cityHash64(dir_id) AS imdb_dir_name_id,  -- Use hash instead of row_number
    dir_id,
    dir_name,
    today() AS valid_from,
    CAST(NULL AS Nullable(Date)) AS valid_to,
    1 AS is_current  -- Use 1/0 instead of TRUE/FALSE
FROM joined
WHERE dir_id IS NOT NULL
ORDER BY dir_id
          )
        
        ...
[0m11:58:36.596213 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m11:58:36.603894 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_director: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_director"} */

    select name, type from system.columns where table = 'dim_director'
    
      and database = 'gold_gold'
    
    order by position
  ...
[0m11:58:36.606730 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:58:36.608744 [debug] [Thread-1 (]: Writing runtime sql for node "model.movie_warehouse.dim_director"
[0m11:58:36.609494 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_director: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_director"} */

  
    
    
    
        
         


        insert into `gold_gold`.`dim_director`
        ("imdb_dir_name_id", "dir_id", "dir_name", "valid_from", "valid_to", "is_current")

WITH first_dir AS (
    SELECT
        tconst,
        TRIM(splitByChar(',', directors)[1]) AS director_id
    FROM `bronze`.`imdb_title_crew_raw`
    WHERE directors IS NOT NULL AND directors != ''
),
deduped AS (
    SELECT DISTINCT director_id
    FROM first_dir
),
joined AS (
    SELECT
        d.director_id AS dir_id,
        n.primaryName AS dir_name
    FROM deduped d
    LEFT JOIN `bronze`.`imdb_name_basics_raw` n
        ON d.director_id = n.nconst
)
SELECT
    cityHash64(dir_id) AS imdb_dir_name_id,  -- Use hash instead of row_number
    dir_id,
    dir_name,
    today() AS valid_from,
    CAST(NULL AS Nullable(Date)) AS valid_to,
    1 AS is_current  -- Use 1/0 instead of TRUE/FALSE
FROM joined
WHERE dir_id IS NOT NULL
ORDER BY dir_id
  ...
[0m11:58:38.357744 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 1.75 seconds
[0m11:58:38.384892 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'de882833-8dbe-4eae-8ad1-339680c83224', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff44db3510>]}
[0m11:58:38.386274 [info ] [Thread-1 (]: 1 of 6 OK created sql table model `gold_gold`.`dim_director` ................... [[32mOK[0m in 1.82s]
[0m11:58:38.387048 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.dim_director
[0m11:58:38.388479 [debug] [Thread-1 (]: Began running node model.movie_warehouse.dim_genre
[0m11:58:38.389114 [info ] [Thread-1 (]: 2 of 6 START sql table model `gold_gold`.`dim_genre` ........................... [RUN]
[0m11:58:38.389555 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.movie_warehouse.dim_director, now model.movie_warehouse.dim_genre)
[0m11:58:38.389820 [debug] [Thread-1 (]: Began compiling node model.movie_warehouse.dim_genre
[0m11:58:38.393234 [debug] [Thread-1 (]: Writing injected SQL for node "model.movie_warehouse.dim_genre"
[0m11:58:38.394254 [debug] [Thread-1 (]: Began executing node model.movie_warehouse.dim_genre
[0m11:58:38.395729 [debug] [Thread-1 (]: Creating new relation dim_genre
[0m11:58:38.396458 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_genre: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_genre"} */

            

    
        create table `gold_gold`.`dim_genre`
        
  
        
  engine = MergeTree()
        order by (genre_id)
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

WITH parsed_genres AS (
    SELECT
        TRIM(splitByChar(',', genres)[1]) AS first_genre
    FROM `bronze`.`tmdb_raw`
    WHERE genres IS NOT NULL AND genres != ''
)
SELECT
    cityHash64(first_genre) AS genre_id,
    first_genre AS genre_name
FROM parsed_genres
GROUP BY first_genre
ORDER BY first_genre
          )
        
        ...
[0m11:58:38.413897 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m11:58:38.415693 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_genre: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_genre"} */

    select name, type from system.columns where table = 'dim_genre'
    
      and database = 'gold_gold'
    
    order by position
  ...
[0m11:58:38.419264 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:58:38.420551 [debug] [Thread-1 (]: Writing runtime sql for node "model.movie_warehouse.dim_genre"
[0m11:58:38.421386 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_genre: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_genre"} */

  
    
    
    
        
         


        insert into `gold_gold`.`dim_genre`
        ("genre_id", "genre_name")

WITH parsed_genres AS (
    SELECT
        TRIM(splitByChar(',', genres)[1]) AS first_genre
    FROM `bronze`.`tmdb_raw`
    WHERE genres IS NOT NULL AND genres != ''
)
SELECT
    cityHash64(first_genre) AS genre_id,
    first_genre AS genre_name
FROM parsed_genres
GROUP BY first_genre
ORDER BY first_genre
  ...
[0m11:58:38.443592 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m11:58:38.444803 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'de882833-8dbe-4eae-8ad1-339680c83224', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff4468da90>]}
[0m11:58:38.445164 [info ] [Thread-1 (]: 2 of 6 OK created sql table model `gold_gold`.`dim_genre` ...................... [[32mOK[0m in 0.06s]
[0m11:58:38.445445 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.dim_genre
[0m11:58:38.445673 [debug] [Thread-1 (]: Began running node model.movie_warehouse.dim_movie
[0m11:58:38.446145 [info ] [Thread-1 (]: 3 of 6 START sql table model `gold_gold`.`dim_movie` ........................... [RUN]
[0m11:58:38.446554 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.movie_warehouse.dim_genre, now model.movie_warehouse.dim_movie)
[0m11:58:38.446754 [debug] [Thread-1 (]: Began compiling node model.movie_warehouse.dim_movie
[0m11:58:38.450004 [debug] [Thread-1 (]: Writing injected SQL for node "model.movie_warehouse.dim_movie"
[0m11:58:38.450841 [debug] [Thread-1 (]: Began executing node model.movie_warehouse.dim_movie
[0m11:58:38.452013 [debug] [Thread-1 (]: Creating new relation dim_movie
[0m11:58:38.452575 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_movie: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_movie"} */

            

    
        create table `gold_gold`.`dim_movie`
        
  
        
  engine = MergeTree()
        order by (movie_id)
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            -- ...existing code...


WITH movie_src AS (
    SELECT
        TRIM(title) AS movie_title,
        imdb_id,
        release_date,
        runtime AS movie_runtime,
        original_language AS language
    FROM `bronze`.`tmdb_raw`
    WHERE title IS NOT NULL AND title != ''
)
SELECT
    cityHash64(movie_title) AS movie_id,
    any(imdb_id) AS imdb_id,
    movie_title,
    any(release_date) AS release_date,
    any(movie_runtime) AS movie_runtime,
    any(language) AS language
FROM movie_src
GROUP BY movie_title
ORDER BY movie_title
          )
        
        ...
[0m11:58:38.460210 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m11:58:38.462724 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_movie: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_movie"} */

    select name, type from system.columns where table = 'dim_movie'
    
      and database = 'gold_gold'
    
    order by position
  ...
[0m11:58:38.466510 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:58:38.467678 [debug] [Thread-1 (]: Writing runtime sql for node "model.movie_warehouse.dim_movie"
[0m11:58:38.468227 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_movie: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_movie"} */

  
    
    
    
        
         


        insert into `gold_gold`.`dim_movie`
        ("movie_id", "imdb_id", "movie_title", "release_date", "movie_runtime", "language")-- ...existing code...


WITH movie_src AS (
    SELECT
        TRIM(title) AS movie_title,
        imdb_id,
        release_date,
        runtime AS movie_runtime,
        original_language AS language
    FROM `bronze`.`tmdb_raw`
    WHERE title IS NOT NULL AND title != ''
)
SELECT
    cityHash64(movie_title) AS movie_id,
    any(imdb_id) AS imdb_id,
    movie_title,
    any(release_date) AS release_date,
    any(movie_runtime) AS movie_runtime,
    any(language) AS language
FROM movie_src
GROUP BY movie_title
ORDER BY movie_title
  ...
[0m11:58:38.750805 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.28 seconds
[0m11:58:38.752317 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'de882833-8dbe-4eae-8ad1-339680c83224', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff84bbbb50>]}
[0m11:58:38.752729 [info ] [Thread-1 (]: 3 of 6 OK created sql table model `gold_gold`.`dim_movie` ...................... [[32mOK[0m in 0.31s]
[0m11:58:38.753222 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.dim_movie
[0m11:58:38.753602 [debug] [Thread-1 (]: Began running node model.movie_warehouse.dim_production
[0m11:58:38.754079 [info ] [Thread-1 (]: 4 of 6 START sql table model `gold_gold`.`dim_production` ...................... [RUN]
[0m11:58:38.754397 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.movie_warehouse.dim_movie, now model.movie_warehouse.dim_production)
[0m11:58:38.754636 [debug] [Thread-1 (]: Began compiling node model.movie_warehouse.dim_production
[0m11:58:38.756619 [debug] [Thread-1 (]: Writing injected SQL for node "model.movie_warehouse.dim_production"
[0m11:58:38.757616 [debug] [Thread-1 (]: Began executing node model.movie_warehouse.dim_production
[0m11:58:38.758906 [debug] [Thread-1 (]: Creating new relation dim_production
[0m11:58:38.759538 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_production: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_production"} */

            

    
        create table `gold_gold`.`dim_production`
        
  
        
  engine = MergeTree()
        order by (production_id)
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

WITH first_production AS (
    SELECT
        imdb_id AS movie_id,
        trim(splitByChar(',', production_companies)[1]) AS production_name
    FROM `bronze`.`tmdb_raw`
    WHERE production_companies IS NOT NULL AND production_companies != ''
)

SELECT
    cityHash64(production_name) AS production_id,
    production_name,
    current_date() AS valid_from,
    CAST(NULL AS Nullable(Date)) AS valid_to,
    TRUE AS is_current
FROM (
    SELECT DISTINCT production_name
    FROM first_production
)
WHERE production_name IS NOT NULL
          )
        
        ...
[0m11:58:38.766383 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m11:58:38.768201 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_production: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_production"} */

    select name, type from system.columns where table = 'dim_production'
    
      and database = 'gold_gold'
    
    order by position
  ...
[0m11:58:38.771318 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:58:38.772918 [debug] [Thread-1 (]: Writing runtime sql for node "model.movie_warehouse.dim_production"
[0m11:58:38.773766 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_production: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_production"} */

  
    
    
    
        
         


        insert into `gold_gold`.`dim_production`
        ("production_id", "production_name", "valid_from", "valid_to", "is_current")

WITH first_production AS (
    SELECT
        imdb_id AS movie_id,
        trim(splitByChar(',', production_companies)[1]) AS production_name
    FROM `bronze`.`tmdb_raw`
    WHERE production_companies IS NOT NULL AND production_companies != ''
)

SELECT
    cityHash64(production_name) AS production_id,
    production_name,
    current_date() AS valid_from,
    CAST(NULL AS Nullable(Date)) AS valid_to,
    TRUE AS is_current
FROM (
    SELECT DISTINCT production_name
    FROM first_production
)
WHERE production_name IS NOT NULL
  ...
[0m11:58:38.779544 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m11:58:38.780649 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'de882833-8dbe-4eae-8ad1-339680c83224', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff84bda810>]}
[0m11:58:38.781175 [info ] [Thread-1 (]: 4 of 6 OK created sql table model `gold_gold`.`dim_production` ................. [[32mOK[0m in 0.03s]
[0m11:58:38.781686 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.dim_production
[0m11:58:38.782058 [debug] [Thread-1 (]: Began running node model.movie_warehouse.dim_release_date
[0m11:58:38.782714 [info ] [Thread-1 (]: 5 of 6 START sql table model `gold_gold`.`dim_release_date` .................... [RUN]
[0m11:58:38.782976 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.movie_warehouse.dim_production, now model.movie_warehouse.dim_release_date)
[0m11:58:38.783150 [debug] [Thread-1 (]: Began compiling node model.movie_warehouse.dim_release_date
[0m11:58:38.785072 [debug] [Thread-1 (]: Writing injected SQL for node "model.movie_warehouse.dim_release_date"
[0m11:58:38.785682 [debug] [Thread-1 (]: Began executing node model.movie_warehouse.dim_release_date
[0m11:58:38.786878 [debug] [Thread-1 (]: Creating new relation dim_release_date
[0m11:58:38.787460 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_release_date: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_release_date"} */

            

    
        create table `gold_gold`.`dim_release_date`
        
  
        
  engine = MergeTree()
        order by (date_id)
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

WITH distinct_dates AS (
    SELECT DISTINCT release_date
    FROM `bronze`.`tmdb_raw`
    WHERE release_date IS NOT NULL
)

SELECT
    cityHash64(release_date)                                    AS date_id,
    release_date                                                AS full_date,
    toYear(release_date)                                        AS year,
    toMonth(release_date)                                       AS month,
    toDayOfMonth(release_date)                                  AS day,
    toISOWeek(release_date)                                     AS week,
    formatDateTime(release_date, '%a')                          AS weekday,
    CASE
        WHEN toMonth(release_date) IN (12,1,2)  THEN 'Winter'
        WHEN toMonth(release_date) IN (3,4,5)   THEN 'Spring'
        WHEN toMonth(release_date) IN (6,7,8)   THEN 'Summer'
        WHEN toMonth(release_date) IN (9,10,11) THEN 'Autumn'
    END                                                         AS season,
    CASE
        WHEN formatDateTime(release_date, '%a') IN ('Saturday','Sunday') THEN 1
        ELSE 0
    END                                                         AS is_weekend,

    /* ---------- holiday tagging ---------- */
    CASE
        WHEN toMonth(release_date)=1  AND toDayOfMonth(release_date)=1  THEN 'New Years Day'
        WHEN toMonth(release_date)=2  AND toDayOfMonth(release_date)=14 THEN 'Valentines Day'
        WHEN toMonth(release_date)=3  AND toDayOfMonth(release_date)=17 THEN 'St. Patricks Day'
        WHEN toMonth(release_date)=4  AND toDayOfMonth(release_date)=1  THEN 'April Fools Day'
        WHEN toMonth(release_date)=4  AND toDayOfMonth(release_date)=22 THEN 'Earth Day'
        WHEN toMonth(release_date)=5  AND toDayOfMonth(release_date)=1  THEN 'May Day'
        WHEN toMonth(release_date)=5  AND toDayOfMonth(release_date)=5  THEN 'Cinco de Mayo'
        WHEN toMonth(release_date)=6  AND toDayOfMonth(release_date) BETWEEN 19 AND 26 THEN 'Midsummer'
        WHEN toMonth(release_date)=7  AND toDayOfMonth(release_date)=4  THEN 'Independence Day'
        WHEN toMonth(release_date)=9  AND toDayOfMonth(release_date) BETWEEN 1 AND 7 
             AND formatDateTime(release_date,'%a')='Monday'             THEN 'Labor Day (US)'
        WHEN toMonth(release_date)=10 AND toDayOfMonth(release_date)=31 THEN 'Halloween'
        WHEN toMonth(release_date)=11 AND formatDateTime(release_date,'%a')='Thursday'
             AND toISOWeek(release_date) >= 47                           THEN 'Thanksgiving'
        WHEN toMonth(release_date)=12 AND toDayOfMonth(release_date)=24 THEN 'Christmas Eve'
        WHEN toMonth(release_date)=12 AND toDayOfMonth(release_date)=25 THEN 'Christmas Day'
        WHEN toMonth(release_date)=12 AND toDayOfMonth(release_date)=31 THEN 'New Years Eve'
        ELSE NULL
    END                                                         AS holiday_name,
    IF(holiday_name IS NOT NULL, 1, 0)                          AS is_holiday,

    /* placeholders for later enhancement */
    CAST(NULL AS Nullable(Int32)) AS days_until_holiday,
    CAST(NULL AS Nullable(Int32)) AS days_after_holiday

FROM distinct_dates
ORDER BY release_date
          )
        
        ...
[0m11:58:38.799462 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m11:58:38.800916 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_release_date: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_release_date"} */

    select name, type from system.columns where table = 'dim_release_date'
    
      and database = 'gold_gold'
    
    order by position
  ...
[0m11:58:38.803179 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:58:38.804417 [debug] [Thread-1 (]: Writing runtime sql for node "model.movie_warehouse.dim_release_date"
[0m11:58:38.804970 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_release_date: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_release_date"} */

  
    
    
    
        
         


        insert into `gold_gold`.`dim_release_date`
        ("date_id", "full_date", "year", "month", "day", "week", "weekday", "season", "is_weekend", "holiday_name", "is_holiday", "days_until_holiday", "days_after_holiday")

WITH distinct_dates AS (
    SELECT DISTINCT release_date
    FROM `bronze`.`tmdb_raw`
    WHERE release_date IS NOT NULL
)

SELECT
    cityHash64(release_date)                                    AS date_id,
    release_date                                                AS full_date,
    toYear(release_date)                                        AS year,
    toMonth(release_date)                                       AS month,
    toDayOfMonth(release_date)                                  AS day,
    toISOWeek(release_date)                                     AS week,
    formatDateTime(release_date, '%a')                          AS weekday,
    CASE
        WHEN toMonth(release_date) IN (12,1,2)  THEN 'Winter'
        WHEN toMonth(release_date) IN (3,4,5)   THEN 'Spring'
        WHEN toMonth(release_date) IN (6,7,8)   THEN 'Summer'
        WHEN toMonth(release_date) IN (9,10,11) THEN 'Autumn'
    END                                                         AS season,
    CASE
        WHEN formatDateTime(release_date, '%a') IN ('Saturday','Sunday') THEN 1
        ELSE 0
    END                                                         AS is_weekend,

    /* ---------- holiday tagging ---------- */
    CASE
        WHEN toMonth(release_date)=1  AND toDayOfMonth(release_date)=1  THEN 'New Years Day'
        WHEN toMonth(release_date)=2  AND toDayOfMonth(release_date)=14 THEN 'Valentines Day'
        WHEN toMonth(release_date)=3  AND toDayOfMonth(release_date)=17 THEN 'St. Patricks Day'
        WHEN toMonth(release_date)=4  AND toDayOfMonth(release_date)=1  THEN 'April Fools Day'
        WHEN toMonth(release_date)=4  AND toDayOfMonth(release_date)=22 THEN 'Earth Day'
        WHEN toMonth(release_date)=5  AND toDayOfMonth(release_date)=1  THEN 'May Day'
        WHEN toMonth(release_date)=5  AND toDayOfMonth(release_date)=5  THEN 'Cinco de Mayo'
        WHEN toMonth(release_date)=6  AND toDayOfMonth(release_date) BETWEEN 19 AND 26 THEN 'Midsummer'
        WHEN toMonth(release_date)=7  AND toDayOfMonth(release_date)=4  THEN 'Independence Day'
        WHEN toMonth(release_date)=9  AND toDayOfMonth(release_date) BETWEEN 1 AND 7 
             AND formatDateTime(release_date,'%a')='Monday'             THEN 'Labor Day (US)'
        WHEN toMonth(release_date)=10 AND toDayOfMonth(release_date)=31 THEN 'Halloween'
        WHEN toMonth(release_date)=11 AND formatDateTime(release_date,'%a')='Thursday'
             AND toISOWeek(release_date) >= 47                           THEN 'Thanksgiving'
        WHEN toMonth(release_date)=12 AND toDayOfMonth(release_date)=24 THEN 'Christmas Eve'
        WHEN toMonth(release_date)=12 AND toDayOfMonth(release_date)=25 THEN 'Christmas Day'
        WHEN toMonth(release_date)=12 AND toDayOfMonth(release_date)=31 THEN 'New Years Eve'
        ELSE NULL
    END                                                         AS holiday_name,
    IF(holiday_name IS NOT NULL, 1, 0)                          AS is_holiday,

    /* placeholders for later enhancement */
    CAST(NULL AS Nullable(Int32)) AS days_until_holiday,
    CAST(NULL AS Nullable(Int32)) AS days_after_holiday

FROM distinct_dates
ORDER BY release_date
  ...
[0m11:58:38.840707 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.04 seconds
[0m11:58:38.843497 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'de882833-8dbe-4eae-8ad1-339680c83224', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff84f668d0>]}
[0m11:58:38.843930 [info ] [Thread-1 (]: 5 of 6 OK created sql table model `gold_gold`.`dim_release_date` ............... [[32mOK[0m in 0.06s]
[0m11:58:38.844250 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.dim_release_date
[0m11:58:38.845190 [debug] [Thread-1 (]: Began running node model.movie_warehouse.fact_movie
[0m11:58:38.845471 [info ] [Thread-1 (]: 6 of 6 START sql table model `gold_gold`.`fact_movie` .......................... [RUN]
[0m11:58:38.845706 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.movie_warehouse.dim_release_date, now model.movie_warehouse.fact_movie)
[0m11:58:38.845892 [debug] [Thread-1 (]: Began compiling node model.movie_warehouse.fact_movie
[0m11:58:38.848224 [debug] [Thread-1 (]: Writing injected SQL for node "model.movie_warehouse.fact_movie"
[0m11:58:38.849039 [debug] [Thread-1 (]: Began executing node model.movie_warehouse.fact_movie
[0m11:58:38.851389 [debug] [Thread-1 (]: Creating new relation fact_movie
[0m11:58:38.852026 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.fact_movie: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.fact_movie"} */

            

    
        create table `gold_gold`.`fact_movie`
        
  
        
  engine = MergeTree()
        order by (fact_id)
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

WITH latest_tmdb AS (
    SELECT
        imdb_id,
        title,
        release_date,
        genres,
        production_companies,
        vote_average,
        vote_count,
        revenue,
        budget,
        popularity,
        ingestion_date,
        row_number() OVER (PARTITION BY id ORDER BY ingestion_date DESC) AS rn
    FROM `bronze`.`tmdb_raw`
),

filtered_tmdb AS (
    SELECT 
        id,
        imdb_id,
        title,
        release_date,
        genres,
        production_companies,
        vote_average,
        vote_count,
        revenue,
        budget,
        popularity
    FROM latest_tmdb
    WHERE rn = 1
),

-- First genre
first_genre AS (
    SELECT
        id AS movie_id,
        trim(splitByChar(',', genres)[1]) AS genre_name
    FROM filtered_tmdb
),

-- First director
first_director AS (
    SELECT
        t.id AS movie_id,
        trim(splitByChar(',', c.directors)[1]) AS director_id
    FROM filtered_tmdb t
    LEFT JOIN `bronze`.`imdb_title_crew_raw` c
        ON t.imdb_id = c.tconst
),

-- Join to dim_production to get production_id
movie_production AS (
    SELECT
        t.id AS movie_id,
        p.production_id
    FROM filtered_tmdb t
    LEFT JOIN `gold_gold`.`dim_production` p
        ON trim(splitByChar(',', t.production_companies)[1]) = p.production_name
),

-- Map genre_name to dim_genre to get genre_id
movie_genre AS (
    SELECT
        fg.movie_id,
        g.genre_id
    FROM first_genre fg
    LEFT JOIN `gold_gold`.`dim_genre` g
        ON fg.genre_name = g.genre_name
),

base AS (
    SELECT
        t.id                                      AS movie_id,
        d.director_id,
        mg.genre_id,
        mp.production_id,
        dr.date_id                                AS date_id,
        t.vote_average                            AS vote_avg,
        t.vote_count,
        t.revenue,
        t.budget,
        t.popularity                              AS movie_popularity,
        toYear(t.release_date)                    AS release_year
    FROM filtered_tmdb t
    LEFT JOIN movie_genre mg       ON mg.movie_id = t.id
    LEFT JOIN first_director d     ON d.movie_id = t.id
    LEFT JOIN movie_production mp  ON mp.movie_id = t.id
    LEFT JOIN `gold_gold`.`dim_release_date` dr
        ON dr.full_date = t.release_date
),

metrics AS (
    SELECT
        b.*,
        b.revenue - lag(b.revenue, 1) OVER (PARTITION BY b.movie_id ORDER BY b.release_year) AS revenue_growth,
        b.movie_popularity - lag(b.movie_popularity, 1) OVER (PARTITION BY b.movie_id ORDER BY b.release_year) AS popularity_change,
        b.vote_avg - lag(b.vote_avg, 1) OVER (PARTITION BY b.movie_id ORDER BY b.release_year) AS vote_avg_change
    FROM base b
)

SELECT
    cityHash64(concat(toString(movie_id), '-', toString(date_id))) AS fact_id,
    movie_id,
    director_id,
    genre_id,
    production_id,
    date_id,
    vote_avg,
    vote_count,
    revenue,
    budget,
    movie_popularity,
    revenue_growth,
    popularity_change,
    vote_avg_change
FROM metrics
          )
        
        ...
[0m11:58:38.856724 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.fact_movie"} */

            

    
        create table `gold_gold`.`fact_movie`
        
  
        
  engine = MergeTree()
        order by (fact_id)
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

WITH latest_tmdb AS (
    SELECT
        imdb_id,
        title,
        release_date,
        genres,
        production_companies,
        vote_average,
        vote_count,
        revenue,
        budget,
        popularity,
        ingestion_date,
        row_number() OVER (PARTITION BY id ORDER BY ingestion_date DESC) AS rn
    FROM `bronze`.`tmdb_raw`
),

filtered_tmdb AS (
    SELECT 
        id,
        imdb_id,
        title,
        release_date,
        genres,
        production_companies,
        vote_average,
        vote_count,
        revenue,
        budget,
        popularity
    FROM latest_tmdb
    WHERE rn = 1
),

-- First genre
first_genre AS (
    SELECT
        id AS movie_id,
        trim(splitByChar(',', genres)[1]) AS genre_name
    FROM filtered_tmdb
),

-- First director
first_director AS (
    SELECT
        t.id AS movie_id,
        trim(splitByChar(',', c.directors)[1]) AS director_id
    FROM filtered_tmdb t
    LEFT JOIN `bronze`.`imdb_title_crew_raw` c
        ON t.imdb_id = c.tconst
),

-- Join to dim_production to get production_id
movie_production AS (
    SELECT
        t.id AS movie_id,
        p.production_id
    FROM filtered_tmdb t
    LEFT JOIN `gold_gold`.`dim_production` p
        ON trim(splitByChar(',', t.production_companies)[1]) = p.production_name
),

-- Map genre_name to dim_genre to get genre_id
movie_genre AS (
    SELECT
        fg.movie_id,
        g.genre_id
    FROM first_genre fg
    LEFT JOIN `gold_gold`.`dim_genre` g
        ON fg.genre_name = g.genre_name
),

base AS (
    SELECT
        t.id                                      AS movie_id,
        d.director_id,
        mg.genre_id,
        mp.production_id,
        dr.date_id                                AS date_id,
        t.vote_average                            AS vote_avg,
        t.vote_count,
        t.revenue,
        t.budget,
        t.popularity                              AS movie_popularity,
        toYear(t.release_date)                    AS release_year
    FROM filtered_tmdb t
    LEFT JOIN movie_genre mg       ON mg.movie_id = t.id
    LEFT JOIN first_director d     ON d.movie_id = t.id
    LEFT JOIN movie_production mp  ON mp.movie_id = t.id
    LEFT JOIN `gold_gold`.`dim_release_date` dr
        ON dr.full_date = t.release_date
),

metrics AS (
    SELECT
        b.*,
        b.revenue - lag(b.revenue, 1) OVER (PARTITION BY b.movie_id ORDER BY b.release_year) AS revenue_growth,
        b.movie_popularity - lag(b.movie_popularity, 1) OVER (PARTITION BY b.movie_id ORDER BY b.release_year) AS popularity_change,
        b.vote_avg - lag(b.vote_avg, 1) OVER (PARTITION BY b.movie_id ORDER BY b.release_year) AS vote_avg_change
    FROM base b
)

SELECT
    cityHash64(concat(toString(movie_id), '-', toString(date_id))) AS fact_id,
    movie_id,
    director_id,
    genre_id,
    production_id,
    date_id,
    vote_avg,
    vote_count,
    revenue,
    budget,
    movie_popularity,
    revenue_growth,
    popularity_change,
    vote_avg_change
FROM metrics
          )
        
        
[0m11:58:38.861453 [debug] [Thread-1 (]: Database Error in model fact_movie (models/gold/fact_movie.sql)
  :HTTPDriver for http://clickhouse-server:8123 returned response code 404)
   Code: 47. DB::Exception: Unknown expression identifier `popularity` in scope  latest_tmdb. (UNKNOWN_IDENTIFIER) (version 25.9.3.48 (official build))
[0m11:58:38.861774 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'de882833-8dbe-4eae-8ad1-339680c83224', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff4474a750>]}
[0m11:58:38.862132 [error] [Thread-1 (]: 6 of 6 ERROR creating sql table model `gold_gold`.`fact_movie` ................. [[31mERROR[0m in 0.02s]
[0m11:58:38.862449 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.fact_movie
[0m11:58:38.864391 [debug] [MainThread]: Connection 'master' was properly closed.
[0m11:58:38.864664 [debug] [MainThread]: Connection 'model.movie_warehouse.fact_movie' was left open.
[0m11:58:38.864883 [debug] [MainThread]: On model.movie_warehouse.fact_movie: Close
[0m11:58:38.865551 [info ] [MainThread]: 
[0m11:58:38.865834 [info ] [MainThread]: Finished running 6 table models in 0 hours 0 minutes and 2.66 seconds (2.66s).
[0m11:58:38.866422 [debug] [MainThread]: Command end result
[0m11:58:38.893979 [info ] [MainThread]: 
[0m11:58:38.894416 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m11:58:38.894631 [info ] [MainThread]: 
[0m11:58:38.894942 [error] [MainThread]:   Database Error in model fact_movie (models/gold/fact_movie.sql)
  :HTTPDriver for http://clickhouse-server:8123 returned response code 404)
   Code: 47. DB::Exception: Unknown expression identifier `popularity` in scope  latest_tmdb. (UNKNOWN_IDENTIFIER) (version 25.9.3.48 (official build))
[0m11:58:38.895134 [info ] [MainThread]: 
[0m11:58:38.895382 [info ] [MainThread]: Done. PASS=5 WARN=0 ERROR=1 SKIP=0 TOTAL=6
[0m11:58:38.897362 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 3.1459718, "process_in_blocks": "0", "process_kernel_time": 0.318145, "process_mem_max_rss": "192844", "process_out_blocks": "3486", "process_user_time": 1.985598}
[0m11:58:38.898653 [debug] [MainThread]: Command `dbt run` failed at 11:58:38.898566 after 3.15 seconds
[0m11:58:38.899147 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8522f5d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff851fe510>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff44dc6ad0>]}
[0m11:58:38.899385 [debug] [MainThread]: Flushing usage events
[0m12:02:17.659262 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff86efd850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff86f2f890>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff86f22050>]}


============================== 12:02:17.667656 | 970f4a46-2d8d-4ffe-835c-aab298ad620e ==============================
[0m12:02:17.667656 [info ] [MainThread]: Running with dbt=1.8.9
[0m12:02:17.668087 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/project_root/dbt', 'fail_fast': 'False', 'version_check': 'True', 'log_path': '/opt/airflow/project_root/dbt/logs', 'debug': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'invocation_command': 'dbt run --project-dir /opt/airflow/project_root/dbt --profiles-dir /opt/airflow/project_root/dbt --select gold', 'log_format': 'default', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m12:02:17.774636 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '970f4a46-2d8d-4ffe-835c-aab298ad620e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8739ea50>]}
[0m12:02:17.809087 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '970f4a46-2d8d-4ffe-835c-aab298ad620e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8792b010>]}
[0m12:02:17.810098 [info ] [MainThread]: Registered adapter: clickhouse=1.8.9
[0m12:02:17.844240 [debug] [MainThread]: checksum: 132857a23e9d07220246854f7763165174ce9b737cfc7867629ace4294e520b1, vars: {}, profile: , target: , version: 1.8.9
[0m12:02:17.905534 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m12:02:17.906014 [debug] [MainThread]: Partial parsing: updated file: movie_warehouse://models/gold/fact_movie.sql
[0m12:02:17.988407 [warn ] [MainThread]: [[33mWARNING[0m]: Deprecated functionality
The `tests` config has been renamed to `data_tests`. Please see
https://docs.getdbt.com/docs/build/data-tests#new-data_tests-syntax for more
information.
[0m12:02:17.988933 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'deprecation', 'label': '970f4a46-2d8d-4ffe-835c-aab298ad620e', 'property_': 'warn', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff86ea9110>]}
[0m12:02:18.053160 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.movie_warehouse.bronze
[0m12:02:18.058520 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '970f4a46-2d8d-4ffe-835c-aab298ad620e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff85773310>]}
[0m12:02:18.144821 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '970f4a46-2d8d-4ffe-835c-aab298ad620e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff868bf550>]}
[0m12:02:18.145259 [info ] [MainThread]: Found 6 models, 12 data tests, 4 sources, 477 macros
[0m12:02:18.145744 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '970f4a46-2d8d-4ffe-835c-aab298ad620e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff857334d0>]}
[0m12:02:18.146933 [info ] [MainThread]: 
[0m12:02:18.147352 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m12:02:18.150175 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m12:02:18.155648 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:02:18.401591 [info ] [ThreadPool]: dbt_clickhouse adapter: Unexpected server exception dropping table
[0m12:02:18.402086 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m12:02:18.404251 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:02:18.458913 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__gold_gold)
[0m12:02:18.461947 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__gold_gold: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "connection_name": "list__gold_gold"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'gold_gold'
      

  ...
[0m12:02:18.466160 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:02:18.467385 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '970f4a46-2d8d-4ffe-835c-aab298ad620e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff42aa3f90>]}
[0m12:02:18.467796 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m12:02:18.468031 [info ] [MainThread]: 
[0m12:02:18.472333 [debug] [Thread-1 (]: Began running node model.movie_warehouse.dim_director
[0m12:02:18.472620 [info ] [Thread-1 (]: 1 of 6 START sql table model `gold_gold`.`dim_director` ........................ [RUN]
[0m12:02:18.472883 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list__gold_gold, now model.movie_warehouse.dim_director)
[0m12:02:18.473120 [debug] [Thread-1 (]: Began compiling node model.movie_warehouse.dim_director
[0m12:02:18.476793 [debug] [Thread-1 (]: Writing injected SQL for node "model.movie_warehouse.dim_director"
[0m12:02:18.477672 [debug] [Thread-1 (]: Began executing node model.movie_warehouse.dim_director
[0m12:02:18.486092 [debug] [Thread-1 (]: Creating new relation dim_director
[0m12:02:18.498992 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_director: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_director"} */

            

    
        create table `gold_gold`.`dim_director`
        
  
        
  engine = MergeTree()
        order by (dir_id)
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

WITH first_dir AS (
    SELECT
        tconst,
        TRIM(splitByChar(',', directors)[1]) AS director_id
    FROM `bronze`.`imdb_title_crew_raw`
    WHERE directors IS NOT NULL AND directors != ''
),
deduped AS (
    SELECT DISTINCT director_id
    FROM first_dir
),
joined AS (
    SELECT
        d.director_id AS dir_id,
        n.primaryName AS dir_name
    FROM deduped d
    LEFT JOIN `bronze`.`imdb_name_basics_raw` n
        ON d.director_id = n.nconst
)
SELECT
    cityHash64(dir_id) AS imdb_dir_name_id,  -- Use hash instead of row_number
    dir_id,
    dir_name,
    today() AS valid_from,
    CAST(NULL AS Nullable(Date)) AS valid_to,
    1 AS is_current  -- Use 1/0 instead of TRUE/FALSE
FROM joined
WHERE dir_id IS NOT NULL
ORDER BY dir_id
          )
        
        ...
[0m12:02:18.506332 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m12:02:18.513364 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_director: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_director"} */

    select name, type from system.columns where table = 'dim_director'
    
      and database = 'gold_gold'
    
    order by position
  ...
[0m12:02:18.516124 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:02:18.517856 [debug] [Thread-1 (]: Writing runtime sql for node "model.movie_warehouse.dim_director"
[0m12:02:18.518713 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_director: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_director"} */

  
    
    
    
        
         


        insert into `gold_gold`.`dim_director`
        ("imdb_dir_name_id", "dir_id", "dir_name", "valid_from", "valid_to", "is_current")

WITH first_dir AS (
    SELECT
        tconst,
        TRIM(splitByChar(',', directors)[1]) AS director_id
    FROM `bronze`.`imdb_title_crew_raw`
    WHERE directors IS NOT NULL AND directors != ''
),
deduped AS (
    SELECT DISTINCT director_id
    FROM first_dir
),
joined AS (
    SELECT
        d.director_id AS dir_id,
        n.primaryName AS dir_name
    FROM deduped d
    LEFT JOIN `bronze`.`imdb_name_basics_raw` n
        ON d.director_id = n.nconst
)
SELECT
    cityHash64(dir_id) AS imdb_dir_name_id,  -- Use hash instead of row_number
    dir_id,
    dir_name,
    today() AS valid_from,
    CAST(NULL AS Nullable(Date)) AS valid_to,
    1 AS is_current  -- Use 1/0 instead of TRUE/FALSE
FROM joined
WHERE dir_id IS NOT NULL
ORDER BY dir_id
  ...
[0m12:02:20.516015 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 1.99 seconds
[0m12:02:20.538568 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '970f4a46-2d8d-4ffe-835c-aab298ad620e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff42501110>]}
[0m12:02:20.539785 [info ] [Thread-1 (]: 1 of 6 OK created sql table model `gold_gold`.`dim_director` ................... [[32mOK[0m in 2.06s]
[0m12:02:20.540485 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.dim_director
[0m12:02:20.541038 [debug] [Thread-1 (]: Began running node model.movie_warehouse.dim_genre
[0m12:02:20.542155 [info ] [Thread-1 (]: 2 of 6 START sql table model `gold_gold`.`dim_genre` ........................... [RUN]
[0m12:02:20.542596 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.movie_warehouse.dim_director, now model.movie_warehouse.dim_genre)
[0m12:02:20.542856 [debug] [Thread-1 (]: Began compiling node model.movie_warehouse.dim_genre
[0m12:02:20.549294 [debug] [Thread-1 (]: Writing injected SQL for node "model.movie_warehouse.dim_genre"
[0m12:02:20.550138 [debug] [Thread-1 (]: Began executing node model.movie_warehouse.dim_genre
[0m12:02:20.551465 [debug] [Thread-1 (]: Creating new relation dim_genre
[0m12:02:20.552190 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_genre: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_genre"} */

            

    
        create table `gold_gold`.`dim_genre`
        
  
        
  engine = MergeTree()
        order by (genre_id)
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

WITH parsed_genres AS (
    SELECT
        TRIM(splitByChar(',', genres)[1]) AS first_genre
    FROM `bronze`.`tmdb_raw`
    WHERE genres IS NOT NULL AND genres != ''
)
SELECT
    cityHash64(first_genre) AS genre_id,
    first_genre AS genre_name
FROM parsed_genres
GROUP BY first_genre
ORDER BY first_genre
          )
        
        ...
[0m12:02:20.560821 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m12:02:20.562573 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_genre: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_genre"} */

    select name, type from system.columns where table = 'dim_genre'
    
      and database = 'gold_gold'
    
    order by position
  ...
[0m12:02:20.565355 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:02:20.566328 [debug] [Thread-1 (]: Writing runtime sql for node "model.movie_warehouse.dim_genre"
[0m12:02:20.566981 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_genre: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_genre"} */

  
    
    
    
        
         


        insert into `gold_gold`.`dim_genre`
        ("genre_id", "genre_name")

WITH parsed_genres AS (
    SELECT
        TRIM(splitByChar(',', genres)[1]) AS first_genre
    FROM `bronze`.`tmdb_raw`
    WHERE genres IS NOT NULL AND genres != ''
)
SELECT
    cityHash64(first_genre) AS genre_id,
    first_genre AS genre_name
FROM parsed_genres
GROUP BY first_genre
ORDER BY first_genre
  ...
[0m12:02:20.589938 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m12:02:20.591434 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '970f4a46-2d8d-4ffe-835c-aab298ad620e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff42776990>]}
[0m12:02:20.591874 [info ] [Thread-1 (]: 2 of 6 OK created sql table model `gold_gold`.`dim_genre` ...................... [[32mOK[0m in 0.05s]
[0m12:02:20.592152 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.dim_genre
[0m12:02:20.592383 [debug] [Thread-1 (]: Began running node model.movie_warehouse.dim_movie
[0m12:02:20.592809 [info ] [Thread-1 (]: 3 of 6 START sql table model `gold_gold`.`dim_movie` ........................... [RUN]
[0m12:02:20.593047 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.movie_warehouse.dim_genre, now model.movie_warehouse.dim_movie)
[0m12:02:20.593218 [debug] [Thread-1 (]: Began compiling node model.movie_warehouse.dim_movie
[0m12:02:20.596853 [debug] [Thread-1 (]: Writing injected SQL for node "model.movie_warehouse.dim_movie"
[0m12:02:20.597925 [debug] [Thread-1 (]: Began executing node model.movie_warehouse.dim_movie
[0m12:02:20.599449 [debug] [Thread-1 (]: Creating new relation dim_movie
[0m12:02:20.600114 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_movie: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_movie"} */

            

    
        create table `gold_gold`.`dim_movie`
        
  
        
  engine = MergeTree()
        order by (movie_id)
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            -- ...existing code...


WITH movie_src AS (
    SELECT
        TRIM(title) AS movie_title,
        imdb_id,
        release_date,
        runtime AS movie_runtime,
        original_language AS language
    FROM `bronze`.`tmdb_raw`
    WHERE title IS NOT NULL AND title != ''
)
SELECT
    cityHash64(movie_title) AS movie_id,
    any(imdb_id) AS imdb_id,
    movie_title,
    any(release_date) AS release_date,
    any(movie_runtime) AS movie_runtime,
    any(language) AS language
FROM movie_src
GROUP BY movie_title
ORDER BY movie_title
          )
        
        ...
[0m12:02:20.606342 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m12:02:20.607773 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_movie: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_movie"} */

    select name, type from system.columns where table = 'dim_movie'
    
      and database = 'gold_gold'
    
    order by position
  ...
[0m12:02:20.610182 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:02:20.611276 [debug] [Thread-1 (]: Writing runtime sql for node "model.movie_warehouse.dim_movie"
[0m12:02:20.611936 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_movie: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_movie"} */

  
    
    
    
        
         


        insert into `gold_gold`.`dim_movie`
        ("movie_id", "imdb_id", "movie_title", "release_date", "movie_runtime", "language")-- ...existing code...


WITH movie_src AS (
    SELECT
        TRIM(title) AS movie_title,
        imdb_id,
        release_date,
        runtime AS movie_runtime,
        original_language AS language
    FROM `bronze`.`tmdb_raw`
    WHERE title IS NOT NULL AND title != ''
)
SELECT
    cityHash64(movie_title) AS movie_id,
    any(imdb_id) AS imdb_id,
    movie_title,
    any(release_date) AS release_date,
    any(movie_runtime) AS movie_runtime,
    any(language) AS language
FROM movie_src
GROUP BY movie_title
ORDER BY movie_title
  ...
[0m12:02:21.077938 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.47 seconds
[0m12:02:21.080090 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '970f4a46-2d8d-4ffe-835c-aab298ad620e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff423d1f50>]}
[0m12:02:21.080634 [info ] [Thread-1 (]: 3 of 6 OK created sql table model `gold_gold`.`dim_movie` ...................... [[32mOK[0m in 0.49s]
[0m12:02:21.081155 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.dim_movie
[0m12:02:21.081442 [debug] [Thread-1 (]: Began running node model.movie_warehouse.dim_production
[0m12:02:21.082003 [info ] [Thread-1 (]: 4 of 6 START sql table model `gold_gold`.`dim_production` ...................... [RUN]
[0m12:02:21.082290 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.movie_warehouse.dim_movie, now model.movie_warehouse.dim_production)
[0m12:02:21.082507 [debug] [Thread-1 (]: Began compiling node model.movie_warehouse.dim_production
[0m12:02:21.085712 [debug] [Thread-1 (]: Writing injected SQL for node "model.movie_warehouse.dim_production"
[0m12:02:21.087474 [debug] [Thread-1 (]: Began executing node model.movie_warehouse.dim_production
[0m12:02:21.089171 [debug] [Thread-1 (]: Creating new relation dim_production
[0m12:02:21.090070 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_production: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_production"} */

            

    
        create table `gold_gold`.`dim_production`
        
  
        
  engine = MergeTree()
        order by (production_id)
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

WITH first_production AS (
    SELECT
        imdb_id AS movie_id,
        trim(splitByChar(',', production_companies)[1]) AS production_name
    FROM `bronze`.`tmdb_raw`
    WHERE production_companies IS NOT NULL AND production_companies != ''
)

SELECT
    cityHash64(production_name) AS production_id,
    production_name,
    current_date() AS valid_from,
    CAST(NULL AS Nullable(Date)) AS valid_to,
    TRUE AS is_current
FROM (
    SELECT DISTINCT production_name
    FROM first_production
)
WHERE production_name IS NOT NULL
          )
        
        ...
[0m12:02:21.104448 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m12:02:21.106286 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_production: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_production"} */

    select name, type from system.columns where table = 'dim_production'
    
      and database = 'gold_gold'
    
    order by position
  ...
[0m12:02:21.113191 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m12:02:21.115366 [debug] [Thread-1 (]: Writing runtime sql for node "model.movie_warehouse.dim_production"
[0m12:02:21.116854 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_production: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_production"} */

  
    
    
    
        
         


        insert into `gold_gold`.`dim_production`
        ("production_id", "production_name", "valid_from", "valid_to", "is_current")

WITH first_production AS (
    SELECT
        imdb_id AS movie_id,
        trim(splitByChar(',', production_companies)[1]) AS production_name
    FROM `bronze`.`tmdb_raw`
    WHERE production_companies IS NOT NULL AND production_companies != ''
)

SELECT
    cityHash64(production_name) AS production_id,
    production_name,
    current_date() AS valid_from,
    CAST(NULL AS Nullable(Date)) AS valid_to,
    TRUE AS is_current
FROM (
    SELECT DISTINCT production_name
    FROM first_production
)
WHERE production_name IS NOT NULL
  ...
[0m12:02:21.123290 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m12:02:21.124421 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '970f4a46-2d8d-4ffe-835c-aab298ad620e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff42b63ad0>]}
[0m12:02:21.124836 [info ] [Thread-1 (]: 4 of 6 OK created sql table model `gold_gold`.`dim_production` ................. [[32mOK[0m in 0.04s]
[0m12:02:21.125144 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.dim_production
[0m12:02:21.125360 [debug] [Thread-1 (]: Began running node model.movie_warehouse.dim_release_date
[0m12:02:21.125767 [info ] [Thread-1 (]: 5 of 6 START sql table model `gold_gold`.`dim_release_date` .................... [RUN]
[0m12:02:21.126011 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.movie_warehouse.dim_production, now model.movie_warehouse.dim_release_date)
[0m12:02:21.126228 [debug] [Thread-1 (]: Began compiling node model.movie_warehouse.dim_release_date
[0m12:02:21.128238 [debug] [Thread-1 (]: Writing injected SQL for node "model.movie_warehouse.dim_release_date"
[0m12:02:21.129201 [debug] [Thread-1 (]: Began executing node model.movie_warehouse.dim_release_date
[0m12:02:21.130475 [debug] [Thread-1 (]: Creating new relation dim_release_date
[0m12:02:21.131060 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_release_date: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_release_date"} */

            

    
        create table `gold_gold`.`dim_release_date`
        
  
        
  engine = MergeTree()
        order by (date_id)
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

WITH distinct_dates AS (
    SELECT DISTINCT release_date
    FROM `bronze`.`tmdb_raw`
    WHERE release_date IS NOT NULL
)

SELECT
    cityHash64(release_date)                                    AS date_id,
    release_date                                                AS full_date,
    toYear(release_date)                                        AS year,
    toMonth(release_date)                                       AS month,
    toDayOfMonth(release_date)                                  AS day,
    toISOWeek(release_date)                                     AS week,
    formatDateTime(release_date, '%a')                          AS weekday,
    CASE
        WHEN toMonth(release_date) IN (12,1,2)  THEN 'Winter'
        WHEN toMonth(release_date) IN (3,4,5)   THEN 'Spring'
        WHEN toMonth(release_date) IN (6,7,8)   THEN 'Summer'
        WHEN toMonth(release_date) IN (9,10,11) THEN 'Autumn'
    END                                                         AS season,
    CASE
        WHEN formatDateTime(release_date, '%a') IN ('Saturday','Sunday') THEN 1
        ELSE 0
    END                                                         AS is_weekend,

    /* ---------- holiday tagging ---------- */
    CASE
        WHEN toMonth(release_date)=1  AND toDayOfMonth(release_date)=1  THEN 'New Years Day'
        WHEN toMonth(release_date)=2  AND toDayOfMonth(release_date)=14 THEN 'Valentines Day'
        WHEN toMonth(release_date)=3  AND toDayOfMonth(release_date)=17 THEN 'St. Patricks Day'
        WHEN toMonth(release_date)=4  AND toDayOfMonth(release_date)=1  THEN 'April Fools Day'
        WHEN toMonth(release_date)=4  AND toDayOfMonth(release_date)=22 THEN 'Earth Day'
        WHEN toMonth(release_date)=5  AND toDayOfMonth(release_date)=1  THEN 'May Day'
        WHEN toMonth(release_date)=5  AND toDayOfMonth(release_date)=5  THEN 'Cinco de Mayo'
        WHEN toMonth(release_date)=6  AND toDayOfMonth(release_date) BETWEEN 19 AND 26 THEN 'Midsummer'
        WHEN toMonth(release_date)=7  AND toDayOfMonth(release_date)=4  THEN 'Independence Day'
        WHEN toMonth(release_date)=9  AND toDayOfMonth(release_date) BETWEEN 1 AND 7 
             AND formatDateTime(release_date,'%a')='Monday'             THEN 'Labor Day (US)'
        WHEN toMonth(release_date)=10 AND toDayOfMonth(release_date)=31 THEN 'Halloween'
        WHEN toMonth(release_date)=11 AND formatDateTime(release_date,'%a')='Thursday'
             AND toISOWeek(release_date) >= 47                           THEN 'Thanksgiving'
        WHEN toMonth(release_date)=12 AND toDayOfMonth(release_date)=24 THEN 'Christmas Eve'
        WHEN toMonth(release_date)=12 AND toDayOfMonth(release_date)=25 THEN 'Christmas Day'
        WHEN toMonth(release_date)=12 AND toDayOfMonth(release_date)=31 THEN 'New Years Eve'
        ELSE NULL
    END                                                         AS holiday_name,
    IF(holiday_name IS NOT NULL, 1, 0)                          AS is_holiday,

    /* placeholders for later enhancement */
    CAST(NULL AS Nullable(Int32)) AS days_until_holiday,
    CAST(NULL AS Nullable(Int32)) AS days_after_holiday

FROM distinct_dates
ORDER BY release_date
          )
        
        ...
[0m12:02:21.142558 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m12:02:21.143960 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_release_date: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_release_date"} */

    select name, type from system.columns where table = 'dim_release_date'
    
      and database = 'gold_gold'
    
    order by position
  ...
[0m12:02:21.146451 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:02:21.147639 [debug] [Thread-1 (]: Writing runtime sql for node "model.movie_warehouse.dim_release_date"
[0m12:02:21.148244 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_release_date: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_release_date"} */

  
    
    
    
        
         


        insert into `gold_gold`.`dim_release_date`
        ("date_id", "full_date", "year", "month", "day", "week", "weekday", "season", "is_weekend", "holiday_name", "is_holiday", "days_until_holiday", "days_after_holiday")

WITH distinct_dates AS (
    SELECT DISTINCT release_date
    FROM `bronze`.`tmdb_raw`
    WHERE release_date IS NOT NULL
)

SELECT
    cityHash64(release_date)                                    AS date_id,
    release_date                                                AS full_date,
    toYear(release_date)                                        AS year,
    toMonth(release_date)                                       AS month,
    toDayOfMonth(release_date)                                  AS day,
    toISOWeek(release_date)                                     AS week,
    formatDateTime(release_date, '%a')                          AS weekday,
    CASE
        WHEN toMonth(release_date) IN (12,1,2)  THEN 'Winter'
        WHEN toMonth(release_date) IN (3,4,5)   THEN 'Spring'
        WHEN toMonth(release_date) IN (6,7,8)   THEN 'Summer'
        WHEN toMonth(release_date) IN (9,10,11) THEN 'Autumn'
    END                                                         AS season,
    CASE
        WHEN formatDateTime(release_date, '%a') IN ('Saturday','Sunday') THEN 1
        ELSE 0
    END                                                         AS is_weekend,

    /* ---------- holiday tagging ---------- */
    CASE
        WHEN toMonth(release_date)=1  AND toDayOfMonth(release_date)=1  THEN 'New Years Day'
        WHEN toMonth(release_date)=2  AND toDayOfMonth(release_date)=14 THEN 'Valentines Day'
        WHEN toMonth(release_date)=3  AND toDayOfMonth(release_date)=17 THEN 'St. Patricks Day'
        WHEN toMonth(release_date)=4  AND toDayOfMonth(release_date)=1  THEN 'April Fools Day'
        WHEN toMonth(release_date)=4  AND toDayOfMonth(release_date)=22 THEN 'Earth Day'
        WHEN toMonth(release_date)=5  AND toDayOfMonth(release_date)=1  THEN 'May Day'
        WHEN toMonth(release_date)=5  AND toDayOfMonth(release_date)=5  THEN 'Cinco de Mayo'
        WHEN toMonth(release_date)=6  AND toDayOfMonth(release_date) BETWEEN 19 AND 26 THEN 'Midsummer'
        WHEN toMonth(release_date)=7  AND toDayOfMonth(release_date)=4  THEN 'Independence Day'
        WHEN toMonth(release_date)=9  AND toDayOfMonth(release_date) BETWEEN 1 AND 7 
             AND formatDateTime(release_date,'%a')='Monday'             THEN 'Labor Day (US)'
        WHEN toMonth(release_date)=10 AND toDayOfMonth(release_date)=31 THEN 'Halloween'
        WHEN toMonth(release_date)=11 AND formatDateTime(release_date,'%a')='Thursday'
             AND toISOWeek(release_date) >= 47                           THEN 'Thanksgiving'
        WHEN toMonth(release_date)=12 AND toDayOfMonth(release_date)=24 THEN 'Christmas Eve'
        WHEN toMonth(release_date)=12 AND toDayOfMonth(release_date)=25 THEN 'Christmas Day'
        WHEN toMonth(release_date)=12 AND toDayOfMonth(release_date)=31 THEN 'New Years Eve'
        ELSE NULL
    END                                                         AS holiday_name,
    IF(holiday_name IS NOT NULL, 1, 0)                          AS is_holiday,

    /* placeholders for later enhancement */
    CAST(NULL AS Nullable(Int32)) AS days_until_holiday,
    CAST(NULL AS Nullable(Int32)) AS days_after_holiday

FROM distinct_dates
ORDER BY release_date
  ...
[0m12:02:21.180031 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.03 seconds
[0m12:02:21.181824 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '970f4a46-2d8d-4ffe-835c-aab298ad620e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff86ac9fd0>]}
[0m12:02:21.182301 [info ] [Thread-1 (]: 5 of 6 OK created sql table model `gold_gold`.`dim_release_date` ............... [[32mOK[0m in 0.06s]
[0m12:02:21.182633 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.dim_release_date
[0m12:02:21.184092 [debug] [Thread-1 (]: Began running node model.movie_warehouse.fact_movie
[0m12:02:21.184409 [info ] [Thread-1 (]: 6 of 6 START sql table model `gold_gold`.`fact_movie` .......................... [RUN]
[0m12:02:21.184747 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.movie_warehouse.dim_release_date, now model.movie_warehouse.fact_movie)
[0m12:02:21.184955 [debug] [Thread-1 (]: Began compiling node model.movie_warehouse.fact_movie
[0m12:02:21.187550 [debug] [Thread-1 (]: Writing injected SQL for node "model.movie_warehouse.fact_movie"
[0m12:02:21.188347 [debug] [Thread-1 (]: Began executing node model.movie_warehouse.fact_movie
[0m12:02:21.190365 [debug] [Thread-1 (]: Creating new relation fact_movie
[0m12:02:21.190969 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.fact_movie: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.fact_movie"} */

            

    
        create table `gold_gold`.`fact_movie`
        
  
        
  engine = MergeTree()
        order by (fact_id)
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

WITH filtered_tmdb AS (
    SELECT 
        imdb_id,
        title,
        release_date,
        production_companies,
        budget,
        revenue,
        vote_average,
        vote_count,
        runtime,
        genres,
        original_language,
        (vote_average * log(1 + vote_count)) AS movie_popularity
    FROM `bronze`.`tmdb_raw`
),

-- First genre
first_genre AS (
    SELECT
        imdb_id AS movie_id,
        trim(splitByChar(',', genres)[1]) AS genre_name
    FROM filtered_tmdb
),

-- First director
first_director AS (
    SELECT
        t.imdb_id AS movie_id,
        trim(splitByChar(',', c.directors)[1]) AS director_id
    FROM filtered_tmdb t
    LEFT JOIN `bronze`.`imdb_title_crew_raw` c
        ON t.imdb_id = c.tconst
),

-- Join to dim_production to get production_id
movie_production AS (
    SELECT
        t.imdb_id AS movie_id,
        p.production_id
    FROM filtered_tmdb t
    LEFT JOIN `gold_gold`.`dim_production` p
        ON trim(splitByChar(',', t.production_companies)[1]) = p.production_name
),

-- Map genre_name to dim_genre to get genre_id
movie_genre AS (
    SELECT
        fg.movie_id,
        g.genre_id
    FROM first_genre fg
    LEFT JOIN `gold_gold`.`dim_genre` g
        ON fg.genre_name = g.genre_name
),

base AS (
    SELECT
        t.imdb_id                                 AS movie_id,
        d.director_id,
        mg.genre_id,
        mp.production_id,
        dr.date_id                                AS date_id,
        t.vote_average                            AS vote_avg,
        t.vote_count,
        t.revenue,
        t.budget,
        t.movie_popularity,
        toYear(t.release_date)                    AS release_year
    FROM filtered_tmdb t
    LEFT JOIN movie_genre mg       ON mg.movie_id = t.imdb_id
    LEFT JOIN first_director d     ON d.movie_id = t.imdb_id
    LEFT JOIN movie_production mp  ON mp.movie_id = t.imdb_id
    LEFT JOIN `gold_gold`.`dim_release_date` dr
        ON dr.full_date = t.release_date
),

metrics AS (
    SELECT
        b.*,
        b.revenue - lag(b.revenue, 1) OVER (PARTITION BY b.movie_id ORDER BY b.release_year) AS revenue_growth,
        b.movie_popularity - lag(b.movie_popularity, 1) OVER (PARTITION BY b.movie_id ORDER BY b.release_year) AS popularity_change,
        b.vote_avg - lag(b.vote_avg, 1) OVER (PARTITION BY b.movie_id ORDER BY b.release_year) AS vote_avg_change
    FROM base b
)

SELECT
    cityHash64(concat(movie_id, '-', toString(date_id))) AS fact_id,
    movie_id,
    director_id,
    genre_id,
    production_id,
    date_id,
    vote_avg,
    vote_count,
    revenue,
    budget,
    movie_popularity,
    revenue_growth,
    popularity_change,
    vote_avg_change
FROM metrics
          )
        
        ...
[0m12:02:21.204977 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m12:02:21.206381 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.fact_movie: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.fact_movie"} */

    select name, type from system.columns where table = 'fact_movie'
    
      and database = 'gold_gold'
    
    order by position
  ...
[0m12:02:21.208516 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:02:21.209612 [debug] [Thread-1 (]: Writing runtime sql for node "model.movie_warehouse.fact_movie"
[0m12:02:21.210151 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.fact_movie: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.fact_movie"} */

  
    
    
    
        
         


        insert into `gold_gold`.`fact_movie`
        ("fact_id", "movie_id", "director_id", "genre_id", "production_id", "date_id", "vote_avg", "vote_count", "revenue", "budget", "movie_popularity", "revenue_growth", "popularity_change", "vote_avg_change")

WITH filtered_tmdb AS (
    SELECT 
        imdb_id,
        title,
        release_date,
        production_companies,
        budget,
        revenue,
        vote_average,
        vote_count,
        runtime,
        genres,
        original_language,
        (vote_average * log(1 + vote_count)) AS movie_popularity
    FROM `bronze`.`tmdb_raw`
),

-- First genre
first_genre AS (
    SELECT
        imdb_id AS movie_id,
        trim(splitByChar(',', genres)[1]) AS genre_name
    FROM filtered_tmdb
),

-- First director
first_director AS (
    SELECT
        t.imdb_id AS movie_id,
        trim(splitByChar(',', c.directors)[1]) AS director_id
    FROM filtered_tmdb t
    LEFT JOIN `bronze`.`imdb_title_crew_raw` c
        ON t.imdb_id = c.tconst
),

-- Join to dim_production to get production_id
movie_production AS (
    SELECT
        t.imdb_id AS movie_id,
        p.production_id
    FROM filtered_tmdb t
    LEFT JOIN `gold_gold`.`dim_production` p
        ON trim(splitByChar(',', t.production_companies)[1]) = p.production_name
),

-- Map genre_name to dim_genre to get genre_id
movie_genre AS (
    SELECT
        fg.movie_id,
        g.genre_id
    FROM first_genre fg
    LEFT JOIN `gold_gold`.`dim_genre` g
        ON fg.genre_name = g.genre_name
),

base AS (
    SELECT
        t.imdb_id                                 AS movie_id,
        d.director_id,
        mg.genre_id,
        mp.production_id,
        dr.date_id                                AS date_id,
        t.vote_average                            AS vote_avg,
        t.vote_count,
        t.revenue,
        t.budget,
        t.movie_popularity,
        toYear(t.release_date)                    AS release_year
    FROM filtered_tmdb t
    LEFT JOIN movie_genre mg       ON mg.movie_id = t.imdb_id
    LEFT JOIN first_director d     ON d.movie_id = t.imdb_id
    LEFT JOIN movie_production mp  ON mp.movie_id = t.imdb_id
    LEFT JOIN `gold_gold`.`dim_release_date` dr
        ON dr.full_date = t.release_date
),

metrics AS (
    SELECT
        b.*,
        b.revenue - lag(b.revenue, 1) OVER (PARTITION BY b.movie_id ORDER BY b.release_year) AS revenue_growth,
        b.movie_popularity - lag(b.movie_popularity, 1) OVER (PARTITION BY b.movie_id ORDER BY b.release_year) AS popularity_change,
        b.vote_avg - lag(b.vote_avg, 1) OVER (PARTITION BY b.movie_id ORDER BY b.release_year) AS vote_avg_change
    FROM base b
)

SELECT
    cityHash64(concat(movie_id, '-', toString(date_id))) AS fact_id,
    movie_id,
    director_id,
    genre_id,
    production_id,
    date_id,
    vote_avg,
    vote_count,
    revenue,
    budget,
    movie_popularity,
    revenue_growth,
    popularity_change,
    vote_avg_change
FROM metrics
  ...
[0m12:02:26.336988 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 5.12 seconds
[0m12:02:26.348651 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '970f4a46-2d8d-4ffe-835c-aab298ad620e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff42438a10>]}
[0m12:02:26.350439 [info ] [Thread-1 (]: 6 of 6 OK created sql table model `gold_gold`.`fact_movie` ..................... [[32mOK[0m in 5.16s]
[0m12:02:26.351571 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.fact_movie
[0m12:02:26.358227 [debug] [MainThread]: Connection 'master' was properly closed.
[0m12:02:26.359347 [debug] [MainThread]: Connection 'model.movie_warehouse.fact_movie' was left open.
[0m12:02:26.359722 [debug] [MainThread]: On model.movie_warehouse.fact_movie: Close
[0m12:02:26.360889 [info ] [MainThread]: 
[0m12:02:26.361447 [info ] [MainThread]: Finished running 6 table models in 0 hours 0 minutes and 8.21 seconds (8.21s).
[0m12:02:26.362912 [debug] [MainThread]: Command end result
[0m12:02:26.421552 [info ] [MainThread]: 
[0m12:02:26.422069 [info ] [MainThread]: [32mCompleted successfully[0m
[0m12:02:26.422361 [info ] [MainThread]: 
[0m12:02:26.422686 [info ] [MainThread]: Done. PASS=6 WARN=0 ERROR=0 SKIP=0 TOTAL=6
[0m12:02:26.425329 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 8.787495, "process_in_blocks": "0", "process_kernel_time": 0.288164, "process_mem_max_rss": "192988", "process_out_blocks": "3485", "process_user_time": 2.187526}
[0m12:02:26.426254 [debug] [MainThread]: Command `dbt run` succeeded at 12:02:26.426168 after 8.79 seconds
[0m12:02:26.426831 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff86f3ab10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff86f3a090>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff86f3a390>]}
[0m12:02:26.427183 [debug] [MainThread]: Flushing usage events
[0m12:05:12.391871 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffad1dc650>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffad213390>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffad1dc590>]}


============================== 12:05:12.395336 | 9825f5b7-9654-4e6e-bbfe-8a5be85821d2 ==============================
[0m12:05:12.395336 [info ] [MainThread]: Running with dbt=1.8.9
[0m12:05:12.395705 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'fail_fast': 'False', 'log_path': '/opt/airflow/project_root/dbt/logs', 'debug': 'False', 'profiles_dir': '/opt/airflow/project_root/dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'invocation_command': 'dbt run --project-dir /opt/airflow/project_root/dbt --profiles-dir /opt/airflow/project_root/dbt --select gold', 'introspect': 'True', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m12:05:12.470818 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '9825f5b7-9654-4e6e-bbfe-8a5be85821d2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffad23be50>]}
[0m12:05:12.491001 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '9825f5b7-9654-4e6e-bbfe-8a5be85821d2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffae6deb50>]}
[0m12:05:12.491573 [info ] [MainThread]: Registered adapter: clickhouse=1.8.9
[0m12:05:12.526480 [debug] [MainThread]: checksum: 132857a23e9d07220246854f7763165174ce9b737cfc7867629ace4294e520b1, vars: {}, profile: , target: , version: 1.8.9
[0m12:05:12.581744 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m12:05:12.582075 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m12:05:12.591329 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.movie_warehouse.bronze
[0m12:05:12.611823 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '9825f5b7-9654-4e6e-bbfe-8a5be85821d2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xfffface15a50>]}
[0m12:05:12.664496 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '9825f5b7-9654-4e6e-bbfe-8a5be85821d2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffacd47390>]}
[0m12:05:12.664828 [info ] [MainThread]: Found 6 models, 12 data tests, 4 sources, 477 macros
[0m12:05:12.665019 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '9825f5b7-9654-4e6e-bbfe-8a5be85821d2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffacfd7890>]}
[0m12:05:12.666133 [info ] [MainThread]: 
[0m12:05:12.666540 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m12:05:12.669496 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m12:05:12.674547 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:05:12.942971 [info ] [ThreadPool]: dbt_clickhouse adapter: Unexpected server exception dropping table
[0m12:05:12.943405 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m12:05:12.945403 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:05:12.965680 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__gold_gold)
[0m12:05:12.968910 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__gold_gold: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "connection_name": "list__gold_gold"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'gold_gold'
      

  ...
[0m12:05:12.973370 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:05:12.974677 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '9825f5b7-9654-4e6e-bbfe-8a5be85821d2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffad5e8250>]}
[0m12:05:12.975031 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m12:05:12.975246 [info ] [MainThread]: 
[0m12:05:12.980046 [debug] [Thread-1 (]: Began running node model.movie_warehouse.dim_director
[0m12:05:12.980383 [info ] [Thread-1 (]: 1 of 6 START sql table model `gold_gold`.`dim_director` ........................ [RUN]
[0m12:05:12.980675 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list__gold_gold, now model.movie_warehouse.dim_director)
[0m12:05:12.980878 [debug] [Thread-1 (]: Began compiling node model.movie_warehouse.dim_director
[0m12:05:12.984553 [debug] [Thread-1 (]: Writing injected SQL for node "model.movie_warehouse.dim_director"
[0m12:05:12.985341 [debug] [Thread-1 (]: Began executing node model.movie_warehouse.dim_director
[0m12:05:12.993838 [debug] [Thread-1 (]: Creating new relation dim_director
[0m12:05:13.008566 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_director: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_director"} */

            

    
        create table `gold_gold`.`dim_director`
        
  
        
  engine = MergeTree()
        order by (dir_id)
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

WITH first_dir AS (
    SELECT
        tconst,
        TRIM(splitByChar(',', directors)[1]) AS director_id
    FROM `bronze`.`imdb_title_crew_raw`
    WHERE directors IS NOT NULL AND directors != ''
),
deduped AS (
    SELECT DISTINCT director_id
    FROM first_dir
),
joined AS (
    SELECT
        d.director_id AS dir_id,
        n.primaryName AS dir_name
    FROM deduped d
    LEFT JOIN `bronze`.`imdb_name_basics_raw` n
        ON d.director_id = n.nconst
)
SELECT
    cityHash64(dir_id) AS imdb_dir_name_id,  -- Use hash instead of row_number
    dir_id,
    dir_name,
    today() AS valid_from,
    CAST(NULL AS Nullable(Date)) AS valid_to,
    1 AS is_current  -- Use 1/0 instead of TRUE/FALSE
FROM joined
WHERE dir_id IS NOT NULL
ORDER BY dir_id
          )
        
        ...
[0m12:05:13.015924 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m12:05:13.023388 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_director: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_director"} */

    select name, type from system.columns where table = 'dim_director'
    
      and database = 'gold_gold'
    
    order by position
  ...
[0m12:05:13.026061 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:05:13.027807 [debug] [Thread-1 (]: Writing runtime sql for node "model.movie_warehouse.dim_director"
[0m12:05:13.028764 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_director: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_director"} */

  
    
    
    
        
         


        insert into `gold_gold`.`dim_director`
        ("imdb_dir_name_id", "dir_id", "dir_name", "valid_from", "valid_to", "is_current")

WITH first_dir AS (
    SELECT
        tconst,
        TRIM(splitByChar(',', directors)[1]) AS director_id
    FROM `bronze`.`imdb_title_crew_raw`
    WHERE directors IS NOT NULL AND directors != ''
),
deduped AS (
    SELECT DISTINCT director_id
    FROM first_dir
),
joined AS (
    SELECT
        d.director_id AS dir_id,
        n.primaryName AS dir_name
    FROM deduped d
    LEFT JOIN `bronze`.`imdb_name_basics_raw` n
        ON d.director_id = n.nconst
)
SELECT
    cityHash64(dir_id) AS imdb_dir_name_id,  -- Use hash instead of row_number
    dir_id,
    dir_name,
    today() AS valid_from,
    CAST(NULL AS Nullable(Date)) AS valid_to,
    1 AS is_current  -- Use 1/0 instead of TRUE/FALSE
FROM joined
WHERE dir_id IS NOT NULL
ORDER BY dir_id
  ...
[0m12:05:16.890123 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 3.86 seconds
[0m12:05:16.939019 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9825f5b7-9654-4e6e-bbfe-8a5be85821d2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff901c7210>]}
[0m12:05:16.941190 [info ] [Thread-1 (]: 1 of 6 OK created sql table model `gold_gold`.`dim_director` ................... [[32mOK[0m in 3.96s]
[0m12:05:16.942463 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.dim_director
[0m12:05:16.943224 [debug] [Thread-1 (]: Began running node model.movie_warehouse.dim_genre
[0m12:05:16.944218 [info ] [Thread-1 (]: 2 of 6 START sql table model `gold_gold`.`dim_genre` ........................... [RUN]
[0m12:05:16.944757 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.movie_warehouse.dim_director, now model.movie_warehouse.dim_genre)
[0m12:05:16.945108 [debug] [Thread-1 (]: Began compiling node model.movie_warehouse.dim_genre
[0m12:05:16.951434 [debug] [Thread-1 (]: Writing injected SQL for node "model.movie_warehouse.dim_genre"
[0m12:05:16.952828 [debug] [Thread-1 (]: Began executing node model.movie_warehouse.dim_genre
[0m12:05:16.955698 [debug] [Thread-1 (]: Creating new relation dim_genre
[0m12:05:16.957351 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_genre: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_genre"} */

            

    
        create table `gold_gold`.`dim_genre`
        
  
        
  engine = MergeTree()
        order by (genre_id)
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

WITH parsed_genres AS (
    SELECT
        TRIM(splitByChar(',', genres)[1]) AS first_genre
    FROM `bronze`.`tmdb_raw`
    WHERE genres IS NOT NULL AND genres != ''
)
SELECT
    cityHash64(first_genre) AS genre_id,
    first_genre AS genre_name
FROM parsed_genres
GROUP BY first_genre
ORDER BY first_genre
          )
        
        ...
[0m12:05:16.976084 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m12:05:16.980892 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_genre: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_genre"} */

    select name, type from system.columns where table = 'dim_genre'
    
      and database = 'gold_gold'
    
    order by position
  ...
[0m12:05:16.987232 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m12:05:16.989055 [debug] [Thread-1 (]: Writing runtime sql for node "model.movie_warehouse.dim_genre"
[0m12:05:16.990211 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_genre: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_genre"} */

  
    
    
    
        
         


        insert into `gold_gold`.`dim_genre`
        ("genre_id", "genre_name")

WITH parsed_genres AS (
    SELECT
        TRIM(splitByChar(',', genres)[1]) AS first_genre
    FROM `bronze`.`tmdb_raw`
    WHERE genres IS NOT NULL AND genres != ''
)
SELECT
    cityHash64(first_genre) AS genre_id,
    first_genre AS genre_name
FROM parsed_genres
GROUP BY first_genre
ORDER BY first_genre
  ...
[0m12:05:17.027545 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.04 seconds
[0m12:05:17.029438 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9825f5b7-9654-4e6e-bbfe-8a5be85821d2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff897c88d0>]}
[0m12:05:17.029927 [info ] [Thread-1 (]: 2 of 6 OK created sql table model `gold_gold`.`dim_genre` ...................... [[32mOK[0m in 0.08s]
[0m12:05:17.030295 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.dim_genre
[0m12:05:17.030587 [debug] [Thread-1 (]: Began running node model.movie_warehouse.dim_movie
[0m12:05:17.031022 [info ] [Thread-1 (]: 3 of 6 START sql table model `gold_gold`.`dim_movie` ........................... [RUN]
[0m12:05:17.031285 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.movie_warehouse.dim_genre, now model.movie_warehouse.dim_movie)
[0m12:05:17.031479 [debug] [Thread-1 (]: Began compiling node model.movie_warehouse.dim_movie
[0m12:05:17.033496 [debug] [Thread-1 (]: Writing injected SQL for node "model.movie_warehouse.dim_movie"
[0m12:05:17.034787 [debug] [Thread-1 (]: Began executing node model.movie_warehouse.dim_movie
[0m12:05:17.036550 [debug] [Thread-1 (]: Creating new relation dim_movie
[0m12:05:17.037295 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_movie: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_movie"} */

            

    
        create table `gold_gold`.`dim_movie`
        
  
        
  engine = MergeTree()
        order by (movie_id)
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            -- ...existing code...


WITH movie_src AS (
    SELECT
        TRIM(title) AS movie_title,
        imdb_id,
        release_date,
        runtime AS movie_runtime,
        original_language AS language
    FROM `bronze`.`tmdb_raw`
    WHERE title IS NOT NULL AND title != ''
)
SELECT
    cityHash64(movie_title) AS movie_id,
    any(imdb_id) AS imdb_id,
    movie_title,
    any(release_date) AS release_date,
    any(movie_runtime) AS movie_runtime,
    any(language) AS language
FROM movie_src
GROUP BY movie_title
ORDER BY movie_title
          )
        
        ...
[0m12:05:17.044294 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m12:05:17.046337 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_movie: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_movie"} */

    select name, type from system.columns where table = 'dim_movie'
    
      and database = 'gold_gold'
    
    order by position
  ...
[0m12:05:17.049745 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:05:17.051297 [debug] [Thread-1 (]: Writing runtime sql for node "model.movie_warehouse.dim_movie"
[0m12:05:17.052135 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_movie: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_movie"} */

  
    
    
    
        
         


        insert into `gold_gold`.`dim_movie`
        ("movie_id", "imdb_id", "movie_title", "release_date", "movie_runtime", "language")-- ...existing code...


WITH movie_src AS (
    SELECT
        TRIM(title) AS movie_title,
        imdb_id,
        release_date,
        runtime AS movie_runtime,
        original_language AS language
    FROM `bronze`.`tmdb_raw`
    WHERE title IS NOT NULL AND title != ''
)
SELECT
    cityHash64(movie_title) AS movie_id,
    any(imdb_id) AS imdb_id,
    movie_title,
    any(release_date) AS release_date,
    any(movie_runtime) AS movie_runtime,
    any(language) AS language
FROM movie_src
GROUP BY movie_title
ORDER BY movie_title
  ...
[0m12:05:17.462973 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.41 seconds
[0m12:05:17.465954 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9825f5b7-9654-4e6e-bbfe-8a5be85821d2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffae6e8990>]}
[0m12:05:17.468534 [info ] [Thread-1 (]: 3 of 6 OK created sql table model `gold_gold`.`dim_movie` ...................... [[32mOK[0m in 0.43s]
[0m12:05:17.470056 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.dim_movie
[0m12:05:17.471445 [debug] [Thread-1 (]: Began running node model.movie_warehouse.dim_production
[0m12:05:17.472676 [info ] [Thread-1 (]: 4 of 6 START sql table model `gold_gold`.`dim_production` ...................... [RUN]
[0m12:05:17.474232 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.movie_warehouse.dim_movie, now model.movie_warehouse.dim_production)
[0m12:05:17.475830 [debug] [Thread-1 (]: Began compiling node model.movie_warehouse.dim_production
[0m12:05:17.483760 [debug] [Thread-1 (]: Writing injected SQL for node "model.movie_warehouse.dim_production"
[0m12:05:17.485897 [debug] [Thread-1 (]: Began executing node model.movie_warehouse.dim_production
[0m12:05:17.488116 [debug] [Thread-1 (]: Creating new relation dim_production
[0m12:05:17.488921 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_production: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_production"} */

            

    
        create table `gold_gold`.`dim_production`
        
  
        
  engine = MergeTree()
        order by (production_id)
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

WITH first_production AS (
    SELECT
        imdb_id AS movie_id,
        trim(splitByChar(',', production_companies)[1]) AS production_name
    FROM `bronze`.`tmdb_raw`
    WHERE production_companies IS NOT NULL AND production_companies != ''
)

SELECT
    cityHash64(production_name) AS production_id,
    production_name,
    current_date() AS valid_from,
    CAST(NULL AS Nullable(Date)) AS valid_to,
    TRUE AS is_current
FROM (
    SELECT DISTINCT production_name
    FROM first_production
)
WHERE production_name IS NOT NULL
          )
        
        ...
[0m12:05:17.503407 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m12:05:17.505949 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_production: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_production"} */

    select name, type from system.columns where table = 'dim_production'
    
      and database = 'gold_gold'
    
    order by position
  ...
[0m12:05:17.511455 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:05:17.513462 [debug] [Thread-1 (]: Writing runtime sql for node "model.movie_warehouse.dim_production"
[0m12:05:17.514706 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_production: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_production"} */

  
    
    
    
        
         


        insert into `gold_gold`.`dim_production`
        ("production_id", "production_name", "valid_from", "valid_to", "is_current")

WITH first_production AS (
    SELECT
        imdb_id AS movie_id,
        trim(splitByChar(',', production_companies)[1]) AS production_name
    FROM `bronze`.`tmdb_raw`
    WHERE production_companies IS NOT NULL AND production_companies != ''
)

SELECT
    cityHash64(production_name) AS production_id,
    production_name,
    current_date() AS valid_from,
    CAST(NULL AS Nullable(Date)) AS valid_to,
    TRUE AS is_current
FROM (
    SELECT DISTINCT production_name
    FROM first_production
)
WHERE production_name IS NOT NULL
  ...
[0m12:05:17.521869 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m12:05:17.523375 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9825f5b7-9654-4e6e-bbfe-8a5be85821d2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffad167990>]}
[0m12:05:17.524054 [info ] [Thread-1 (]: 4 of 6 OK created sql table model `gold_gold`.`dim_production` ................. [[32mOK[0m in 0.05s]
[0m12:05:17.524752 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.dim_production
[0m12:05:17.525361 [debug] [Thread-1 (]: Began running node model.movie_warehouse.dim_release_date
[0m12:05:17.525912 [info ] [Thread-1 (]: 5 of 6 START sql table model `gold_gold`.`dim_release_date` .................... [RUN]
[0m12:05:17.526321 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.movie_warehouse.dim_production, now model.movie_warehouse.dim_release_date)
[0m12:05:17.526619 [debug] [Thread-1 (]: Began compiling node model.movie_warehouse.dim_release_date
[0m12:05:17.529931 [debug] [Thread-1 (]: Writing injected SQL for node "model.movie_warehouse.dim_release_date"
[0m12:05:17.531016 [debug] [Thread-1 (]: Began executing node model.movie_warehouse.dim_release_date
[0m12:05:17.533467 [debug] [Thread-1 (]: Creating new relation dim_release_date
[0m12:05:17.534484 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_release_date: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_release_date"} */

            

    
        create table `gold_gold`.`dim_release_date`
        
  
        
  engine = MergeTree()
        order by (date_id)
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

WITH distinct_dates AS (
    SELECT DISTINCT release_date
    FROM `bronze`.`tmdb_raw`
    WHERE release_date IS NOT NULL
)

SELECT
    cityHash64(release_date)                                    AS date_id,
    release_date                                                AS full_date,
    toYear(release_date)                                        AS year,
    toMonth(release_date)                                       AS month,
    toDayOfMonth(release_date)                                  AS day,
    toISOWeek(release_date)                                     AS week,
    formatDateTime(release_date, '%a')                          AS weekday,
    CASE
        WHEN toMonth(release_date) IN (12,1,2)  THEN 'Winter'
        WHEN toMonth(release_date) IN (3,4,5)   THEN 'Spring'
        WHEN toMonth(release_date) IN (6,7,8)   THEN 'Summer'
        WHEN toMonth(release_date) IN (9,10,11) THEN 'Autumn'
    END                                                         AS season,
    CASE
        WHEN formatDateTime(release_date, '%a') IN ('Saturday','Sunday') THEN 1
        ELSE 0
    END                                                         AS is_weekend,

    /* ---------- holiday tagging ---------- */
    CASE
        WHEN toMonth(release_date)=1  AND toDayOfMonth(release_date)=1  THEN 'New Years Day'
        WHEN toMonth(release_date)=2  AND toDayOfMonth(release_date)=14 THEN 'Valentines Day'
        WHEN toMonth(release_date)=3  AND toDayOfMonth(release_date)=17 THEN 'St. Patricks Day'
        WHEN toMonth(release_date)=4  AND toDayOfMonth(release_date)=1  THEN 'April Fools Day'
        WHEN toMonth(release_date)=4  AND toDayOfMonth(release_date)=22 THEN 'Earth Day'
        WHEN toMonth(release_date)=5  AND toDayOfMonth(release_date)=1  THEN 'May Day'
        WHEN toMonth(release_date)=5  AND toDayOfMonth(release_date)=5  THEN 'Cinco de Mayo'
        WHEN toMonth(release_date)=6  AND toDayOfMonth(release_date) BETWEEN 19 AND 26 THEN 'Midsummer'
        WHEN toMonth(release_date)=7  AND toDayOfMonth(release_date)=4  THEN 'Independence Day'
        WHEN toMonth(release_date)=9  AND toDayOfMonth(release_date) BETWEEN 1 AND 7 
             AND formatDateTime(release_date,'%a')='Monday'             THEN 'Labor Day (US)'
        WHEN toMonth(release_date)=10 AND toDayOfMonth(release_date)=31 THEN 'Halloween'
        WHEN toMonth(release_date)=11 AND formatDateTime(release_date,'%a')='Thursday'
             AND toISOWeek(release_date) >= 47                           THEN 'Thanksgiving'
        WHEN toMonth(release_date)=12 AND toDayOfMonth(release_date)=24 THEN 'Christmas Eve'
        WHEN toMonth(release_date)=12 AND toDayOfMonth(release_date)=25 THEN 'Christmas Day'
        WHEN toMonth(release_date)=12 AND toDayOfMonth(release_date)=31 THEN 'New Years Eve'
        ELSE NULL
    END                                                         AS holiday_name,
    IF(holiday_name IS NOT NULL, 1, 0)                          AS is_holiday,

    /* placeholders for later enhancement */
    CAST(NULL AS Nullable(Int32)) AS days_until_holiday,
    CAST(NULL AS Nullable(Int32)) AS days_after_holiday

FROM distinct_dates
ORDER BY release_date
          )
        
        ...
[0m12:05:17.558717 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m12:05:17.563925 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_release_date: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_release_date"} */

    select name, type from system.columns where table = 'dim_release_date'
    
      and database = 'gold_gold'
    
    order by position
  ...
[0m12:05:17.569359 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:05:17.571000 [debug] [Thread-1 (]: Writing runtime sql for node "model.movie_warehouse.dim_release_date"
[0m12:05:17.571655 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_release_date: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_release_date"} */

  
    
    
    
        
         


        insert into `gold_gold`.`dim_release_date`
        ("date_id", "full_date", "year", "month", "day", "week", "weekday", "season", "is_weekend", "holiday_name", "is_holiday", "days_until_holiday", "days_after_holiday")

WITH distinct_dates AS (
    SELECT DISTINCT release_date
    FROM `bronze`.`tmdb_raw`
    WHERE release_date IS NOT NULL
)

SELECT
    cityHash64(release_date)                                    AS date_id,
    release_date                                                AS full_date,
    toYear(release_date)                                        AS year,
    toMonth(release_date)                                       AS month,
    toDayOfMonth(release_date)                                  AS day,
    toISOWeek(release_date)                                     AS week,
    formatDateTime(release_date, '%a')                          AS weekday,
    CASE
        WHEN toMonth(release_date) IN (12,1,2)  THEN 'Winter'
        WHEN toMonth(release_date) IN (3,4,5)   THEN 'Spring'
        WHEN toMonth(release_date) IN (6,7,8)   THEN 'Summer'
        WHEN toMonth(release_date) IN (9,10,11) THEN 'Autumn'
    END                                                         AS season,
    CASE
        WHEN formatDateTime(release_date, '%a') IN ('Saturday','Sunday') THEN 1
        ELSE 0
    END                                                         AS is_weekend,

    /* ---------- holiday tagging ---------- */
    CASE
        WHEN toMonth(release_date)=1  AND toDayOfMonth(release_date)=1  THEN 'New Years Day'
        WHEN toMonth(release_date)=2  AND toDayOfMonth(release_date)=14 THEN 'Valentines Day'
        WHEN toMonth(release_date)=3  AND toDayOfMonth(release_date)=17 THEN 'St. Patricks Day'
        WHEN toMonth(release_date)=4  AND toDayOfMonth(release_date)=1  THEN 'April Fools Day'
        WHEN toMonth(release_date)=4  AND toDayOfMonth(release_date)=22 THEN 'Earth Day'
        WHEN toMonth(release_date)=5  AND toDayOfMonth(release_date)=1  THEN 'May Day'
        WHEN toMonth(release_date)=5  AND toDayOfMonth(release_date)=5  THEN 'Cinco de Mayo'
        WHEN toMonth(release_date)=6  AND toDayOfMonth(release_date) BETWEEN 19 AND 26 THEN 'Midsummer'
        WHEN toMonth(release_date)=7  AND toDayOfMonth(release_date)=4  THEN 'Independence Day'
        WHEN toMonth(release_date)=9  AND toDayOfMonth(release_date) BETWEEN 1 AND 7 
             AND formatDateTime(release_date,'%a')='Monday'             THEN 'Labor Day (US)'
        WHEN toMonth(release_date)=10 AND toDayOfMonth(release_date)=31 THEN 'Halloween'
        WHEN toMonth(release_date)=11 AND formatDateTime(release_date,'%a')='Thursday'
             AND toISOWeek(release_date) >= 47                           THEN 'Thanksgiving'
        WHEN toMonth(release_date)=12 AND toDayOfMonth(release_date)=24 THEN 'Christmas Eve'
        WHEN toMonth(release_date)=12 AND toDayOfMonth(release_date)=25 THEN 'Christmas Day'
        WHEN toMonth(release_date)=12 AND toDayOfMonth(release_date)=31 THEN 'New Years Eve'
        ELSE NULL
    END                                                         AS holiday_name,
    IF(holiday_name IS NOT NULL, 1, 0)                          AS is_holiday,

    /* placeholders for later enhancement */
    CAST(NULL AS Nullable(Int32)) AS days_until_holiday,
    CAST(NULL AS Nullable(Int32)) AS days_after_holiday

FROM distinct_dates
ORDER BY release_date
  ...
[0m12:05:17.610699 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.04 seconds
[0m12:05:17.612877 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9825f5b7-9654-4e6e-bbfe-8a5be85821d2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff897dc990>]}
[0m12:05:17.613628 [info ] [Thread-1 (]: 5 of 6 OK created sql table model `gold_gold`.`dim_release_date` ............... [[32mOK[0m in 0.09s]
[0m12:05:17.614133 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.dim_release_date
[0m12:05:17.615776 [debug] [Thread-1 (]: Began running node model.movie_warehouse.fact_movie
[0m12:05:17.616293 [info ] [Thread-1 (]: 6 of 6 START sql table model `gold_gold`.`fact_movie` .......................... [RUN]
[0m12:05:17.616840 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.movie_warehouse.dim_release_date, now model.movie_warehouse.fact_movie)
[0m12:05:17.617263 [debug] [Thread-1 (]: Began compiling node model.movie_warehouse.fact_movie
[0m12:05:17.624694 [debug] [Thread-1 (]: Writing injected SQL for node "model.movie_warehouse.fact_movie"
[0m12:05:17.626378 [debug] [Thread-1 (]: Began executing node model.movie_warehouse.fact_movie
[0m12:05:17.773374 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.fact_movie: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.fact_movie"} */

            

    
        create table `gold_gold`.`fact_movie__dbt_backup`
        
  
        
  engine = MergeTree()
        order by (fact_id)
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

WITH filtered_tmdb AS (
    SELECT 
        imdb_id,
        title,
        release_date,
        production_companies,
        budget,
        revenue,
        vote_average,
        vote_count,
        runtime,
        genres,
        original_language,
        (vote_average * log(1 + vote_count)) AS movie_popularity
    FROM `bronze`.`tmdb_raw`
),

-- First genre
first_genre AS (
    SELECT
        imdb_id AS movie_id,
        trim(splitByChar(',', genres)[1]) AS genre_name
    FROM filtered_tmdb
),

-- First director
first_director AS (
    SELECT
        t.imdb_id AS movie_id,
        trim(splitByChar(',', c.directors)[1]) AS director_id
    FROM filtered_tmdb t
    LEFT JOIN `bronze`.`imdb_title_crew_raw` c
        ON t.imdb_id = c.tconst
),

-- Join to dim_production to get production_id
movie_production AS (
    SELECT
        t.imdb_id AS movie_id,
        p.production_id
    FROM filtered_tmdb t
    LEFT JOIN `gold_gold`.`dim_production` p
        ON trim(splitByChar(',', t.production_companies)[1]) = p.production_name
),

-- Map genre_name to dim_genre to get genre_id
movie_genre AS (
    SELECT
        fg.movie_id,
        g.genre_id
    FROM first_genre fg
    LEFT JOIN `gold_gold`.`dim_genre` g
        ON fg.genre_name = g.genre_name
),

base AS (
    SELECT
        t.imdb_id                                 AS movie_id,
        d.director_id,
        mg.genre_id,
        mp.production_id,
        dr.date_id                                AS date_id,
        t.vote_average                            AS vote_avg,
        t.vote_count,
        t.revenue,
        t.budget,
        t.movie_popularity,
        toYear(t.release_date)                    AS release_year
    FROM filtered_tmdb t
    LEFT JOIN movie_genre mg       ON mg.movie_id = t.imdb_id
    LEFT JOIN first_director d     ON d.movie_id = t.imdb_id
    LEFT JOIN movie_production mp  ON mp.movie_id = t.imdb_id
    LEFT JOIN `gold_gold`.`dim_release_date` dr
        ON dr.full_date = t.release_date
),

metrics AS (
    SELECT
        b.*,
        b.revenue - lag(b.revenue, 1) OVER (PARTITION BY b.movie_id ORDER BY b.release_year) AS revenue_growth,
        b.movie_popularity - lag(b.movie_popularity, 1) OVER (PARTITION BY b.movie_id ORDER BY b.release_year) AS popularity_change,
        b.vote_avg - lag(b.vote_avg, 1) OVER (PARTITION BY b.movie_id ORDER BY b.release_year) AS vote_avg_change
    FROM base b
)

SELECT
    cityHash64(concat(movie_id, '-', toString(date_id))) AS fact_id,
    movie_id,
    director_id,
    genre_id,
    production_id,
    date_id,
    vote_avg,
    vote_count,
    revenue,
    budget,
    movie_popularity,
    revenue_growth,
    popularity_change,
    vote_avg_change
FROM metrics
          )
        
        ...
[0m12:05:17.800096 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.03 seconds
[0m12:05:17.802729 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.fact_movie: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.fact_movie"} */

    select name, type from system.columns where table = 'fact_movie__dbt_backup'
    
      and database = 'gold_gold'
    
    order by position
  ...
[0m12:05:17.805863 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:05:17.810514 [debug] [Thread-1 (]: Writing runtime sql for node "model.movie_warehouse.fact_movie"
[0m12:05:17.811958 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.fact_movie: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.fact_movie"} */

  
    
    
    
        
         


        insert into `gold_gold`.`fact_movie__dbt_backup`
        ("fact_id", "movie_id", "director_id", "genre_id", "production_id", "date_id", "vote_avg", "vote_count", "revenue", "budget", "movie_popularity", "revenue_growth", "popularity_change", "vote_avg_change")

WITH filtered_tmdb AS (
    SELECT 
        imdb_id,
        title,
        release_date,
        production_companies,
        budget,
        revenue,
        vote_average,
        vote_count,
        runtime,
        genres,
        original_language,
        (vote_average * log(1 + vote_count)) AS movie_popularity
    FROM `bronze`.`tmdb_raw`
),

-- First genre
first_genre AS (
    SELECT
        imdb_id AS movie_id,
        trim(splitByChar(',', genres)[1]) AS genre_name
    FROM filtered_tmdb
),

-- First director
first_director AS (
    SELECT
        t.imdb_id AS movie_id,
        trim(splitByChar(',', c.directors)[1]) AS director_id
    FROM filtered_tmdb t
    LEFT JOIN `bronze`.`imdb_title_crew_raw` c
        ON t.imdb_id = c.tconst
),

-- Join to dim_production to get production_id
movie_production AS (
    SELECT
        t.imdb_id AS movie_id,
        p.production_id
    FROM filtered_tmdb t
    LEFT JOIN `gold_gold`.`dim_production` p
        ON trim(splitByChar(',', t.production_companies)[1]) = p.production_name
),

-- Map genre_name to dim_genre to get genre_id
movie_genre AS (
    SELECT
        fg.movie_id,
        g.genre_id
    FROM first_genre fg
    LEFT JOIN `gold_gold`.`dim_genre` g
        ON fg.genre_name = g.genre_name
),

base AS (
    SELECT
        t.imdb_id                                 AS movie_id,
        d.director_id,
        mg.genre_id,
        mp.production_id,
        dr.date_id                                AS date_id,
        t.vote_average                            AS vote_avg,
        t.vote_count,
        t.revenue,
        t.budget,
        t.movie_popularity,
        toYear(t.release_date)                    AS release_year
    FROM filtered_tmdb t
    LEFT JOIN movie_genre mg       ON mg.movie_id = t.imdb_id
    LEFT JOIN first_director d     ON d.movie_id = t.imdb_id
    LEFT JOIN movie_production mp  ON mp.movie_id = t.imdb_id
    LEFT JOIN `gold_gold`.`dim_release_date` dr
        ON dr.full_date = t.release_date
),

metrics AS (
    SELECT
        b.*,
        b.revenue - lag(b.revenue, 1) OVER (PARTITION BY b.movie_id ORDER BY b.release_year) AS revenue_growth,
        b.movie_popularity - lag(b.movie_popularity, 1) OVER (PARTITION BY b.movie_id ORDER BY b.release_year) AS popularity_change,
        b.vote_avg - lag(b.vote_avg, 1) OVER (PARTITION BY b.movie_id ORDER BY b.release_year) AS vote_avg_change
    FROM base b
)

SELECT
    cityHash64(concat(movie_id, '-', toString(date_id))) AS fact_id,
    movie_id,
    director_id,
    genre_id,
    production_id,
    date_id,
    vote_avg,
    vote_count,
    revenue,
    budget,
    movie_popularity,
    revenue_growth,
    popularity_change,
    vote_avg_change
FROM metrics
  ...
[0m12:05:21.516393 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 3.70 seconds
[0m12:05:21.529778 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.fact_movie: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.fact_movie"} */
EXCHANGE TABLES `gold_gold`.`fact_movie__dbt_backup` AND `gold_gold`.`fact_movie` 
  
  ...
[0m12:05:21.536028 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m12:05:21.545599 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.fact_movie: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.fact_movie"} */

    drop table if exists `gold_gold`.`fact_movie__dbt_backup` 
  ...
[0m12:05:21.553945 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.fact_movie"} */

    drop table if exists `gold_gold`.`fact_movie__dbt_backup` 
  
[0m12:05:21.554512 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: macro drop_relation
[0m12:05:21.567844 [debug] [Thread-1 (]: Database Error in model fact_movie (models/gold/fact_movie.sql)
  :HTTPDriver for http://clickhouse-server:8123 returned response code 500)
   std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/8c9/8c9b38bb-5974-4368-97d1-712fe72b58b0/fact_movie__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/gold_gold.fact_movie__dbt_backup.8d94aa7b-1e65-4380-aec1-7525172ad700.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build))
  compiled code at target/run/movie_warehouse/models/gold/fact_movie.sql
[0m12:05:21.568922 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9825f5b7-9654-4e6e-bbfe-8a5be85821d2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff89a72e90>]}
[0m12:05:21.570818 [error] [Thread-1 (]: 6 of 6 ERROR creating sql table model `gold_gold`.`fact_movie` ................. [[31mERROR[0m in 3.95s]
[0m12:05:21.571906 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.fact_movie
[0m12:05:21.576226 [debug] [MainThread]: Connection 'master' was properly closed.
[0m12:05:21.576735 [debug] [MainThread]: Connection 'model.movie_warehouse.fact_movie' was left open.
[0m12:05:21.577012 [debug] [MainThread]: On model.movie_warehouse.fact_movie: Close
[0m12:05:21.578367 [info ] [MainThread]: 
[0m12:05:21.579296 [info ] [MainThread]: Finished running 6 table models in 0 hours 0 minutes and 8.91 seconds (8.91s).
[0m12:05:21.580126 [debug] [MainThread]: Command end result
[0m12:05:21.618594 [info ] [MainThread]: 
[0m12:05:21.619003 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m12:05:21.619195 [info ] [MainThread]: 
[0m12:05:21.619466 [error] [MainThread]:   Database Error in model fact_movie (models/gold/fact_movie.sql)
  :HTTPDriver for http://clickhouse-server:8123 returned response code 500)
   std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/8c9/8c9b38bb-5974-4368-97d1-712fe72b58b0/fact_movie__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/gold_gold.fact_movie__dbt_backup.8d94aa7b-1e65-4380-aec1-7525172ad700.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build))
  compiled code at target/run/movie_warehouse/models/gold/fact_movie.sql
[0m12:05:21.619681 [info ] [MainThread]: 
[0m12:05:21.619924 [info ] [MainThread]: Done. PASS=5 WARN=0 ERROR=1 SKIP=0 TOTAL=6
[0m12:05:21.622206 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 9.247589, "process_in_blocks": "392", "process_kernel_time": 0.281735, "process_mem_max_rss": "186688", "process_out_blocks": "2414", "process_user_time": 2.146602}
[0m12:05:21.623077 [debug] [MainThread]: Command `dbt run` failed at 12:05:21.622977 after 9.25 seconds
[0m12:05:21.623625 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffad213b10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffad1de490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffad1de050>]}
[0m12:05:21.623899 [debug] [MainThread]: Flushing usage events
[0m12:06:48.001915 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa360dbd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa35ff010>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa3632110>]}


============================== 12:06:48.006493 | b135e187-2c81-43ed-b096-6077fb7364c1 ==============================
[0m12:06:48.006493 [info ] [MainThread]: Running with dbt=1.8.9
[0m12:06:48.006789 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'debug': 'False', 'log_path': '/opt/airflow/project_root/dbt/logs', 'version_check': 'True', 'profiles_dir': '/opt/airflow/project_root/dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'target_path': 'None', 'invocation_command': 'dbt run --project-dir /opt/airflow/project_root/dbt --profiles-dir /opt/airflow/project_root/dbt --select gold', 'send_anonymous_usage_stats': 'True'}
[0m12:06:48.074151 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'b135e187-2c81-43ed-b096-6077fb7364c1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa351aad0>]}
[0m12:06:48.092640 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'b135e187-2c81-43ed-b096-6077fb7364c1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa403b210>]}
[0m12:06:48.093073 [info ] [MainThread]: Registered adapter: clickhouse=1.8.9
[0m12:06:48.124730 [debug] [MainThread]: checksum: 132857a23e9d07220246854f7763165174ce9b737cfc7867629ace4294e520b1, vars: {}, profile: , target: , version: 1.8.9
[0m12:06:48.173847 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m12:06:48.174116 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m12:06:48.176719 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.movie_warehouse.bronze
[0m12:06:48.191605 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'b135e187-2c81-43ed-b096-6077fb7364c1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa39656d0>]}
[0m12:06:48.238973 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'b135e187-2c81-43ed-b096-6077fb7364c1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa3177250>]}
[0m12:06:48.239295 [info ] [MainThread]: Found 6 models, 12 data tests, 4 sources, 477 macros
[0m12:06:48.239482 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'b135e187-2c81-43ed-b096-6077fb7364c1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa35fd5d0>]}
[0m12:06:48.240270 [info ] [MainThread]: 
[0m12:06:48.240569 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m12:06:48.243387 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m12:06:48.248406 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:06:48.529753 [info ] [ThreadPool]: dbt_clickhouse adapter: Unexpected server exception dropping table
[0m12:06:48.530206 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m12:06:48.531851 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:06:48.548085 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__gold_gold)
[0m12:06:48.551328 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__gold_gold: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "connection_name": "list__gold_gold"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'gold_gold'
      

  ...
[0m12:06:48.557170 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m12:06:48.558701 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'b135e187-2c81-43ed-b096-6077fb7364c1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa3630390>]}
[0m12:06:48.559113 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m12:06:48.559352 [info ] [MainThread]: 
[0m12:06:48.564600 [debug] [Thread-1 (]: Began running node model.movie_warehouse.dim_director
[0m12:06:48.564978 [info ] [Thread-1 (]: 1 of 6 START sql table model `gold_gold`.`dim_director` ........................ [RUN]
[0m12:06:48.565276 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list__gold_gold, now model.movie_warehouse.dim_director)
[0m12:06:48.565502 [debug] [Thread-1 (]: Began compiling node model.movie_warehouse.dim_director
[0m12:06:48.569123 [debug] [Thread-1 (]: Writing injected SQL for node "model.movie_warehouse.dim_director"
[0m12:06:48.569853 [debug] [Thread-1 (]: Began executing node model.movie_warehouse.dim_director
[0m12:06:48.578071 [debug] [Thread-1 (]: Creating new relation dim_director
[0m12:06:48.590016 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_director: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_director"} */

            

    
        create table `gold_gold`.`dim_director`
        
  
        
  engine = MergeTree()
        order by (dir_id)
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

WITH first_dir AS (
    SELECT
        tconst,
        TRIM(splitByChar(',', directors)[1]) AS director_id
    FROM `bronze`.`imdb_title_crew_raw`
    WHERE directors IS NOT NULL AND directors != ''
),
deduped AS (
    SELECT DISTINCT director_id
    FROM first_dir
),
joined AS (
    SELECT
        d.director_id AS dir_id,
        n.primaryName AS dir_name
    FROM deduped d
    LEFT JOIN `bronze`.`imdb_name_basics_raw` n
        ON d.director_id = n.nconst
)
SELECT
    cityHash64(dir_id) AS imdb_dir_name_id,  -- Use hash instead of row_number
    dir_id,
    dir_name,
    today() AS valid_from,
    CAST(NULL AS Nullable(Date)) AS valid_to,
    1 AS is_current  -- Use 1/0 instead of TRUE/FALSE
FROM joined
WHERE dir_id IS NOT NULL
ORDER BY dir_id
          )
        
        ...
[0m12:06:48.596555 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m12:06:48.603474 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_director: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_director"} */

    select name, type from system.columns where table = 'dim_director'
    
      and database = 'gold_gold'
    
    order by position
  ...
[0m12:06:48.606042 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:06:48.607778 [debug] [Thread-1 (]: Writing runtime sql for node "model.movie_warehouse.dim_director"
[0m12:06:48.610092 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_director: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_director"} */

  
    
    
    
        
         


        insert into `gold_gold`.`dim_director`
        ("imdb_dir_name_id", "dir_id", "dir_name", "valid_from", "valid_to", "is_current")

WITH first_dir AS (
    SELECT
        tconst,
        TRIM(splitByChar(',', directors)[1]) AS director_id
    FROM `bronze`.`imdb_title_crew_raw`
    WHERE directors IS NOT NULL AND directors != ''
),
deduped AS (
    SELECT DISTINCT director_id
    FROM first_dir
),
joined AS (
    SELECT
        d.director_id AS dir_id,
        n.primaryName AS dir_name
    FROM deduped d
    LEFT JOIN `bronze`.`imdb_name_basics_raw` n
        ON d.director_id = n.nconst
)
SELECT
    cityHash64(dir_id) AS imdb_dir_name_id,  -- Use hash instead of row_number
    dir_id,
    dir_name,
    today() AS valid_from,
    CAST(NULL AS Nullable(Date)) AS valid_to,
    1 AS is_current  -- Use 1/0 instead of TRUE/FALSE
FROM joined
WHERE dir_id IS NOT NULL
ORDER BY dir_id
  ...
[0m12:06:50.526056 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 1.91 seconds
[0m12:06:50.557871 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b135e187-2c81-43ed-b096-6077fb7364c1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff7fc20a90>]}
[0m12:06:50.559259 [info ] [Thread-1 (]: 1 of 6 OK created sql table model `gold_gold`.`dim_director` ................... [[32mOK[0m in 1.99s]
[0m12:06:50.560066 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.dim_director
[0m12:06:50.560738 [debug] [Thread-1 (]: Began running node model.movie_warehouse.dim_genre
[0m12:06:50.562722 [info ] [Thread-1 (]: 2 of 6 START sql table model `gold_gold`.`dim_genre` ........................... [RUN]
[0m12:06:50.563278 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.movie_warehouse.dim_director, now model.movie_warehouse.dim_genre)
[0m12:06:50.563555 [debug] [Thread-1 (]: Began compiling node model.movie_warehouse.dim_genre
[0m12:06:50.568301 [debug] [Thread-1 (]: Writing injected SQL for node "model.movie_warehouse.dim_genre"
[0m12:06:50.571418 [debug] [Thread-1 (]: Began executing node model.movie_warehouse.dim_genre
[0m12:06:50.573815 [debug] [Thread-1 (]: Creating new relation dim_genre
[0m12:06:50.574730 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_genre: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_genre"} */

            

    
        create table `gold_gold`.`dim_genre`
        
  
        
  engine = MergeTree()
        order by (genre_id)
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

WITH parsed_genres AS (
    SELECT
        TRIM(splitByChar(',', genres)[1]) AS first_genre
    FROM `bronze`.`tmdb_raw`
    WHERE genres IS NOT NULL AND genres != ''
)
SELECT
    cityHash64(first_genre) AS genre_id,
    first_genre AS genre_name
FROM parsed_genres
GROUP BY first_genre
ORDER BY first_genre
          )
        
        ...
[0m12:06:50.588871 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m12:06:50.592669 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_genre: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_genre"} */

    select name, type from system.columns where table = 'dim_genre'
    
      and database = 'gold_gold'
    
    order by position
  ...
[0m12:06:50.599136 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m12:06:50.600318 [debug] [Thread-1 (]: Writing runtime sql for node "model.movie_warehouse.dim_genre"
[0m12:06:50.601200 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_genre: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_genre"} */

  
    
    
    
        
         


        insert into `gold_gold`.`dim_genre`
        ("genre_id", "genre_name")

WITH parsed_genres AS (
    SELECT
        TRIM(splitByChar(',', genres)[1]) AS first_genre
    FROM `bronze`.`tmdb_raw`
    WHERE genres IS NOT NULL AND genres != ''
)
SELECT
    cityHash64(first_genre) AS genre_id,
    first_genre AS genre_name
FROM parsed_genres
GROUP BY first_genre
ORDER BY first_genre
  ...
[0m12:06:50.632304 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.03 seconds
[0m12:06:50.635515 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b135e187-2c81-43ed-b096-6077fb7364c1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff7fb0be90>]}
[0m12:06:50.636080 [info ] [Thread-1 (]: 2 of 6 OK created sql table model `gold_gold`.`dim_genre` ...................... [[32mOK[0m in 0.07s]
[0m12:06:50.636573 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.dim_genre
[0m12:06:50.636881 [debug] [Thread-1 (]: Began running node model.movie_warehouse.dim_movie
[0m12:06:50.637403 [info ] [Thread-1 (]: 3 of 6 START sql table model `gold_gold`.`dim_movie` ........................... [RUN]
[0m12:06:50.637723 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.movie_warehouse.dim_genre, now model.movie_warehouse.dim_movie)
[0m12:06:50.637941 [debug] [Thread-1 (]: Began compiling node model.movie_warehouse.dim_movie
[0m12:06:50.640825 [debug] [Thread-1 (]: Writing injected SQL for node "model.movie_warehouse.dim_movie"
[0m12:06:50.641581 [debug] [Thread-1 (]: Began executing node model.movie_warehouse.dim_movie
[0m12:06:50.642698 [debug] [Thread-1 (]: Creating new relation dim_movie
[0m12:06:50.643263 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_movie: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_movie"} */

            

    
        create table `gold_gold`.`dim_movie`
        
  
        
  engine = MergeTree()
        order by (movie_id)
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            -- ...existing code...


WITH movie_src AS (
    SELECT
        TRIM(title) AS movie_title,
        imdb_id,
        release_date,
        runtime AS movie_runtime,
        original_language AS language
    FROM `bronze`.`tmdb_raw`
    WHERE title IS NOT NULL AND title != ''
)
SELECT
    cityHash64(movie_title) AS movie_id,
    any(imdb_id) AS imdb_id,
    movie_title,
    any(release_date) AS release_date,
    any(movie_runtime) AS movie_runtime,
    any(language) AS language
FROM movie_src
GROUP BY movie_title
ORDER BY movie_title
          )
        
        ...
[0m12:06:50.654481 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m12:06:50.657936 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_movie: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_movie"} */

    select name, type from system.columns where table = 'dim_movie'
    
      and database = 'gold_gold'
    
    order by position
  ...
[0m12:06:50.662662 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:06:50.664190 [debug] [Thread-1 (]: Writing runtime sql for node "model.movie_warehouse.dim_movie"
[0m12:06:50.665560 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_movie: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_movie"} */

  
    
    
    
        
         


        insert into `gold_gold`.`dim_movie`
        ("movie_id", "imdb_id", "movie_title", "release_date", "movie_runtime", "language")-- ...existing code...


WITH movie_src AS (
    SELECT
        TRIM(title) AS movie_title,
        imdb_id,
        release_date,
        runtime AS movie_runtime,
        original_language AS language
    FROM `bronze`.`tmdb_raw`
    WHERE title IS NOT NULL AND title != ''
)
SELECT
    cityHash64(movie_title) AS movie_id,
    any(imdb_id) AS imdb_id,
    movie_title,
    any(release_date) AS release_date,
    any(movie_runtime) AS movie_runtime,
    any(language) AS language
FROM movie_src
GROUP BY movie_title
ORDER BY movie_title
  ...
[0m12:06:50.960827 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.29 seconds
[0m12:06:50.962299 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b135e187-2c81-43ed-b096-6077fb7364c1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff7fcde890>]}
[0m12:06:50.962767 [info ] [Thread-1 (]: 3 of 6 OK created sql table model `gold_gold`.`dim_movie` ...................... [[32mOK[0m in 0.32s]
[0m12:06:50.963107 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.dim_movie
[0m12:06:50.963525 [debug] [Thread-1 (]: Began running node model.movie_warehouse.dim_production
[0m12:06:50.964257 [info ] [Thread-1 (]: 4 of 6 START sql table model `gold_gold`.`dim_production` ...................... [RUN]
[0m12:06:50.964896 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.movie_warehouse.dim_movie, now model.movie_warehouse.dim_production)
[0m12:06:50.965527 [debug] [Thread-1 (]: Began compiling node model.movie_warehouse.dim_production
[0m12:06:50.967880 [debug] [Thread-1 (]: Writing injected SQL for node "model.movie_warehouse.dim_production"
[0m12:06:50.968777 [debug] [Thread-1 (]: Began executing node model.movie_warehouse.dim_production
[0m12:06:50.969936 [debug] [Thread-1 (]: Creating new relation dim_production
[0m12:06:50.970526 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_production: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_production"} */

            

    
        create table `gold_gold`.`dim_production`
        
  
        
  engine = MergeTree()
        order by (production_id)
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

WITH first_production AS (
    SELECT
        imdb_id AS movie_id,
        trim(splitByChar(',', production_companies)[1]) AS production_name
    FROM `bronze`.`tmdb_raw`
    WHERE production_companies IS NOT NULL AND production_companies != ''
)

SELECT
    cityHash64(production_name) AS production_id,
    production_name,
    current_date() AS valid_from,
    CAST(NULL AS Nullable(Date)) AS valid_to,
    TRUE AS is_current
FROM (
    SELECT DISTINCT production_name
    FROM first_production
)
WHERE production_name IS NOT NULL
          )
        
        ...
[0m12:06:50.977826 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m12:06:50.979275 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_production: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_production"} */

    select name, type from system.columns where table = 'dim_production'
    
      and database = 'gold_gold'
    
    order by position
  ...
[0m12:06:50.981777 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:06:50.982838 [debug] [Thread-1 (]: Writing runtime sql for node "model.movie_warehouse.dim_production"
[0m12:06:50.983464 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_production: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_production"} */

  
    
    
    
        
         


        insert into `gold_gold`.`dim_production`
        ("production_id", "production_name", "valid_from", "valid_to", "is_current")

WITH first_production AS (
    SELECT
        imdb_id AS movie_id,
        trim(splitByChar(',', production_companies)[1]) AS production_name
    FROM `bronze`.`tmdb_raw`
    WHERE production_companies IS NOT NULL AND production_companies != ''
)

SELECT
    cityHash64(production_name) AS production_id,
    production_name,
    current_date() AS valid_from,
    CAST(NULL AS Nullable(Date)) AS valid_to,
    TRUE AS is_current
FROM (
    SELECT DISTINCT production_name
    FROM first_production
)
WHERE production_name IS NOT NULL
  ...
[0m12:06:50.986435 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:06:50.987213 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b135e187-2c81-43ed-b096-6077fb7364c1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff7fb05090>]}
[0m12:06:50.987587 [info ] [Thread-1 (]: 4 of 6 OK created sql table model `gold_gold`.`dim_production` ................. [[32mOK[0m in 0.02s]
[0m12:06:50.987913 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.dim_production
[0m12:06:50.988176 [debug] [Thread-1 (]: Began running node model.movie_warehouse.dim_release_date
[0m12:06:50.988462 [info ] [Thread-1 (]: 5 of 6 START sql table model `gold_gold`.`dim_release_date` .................... [RUN]
[0m12:06:50.988710 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.movie_warehouse.dim_production, now model.movie_warehouse.dim_release_date)
[0m12:06:50.988900 [debug] [Thread-1 (]: Began compiling node model.movie_warehouse.dim_release_date
[0m12:06:50.990604 [debug] [Thread-1 (]: Writing injected SQL for node "model.movie_warehouse.dim_release_date"
[0m12:06:50.991058 [debug] [Thread-1 (]: Began executing node model.movie_warehouse.dim_release_date
[0m12:06:50.992410 [debug] [Thread-1 (]: Creating new relation dim_release_date
[0m12:06:50.992968 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_release_date: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_release_date"} */

            

    
        create table `gold_gold`.`dim_release_date`
        
  
        
  engine = MergeTree()
        order by (date_id)
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

WITH distinct_dates AS (
    SELECT DISTINCT release_date
    FROM `bronze`.`tmdb_raw`
    WHERE release_date IS NOT NULL
)

SELECT
    cityHash64(release_date)                                    AS date_id,
    release_date                                                AS full_date,
    toYear(release_date)                                        AS year,
    toMonth(release_date)                                       AS month,
    toDayOfMonth(release_date)                                  AS day,
    toISOWeek(release_date)                                     AS week,
    formatDateTime(release_date, '%a')                          AS weekday,
    CASE
        WHEN toMonth(release_date) IN (12,1,2)  THEN 'Winter'
        WHEN toMonth(release_date) IN (3,4,5)   THEN 'Spring'
        WHEN toMonth(release_date) IN (6,7,8)   THEN 'Summer'
        WHEN toMonth(release_date) IN (9,10,11) THEN 'Autumn'
    END                                                         AS season,
    CASE
        WHEN formatDateTime(release_date, '%a') IN ('Saturday','Sunday') THEN 1
        ELSE 0
    END                                                         AS is_weekend,

    /* ---------- holiday tagging ---------- */
    CASE
        WHEN toMonth(release_date)=1  AND toDayOfMonth(release_date)=1  THEN 'New Years Day'
        WHEN toMonth(release_date)=2  AND toDayOfMonth(release_date)=14 THEN 'Valentines Day'
        WHEN toMonth(release_date)=3  AND toDayOfMonth(release_date)=17 THEN 'St. Patricks Day'
        WHEN toMonth(release_date)=4  AND toDayOfMonth(release_date)=1  THEN 'April Fools Day'
        WHEN toMonth(release_date)=4  AND toDayOfMonth(release_date)=22 THEN 'Earth Day'
        WHEN toMonth(release_date)=5  AND toDayOfMonth(release_date)=1  THEN 'May Day'
        WHEN toMonth(release_date)=5  AND toDayOfMonth(release_date)=5  THEN 'Cinco de Mayo'
        WHEN toMonth(release_date)=6  AND toDayOfMonth(release_date) BETWEEN 19 AND 26 THEN 'Midsummer'
        WHEN toMonth(release_date)=7  AND toDayOfMonth(release_date)=4  THEN 'Independence Day'
        WHEN toMonth(release_date)=9  AND toDayOfMonth(release_date) BETWEEN 1 AND 7 
             AND formatDateTime(release_date,'%a')='Monday'             THEN 'Labor Day (US)'
        WHEN toMonth(release_date)=10 AND toDayOfMonth(release_date)=31 THEN 'Halloween'
        WHEN toMonth(release_date)=11 AND formatDateTime(release_date,'%a')='Thursday'
             AND toISOWeek(release_date) >= 47                           THEN 'Thanksgiving'
        WHEN toMonth(release_date)=12 AND toDayOfMonth(release_date)=24 THEN 'Christmas Eve'
        WHEN toMonth(release_date)=12 AND toDayOfMonth(release_date)=25 THEN 'Christmas Day'
        WHEN toMonth(release_date)=12 AND toDayOfMonth(release_date)=31 THEN 'New Years Eve'
        ELSE NULL
    END                                                         AS holiday_name,
    IF(holiday_name IS NOT NULL, 1, 0)                          AS is_holiday,

    /* placeholders for later enhancement */
    CAST(NULL AS Nullable(Int32)) AS days_until_holiday,
    CAST(NULL AS Nullable(Int32)) AS days_after_holiday

FROM distinct_dates
ORDER BY release_date
          )
        
        ...
[0m12:06:51.009179 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m12:06:51.011099 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_release_date: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_release_date"} */

    select name, type from system.columns where table = 'dim_release_date'
    
      and database = 'gold_gold'
    
    order by position
  ...
[0m12:06:51.014476 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:06:51.016816 [debug] [Thread-1 (]: Writing runtime sql for node "model.movie_warehouse.dim_release_date"
[0m12:06:51.017487 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_release_date: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_release_date"} */

  
    
    
    
        
         


        insert into `gold_gold`.`dim_release_date`
        ("date_id", "full_date", "year", "month", "day", "week", "weekday", "season", "is_weekend", "holiday_name", "is_holiday", "days_until_holiday", "days_after_holiday")

WITH distinct_dates AS (
    SELECT DISTINCT release_date
    FROM `bronze`.`tmdb_raw`
    WHERE release_date IS NOT NULL
)

SELECT
    cityHash64(release_date)                                    AS date_id,
    release_date                                                AS full_date,
    toYear(release_date)                                        AS year,
    toMonth(release_date)                                       AS month,
    toDayOfMonth(release_date)                                  AS day,
    toISOWeek(release_date)                                     AS week,
    formatDateTime(release_date, '%a')                          AS weekday,
    CASE
        WHEN toMonth(release_date) IN (12,1,2)  THEN 'Winter'
        WHEN toMonth(release_date) IN (3,4,5)   THEN 'Spring'
        WHEN toMonth(release_date) IN (6,7,8)   THEN 'Summer'
        WHEN toMonth(release_date) IN (9,10,11) THEN 'Autumn'
    END                                                         AS season,
    CASE
        WHEN formatDateTime(release_date, '%a') IN ('Saturday','Sunday') THEN 1
        ELSE 0
    END                                                         AS is_weekend,

    /* ---------- holiday tagging ---------- */
    CASE
        WHEN toMonth(release_date)=1  AND toDayOfMonth(release_date)=1  THEN 'New Years Day'
        WHEN toMonth(release_date)=2  AND toDayOfMonth(release_date)=14 THEN 'Valentines Day'
        WHEN toMonth(release_date)=3  AND toDayOfMonth(release_date)=17 THEN 'St. Patricks Day'
        WHEN toMonth(release_date)=4  AND toDayOfMonth(release_date)=1  THEN 'April Fools Day'
        WHEN toMonth(release_date)=4  AND toDayOfMonth(release_date)=22 THEN 'Earth Day'
        WHEN toMonth(release_date)=5  AND toDayOfMonth(release_date)=1  THEN 'May Day'
        WHEN toMonth(release_date)=5  AND toDayOfMonth(release_date)=5  THEN 'Cinco de Mayo'
        WHEN toMonth(release_date)=6  AND toDayOfMonth(release_date) BETWEEN 19 AND 26 THEN 'Midsummer'
        WHEN toMonth(release_date)=7  AND toDayOfMonth(release_date)=4  THEN 'Independence Day'
        WHEN toMonth(release_date)=9  AND toDayOfMonth(release_date) BETWEEN 1 AND 7 
             AND formatDateTime(release_date,'%a')='Monday'             THEN 'Labor Day (US)'
        WHEN toMonth(release_date)=10 AND toDayOfMonth(release_date)=31 THEN 'Halloween'
        WHEN toMonth(release_date)=11 AND formatDateTime(release_date,'%a')='Thursday'
             AND toISOWeek(release_date) >= 47                           THEN 'Thanksgiving'
        WHEN toMonth(release_date)=12 AND toDayOfMonth(release_date)=24 THEN 'Christmas Eve'
        WHEN toMonth(release_date)=12 AND toDayOfMonth(release_date)=25 THEN 'Christmas Day'
        WHEN toMonth(release_date)=12 AND toDayOfMonth(release_date)=31 THEN 'New Years Eve'
        ELSE NULL
    END                                                         AS holiday_name,
    IF(holiday_name IS NOT NULL, 1, 0)                          AS is_holiday,

    /* placeholders for later enhancement */
    CAST(NULL AS Nullable(Int32)) AS days_until_holiday,
    CAST(NULL AS Nullable(Int32)) AS days_after_holiday

FROM distinct_dates
ORDER BY release_date
  ...
[0m12:06:51.042255 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m12:06:51.043568 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b135e187-2c81-43ed-b096-6077fb7364c1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8660b210>]}
[0m12:06:51.043880 [info ] [Thread-1 (]: 5 of 6 OK created sql table model `gold_gold`.`dim_release_date` ............... [[32mOK[0m in 0.05s]
[0m12:06:51.044144 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.dim_release_date
[0m12:06:51.045143 [debug] [Thread-1 (]: Began running node model.movie_warehouse.fact_movie
[0m12:06:51.045486 [info ] [Thread-1 (]: 6 of 6 START sql table model `gold_gold`.`fact_movie` .......................... [RUN]
[0m12:06:51.045825 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.movie_warehouse.dim_release_date, now model.movie_warehouse.fact_movie)
[0m12:06:51.046035 [debug] [Thread-1 (]: Began compiling node model.movie_warehouse.fact_movie
[0m12:06:51.049279 [debug] [Thread-1 (]: Writing injected SQL for node "model.movie_warehouse.fact_movie"
[0m12:06:51.049926 [debug] [Thread-1 (]: Began executing node model.movie_warehouse.fact_movie
[0m12:06:51.140182 [debug] [Thread-1 (]: Creating new relation fact_movie
[0m12:06:51.140901 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.fact_movie: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.fact_movie"} */

            

    
        create table `gold_gold`.`fact_movie`
        
  
        
  engine = MergeTree()
        order by (fact_id)
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

WITH filtered_tmdb AS (
    SELECT 
        imdb_id,
        title,
        release_date,
        production_companies,
        budget,
        revenue,
        vote_average,
        vote_count,
        runtime,
        genres,
        original_language,
        (vote_average * log(1 + vote_count)) AS movie_popularity
    FROM `bronze`.`tmdb_raw`
),

-- First genre
first_genre AS (
    SELECT
        imdb_id AS movie_id,
        trim(splitByChar(',', genres)[1]) AS genre_name
    FROM filtered_tmdb
),

-- First director
first_director AS (
    SELECT
        t.imdb_id AS movie_id,
        trim(splitByChar(',', c.directors)[1]) AS director_id
    FROM filtered_tmdb t
    LEFT JOIN `bronze`.`imdb_title_crew_raw` c
        ON t.imdb_id = c.tconst
),

-- Join to dim_production to get production_id
movie_production AS (
    SELECT
        t.imdb_id AS movie_id,
        p.production_id
    FROM filtered_tmdb t
    LEFT JOIN `gold_gold`.`dim_production` p
        ON trim(splitByChar(',', t.production_companies)[1]) = p.production_name
),

-- Map genre_name to dim_genre to get genre_id
movie_genre AS (
    SELECT
        fg.movie_id,
        g.genre_id
    FROM first_genre fg
    LEFT JOIN `gold_gold`.`dim_genre` g
        ON fg.genre_name = g.genre_name
),

base AS (
    SELECT
        t.imdb_id                                 AS movie_id,
        d.director_id,
        mg.genre_id,
        mp.production_id,
        dr.date_id                                AS date_id,
        t.vote_average                            AS vote_avg,
        t.vote_count,
        t.revenue,
        t.budget,
        t.movie_popularity,
        toYear(t.release_date)                    AS release_year
    FROM filtered_tmdb t
    LEFT JOIN movie_genre mg       ON mg.movie_id = t.imdb_id
    LEFT JOIN first_director d     ON d.movie_id = t.imdb_id
    LEFT JOIN movie_production mp  ON mp.movie_id = t.imdb_id
    LEFT JOIN `gold_gold`.`dim_release_date` dr
        ON dr.full_date = t.release_date
),

metrics AS (
    SELECT
        b.*,
        b.revenue - lag(b.revenue, 1) OVER (PARTITION BY b.movie_id ORDER BY b.release_year) AS revenue_growth,
        b.movie_popularity - lag(b.movie_popularity, 1) OVER (PARTITION BY b.movie_id ORDER BY b.release_year) AS popularity_change,
        b.vote_avg - lag(b.vote_avg, 1) OVER (PARTITION BY b.movie_id ORDER BY b.release_year) AS vote_avg_change
    FROM base b
)

SELECT
    cityHash64(concat(movie_id, '-', toString(date_id))) AS fact_id,
    movie_id,
    director_id,
    genre_id,
    production_id,
    date_id,
    vote_avg,
    vote_count,
    revenue,
    budget,
    movie_popularity,
    revenue_growth,
    popularity_change,
    vote_avg_change
FROM metrics
          )
        
        ...
[0m12:06:51.153729 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m12:06:51.155910 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.fact_movie: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.fact_movie"} */

    select name, type from system.columns where table = 'fact_movie'
    
      and database = 'gold_gold'
    
    order by position
  ...
[0m12:06:51.159392 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:06:51.160831 [debug] [Thread-1 (]: Writing runtime sql for node "model.movie_warehouse.fact_movie"
[0m12:06:51.162212 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.fact_movie: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.fact_movie"} */

  
    
    
    
        
         


        insert into `gold_gold`.`fact_movie`
        ("fact_id", "movie_id", "director_id", "genre_id", "production_id", "date_id", "vote_avg", "vote_count", "revenue", "budget", "movie_popularity", "revenue_growth", "popularity_change", "vote_avg_change")

WITH filtered_tmdb AS (
    SELECT 
        imdb_id,
        title,
        release_date,
        production_companies,
        budget,
        revenue,
        vote_average,
        vote_count,
        runtime,
        genres,
        original_language,
        (vote_average * log(1 + vote_count)) AS movie_popularity
    FROM `bronze`.`tmdb_raw`
),

-- First genre
first_genre AS (
    SELECT
        imdb_id AS movie_id,
        trim(splitByChar(',', genres)[1]) AS genre_name
    FROM filtered_tmdb
),

-- First director
first_director AS (
    SELECT
        t.imdb_id AS movie_id,
        trim(splitByChar(',', c.directors)[1]) AS director_id
    FROM filtered_tmdb t
    LEFT JOIN `bronze`.`imdb_title_crew_raw` c
        ON t.imdb_id = c.tconst
),

-- Join to dim_production to get production_id
movie_production AS (
    SELECT
        t.imdb_id AS movie_id,
        p.production_id
    FROM filtered_tmdb t
    LEFT JOIN `gold_gold`.`dim_production` p
        ON trim(splitByChar(',', t.production_companies)[1]) = p.production_name
),

-- Map genre_name to dim_genre to get genre_id
movie_genre AS (
    SELECT
        fg.movie_id,
        g.genre_id
    FROM first_genre fg
    LEFT JOIN `gold_gold`.`dim_genre` g
        ON fg.genre_name = g.genre_name
),

base AS (
    SELECT
        t.imdb_id                                 AS movie_id,
        d.director_id,
        mg.genre_id,
        mp.production_id,
        dr.date_id                                AS date_id,
        t.vote_average                            AS vote_avg,
        t.vote_count,
        t.revenue,
        t.budget,
        t.movie_popularity,
        toYear(t.release_date)                    AS release_year
    FROM filtered_tmdb t
    LEFT JOIN movie_genre mg       ON mg.movie_id = t.imdb_id
    LEFT JOIN first_director d     ON d.movie_id = t.imdb_id
    LEFT JOIN movie_production mp  ON mp.movie_id = t.imdb_id
    LEFT JOIN `gold_gold`.`dim_release_date` dr
        ON dr.full_date = t.release_date
),

metrics AS (
    SELECT
        b.*,
        b.revenue - lag(b.revenue, 1) OVER (PARTITION BY b.movie_id ORDER BY b.release_year) AS revenue_growth,
        b.movie_popularity - lag(b.movie_popularity, 1) OVER (PARTITION BY b.movie_id ORDER BY b.release_year) AS popularity_change,
        b.vote_avg - lag(b.vote_avg, 1) OVER (PARTITION BY b.movie_id ORDER BY b.release_year) AS vote_avg_change
    FROM base b
)

SELECT
    cityHash64(concat(movie_id, '-', toString(date_id))) AS fact_id,
    movie_id,
    director_id,
    genre_id,
    production_id,
    date_id,
    vote_avg,
    vote_count,
    revenue,
    budget,
    movie_popularity,
    revenue_growth,
    popularity_change,
    vote_avg_change
FROM metrics
  ...
[0m12:06:54.146973 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 2.98 seconds
[0m12:06:54.163598 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b135e187-2c81-43ed-b096-6077fb7364c1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff7fbcf8d0>]}
[0m12:06:54.165176 [info ] [Thread-1 (]: 6 of 6 OK created sql table model `gold_gold`.`fact_movie` ..................... [[32mOK[0m in 3.12s]
[0m12:06:54.166113 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.fact_movie
[0m12:06:54.169885 [debug] [MainThread]: Connection 'master' was properly closed.
[0m12:06:54.170410 [debug] [MainThread]: Connection 'model.movie_warehouse.fact_movie' was left open.
[0m12:06:54.170729 [debug] [MainThread]: On model.movie_warehouse.fact_movie: Close
[0m12:06:54.171723 [info ] [MainThread]: 
[0m12:06:54.172083 [info ] [MainThread]: Finished running 6 table models in 0 hours 0 minutes and 5.93 seconds (5.93s).
[0m12:06:54.173893 [debug] [MainThread]: Command end result
[0m12:06:54.223991 [info ] [MainThread]: 
[0m12:06:54.224593 [info ] [MainThread]: [32mCompleted successfully[0m
[0m12:06:54.224830 [info ] [MainThread]: 
[0m12:06:54.225236 [info ] [MainThread]: Done. PASS=6 WARN=0 ERROR=0 SKIP=0 TOTAL=6
[0m12:06:54.230618 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 6.247911, "process_in_blocks": "3512", "process_kernel_time": 0.240951, "process_mem_max_rss": "189468", "process_out_blocks": "2408", "process_user_time": 1.912036}
[0m12:06:54.234905 [debug] [MainThread]: Command `dbt run` succeeded at 12:06:54.234371 after 6.25 seconds
[0m12:06:54.237075 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa363f5d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa8509e10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa8509910>]}
[0m12:06:54.238241 [debug] [MainThread]: Flushing usage events
[0m12:06:58.020342 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff94d0d590>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff94d43390>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff94d0d010>]}


============================== 12:06:58.024726 | f0777c27-fa91-4606-a0a0-893dbf3f5d04 ==============================
[0m12:06:58.024726 [info ] [MainThread]: Running with dbt=1.8.9
[0m12:06:58.025397 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'debug': 'False', 'log_path': '/opt/airflow/project_root/dbt/logs', 'profiles_dir': '/opt/airflow/project_root/dbt', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'invocation_command': 'dbt test --project-dir /opt/airflow/project_root/dbt --profiles-dir /opt/airflow/project_root/dbt --select gold', 'introspect': 'True', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m12:06:58.098008 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'f0777c27-fa91-4606-a0a0-893dbf3f5d04', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff94d4d710>]}
[0m12:06:58.121948 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'f0777c27-fa91-4606-a0a0-893dbf3f5d04', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff9573b250>]}
[0m12:06:58.122576 [info ] [MainThread]: Registered adapter: clickhouse=1.8.9
[0m12:06:58.154315 [debug] [MainThread]: checksum: 132857a23e9d07220246854f7763165174ce9b737cfc7867629ace4294e520b1, vars: {}, profile: , target: , version: 1.8.9
[0m12:06:58.207176 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m12:06:58.207522 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m12:06:58.210470 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.movie_warehouse.bronze
[0m12:06:58.227512 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'f0777c27-fa91-4606-a0a0-893dbf3f5d04', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff94d43f90>]}
[0m12:06:58.294409 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'f0777c27-fa91-4606-a0a0-893dbf3f5d04', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff9479d450>]}
[0m12:06:58.294803 [info ] [MainThread]: Found 6 models, 12 data tests, 4 sources, 477 macros
[0m12:06:58.295031 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'f0777c27-fa91-4606-a0a0-893dbf3f5d04', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff94a741d0>]}
[0m12:06:58.296061 [info ] [MainThread]: 
[0m12:06:58.296397 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m12:06:58.299305 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list__gold_gold'
[0m12:06:58.306833 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:06:58.777769 [info ] [ThreadPool]: dbt_clickhouse adapter: Unexpected server exception dropping table
[0m12:06:58.778359 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__gold_gold: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "connection_name": "list__gold_gold"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'gold_gold'
      

  ...
[0m12:06:58.783941 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m12:06:58.811914 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'f0777c27-fa91-4606-a0a0-893dbf3f5d04', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff755eed50>]}
[0m12:06:58.812647 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m12:06:58.812948 [info ] [MainThread]: 
[0m12:06:58.823317 [debug] [Thread-1 (]: Began running node test.movie_warehouse.not_null_dim_genre_genre_id.9bb76b166c
[0m12:06:58.824003 [info ] [Thread-1 (]: 1 of 12 START test not_null_dim_genre_genre_id ................................. [RUN]
[0m12:06:58.824696 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list__gold_gold, now test.movie_warehouse.not_null_dim_genre_genre_id.9bb76b166c)
[0m12:06:58.825072 [debug] [Thread-1 (]: Began compiling node test.movie_warehouse.not_null_dim_genre_genre_id.9bb76b166c
[0m12:06:58.834067 [debug] [Thread-1 (]: Writing injected SQL for node "test.movie_warehouse.not_null_dim_genre_genre_id.9bb76b166c"
[0m12:06:58.835359 [debug] [Thread-1 (]: Began executing node test.movie_warehouse.not_null_dim_genre_genre_id.9bb76b166c
[0m12:06:58.847053 [debug] [Thread-1 (]: Writing runtime sql for node "test.movie_warehouse.not_null_dim_genre_genre_id.9bb76b166c"
[0m12:06:58.848517 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.movie_warehouse.not_null_dim_genre_genre_id.9bb76b166c: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "test.movie_warehouse.not_null_dim_genre_genre_id.9bb76b166c"} */

    
    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select genre_id
from `gold_gold`.`dim_genre`
where genre_id is null



  
  
    ) dbt_internal_test...
[0m12:06:58.859705 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m12:06:58.864327 [info ] [Thread-1 (]: 1 of 12 PASS not_null_dim_genre_genre_id ....................................... [[32mPASS[0m in 0.04s]
[0m12:06:58.864880 [debug] [Thread-1 (]: Finished running node test.movie_warehouse.not_null_dim_genre_genre_id.9bb76b166c
[0m12:06:58.865219 [debug] [Thread-1 (]: Began running node test.movie_warehouse.not_null_dim_movie_movie_id.fd05907b20
[0m12:06:58.865519 [info ] [Thread-1 (]: 2 of 12 START test not_null_dim_movie_movie_id ................................. [RUN]
[0m12:06:58.865916 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.movie_warehouse.not_null_dim_genre_genre_id.9bb76b166c, now test.movie_warehouse.not_null_dim_movie_movie_id.fd05907b20)
[0m12:06:58.866260 [debug] [Thread-1 (]: Began compiling node test.movie_warehouse.not_null_dim_movie_movie_id.fd05907b20
[0m12:06:58.869954 [debug] [Thread-1 (]: Writing injected SQL for node "test.movie_warehouse.not_null_dim_movie_movie_id.fd05907b20"
[0m12:06:58.871019 [debug] [Thread-1 (]: Began executing node test.movie_warehouse.not_null_dim_movie_movie_id.fd05907b20
[0m12:06:58.872933 [debug] [Thread-1 (]: Writing runtime sql for node "test.movie_warehouse.not_null_dim_movie_movie_id.fd05907b20"
[0m12:06:58.873746 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.movie_warehouse.not_null_dim_movie_movie_id.fd05907b20: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "test.movie_warehouse.not_null_dim_movie_movie_id.fd05907b20"} */

    
    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select movie_id
from `gold_gold`.`dim_movie`
where movie_id is null



  
  
    ) dbt_internal_test...
[0m12:06:58.879858 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m12:06:58.880935 [info ] [Thread-1 (]: 2 of 12 PASS not_null_dim_movie_movie_id ....................................... [[32mPASS[0m in 0.02s]
[0m12:06:58.881274 [debug] [Thread-1 (]: Finished running node test.movie_warehouse.not_null_dim_movie_movie_id.fd05907b20
[0m12:06:58.881520 [debug] [Thread-1 (]: Began running node test.movie_warehouse.not_null_dim_production_production_id.7ff384ec2b
[0m12:06:58.881761 [info ] [Thread-1 (]: 3 of 12 START test not_null_dim_production_production_id ....................... [RUN]
[0m12:06:58.882008 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.movie_warehouse.not_null_dim_movie_movie_id.fd05907b20, now test.movie_warehouse.not_null_dim_production_production_id.7ff384ec2b)
[0m12:06:58.882321 [debug] [Thread-1 (]: Began compiling node test.movie_warehouse.not_null_dim_production_production_id.7ff384ec2b
[0m12:06:58.887416 [debug] [Thread-1 (]: Writing injected SQL for node "test.movie_warehouse.not_null_dim_production_production_id.7ff384ec2b"
[0m12:06:58.888170 [debug] [Thread-1 (]: Began executing node test.movie_warehouse.not_null_dim_production_production_id.7ff384ec2b
[0m12:06:58.889359 [debug] [Thread-1 (]: Writing runtime sql for node "test.movie_warehouse.not_null_dim_production_production_id.7ff384ec2b"
[0m12:06:58.890035 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.movie_warehouse.not_null_dim_production_production_id.7ff384ec2b: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "test.movie_warehouse.not_null_dim_production_production_id.7ff384ec2b"} */

    
    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select production_id
from `gold_gold`.`dim_production`
where production_id is null



  
  
    ) dbt_internal_test...
[0m12:06:58.895401 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m12:06:58.897066 [info ] [Thread-1 (]: 3 of 12 PASS not_null_dim_production_production_id ............................. [[32mPASS[0m in 0.01s]
[0m12:06:58.897747 [debug] [Thread-1 (]: Finished running node test.movie_warehouse.not_null_dim_production_production_id.7ff384ec2b
[0m12:06:58.898255 [debug] [Thread-1 (]: Began running node test.movie_warehouse.not_null_dim_release_date_date_id.f6b8c9c3d5
[0m12:06:58.898725 [info ] [Thread-1 (]: 4 of 12 START test not_null_dim_release_date_date_id ........................... [RUN]
[0m12:06:58.899173 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.movie_warehouse.not_null_dim_production_production_id.7ff384ec2b, now test.movie_warehouse.not_null_dim_release_date_date_id.f6b8c9c3d5)
[0m12:06:58.899405 [debug] [Thread-1 (]: Began compiling node test.movie_warehouse.not_null_dim_release_date_date_id.f6b8c9c3d5
[0m12:06:58.902016 [debug] [Thread-1 (]: Writing injected SQL for node "test.movie_warehouse.not_null_dim_release_date_date_id.f6b8c9c3d5"
[0m12:06:58.903001 [debug] [Thread-1 (]: Began executing node test.movie_warehouse.not_null_dim_release_date_date_id.f6b8c9c3d5
[0m12:06:58.905014 [debug] [Thread-1 (]: Writing runtime sql for node "test.movie_warehouse.not_null_dim_release_date_date_id.f6b8c9c3d5"
[0m12:06:58.905813 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.movie_warehouse.not_null_dim_release_date_date_id.f6b8c9c3d5: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "test.movie_warehouse.not_null_dim_release_date_date_id.f6b8c9c3d5"} */

    
    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select date_id
from `gold_gold`.`dim_release_date`
where date_id is null



  
  
    ) dbt_internal_test...
[0m12:06:58.911834 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m12:06:58.913442 [info ] [Thread-1 (]: 4 of 12 PASS not_null_dim_release_date_date_id ................................. [[32mPASS[0m in 0.01s]
[0m12:06:58.913969 [debug] [Thread-1 (]: Finished running node test.movie_warehouse.not_null_dim_release_date_date_id.f6b8c9c3d5
[0m12:06:58.914475 [debug] [Thread-1 (]: Began running node test.movie_warehouse.not_null_fact_movie_date_id.ca6e5e8ca0
[0m12:06:58.915064 [info ] [Thread-1 (]: 5 of 12 START test not_null_fact_movie_date_id ................................. [RUN]
[0m12:06:58.915411 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.movie_warehouse.not_null_dim_release_date_date_id.f6b8c9c3d5, now test.movie_warehouse.not_null_fact_movie_date_id.ca6e5e8ca0)
[0m12:06:58.915615 [debug] [Thread-1 (]: Began compiling node test.movie_warehouse.not_null_fact_movie_date_id.ca6e5e8ca0
[0m12:06:58.917920 [debug] [Thread-1 (]: Writing injected SQL for node "test.movie_warehouse.not_null_fact_movie_date_id.ca6e5e8ca0"
[0m12:06:58.918720 [debug] [Thread-1 (]: Began executing node test.movie_warehouse.not_null_fact_movie_date_id.ca6e5e8ca0
[0m12:06:58.920708 [debug] [Thread-1 (]: Writing runtime sql for node "test.movie_warehouse.not_null_fact_movie_date_id.ca6e5e8ca0"
[0m12:06:58.921707 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.movie_warehouse.not_null_fact_movie_date_id.ca6e5e8ca0: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "test.movie_warehouse.not_null_fact_movie_date_id.ca6e5e8ca0"} */

    
    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select date_id
from `gold_gold`.`fact_movie`
where date_id is null



  
  
    ) dbt_internal_test...
[0m12:06:58.927856 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m12:06:58.929253 [info ] [Thread-1 (]: 5 of 12 PASS not_null_fact_movie_date_id ....................................... [[32mPASS[0m in 0.01s]
[0m12:06:58.929616 [debug] [Thread-1 (]: Finished running node test.movie_warehouse.not_null_fact_movie_date_id.ca6e5e8ca0
[0m12:06:58.929917 [debug] [Thread-1 (]: Began running node test.movie_warehouse.not_null_fact_movie_fact_id.1f53f01729
[0m12:06:58.930300 [info ] [Thread-1 (]: 6 of 12 START test not_null_fact_movie_fact_id ................................. [RUN]
[0m12:06:58.930838 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.movie_warehouse.not_null_fact_movie_date_id.ca6e5e8ca0, now test.movie_warehouse.not_null_fact_movie_fact_id.1f53f01729)
[0m12:06:58.931219 [debug] [Thread-1 (]: Began compiling node test.movie_warehouse.not_null_fact_movie_fact_id.1f53f01729
[0m12:06:58.933821 [debug] [Thread-1 (]: Writing injected SQL for node "test.movie_warehouse.not_null_fact_movie_fact_id.1f53f01729"
[0m12:06:58.934449 [debug] [Thread-1 (]: Began executing node test.movie_warehouse.not_null_fact_movie_fact_id.1f53f01729
[0m12:06:58.935674 [debug] [Thread-1 (]: Writing runtime sql for node "test.movie_warehouse.not_null_fact_movie_fact_id.1f53f01729"
[0m12:06:58.936378 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.movie_warehouse.not_null_fact_movie_fact_id.1f53f01729: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "test.movie_warehouse.not_null_fact_movie_fact_id.1f53f01729"} */

    
    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select fact_id
from `gold_gold`.`fact_movie`
where fact_id is null



  
  
    ) dbt_internal_test...
[0m12:06:58.940899 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:06:58.942096 [info ] [Thread-1 (]: 6 of 12 PASS not_null_fact_movie_fact_id ....................................... [[32mPASS[0m in 0.01s]
[0m12:06:58.942471 [debug] [Thread-1 (]: Finished running node test.movie_warehouse.not_null_fact_movie_fact_id.1f53f01729
[0m12:06:58.942744 [debug] [Thread-1 (]: Began running node test.movie_warehouse.not_null_fact_movie_movie_id.115d5160ae
[0m12:06:58.942998 [info ] [Thread-1 (]: 7 of 12 START test not_null_fact_movie_movie_id ................................ [RUN]
[0m12:06:58.943272 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.movie_warehouse.not_null_fact_movie_fact_id.1f53f01729, now test.movie_warehouse.not_null_fact_movie_movie_id.115d5160ae)
[0m12:06:58.943487 [debug] [Thread-1 (]: Began compiling node test.movie_warehouse.not_null_fact_movie_movie_id.115d5160ae
[0m12:06:58.945978 [debug] [Thread-1 (]: Writing injected SQL for node "test.movie_warehouse.not_null_fact_movie_movie_id.115d5160ae"
[0m12:06:58.947001 [debug] [Thread-1 (]: Began executing node test.movie_warehouse.not_null_fact_movie_movie_id.115d5160ae
[0m12:06:58.948364 [debug] [Thread-1 (]: Writing runtime sql for node "test.movie_warehouse.not_null_fact_movie_movie_id.115d5160ae"
[0m12:06:58.949116 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.movie_warehouse.not_null_fact_movie_movie_id.115d5160ae: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "test.movie_warehouse.not_null_fact_movie_movie_id.115d5160ae"} */

    
    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select movie_id
from `gold_gold`.`fact_movie`
where movie_id is null



  
  
    ) dbt_internal_test...
[0m12:06:58.953949 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:06:58.955256 [info ] [Thread-1 (]: 7 of 12 PASS not_null_fact_movie_movie_id ...................................... [[32mPASS[0m in 0.01s]
[0m12:06:58.955729 [debug] [Thread-1 (]: Finished running node test.movie_warehouse.not_null_fact_movie_movie_id.115d5160ae
[0m12:06:58.956035 [debug] [Thread-1 (]: Began running node test.movie_warehouse.unique_dim_genre_genre_id.757304f7bc
[0m12:06:58.956356 [info ] [Thread-1 (]: 8 of 12 START test unique_dim_genre_genre_id ................................... [RUN]
[0m12:06:58.956676 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.movie_warehouse.not_null_fact_movie_movie_id.115d5160ae, now test.movie_warehouse.unique_dim_genre_genre_id.757304f7bc)
[0m12:06:58.956911 [debug] [Thread-1 (]: Began compiling node test.movie_warehouse.unique_dim_genre_genre_id.757304f7bc
[0m12:06:59.031926 [debug] [Thread-1 (]: Writing injected SQL for node "test.movie_warehouse.unique_dim_genre_genre_id.757304f7bc"
[0m12:06:59.033097 [debug] [Thread-1 (]: Began executing node test.movie_warehouse.unique_dim_genre_genre_id.757304f7bc
[0m12:06:59.034731 [debug] [Thread-1 (]: Writing runtime sql for node "test.movie_warehouse.unique_dim_genre_genre_id.757304f7bc"
[0m12:06:59.035522 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.movie_warehouse.unique_dim_genre_genre_id.757304f7bc: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "test.movie_warehouse.unique_dim_genre_genre_id.757304f7bc"} */

    
    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    genre_id as unique_field,
    count(*) as n_records

from `gold_gold`.`dim_genre`
where genre_id is not null
group by genre_id
having count(*) > 1



  
  
    ) dbt_internal_test...
[0m12:06:59.045941 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m12:06:59.047512 [info ] [Thread-1 (]: 8 of 12 PASS unique_dim_genre_genre_id ......................................... [[32mPASS[0m in 0.09s]
[0m12:06:59.048017 [debug] [Thread-1 (]: Finished running node test.movie_warehouse.unique_dim_genre_genre_id.757304f7bc
[0m12:06:59.048377 [debug] [Thread-1 (]: Began running node test.movie_warehouse.unique_dim_movie_movie_id.42054933eb
[0m12:06:59.048696 [info ] [Thread-1 (]: 9 of 12 START test unique_dim_movie_movie_id ................................... [RUN]
[0m12:06:59.049017 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.movie_warehouse.unique_dim_genre_genre_id.757304f7bc, now test.movie_warehouse.unique_dim_movie_movie_id.42054933eb)
[0m12:06:59.049251 [debug] [Thread-1 (]: Began compiling node test.movie_warehouse.unique_dim_movie_movie_id.42054933eb
[0m12:06:59.051568 [debug] [Thread-1 (]: Writing injected SQL for node "test.movie_warehouse.unique_dim_movie_movie_id.42054933eb"
[0m12:06:59.052361 [debug] [Thread-1 (]: Began executing node test.movie_warehouse.unique_dim_movie_movie_id.42054933eb
[0m12:06:59.053732 [debug] [Thread-1 (]: Writing runtime sql for node "test.movie_warehouse.unique_dim_movie_movie_id.42054933eb"
[0m12:06:59.054392 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.movie_warehouse.unique_dim_movie_movie_id.42054933eb: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "test.movie_warehouse.unique_dim_movie_movie_id.42054933eb"} */

    
    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    movie_id as unique_field,
    count(*) as n_records

from `gold_gold`.`dim_movie`
where movie_id is not null
group by movie_id
having count(*) > 1



  
  
    ) dbt_internal_test...
[0m12:06:59.123493 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.07 seconds
[0m12:06:59.124802 [info ] [Thread-1 (]: 9 of 12 PASS unique_dim_movie_movie_id ......................................... [[32mPASS[0m in 0.08s]
[0m12:06:59.125575 [debug] [Thread-1 (]: Finished running node test.movie_warehouse.unique_dim_movie_movie_id.42054933eb
[0m12:06:59.126042 [debug] [Thread-1 (]: Began running node test.movie_warehouse.unique_dim_production_production_id.b674858001
[0m12:06:59.126456 [info ] [Thread-1 (]: 10 of 12 START test unique_dim_production_production_id ........................ [RUN]
[0m12:06:59.127055 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.movie_warehouse.unique_dim_movie_movie_id.42054933eb, now test.movie_warehouse.unique_dim_production_production_id.b674858001)
[0m12:06:59.127379 [debug] [Thread-1 (]: Began compiling node test.movie_warehouse.unique_dim_production_production_id.b674858001
[0m12:06:59.132179 [debug] [Thread-1 (]: Writing injected SQL for node "test.movie_warehouse.unique_dim_production_production_id.b674858001"
[0m12:06:59.133590 [debug] [Thread-1 (]: Began executing node test.movie_warehouse.unique_dim_production_production_id.b674858001
[0m12:06:59.135493 [debug] [Thread-1 (]: Writing runtime sql for node "test.movie_warehouse.unique_dim_production_production_id.b674858001"
[0m12:06:59.136697 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.movie_warehouse.unique_dim_production_production_id.b674858001: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "test.movie_warehouse.unique_dim_production_production_id.b674858001"} */

    
    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    production_id as unique_field,
    count(*) as n_records

from `gold_gold`.`dim_production`
where production_id is not null
group by production_id
having count(*) > 1



  
  
    ) dbt_internal_test...
[0m12:06:59.141363 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:06:59.142389 [info ] [Thread-1 (]: 10 of 12 PASS unique_dim_production_production_id .............................. [[32mPASS[0m in 0.02s]
[0m12:06:59.142703 [debug] [Thread-1 (]: Finished running node test.movie_warehouse.unique_dim_production_production_id.b674858001
[0m12:06:59.142939 [debug] [Thread-1 (]: Began running node test.movie_warehouse.unique_dim_release_date_date_id.fdf0ed82bf
[0m12:06:59.143144 [info ] [Thread-1 (]: 11 of 12 START test unique_dim_release_date_date_id ............................ [RUN]
[0m12:06:59.143355 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.movie_warehouse.unique_dim_production_production_id.b674858001, now test.movie_warehouse.unique_dim_release_date_date_id.fdf0ed82bf)
[0m12:06:59.143528 [debug] [Thread-1 (]: Began compiling node test.movie_warehouse.unique_dim_release_date_date_id.fdf0ed82bf
[0m12:06:59.145862 [debug] [Thread-1 (]: Writing injected SQL for node "test.movie_warehouse.unique_dim_release_date_date_id.fdf0ed82bf"
[0m12:06:59.146410 [debug] [Thread-1 (]: Began executing node test.movie_warehouse.unique_dim_release_date_date_id.fdf0ed82bf
[0m12:06:59.147439 [debug] [Thread-1 (]: Writing runtime sql for node "test.movie_warehouse.unique_dim_release_date_date_id.fdf0ed82bf"
[0m12:06:59.148124 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.movie_warehouse.unique_dim_release_date_date_id.fdf0ed82bf: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "test.movie_warehouse.unique_dim_release_date_date_id.fdf0ed82bf"} */

    
    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    date_id as unique_field,
    count(*) as n_records

from `gold_gold`.`dim_release_date`
where date_id is not null
group by date_id
having count(*) > 1



  
  
    ) dbt_internal_test...
[0m12:06:59.160876 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m12:06:59.162056 [info ] [Thread-1 (]: 11 of 12 PASS unique_dim_release_date_date_id .................................. [[32mPASS[0m in 0.02s]
[0m12:06:59.162401 [debug] [Thread-1 (]: Finished running node test.movie_warehouse.unique_dim_release_date_date_id.fdf0ed82bf
[0m12:06:59.162641 [debug] [Thread-1 (]: Began running node test.movie_warehouse.unique_fact_movie_fact_id.fbd4f040d2
[0m12:06:59.162853 [info ] [Thread-1 (]: 12 of 12 START test unique_fact_movie_fact_id .................................. [RUN]
[0m12:06:59.163074 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.movie_warehouse.unique_dim_release_date_date_id.fdf0ed82bf, now test.movie_warehouse.unique_fact_movie_fact_id.fbd4f040d2)
[0m12:06:59.163254 [debug] [Thread-1 (]: Began compiling node test.movie_warehouse.unique_fact_movie_fact_id.fbd4f040d2
[0m12:06:59.165279 [debug] [Thread-1 (]: Writing injected SQL for node "test.movie_warehouse.unique_fact_movie_fact_id.fbd4f040d2"
[0m12:06:59.165919 [debug] [Thread-1 (]: Began executing node test.movie_warehouse.unique_fact_movie_fact_id.fbd4f040d2
[0m12:06:59.166984 [debug] [Thread-1 (]: Writing runtime sql for node "test.movie_warehouse.unique_fact_movie_fact_id.fbd4f040d2"
[0m12:06:59.167514 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.movie_warehouse.unique_fact_movie_fact_id.fbd4f040d2: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "test.movie_warehouse.unique_fact_movie_fact_id.fbd4f040d2"} */

    
    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    fact_id as unique_field,
    count(*) as n_records

from `gold_gold`.`fact_movie`
where fact_id is not null
group by fact_id
having count(*) > 1



  
  
    ) dbt_internal_test...
[0m12:06:59.246162 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.08 seconds
[0m12:06:59.247980 [error] [Thread-1 (]: 12 of 12 FAIL 1050 unique_fact_movie_fact_id ................................... [[31mFAIL 1050[0m in 0.08s]
[0m12:06:59.248690 [debug] [Thread-1 (]: Finished running node test.movie_warehouse.unique_fact_movie_fact_id.fbd4f040d2
[0m12:06:59.250085 [debug] [MainThread]: Connection 'master' was properly closed.
[0m12:06:59.250353 [debug] [MainThread]: Connection 'test.movie_warehouse.unique_fact_movie_fact_id.fbd4f040d2' was left open.
[0m12:06:59.250529 [debug] [MainThread]: On test.movie_warehouse.unique_fact_movie_fact_id.fbd4f040d2: Close
[0m12:06:59.250791 [info ] [MainThread]: 
[0m12:06:59.251040 [info ] [MainThread]: Finished running 12 data tests in 0 hours 0 minutes and 0.95 seconds (0.95s).
[0m12:06:59.251898 [debug] [MainThread]: Command end result
[0m12:06:59.279208 [info ] [MainThread]: 
[0m12:06:59.279560 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m12:06:59.279779 [info ] [MainThread]: 
[0m12:06:59.280006 [error] [MainThread]: [31mFailure in test unique_fact_movie_fact_id (models/gold/schema.yml)[0m
[0m12:06:59.280206 [error] [MainThread]:   Got 1050 results, configured to fail if != 0
[0m12:06:59.280381 [info ] [MainThread]: 
[0m12:06:59.280574 [info ] [MainThread]:   compiled code at target/compiled/movie_warehouse/models/gold/schema.yml/unique_fact_movie_fact_id.sql
[0m12:06:59.280767 [info ] [MainThread]: 
[0m12:06:59.281038 [info ] [MainThread]: Done. PASS=11 WARN=0 ERROR=1 SKIP=0 TOTAL=12
[0m12:06:59.282009 [debug] [MainThread]: Resource report: {"command_name": "test", "command_success": false, "command_wall_clock_time": 1.2841697, "process_in_blocks": "1232", "process_kernel_time": 0.305726, "process_mem_max_rss": "187368", "process_out_blocks": "2349", "process_user_time": 1.934231}
[0m12:06:59.282350 [debug] [MainThread]: Command `dbt test` failed at 12:06:59.282298 after 1.28 seconds
[0m12:06:59.282667 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff94d6b1d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff99c09e10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff99c0a110>]}
[0m12:06:59.282936 [debug] [MainThread]: Flushing usage events
[0m12:07:56.665725 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8127d810>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff812b3910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff812b3d10>]}


============================== 12:07:56.668983 | 60cebfbd-3ad9-4347-adbd-d1042feb9733 ==============================
[0m12:07:56.668983 [info ] [MainThread]: Running with dbt=1.8.9
[0m12:07:56.669322 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'profiles_dir': '/opt/airflow/project_root/dbt', 'log_path': '/opt/airflow/project_root/dbt/logs', 'debug': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run --project-dir /opt/airflow/project_root/dbt --profiles-dir /opt/airflow/project_root/dbt --select gold', 'introspect': 'True', 'log_format': 'default', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m12:07:56.739849 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '60cebfbd-3ad9-4347-adbd-d1042feb9733', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff830b3510>]}
[0m12:07:56.759937 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '60cebfbd-3ad9-4347-adbd-d1042feb9733', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff81cab250>]}
[0m12:07:56.760744 [info ] [MainThread]: Registered adapter: clickhouse=1.8.9
[0m12:07:56.792095 [debug] [MainThread]: checksum: 132857a23e9d07220246854f7763165174ce9b737cfc7867629ace4294e520b1, vars: {}, profile: , target: , version: 1.8.9
[0m12:07:56.840898 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m12:07:56.841349 [debug] [MainThread]: Partial parsing: updated file: movie_warehouse://models/gold/fact_movie.sql
[0m12:07:56.924171 [warn ] [MainThread]: [[33mWARNING[0m]: Deprecated functionality
The `tests` config has been renamed to `data_tests`. Please see
https://docs.getdbt.com/docs/build/data-tests#new-data_tests-syntax for more
information.
[0m12:07:56.924595 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'deprecation', 'label': '60cebfbd-3ad9-4347-adbd-d1042feb9733', 'property_': 'warn', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8127e910>]}
[0m12:07:56.986110 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.movie_warehouse.bronze
[0m12:07:56.991467 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '60cebfbd-3ad9-4347-adbd-d1042feb9733', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff80e6add0>]}
[0m12:07:57.069990 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '60cebfbd-3ad9-4347-adbd-d1042feb9733', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff80c58dd0>]}
[0m12:07:57.070346 [info ] [MainThread]: Found 6 models, 12 data tests, 4 sources, 477 macros
[0m12:07:57.070560 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '60cebfbd-3ad9-4347-adbd-d1042feb9733', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff80c3f850>]}
[0m12:07:57.071381 [info ] [MainThread]: 
[0m12:07:57.071733 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m12:07:57.074601 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m12:07:57.078889 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:07:57.318631 [info ] [ThreadPool]: dbt_clickhouse adapter: Unexpected server exception dropping table
[0m12:07:57.319121 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m12:07:57.321584 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:07:57.382070 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__gold_gold)
[0m12:07:57.385485 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__gold_gold: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "connection_name": "list__gold_gold"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'gold_gold'
      

  ...
[0m12:07:57.390106 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:07:57.391503 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '60cebfbd-3ad9-4347-adbd-d1042feb9733', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff432a0790>]}
[0m12:07:57.391840 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m12:07:57.392046 [info ] [MainThread]: 
[0m12:07:57.396527 [debug] [Thread-1 (]: Began running node model.movie_warehouse.dim_director
[0m12:07:57.396928 [info ] [Thread-1 (]: 1 of 6 START sql table model `gold_gold`.`dim_director` ........................ [RUN]
[0m12:07:57.397302 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list__gold_gold, now model.movie_warehouse.dim_director)
[0m12:07:57.397509 [debug] [Thread-1 (]: Began compiling node model.movie_warehouse.dim_director
[0m12:07:57.401525 [debug] [Thread-1 (]: Writing injected SQL for node "model.movie_warehouse.dim_director"
[0m12:07:57.402491 [debug] [Thread-1 (]: Began executing node model.movie_warehouse.dim_director
[0m12:07:57.411085 [debug] [Thread-1 (]: Creating new relation dim_director
[0m12:07:57.423532 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_director: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_director"} */

            

    
        create table `gold_gold`.`dim_director`
        
  
        
  engine = MergeTree()
        order by (dir_id)
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

WITH first_dir AS (
    SELECT
        tconst,
        TRIM(splitByChar(',', directors)[1]) AS director_id
    FROM `bronze`.`imdb_title_crew_raw`
    WHERE directors IS NOT NULL AND directors != ''
),
deduped AS (
    SELECT DISTINCT director_id
    FROM first_dir
),
joined AS (
    SELECT
        d.director_id AS dir_id,
        n.primaryName AS dir_name
    FROM deduped d
    LEFT JOIN `bronze`.`imdb_name_basics_raw` n
        ON d.director_id = n.nconst
)
SELECT
    cityHash64(dir_id) AS imdb_dir_name_id,  -- Use hash instead of row_number
    dir_id,
    dir_name,
    today() AS valid_from,
    CAST(NULL AS Nullable(Date)) AS valid_to,
    1 AS is_current  -- Use 1/0 instead of TRUE/FALSE
FROM joined
WHERE dir_id IS NOT NULL
ORDER BY dir_id
          )
        
        ...
[0m12:07:57.431030 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m12:07:57.437706 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_director: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_director"} */

    select name, type from system.columns where table = 'dim_director'
    
      and database = 'gold_gold'
    
    order by position
  ...
[0m12:07:57.439993 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:07:57.441760 [debug] [Thread-1 (]: Writing runtime sql for node "model.movie_warehouse.dim_director"
[0m12:07:57.442634 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_director: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_director"} */

  
    
    
    
        
         


        insert into `gold_gold`.`dim_director`
        ("imdb_dir_name_id", "dir_id", "dir_name", "valid_from", "valid_to", "is_current")

WITH first_dir AS (
    SELECT
        tconst,
        TRIM(splitByChar(',', directors)[1]) AS director_id
    FROM `bronze`.`imdb_title_crew_raw`
    WHERE directors IS NOT NULL AND directors != ''
),
deduped AS (
    SELECT DISTINCT director_id
    FROM first_dir
),
joined AS (
    SELECT
        d.director_id AS dir_id,
        n.primaryName AS dir_name
    FROM deduped d
    LEFT JOIN `bronze`.`imdb_name_basics_raw` n
        ON d.director_id = n.nconst
)
SELECT
    cityHash64(dir_id) AS imdb_dir_name_id,  -- Use hash instead of row_number
    dir_id,
    dir_name,
    today() AS valid_from,
    CAST(NULL AS Nullable(Date)) AS valid_to,
    1 AS is_current  -- Use 1/0 instead of TRUE/FALSE
FROM joined
WHERE dir_id IS NOT NULL
ORDER BY dir_id
  ...
[0m12:07:59.179798 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 1.74 seconds
[0m12:07:59.201894 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '60cebfbd-3ad9-4347-adbd-d1042feb9733', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff4334b750>]}
[0m12:07:59.203164 [info ] [Thread-1 (]: 1 of 6 OK created sql table model `gold_gold`.`dim_director` ................... [[32mOK[0m in 1.80s]
[0m12:07:59.203856 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.dim_director
[0m12:07:59.204382 [debug] [Thread-1 (]: Began running node model.movie_warehouse.dim_genre
[0m12:07:59.205059 [info ] [Thread-1 (]: 2 of 6 START sql table model `gold_gold`.`dim_genre` ........................... [RUN]
[0m12:07:59.205480 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.movie_warehouse.dim_director, now model.movie_warehouse.dim_genre)
[0m12:07:59.205750 [debug] [Thread-1 (]: Began compiling node model.movie_warehouse.dim_genre
[0m12:07:59.209586 [debug] [Thread-1 (]: Writing injected SQL for node "model.movie_warehouse.dim_genre"
[0m12:07:59.210644 [debug] [Thread-1 (]: Began executing node model.movie_warehouse.dim_genre
[0m12:07:59.212168 [debug] [Thread-1 (]: Creating new relation dim_genre
[0m12:07:59.212966 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_genre: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_genre"} */

            

    
        create table `gold_gold`.`dim_genre`
        
  
        
  engine = MergeTree()
        order by (genre_id)
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

WITH parsed_genres AS (
    SELECT
        TRIM(splitByChar(',', genres)[1]) AS first_genre
    FROM `bronze`.`tmdb_raw`
    WHERE genres IS NOT NULL AND genres != ''
)
SELECT
    cityHash64(first_genre) AS genre_id,
    first_genre AS genre_name
FROM parsed_genres
GROUP BY first_genre
ORDER BY first_genre
          )
        
        ...
[0m12:07:59.228981 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m12:07:59.230767 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_genre: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_genre"} */

    select name, type from system.columns where table = 'dim_genre'
    
      and database = 'gold_gold'
    
    order by position
  ...
[0m12:07:59.234454 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:07:59.235800 [debug] [Thread-1 (]: Writing runtime sql for node "model.movie_warehouse.dim_genre"
[0m12:07:59.236621 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_genre: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_genre"} */

  
    
    
    
        
         


        insert into `gold_gold`.`dim_genre`
        ("genre_id", "genre_name")

WITH parsed_genres AS (
    SELECT
        TRIM(splitByChar(',', genres)[1]) AS first_genre
    FROM `bronze`.`tmdb_raw`
    WHERE genres IS NOT NULL AND genres != ''
)
SELECT
    cityHash64(first_genre) AS genre_id,
    first_genre AS genre_name
FROM parsed_genres
GROUP BY first_genre
ORDER BY first_genre
  ...
[0m12:07:59.258100 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m12:07:59.259345 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '60cebfbd-3ad9-4347-adbd-d1042feb9733', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff40854050>]}
[0m12:07:59.259683 [info ] [Thread-1 (]: 2 of 6 OK created sql table model `gold_gold`.`dim_genre` ...................... [[32mOK[0m in 0.05s]
[0m12:07:59.259965 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.dim_genre
[0m12:07:59.260254 [debug] [Thread-1 (]: Began running node model.movie_warehouse.dim_movie
[0m12:07:59.260610 [info ] [Thread-1 (]: 3 of 6 START sql table model `gold_gold`.`dim_movie` ........................... [RUN]
[0m12:07:59.260860 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.movie_warehouse.dim_genre, now model.movie_warehouse.dim_movie)
[0m12:07:59.261040 [debug] [Thread-1 (]: Began compiling node model.movie_warehouse.dim_movie
[0m12:07:59.264503 [debug] [Thread-1 (]: Writing injected SQL for node "model.movie_warehouse.dim_movie"
[0m12:07:59.265523 [debug] [Thread-1 (]: Began executing node model.movie_warehouse.dim_movie
[0m12:07:59.266800 [debug] [Thread-1 (]: Creating new relation dim_movie
[0m12:07:59.267408 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_movie: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_movie"} */

            

    
        create table `gold_gold`.`dim_movie`
        
  
        
  engine = MergeTree()
        order by (movie_id)
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            -- ...existing code...


WITH movie_src AS (
    SELECT
        TRIM(title) AS movie_title,
        imdb_id,
        release_date,
        runtime AS movie_runtime,
        original_language AS language
    FROM `bronze`.`tmdb_raw`
    WHERE title IS NOT NULL AND title != ''
)
SELECT
    cityHash64(movie_title) AS movie_id,
    any(imdb_id) AS imdb_id,
    movie_title,
    any(release_date) AS release_date,
    any(movie_runtime) AS movie_runtime,
    any(language) AS language
FROM movie_src
GROUP BY movie_title
ORDER BY movie_title
          )
        
        ...
[0m12:07:59.274433 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m12:07:59.276045 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_movie: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_movie"} */

    select name, type from system.columns where table = 'dim_movie'
    
      and database = 'gold_gold'
    
    order by position
  ...
[0m12:07:59.279502 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:07:59.280610 [debug] [Thread-1 (]: Writing runtime sql for node "model.movie_warehouse.dim_movie"
[0m12:07:59.281516 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_movie: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_movie"} */

  
    
    
    
        
         


        insert into `gold_gold`.`dim_movie`
        ("movie_id", "imdb_id", "movie_title", "release_date", "movie_runtime", "language")-- ...existing code...


WITH movie_src AS (
    SELECT
        TRIM(title) AS movie_title,
        imdb_id,
        release_date,
        runtime AS movie_runtime,
        original_language AS language
    FROM `bronze`.`tmdb_raw`
    WHERE title IS NOT NULL AND title != ''
)
SELECT
    cityHash64(movie_title) AS movie_id,
    any(imdb_id) AS imdb_id,
    movie_title,
    any(release_date) AS release_date,
    any(movie_runtime) AS movie_runtime,
    any(language) AS language
FROM movie_src
GROUP BY movie_title
ORDER BY movie_title
  ...
[0m12:07:59.508593 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.23 seconds
[0m12:07:59.509924 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '60cebfbd-3ad9-4347-adbd-d1042feb9733', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff4074c7d0>]}
[0m12:07:59.510307 [info ] [Thread-1 (]: 3 of 6 OK created sql table model `gold_gold`.`dim_movie` ...................... [[32mOK[0m in 0.25s]
[0m12:07:59.510605 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.dim_movie
[0m12:07:59.510875 [debug] [Thread-1 (]: Began running node model.movie_warehouse.dim_production
[0m12:07:59.511203 [info ] [Thread-1 (]: 4 of 6 START sql table model `gold_gold`.`dim_production` ...................... [RUN]
[0m12:07:59.511451 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.movie_warehouse.dim_movie, now model.movie_warehouse.dim_production)
[0m12:07:59.511668 [debug] [Thread-1 (]: Began compiling node model.movie_warehouse.dim_production
[0m12:07:59.513245 [debug] [Thread-1 (]: Writing injected SQL for node "model.movie_warehouse.dim_production"
[0m12:07:59.513835 [debug] [Thread-1 (]: Began executing node model.movie_warehouse.dim_production
[0m12:07:59.515054 [debug] [Thread-1 (]: Creating new relation dim_production
[0m12:07:59.515877 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_production: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_production"} */

            

    
        create table `gold_gold`.`dim_production`
        
  
        
  engine = MergeTree()
        order by (production_id)
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

WITH first_production AS (
    SELECT
        imdb_id AS movie_id,
        trim(splitByChar(',', production_companies)[1]) AS production_name
    FROM `bronze`.`tmdb_raw`
    WHERE production_companies IS NOT NULL AND production_companies != ''
)

SELECT
    cityHash64(production_name) AS production_id,
    production_name,
    current_date() AS valid_from,
    CAST(NULL AS Nullable(Date)) AS valid_to,
    TRUE AS is_current
FROM (
    SELECT DISTINCT production_name
    FROM first_production
)
WHERE production_name IS NOT NULL
          )
        
        ...
[0m12:07:59.524841 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m12:07:59.526696 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_production: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_production"} */

    select name, type from system.columns where table = 'dim_production'
    
      and database = 'gold_gold'
    
    order by position
  ...
[0m12:07:59.529518 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:07:59.530647 [debug] [Thread-1 (]: Writing runtime sql for node "model.movie_warehouse.dim_production"
[0m12:07:59.531274 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_production: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_production"} */

  
    
    
    
        
         


        insert into `gold_gold`.`dim_production`
        ("production_id", "production_name", "valid_from", "valid_to", "is_current")

WITH first_production AS (
    SELECT
        imdb_id AS movie_id,
        trim(splitByChar(',', production_companies)[1]) AS production_name
    FROM `bronze`.`tmdb_raw`
    WHERE production_companies IS NOT NULL AND production_companies != ''
)

SELECT
    cityHash64(production_name) AS production_id,
    production_name,
    current_date() AS valid_from,
    CAST(NULL AS Nullable(Date)) AS valid_to,
    TRUE AS is_current
FROM (
    SELECT DISTINCT production_name
    FROM first_production
)
WHERE production_name IS NOT NULL
  ...
[0m12:07:59.534676 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:07:59.535830 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '60cebfbd-3ad9-4347-adbd-d1042feb9733', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff80f04650>]}
[0m12:07:59.536518 [info ] [Thread-1 (]: 4 of 6 OK created sql table model `gold_gold`.`dim_production` ................. [[32mOK[0m in 0.02s]
[0m12:07:59.536942 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.dim_production
[0m12:07:59.537181 [debug] [Thread-1 (]: Began running node model.movie_warehouse.dim_release_date
[0m12:07:59.537477 [info ] [Thread-1 (]: 5 of 6 START sql table model `gold_gold`.`dim_release_date` .................... [RUN]
[0m12:07:59.537723 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.movie_warehouse.dim_production, now model.movie_warehouse.dim_release_date)
[0m12:07:59.537928 [debug] [Thread-1 (]: Began compiling node model.movie_warehouse.dim_release_date
[0m12:07:59.539939 [debug] [Thread-1 (]: Writing injected SQL for node "model.movie_warehouse.dim_release_date"
[0m12:07:59.540593 [debug] [Thread-1 (]: Began executing node model.movie_warehouse.dim_release_date
[0m12:07:59.541660 [debug] [Thread-1 (]: Creating new relation dim_release_date
[0m12:07:59.542231 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_release_date: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_release_date"} */

            

    
        create table `gold_gold`.`dim_release_date`
        
  
        
  engine = MergeTree()
        order by (date_id)
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

WITH distinct_dates AS (
    SELECT DISTINCT release_date
    FROM `bronze`.`tmdb_raw`
    WHERE release_date IS NOT NULL
)

SELECT
    cityHash64(release_date)                                    AS date_id,
    release_date                                                AS full_date,
    toYear(release_date)                                        AS year,
    toMonth(release_date)                                       AS month,
    toDayOfMonth(release_date)                                  AS day,
    toISOWeek(release_date)                                     AS week,
    formatDateTime(release_date, '%a')                          AS weekday,
    CASE
        WHEN toMonth(release_date) IN (12,1,2)  THEN 'Winter'
        WHEN toMonth(release_date) IN (3,4,5)   THEN 'Spring'
        WHEN toMonth(release_date) IN (6,7,8)   THEN 'Summer'
        WHEN toMonth(release_date) IN (9,10,11) THEN 'Autumn'
    END                                                         AS season,
    CASE
        WHEN formatDateTime(release_date, '%a') IN ('Saturday','Sunday') THEN 1
        ELSE 0
    END                                                         AS is_weekend,

    /* ---------- holiday tagging ---------- */
    CASE
        WHEN toMonth(release_date)=1  AND toDayOfMonth(release_date)=1  THEN 'New Years Day'
        WHEN toMonth(release_date)=2  AND toDayOfMonth(release_date)=14 THEN 'Valentines Day'
        WHEN toMonth(release_date)=3  AND toDayOfMonth(release_date)=17 THEN 'St. Patricks Day'
        WHEN toMonth(release_date)=4  AND toDayOfMonth(release_date)=1  THEN 'April Fools Day'
        WHEN toMonth(release_date)=4  AND toDayOfMonth(release_date)=22 THEN 'Earth Day'
        WHEN toMonth(release_date)=5  AND toDayOfMonth(release_date)=1  THEN 'May Day'
        WHEN toMonth(release_date)=5  AND toDayOfMonth(release_date)=5  THEN 'Cinco de Mayo'
        WHEN toMonth(release_date)=6  AND toDayOfMonth(release_date) BETWEEN 19 AND 26 THEN 'Midsummer'
        WHEN toMonth(release_date)=7  AND toDayOfMonth(release_date)=4  THEN 'Independence Day'
        WHEN toMonth(release_date)=9  AND toDayOfMonth(release_date) BETWEEN 1 AND 7 
             AND formatDateTime(release_date,'%a')='Monday'             THEN 'Labor Day (US)'
        WHEN toMonth(release_date)=10 AND toDayOfMonth(release_date)=31 THEN 'Halloween'
        WHEN toMonth(release_date)=11 AND formatDateTime(release_date,'%a')='Thursday'
             AND toISOWeek(release_date) >= 47                           THEN 'Thanksgiving'
        WHEN toMonth(release_date)=12 AND toDayOfMonth(release_date)=24 THEN 'Christmas Eve'
        WHEN toMonth(release_date)=12 AND toDayOfMonth(release_date)=25 THEN 'Christmas Day'
        WHEN toMonth(release_date)=12 AND toDayOfMonth(release_date)=31 THEN 'New Years Eve'
        ELSE NULL
    END                                                         AS holiday_name,
    IF(holiday_name IS NOT NULL, 1, 0)                          AS is_holiday,

    /* placeholders for later enhancement */
    CAST(NULL AS Nullable(Int32)) AS days_until_holiday,
    CAST(NULL AS Nullable(Int32)) AS days_after_holiday

FROM distinct_dates
ORDER BY release_date
          )
        
        ...
[0m12:07:59.554515 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m12:07:59.555875 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_release_date: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_release_date"} */

    select name, type from system.columns where table = 'dim_release_date'
    
      and database = 'gold_gold'
    
    order by position
  ...
[0m12:07:59.557866 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:07:59.559001 [debug] [Thread-1 (]: Writing runtime sql for node "model.movie_warehouse.dim_release_date"
[0m12:07:59.559532 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_release_date: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_release_date"} */

  
    
    
    
        
         


        insert into `gold_gold`.`dim_release_date`
        ("date_id", "full_date", "year", "month", "day", "week", "weekday", "season", "is_weekend", "holiday_name", "is_holiday", "days_until_holiday", "days_after_holiday")

WITH distinct_dates AS (
    SELECT DISTINCT release_date
    FROM `bronze`.`tmdb_raw`
    WHERE release_date IS NOT NULL
)

SELECT
    cityHash64(release_date)                                    AS date_id,
    release_date                                                AS full_date,
    toYear(release_date)                                        AS year,
    toMonth(release_date)                                       AS month,
    toDayOfMonth(release_date)                                  AS day,
    toISOWeek(release_date)                                     AS week,
    formatDateTime(release_date, '%a')                          AS weekday,
    CASE
        WHEN toMonth(release_date) IN (12,1,2)  THEN 'Winter'
        WHEN toMonth(release_date) IN (3,4,5)   THEN 'Spring'
        WHEN toMonth(release_date) IN (6,7,8)   THEN 'Summer'
        WHEN toMonth(release_date) IN (9,10,11) THEN 'Autumn'
    END                                                         AS season,
    CASE
        WHEN formatDateTime(release_date, '%a') IN ('Saturday','Sunday') THEN 1
        ELSE 0
    END                                                         AS is_weekend,

    /* ---------- holiday tagging ---------- */
    CASE
        WHEN toMonth(release_date)=1  AND toDayOfMonth(release_date)=1  THEN 'New Years Day'
        WHEN toMonth(release_date)=2  AND toDayOfMonth(release_date)=14 THEN 'Valentines Day'
        WHEN toMonth(release_date)=3  AND toDayOfMonth(release_date)=17 THEN 'St. Patricks Day'
        WHEN toMonth(release_date)=4  AND toDayOfMonth(release_date)=1  THEN 'April Fools Day'
        WHEN toMonth(release_date)=4  AND toDayOfMonth(release_date)=22 THEN 'Earth Day'
        WHEN toMonth(release_date)=5  AND toDayOfMonth(release_date)=1  THEN 'May Day'
        WHEN toMonth(release_date)=5  AND toDayOfMonth(release_date)=5  THEN 'Cinco de Mayo'
        WHEN toMonth(release_date)=6  AND toDayOfMonth(release_date) BETWEEN 19 AND 26 THEN 'Midsummer'
        WHEN toMonth(release_date)=7  AND toDayOfMonth(release_date)=4  THEN 'Independence Day'
        WHEN toMonth(release_date)=9  AND toDayOfMonth(release_date) BETWEEN 1 AND 7 
             AND formatDateTime(release_date,'%a')='Monday'             THEN 'Labor Day (US)'
        WHEN toMonth(release_date)=10 AND toDayOfMonth(release_date)=31 THEN 'Halloween'
        WHEN toMonth(release_date)=11 AND formatDateTime(release_date,'%a')='Thursday'
             AND toISOWeek(release_date) >= 47                           THEN 'Thanksgiving'
        WHEN toMonth(release_date)=12 AND toDayOfMonth(release_date)=24 THEN 'Christmas Eve'
        WHEN toMonth(release_date)=12 AND toDayOfMonth(release_date)=25 THEN 'Christmas Day'
        WHEN toMonth(release_date)=12 AND toDayOfMonth(release_date)=31 THEN 'New Years Eve'
        ELSE NULL
    END                                                         AS holiday_name,
    IF(holiday_name IS NOT NULL, 1, 0)                          AS is_holiday,

    /* placeholders for later enhancement */
    CAST(NULL AS Nullable(Int32)) AS days_until_holiday,
    CAST(NULL AS Nullable(Int32)) AS days_after_holiday

FROM distinct_dates
ORDER BY release_date
  ...
[0m12:07:59.583461 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m12:07:59.584741 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '60cebfbd-3ad9-4347-adbd-d1042feb9733', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff4073ef50>]}
[0m12:07:59.585243 [info ] [Thread-1 (]: 5 of 6 OK created sql table model `gold_gold`.`dim_release_date` ............... [[32mOK[0m in 0.05s]
[0m12:07:59.585617 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.dim_release_date
[0m12:07:59.588791 [debug] [Thread-1 (]: Began running node model.movie_warehouse.fact_movie
[0m12:07:59.589514 [info ] [Thread-1 (]: 6 of 6 START sql table model `gold_gold`.`fact_movie` .......................... [RUN]
[0m12:07:59.589836 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.movie_warehouse.dim_release_date, now model.movie_warehouse.fact_movie)
[0m12:07:59.590267 [debug] [Thread-1 (]: Began compiling node model.movie_warehouse.fact_movie
[0m12:07:59.594287 [debug] [Thread-1 (]: Writing injected SQL for node "model.movie_warehouse.fact_movie"
[0m12:07:59.595593 [debug] [Thread-1 (]: Began executing node model.movie_warehouse.fact_movie
[0m12:07:59.600622 [debug] [Thread-1 (]: Creating new relation fact_movie
[0m12:07:59.602839 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.fact_movie: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.fact_movie"} */

            

    
        create table `gold_gold`.`fact_movie`
        
  
        
  engine = MergeTree()
        order by (fact_id)
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

WITH filtered_tmdb AS (
    SELECT 
        imdb_id,
        title,
        release_date,
        production_companies,
        budget,
        revenue,
        vote_average,
        vote_count,
        runtime,
        genres,
        original_language,
        (vote_average * log(1 + vote_count)) AS movie_popularity
    FROM `bronze`.`tmdb_raw`
),

-- First genre
first_genre AS (
    SELECT
        imdb_id AS movie_id,
        trim(splitByChar(',', genres)[1]) AS genre_name
    FROM filtered_tmdb
),

-- First director
first_director AS (
    SELECT
        t.imdb_id AS movie_id,
        trim(splitByChar(',', c.directors)[1]) AS director_id
    FROM filtered_tmdb t
    LEFT JOIN `bronze`.`imdb_title_crew_raw` c
        ON t.imdb_id = c.tconst
),

-- Join to dim_production to get production_id
movie_production AS (
    SELECT
        t.imdb_id AS movie_id,
        p.production_id
    FROM filtered_tmdb t
    LEFT JOIN `gold_gold`.`dim_production` p
        ON trim(splitByChar(',', t.production_companies)[1]) = p.production_name
),

-- Map genre_name to dim_genre to get genre_id
movie_genre AS (
    SELECT
        fg.movie_id,
        g.genre_id
    FROM first_genre fg
    LEFT JOIN `gold_gold`.`dim_genre` g
        ON fg.genre_name = g.genre_name
),

base AS (
    SELECT
        t.imdb_id                                 AS movie_id,
        d.director_id,
        mg.genre_id,
        mp.production_id,
        dr.date_id                                AS date_id,
        t.vote_average                            AS vote_avg,
        t.vote_count,
        t.revenue,
        t.budget,
        t.movie_popularity,
        toYear(t.release_date)                    AS release_year
    FROM filtered_tmdb t
    LEFT JOIN movie_genre mg       ON mg.movie_id = t.imdb_id
    LEFT JOIN first_director d     ON d.movie_id = t.imdb_id
    LEFT JOIN movie_production mp  ON mp.movie_id = t.imdb_id
    LEFT JOIN `gold_gold`.`dim_release_date` dr
        ON dr.full_date = t.release_date
),

metrics AS (
    SELECT
        b.*,
        b.revenue - lag(b.revenue, 1) OVER (PARTITION BY b.movie_id ORDER BY b.release_year) AS revenue_growth,
        b.movie_popularity - lag(b.movie_popularity, 1) OVER (PARTITION BY b.movie_id ORDER BY b.release_year) AS popularity_change,
        b.vote_avg - lag(b.vote_avg, 1) OVER (PARTITION BY b.movie_id ORDER BY b.release_year) AS vote_avg_change
    FROM base b
)

SELECT
    cityHash64(concat(
        coalesce(movie_id, 'null'), '-',
        coalesce(toString(date_id), 'null'), '-',
        coalesce(toString(director_id), 'null'), '-',
        coalesce(toString(genre_id), 'null')
    )) AS fact_id,
    movie_id,
    director_id,
    genre_id,
    production_id,
    date_id,
    vote_avg,
    vote_count,
    revenue,
    budget,
    movie_popularity,
    revenue_growth,
    popularity_change,
    vote_avg_change
FROM metrics
          )
        
        ...
[0m12:07:59.619509 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m12:07:59.621659 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.fact_movie: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.fact_movie"} */

    select name, type from system.columns where table = 'fact_movie'
    
      and database = 'gold_gold'
    
    order by position
  ...
[0m12:07:59.625214 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:07:59.626489 [debug] [Thread-1 (]: Writing runtime sql for node "model.movie_warehouse.fact_movie"
[0m12:07:59.627390 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.fact_movie: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.fact_movie"} */

  
    
    
    
        
         


        insert into `gold_gold`.`fact_movie`
        ("fact_id", "movie_id", "director_id", "genre_id", "production_id", "date_id", "vote_avg", "vote_count", "revenue", "budget", "movie_popularity", "revenue_growth", "popularity_change", "vote_avg_change")

WITH filtered_tmdb AS (
    SELECT 
        imdb_id,
        title,
        release_date,
        production_companies,
        budget,
        revenue,
        vote_average,
        vote_count,
        runtime,
        genres,
        original_language,
        (vote_average * log(1 + vote_count)) AS movie_popularity
    FROM `bronze`.`tmdb_raw`
),

-- First genre
first_genre AS (
    SELECT
        imdb_id AS movie_id,
        trim(splitByChar(',', genres)[1]) AS genre_name
    FROM filtered_tmdb
),

-- First director
first_director AS (
    SELECT
        t.imdb_id AS movie_id,
        trim(splitByChar(',', c.directors)[1]) AS director_id
    FROM filtered_tmdb t
    LEFT JOIN `bronze`.`imdb_title_crew_raw` c
        ON t.imdb_id = c.tconst
),

-- Join to dim_production to get production_id
movie_production AS (
    SELECT
        t.imdb_id AS movie_id,
        p.production_id
    FROM filtered_tmdb t
    LEFT JOIN `gold_gold`.`dim_production` p
        ON trim(splitByChar(',', t.production_companies)[1]) = p.production_name
),

-- Map genre_name to dim_genre to get genre_id
movie_genre AS (
    SELECT
        fg.movie_id,
        g.genre_id
    FROM first_genre fg
    LEFT JOIN `gold_gold`.`dim_genre` g
        ON fg.genre_name = g.genre_name
),

base AS (
    SELECT
        t.imdb_id                                 AS movie_id,
        d.director_id,
        mg.genre_id,
        mp.production_id,
        dr.date_id                                AS date_id,
        t.vote_average                            AS vote_avg,
        t.vote_count,
        t.revenue,
        t.budget,
        t.movie_popularity,
        toYear(t.release_date)                    AS release_year
    FROM filtered_tmdb t
    LEFT JOIN movie_genre mg       ON mg.movie_id = t.imdb_id
    LEFT JOIN first_director d     ON d.movie_id = t.imdb_id
    LEFT JOIN movie_production mp  ON mp.movie_id = t.imdb_id
    LEFT JOIN `gold_gold`.`dim_release_date` dr
        ON dr.full_date = t.release_date
),

metrics AS (
    SELECT
        b.*,
        b.revenue - lag(b.revenue, 1) OVER (PARTITION BY b.movie_id ORDER BY b.release_year) AS revenue_growth,
        b.movie_popularity - lag(b.movie_popularity, 1) OVER (PARTITION BY b.movie_id ORDER BY b.release_year) AS popularity_change,
        b.vote_avg - lag(b.vote_avg, 1) OVER (PARTITION BY b.movie_id ORDER BY b.release_year) AS vote_avg_change
    FROM base b
)

SELECT
    cityHash64(concat(
        coalesce(movie_id, 'null'), '-',
        coalesce(toString(date_id), 'null'), '-',
        coalesce(toString(director_id), 'null'), '-',
        coalesce(toString(genre_id), 'null')
    )) AS fact_id,
    movie_id,
    director_id,
    genre_id,
    production_id,
    date_id,
    vote_avg,
    vote_count,
    revenue,
    budget,
    movie_popularity,
    revenue_growth,
    popularity_change,
    vote_avg_change
FROM metrics
  ...
[0m12:08:02.387994 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 2.76 seconds
[0m12:08:02.399568 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '60cebfbd-3ad9-4347-adbd-d1042feb9733', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff407ab5d0>]}
[0m12:08:02.401098 [info ] [Thread-1 (]: 6 of 6 OK created sql table model `gold_gold`.`fact_movie` ..................... [[32mOK[0m in 2.81s]
[0m12:08:02.402029 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.fact_movie
[0m12:08:02.405563 [debug] [MainThread]: Connection 'master' was properly closed.
[0m12:08:02.405936 [debug] [MainThread]: Connection 'model.movie_warehouse.fact_movie' was left open.
[0m12:08:02.406229 [debug] [MainThread]: On model.movie_warehouse.fact_movie: Close
[0m12:08:02.407434 [info ] [MainThread]: 
[0m12:08:02.407786 [info ] [MainThread]: Finished running 6 table models in 0 hours 0 minutes and 5.34 seconds (5.34s).
[0m12:08:02.409061 [debug] [MainThread]: Command end result
[0m12:08:02.448326 [info ] [MainThread]: 
[0m12:08:02.448694 [info ] [MainThread]: [32mCompleted successfully[0m
[0m12:08:02.448932 [info ] [MainThread]: 
[0m12:08:02.449234 [info ] [MainThread]: Done. PASS=6 WARN=0 ERROR=0 SKIP=0 TOTAL=6
[0m12:08:02.452338 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 5.8046446, "process_in_blocks": "0", "process_kernel_time": 0.24733, "process_mem_max_rss": "192900", "process_out_blocks": "3488", "process_user_time": 1.86249}
[0m12:08:02.453114 [debug] [MainThread]: Command `dbt run` succeeded at 12:08:02.453040 after 5.81 seconds
[0m12:08:02.453605 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff86041ed0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff86178890>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff86179fd0>]}
[0m12:08:02.453834 [debug] [MainThread]: Flushing usage events
[0m12:08:05.211267 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8eb9d150>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8ebcf890>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8eb9d5d0>]}


============================== 12:08:05.214751 | e8b764be-c58d-43d1-b646-ef13783ff173 ==============================
[0m12:08:05.214751 [info ] [MainThread]: Running with dbt=1.8.9
[0m12:08:05.215158 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'debug': 'False', 'log_path': '/opt/airflow/project_root/dbt/logs', 'profiles_dir': '/opt/airflow/project_root/dbt', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'log_format': 'default', 'introspect': 'True', 'target_path': 'None', 'invocation_command': 'dbt test --project-dir /opt/airflow/project_root/dbt --profiles-dir /opt/airflow/project_root/dbt --select gold', 'send_anonymous_usage_stats': 'True'}
[0m12:08:05.297840 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'e8b764be-c58d-43d1-b646-ef13783ff173', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff909d3110>]}
[0m12:08:05.319874 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'e8b764be-c58d-43d1-b646-ef13783ff173', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8f5cb190>]}
[0m12:08:05.320494 [info ] [MainThread]: Registered adapter: clickhouse=1.8.9
[0m12:08:05.354724 [debug] [MainThread]: checksum: 132857a23e9d07220246854f7763165174ce9b737cfc7867629ace4294e520b1, vars: {}, profile: , target: , version: 1.8.9
[0m12:08:05.413066 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m12:08:05.413441 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m12:08:05.416656 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.movie_warehouse.bronze
[0m12:08:05.439846 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'e8b764be-c58d-43d1-b646-ef13783ff173', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8e995d10>]}
[0m12:08:05.501901 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'e8b764be-c58d-43d1-b646-ef13783ff173', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8e62cb90>]}
[0m12:08:05.502260 [info ] [MainThread]: Found 6 models, 12 data tests, 4 sources, 477 macros
[0m12:08:05.502638 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'e8b764be-c58d-43d1-b646-ef13783ff173', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8e904110>]}
[0m12:08:05.503681 [info ] [MainThread]: 
[0m12:08:05.504031 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m12:08:05.506818 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list__gold_gold'
[0m12:08:05.512261 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:08:05.778504 [info ] [ThreadPool]: dbt_clickhouse adapter: Unexpected server exception dropping table
[0m12:08:05.778903 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__gold_gold: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "connection_name": "list__gold_gold"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'gold_gold'
      

  ...
[0m12:08:05.782196 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:08:05.797275 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'e8b764be-c58d-43d1-b646-ef13783ff173', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8e886490>]}
[0m12:08:05.797664 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m12:08:05.797891 [info ] [MainThread]: 
[0m12:08:05.802183 [debug] [Thread-1 (]: Began running node test.movie_warehouse.not_null_dim_genre_genre_id.9bb76b166c
[0m12:08:05.802481 [info ] [Thread-1 (]: 1 of 12 START test not_null_dim_genre_genre_id ................................. [RUN]
[0m12:08:05.802785 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list__gold_gold, now test.movie_warehouse.not_null_dim_genre_genre_id.9bb76b166c)
[0m12:08:05.803031 [debug] [Thread-1 (]: Began compiling node test.movie_warehouse.not_null_dim_genre_genre_id.9bb76b166c
[0m12:08:05.809981 [debug] [Thread-1 (]: Writing injected SQL for node "test.movie_warehouse.not_null_dim_genre_genre_id.9bb76b166c"
[0m12:08:05.810870 [debug] [Thread-1 (]: Began executing node test.movie_warehouse.not_null_dim_genre_genre_id.9bb76b166c
[0m12:08:05.818157 [debug] [Thread-1 (]: Writing runtime sql for node "test.movie_warehouse.not_null_dim_genre_genre_id.9bb76b166c"
[0m12:08:05.818911 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.movie_warehouse.not_null_dim_genre_genre_id.9bb76b166c: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "test.movie_warehouse.not_null_dim_genre_genre_id.9bb76b166c"} */

    
    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select genre_id
from `gold_gold`.`dim_genre`
where genre_id is null



  
  
    ) dbt_internal_test...
[0m12:08:05.823264 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:08:05.825463 [info ] [Thread-1 (]: 1 of 12 PASS not_null_dim_genre_genre_id ....................................... [[32mPASS[0m in 0.02s]
[0m12:08:05.825810 [debug] [Thread-1 (]: Finished running node test.movie_warehouse.not_null_dim_genre_genre_id.9bb76b166c
[0m12:08:05.826046 [debug] [Thread-1 (]: Began running node test.movie_warehouse.not_null_dim_movie_movie_id.fd05907b20
[0m12:08:05.826298 [info ] [Thread-1 (]: 2 of 12 START test not_null_dim_movie_movie_id ................................. [RUN]
[0m12:08:05.826528 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.movie_warehouse.not_null_dim_genre_genre_id.9bb76b166c, now test.movie_warehouse.not_null_dim_movie_movie_id.fd05907b20)
[0m12:08:05.826744 [debug] [Thread-1 (]: Began compiling node test.movie_warehouse.not_null_dim_movie_movie_id.fd05907b20
[0m12:08:05.828916 [debug] [Thread-1 (]: Writing injected SQL for node "test.movie_warehouse.not_null_dim_movie_movie_id.fd05907b20"
[0m12:08:05.829573 [debug] [Thread-1 (]: Began executing node test.movie_warehouse.not_null_dim_movie_movie_id.fd05907b20
[0m12:08:05.831613 [debug] [Thread-1 (]: Writing runtime sql for node "test.movie_warehouse.not_null_dim_movie_movie_id.fd05907b20"
[0m12:08:05.832343 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.movie_warehouse.not_null_dim_movie_movie_id.fd05907b20: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "test.movie_warehouse.not_null_dim_movie_movie_id.fd05907b20"} */

    
    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select movie_id
from `gold_gold`.`dim_movie`
where movie_id is null



  
  
    ) dbt_internal_test...
[0m12:08:05.836597 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:08:05.837783 [info ] [Thread-1 (]: 2 of 12 PASS not_null_dim_movie_movie_id ....................................... [[32mPASS[0m in 0.01s]
[0m12:08:05.838182 [debug] [Thread-1 (]: Finished running node test.movie_warehouse.not_null_dim_movie_movie_id.fd05907b20
[0m12:08:05.838520 [debug] [Thread-1 (]: Began running node test.movie_warehouse.not_null_dim_production_production_id.7ff384ec2b
[0m12:08:05.838822 [info ] [Thread-1 (]: 3 of 12 START test not_null_dim_production_production_id ....................... [RUN]
[0m12:08:05.839133 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.movie_warehouse.not_null_dim_movie_movie_id.fd05907b20, now test.movie_warehouse.not_null_dim_production_production_id.7ff384ec2b)
[0m12:08:05.839393 [debug] [Thread-1 (]: Began compiling node test.movie_warehouse.not_null_dim_production_production_id.7ff384ec2b
[0m12:08:05.841850 [debug] [Thread-1 (]: Writing injected SQL for node "test.movie_warehouse.not_null_dim_production_production_id.7ff384ec2b"
[0m12:08:05.842540 [debug] [Thread-1 (]: Began executing node test.movie_warehouse.not_null_dim_production_production_id.7ff384ec2b
[0m12:08:05.843845 [debug] [Thread-1 (]: Writing runtime sql for node "test.movie_warehouse.not_null_dim_production_production_id.7ff384ec2b"
[0m12:08:05.844462 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.movie_warehouse.not_null_dim_production_production_id.7ff384ec2b: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "test.movie_warehouse.not_null_dim_production_production_id.7ff384ec2b"} */

    
    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select production_id
from `gold_gold`.`dim_production`
where production_id is null



  
  
    ) dbt_internal_test...
[0m12:08:05.848788 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:08:05.850016 [info ] [Thread-1 (]: 3 of 12 PASS not_null_dim_production_production_id ............................. [[32mPASS[0m in 0.01s]
[0m12:08:05.850443 [debug] [Thread-1 (]: Finished running node test.movie_warehouse.not_null_dim_production_production_id.7ff384ec2b
[0m12:08:05.850758 [debug] [Thread-1 (]: Began running node test.movie_warehouse.not_null_dim_release_date_date_id.f6b8c9c3d5
[0m12:08:05.851098 [info ] [Thread-1 (]: 4 of 12 START test not_null_dim_release_date_date_id ........................... [RUN]
[0m12:08:05.851389 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.movie_warehouse.not_null_dim_production_production_id.7ff384ec2b, now test.movie_warehouse.not_null_dim_release_date_date_id.f6b8c9c3d5)
[0m12:08:05.851633 [debug] [Thread-1 (]: Began compiling node test.movie_warehouse.not_null_dim_release_date_date_id.f6b8c9c3d5
[0m12:08:05.854135 [debug] [Thread-1 (]: Writing injected SQL for node "test.movie_warehouse.not_null_dim_release_date_date_id.f6b8c9c3d5"
[0m12:08:05.854851 [debug] [Thread-1 (]: Began executing node test.movie_warehouse.not_null_dim_release_date_date_id.f6b8c9c3d5
[0m12:08:05.856100 [debug] [Thread-1 (]: Writing runtime sql for node "test.movie_warehouse.not_null_dim_release_date_date_id.f6b8c9c3d5"
[0m12:08:05.856702 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.movie_warehouse.not_null_dim_release_date_date_id.f6b8c9c3d5: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "test.movie_warehouse.not_null_dim_release_date_date_id.f6b8c9c3d5"} */

    
    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select date_id
from `gold_gold`.`dim_release_date`
where date_id is null



  
  
    ) dbt_internal_test...
[0m12:08:05.861572 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:08:05.862871 [info ] [Thread-1 (]: 4 of 12 PASS not_null_dim_release_date_date_id ................................. [[32mPASS[0m in 0.01s]
[0m12:08:05.863285 [debug] [Thread-1 (]: Finished running node test.movie_warehouse.not_null_dim_release_date_date_id.f6b8c9c3d5
[0m12:08:05.863581 [debug] [Thread-1 (]: Began running node test.movie_warehouse.not_null_fact_movie_date_id.ca6e5e8ca0
[0m12:08:05.863868 [info ] [Thread-1 (]: 5 of 12 START test not_null_fact_movie_date_id ................................. [RUN]
[0m12:08:05.864171 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.movie_warehouse.not_null_dim_release_date_date_id.f6b8c9c3d5, now test.movie_warehouse.not_null_fact_movie_date_id.ca6e5e8ca0)
[0m12:08:05.864399 [debug] [Thread-1 (]: Began compiling node test.movie_warehouse.not_null_fact_movie_date_id.ca6e5e8ca0
[0m12:08:05.866851 [debug] [Thread-1 (]: Writing injected SQL for node "test.movie_warehouse.not_null_fact_movie_date_id.ca6e5e8ca0"
[0m12:08:05.867509 [debug] [Thread-1 (]: Began executing node test.movie_warehouse.not_null_fact_movie_date_id.ca6e5e8ca0
[0m12:08:05.868689 [debug] [Thread-1 (]: Writing runtime sql for node "test.movie_warehouse.not_null_fact_movie_date_id.ca6e5e8ca0"
[0m12:08:05.869344 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.movie_warehouse.not_null_fact_movie_date_id.ca6e5e8ca0: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "test.movie_warehouse.not_null_fact_movie_date_id.ca6e5e8ca0"} */

    
    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select date_id
from `gold_gold`.`fact_movie`
where date_id is null



  
  
    ) dbt_internal_test...
[0m12:08:05.874798 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m12:08:05.876191 [info ] [Thread-1 (]: 5 of 12 PASS not_null_fact_movie_date_id ....................................... [[32mPASS[0m in 0.01s]
[0m12:08:05.876687 [debug] [Thread-1 (]: Finished running node test.movie_warehouse.not_null_fact_movie_date_id.ca6e5e8ca0
[0m12:08:05.876967 [debug] [Thread-1 (]: Began running node test.movie_warehouse.not_null_fact_movie_fact_id.1f53f01729
[0m12:08:05.877309 [info ] [Thread-1 (]: 6 of 12 START test not_null_fact_movie_fact_id ................................. [RUN]
[0m12:08:05.877656 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.movie_warehouse.not_null_fact_movie_date_id.ca6e5e8ca0, now test.movie_warehouse.not_null_fact_movie_fact_id.1f53f01729)
[0m12:08:05.877880 [debug] [Thread-1 (]: Began compiling node test.movie_warehouse.not_null_fact_movie_fact_id.1f53f01729
[0m12:08:05.880787 [debug] [Thread-1 (]: Writing injected SQL for node "test.movie_warehouse.not_null_fact_movie_fact_id.1f53f01729"
[0m12:08:05.881849 [debug] [Thread-1 (]: Began executing node test.movie_warehouse.not_null_fact_movie_fact_id.1f53f01729
[0m12:08:05.883470 [debug] [Thread-1 (]: Writing runtime sql for node "test.movie_warehouse.not_null_fact_movie_fact_id.1f53f01729"
[0m12:08:05.884230 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.movie_warehouse.not_null_fact_movie_fact_id.1f53f01729: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "test.movie_warehouse.not_null_fact_movie_fact_id.1f53f01729"} */

    
    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select fact_id
from `gold_gold`.`fact_movie`
where fact_id is null



  
  
    ) dbt_internal_test...
[0m12:08:05.889305 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:08:05.890318 [info ] [Thread-1 (]: 6 of 12 PASS not_null_fact_movie_fact_id ....................................... [[32mPASS[0m in 0.01s]
[0m12:08:05.890621 [debug] [Thread-1 (]: Finished running node test.movie_warehouse.not_null_fact_movie_fact_id.1f53f01729
[0m12:08:05.890837 [debug] [Thread-1 (]: Began running node test.movie_warehouse.not_null_fact_movie_movie_id.115d5160ae
[0m12:08:05.891052 [info ] [Thread-1 (]: 7 of 12 START test not_null_fact_movie_movie_id ................................ [RUN]
[0m12:08:05.891282 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.movie_warehouse.not_null_fact_movie_fact_id.1f53f01729, now test.movie_warehouse.not_null_fact_movie_movie_id.115d5160ae)
[0m12:08:05.891453 [debug] [Thread-1 (]: Began compiling node test.movie_warehouse.not_null_fact_movie_movie_id.115d5160ae
[0m12:08:05.894074 [debug] [Thread-1 (]: Writing injected SQL for node "test.movie_warehouse.not_null_fact_movie_movie_id.115d5160ae"
[0m12:08:05.894791 [debug] [Thread-1 (]: Began executing node test.movie_warehouse.not_null_fact_movie_movie_id.115d5160ae
[0m12:08:05.896162 [debug] [Thread-1 (]: Writing runtime sql for node "test.movie_warehouse.not_null_fact_movie_movie_id.115d5160ae"
[0m12:08:05.896782 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.movie_warehouse.not_null_fact_movie_movie_id.115d5160ae: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "test.movie_warehouse.not_null_fact_movie_movie_id.115d5160ae"} */

    
    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select movie_id
from `gold_gold`.`fact_movie`
where movie_id is null



  
  
    ) dbt_internal_test...
[0m12:08:05.901337 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:08:05.902807 [info ] [Thread-1 (]: 7 of 12 PASS not_null_fact_movie_movie_id ...................................... [[32mPASS[0m in 0.01s]
[0m12:08:05.903200 [debug] [Thread-1 (]: Finished running node test.movie_warehouse.not_null_fact_movie_movie_id.115d5160ae
[0m12:08:05.903469 [debug] [Thread-1 (]: Began running node test.movie_warehouse.unique_dim_genre_genre_id.757304f7bc
[0m12:08:05.903720 [info ] [Thread-1 (]: 8 of 12 START test unique_dim_genre_genre_id ................................... [RUN]
[0m12:08:05.903974 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.movie_warehouse.not_null_fact_movie_movie_id.115d5160ae, now test.movie_warehouse.unique_dim_genre_genre_id.757304f7bc)
[0m12:08:05.904224 [debug] [Thread-1 (]: Began compiling node test.movie_warehouse.unique_dim_genre_genre_id.757304f7bc
[0m12:08:05.961678 [debug] [Thread-1 (]: Writing injected SQL for node "test.movie_warehouse.unique_dim_genre_genre_id.757304f7bc"
[0m12:08:05.962494 [debug] [Thread-1 (]: Began executing node test.movie_warehouse.unique_dim_genre_genre_id.757304f7bc
[0m12:08:05.963928 [debug] [Thread-1 (]: Writing runtime sql for node "test.movie_warehouse.unique_dim_genre_genre_id.757304f7bc"
[0m12:08:05.964648 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.movie_warehouse.unique_dim_genre_genre_id.757304f7bc: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "test.movie_warehouse.unique_dim_genre_genre_id.757304f7bc"} */

    
    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    genre_id as unique_field,
    count(*) as n_records

from `gold_gold`.`dim_genre`
where genre_id is not null
group by genre_id
having count(*) > 1



  
  
    ) dbt_internal_test...
[0m12:08:05.971978 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m12:08:05.974186 [info ] [Thread-1 (]: 8 of 12 PASS unique_dim_genre_genre_id ......................................... [[32mPASS[0m in 0.07s]
[0m12:08:05.975740 [debug] [Thread-1 (]: Finished running node test.movie_warehouse.unique_dim_genre_genre_id.757304f7bc
[0m12:08:05.976528 [debug] [Thread-1 (]: Began running node test.movie_warehouse.unique_dim_movie_movie_id.42054933eb
[0m12:08:05.977247 [info ] [Thread-1 (]: 9 of 12 START test unique_dim_movie_movie_id ................................... [RUN]
[0m12:08:05.977643 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.movie_warehouse.unique_dim_genre_genre_id.757304f7bc, now test.movie_warehouse.unique_dim_movie_movie_id.42054933eb)
[0m12:08:05.977840 [debug] [Thread-1 (]: Began compiling node test.movie_warehouse.unique_dim_movie_movie_id.42054933eb
[0m12:08:05.980229 [debug] [Thread-1 (]: Writing injected SQL for node "test.movie_warehouse.unique_dim_movie_movie_id.42054933eb"
[0m12:08:05.981200 [debug] [Thread-1 (]: Began executing node test.movie_warehouse.unique_dim_movie_movie_id.42054933eb
[0m12:08:05.982369 [debug] [Thread-1 (]: Writing runtime sql for node "test.movie_warehouse.unique_dim_movie_movie_id.42054933eb"
[0m12:08:05.982942 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.movie_warehouse.unique_dim_movie_movie_id.42054933eb: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "test.movie_warehouse.unique_dim_movie_movie_id.42054933eb"} */

    
    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    movie_id as unique_field,
    count(*) as n_records

from `gold_gold`.`dim_movie`
where movie_id is not null
group by movie_id
having count(*) > 1



  
  
    ) dbt_internal_test...
[0m12:08:06.014303 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.03 seconds
[0m12:08:06.015424 [info ] [Thread-1 (]: 9 of 12 PASS unique_dim_movie_movie_id ......................................... [[32mPASS[0m in 0.04s]
[0m12:08:06.015809 [debug] [Thread-1 (]: Finished running node test.movie_warehouse.unique_dim_movie_movie_id.42054933eb
[0m12:08:06.016060 [debug] [Thread-1 (]: Began running node test.movie_warehouse.unique_dim_production_production_id.b674858001
[0m12:08:06.016401 [info ] [Thread-1 (]: 10 of 12 START test unique_dim_production_production_id ........................ [RUN]
[0m12:08:06.016677 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.movie_warehouse.unique_dim_movie_movie_id.42054933eb, now test.movie_warehouse.unique_dim_production_production_id.b674858001)
[0m12:08:06.016931 [debug] [Thread-1 (]: Began compiling node test.movie_warehouse.unique_dim_production_production_id.b674858001
[0m12:08:06.019123 [debug] [Thread-1 (]: Writing injected SQL for node "test.movie_warehouse.unique_dim_production_production_id.b674858001"
[0m12:08:06.019777 [debug] [Thread-1 (]: Began executing node test.movie_warehouse.unique_dim_production_production_id.b674858001
[0m12:08:06.022142 [debug] [Thread-1 (]: Writing runtime sql for node "test.movie_warehouse.unique_dim_production_production_id.b674858001"
[0m12:08:06.023038 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.movie_warehouse.unique_dim_production_production_id.b674858001: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "test.movie_warehouse.unique_dim_production_production_id.b674858001"} */

    
    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    production_id as unique_field,
    count(*) as n_records

from `gold_gold`.`dim_production`
where production_id is not null
group by production_id
having count(*) > 1



  
  
    ) dbt_internal_test...
[0m12:08:06.028707 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m12:08:06.029809 [info ] [Thread-1 (]: 10 of 12 PASS unique_dim_production_production_id .............................. [[32mPASS[0m in 0.01s]
[0m12:08:06.030253 [debug] [Thread-1 (]: Finished running node test.movie_warehouse.unique_dim_production_production_id.b674858001
[0m12:08:06.030533 [debug] [Thread-1 (]: Began running node test.movie_warehouse.unique_dim_release_date_date_id.fdf0ed82bf
[0m12:08:06.030756 [info ] [Thread-1 (]: 11 of 12 START test unique_dim_release_date_date_id ............................ [RUN]
[0m12:08:06.030990 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.movie_warehouse.unique_dim_production_production_id.b674858001, now test.movie_warehouse.unique_dim_release_date_date_id.fdf0ed82bf)
[0m12:08:06.031224 [debug] [Thread-1 (]: Began compiling node test.movie_warehouse.unique_dim_release_date_date_id.fdf0ed82bf
[0m12:08:06.033434 [debug] [Thread-1 (]: Writing injected SQL for node "test.movie_warehouse.unique_dim_release_date_date_id.fdf0ed82bf"
[0m12:08:06.034292 [debug] [Thread-1 (]: Began executing node test.movie_warehouse.unique_dim_release_date_date_id.fdf0ed82bf
[0m12:08:06.036056 [debug] [Thread-1 (]: Writing runtime sql for node "test.movie_warehouse.unique_dim_release_date_date_id.fdf0ed82bf"
[0m12:08:06.037324 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.movie_warehouse.unique_dim_release_date_date_id.fdf0ed82bf: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "test.movie_warehouse.unique_dim_release_date_date_id.fdf0ed82bf"} */

    
    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    date_id as unique_field,
    count(*) as n_records

from `gold_gold`.`dim_release_date`
where date_id is not null
group by date_id
having count(*) > 1



  
  
    ) dbt_internal_test...
[0m12:08:06.048259 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m12:08:06.049761 [info ] [Thread-1 (]: 11 of 12 PASS unique_dim_release_date_date_id .................................. [[32mPASS[0m in 0.02s]
[0m12:08:06.050131 [debug] [Thread-1 (]: Finished running node test.movie_warehouse.unique_dim_release_date_date_id.fdf0ed82bf
[0m12:08:06.050381 [debug] [Thread-1 (]: Began running node test.movie_warehouse.unique_fact_movie_fact_id.fbd4f040d2
[0m12:08:06.050621 [info ] [Thread-1 (]: 12 of 12 START test unique_fact_movie_fact_id .................................. [RUN]
[0m12:08:06.050883 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.movie_warehouse.unique_dim_release_date_date_id.fdf0ed82bf, now test.movie_warehouse.unique_fact_movie_fact_id.fbd4f040d2)
[0m12:08:06.051116 [debug] [Thread-1 (]: Began compiling node test.movie_warehouse.unique_fact_movie_fact_id.fbd4f040d2
[0m12:08:06.053136 [debug] [Thread-1 (]: Writing injected SQL for node "test.movie_warehouse.unique_fact_movie_fact_id.fbd4f040d2"
[0m12:08:06.053671 [debug] [Thread-1 (]: Began executing node test.movie_warehouse.unique_fact_movie_fact_id.fbd4f040d2
[0m12:08:06.054697 [debug] [Thread-1 (]: Writing runtime sql for node "test.movie_warehouse.unique_fact_movie_fact_id.fbd4f040d2"
[0m12:08:06.055169 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.movie_warehouse.unique_fact_movie_fact_id.fbd4f040d2: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "test.movie_warehouse.unique_fact_movie_fact_id.fbd4f040d2"} */

    
    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    fact_id as unique_field,
    count(*) as n_records

from `gold_gold`.`fact_movie`
where fact_id is not null
group by fact_id
having count(*) > 1



  
  
    ) dbt_internal_test...
[0m12:08:06.099424 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.04 seconds
[0m12:08:06.100643 [error] [Thread-1 (]: 12 of 12 FAIL 1726 unique_fact_movie_fact_id ................................... [[31mFAIL 1726[0m in 0.05s]
[0m12:08:06.101007 [debug] [Thread-1 (]: Finished running node test.movie_warehouse.unique_fact_movie_fact_id.fbd4f040d2
[0m12:08:06.101952 [debug] [MainThread]: Connection 'master' was properly closed.
[0m12:08:06.102184 [debug] [MainThread]: Connection 'test.movie_warehouse.unique_fact_movie_fact_id.fbd4f040d2' was left open.
[0m12:08:06.102395 [debug] [MainThread]: On test.movie_warehouse.unique_fact_movie_fact_id.fbd4f040d2: Close
[0m12:08:06.102654 [info ] [MainThread]: 
[0m12:08:06.102840 [info ] [MainThread]: Finished running 12 data tests in 0 hours 0 minutes and 0.60 seconds (0.60s).
[0m12:08:06.103628 [debug] [MainThread]: Command end result
[0m12:08:06.125501 [info ] [MainThread]: 
[0m12:08:06.125787 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m12:08:06.125983 [info ] [MainThread]: 
[0m12:08:06.126213 [error] [MainThread]: [31mFailure in test unique_fact_movie_fact_id (models/gold/schema.yml)[0m
[0m12:08:06.126396 [error] [MainThread]:   Got 1726 results, configured to fail if != 0
[0m12:08:06.126539 [info ] [MainThread]: 
[0m12:08:06.126704 [info ] [MainThread]:   compiled code at target/compiled/movie_warehouse/models/gold/schema.yml/unique_fact_movie_fact_id.sql
[0m12:08:06.126859 [info ] [MainThread]: 
[0m12:08:06.127028 [info ] [MainThread]: Done. PASS=11 WARN=0 ERROR=1 SKIP=0 TOTAL=12
[0m12:08:06.127563 [debug] [MainThread]: Resource report: {"command_name": "test", "command_success": false, "command_wall_clock_time": 0.93747085, "process_in_blocks": "0", "process_kernel_time": 0.131892, "process_mem_max_rss": "187392", "process_out_blocks": "2350", "process_user_time": 1.785076}
[0m12:08:06.127821 [debug] [MainThread]: Command `dbt test` failed at 12:08:06.127782 after 0.94 seconds
[0m12:08:06.128047 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8ebcf5d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff93961f10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff93961e50>]}
[0m12:08:06.128258 [debug] [MainThread]: Flushing usage events
[0m12:09:07.367873 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff92d0c910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff92d0ca10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff92d0c6d0>]}


============================== 12:09:07.371807 | 0c8183f6-35cb-403c-9cfc-1e3bd4801316 ==============================
[0m12:09:07.371807 [info ] [MainThread]: Running with dbt=1.8.9
[0m12:09:07.372337 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/project_root/dbt', 'debug': 'False', 'warn_error': 'None', 'log_path': '/opt/airflow/project_root/dbt/logs', 'fail_fast': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'target_path': 'None', 'invocation_command': 'dbt run --project-dir /opt/airflow/project_root/dbt --profiles-dir /opt/airflow/project_root/dbt --select gold', 'send_anonymous_usage_stats': 'True'}
[0m12:09:07.447946 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '0c8183f6-35cb-403c-9cfc-1e3bd4801316', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff92d15090>]}
[0m12:09:07.468959 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '0c8183f6-35cb-403c-9cfc-1e3bd4801316', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff9373b390>]}
[0m12:09:07.469788 [info ] [MainThread]: Registered adapter: clickhouse=1.8.9
[0m12:09:07.503278 [debug] [MainThread]: checksum: 132857a23e9d07220246854f7763165174ce9b737cfc7867629ace4294e520b1, vars: {}, profile: , target: , version: 1.8.9
[0m12:09:07.567866 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m12:09:07.568497 [debug] [MainThread]: Partial parsing: updated file: movie_warehouse://models/gold/fact_movie.sql
[0m12:09:07.659520 [warn ] [MainThread]: [[33mWARNING[0m]: Deprecated functionality
The `tests` config has been renamed to `data_tests`. Please see
https://docs.getdbt.com/docs/build/data-tests#new-data_tests-syntax for more
information.
[0m12:09:07.660059 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'deprecation', 'label': '0c8183f6-35cb-403c-9cfc-1e3bd4801316', 'property_': 'warn', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff928615d0>]}
[0m12:09:07.732235 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.movie_warehouse.bronze
[0m12:09:07.740032 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '0c8183f6-35cb-403c-9cfc-1e3bd4801316', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff9278d490>]}
[0m12:09:07.830873 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '0c8183f6-35cb-403c-9cfc-1e3bd4801316', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff926ac610>]}
[0m12:09:07.831222 [info ] [MainThread]: Found 6 models, 12 data tests, 4 sources, 477 macros
[0m12:09:07.831424 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '0c8183f6-35cb-403c-9cfc-1e3bd4801316', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff9271ab50>]}
[0m12:09:07.832242 [info ] [MainThread]: 
[0m12:09:07.832577 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m12:09:07.835330 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m12:09:07.839413 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:09:08.032079 [info ] [ThreadPool]: dbt_clickhouse adapter: Unexpected server exception dropping table
[0m12:09:08.032474 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m12:09:08.034108 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:09:08.090822 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__gold_gold)
[0m12:09:08.094078 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__gold_gold: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "connection_name": "list__gold_gold"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'gold_gold'
      

  ...
[0m12:09:08.098794 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:09:08.099997 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '0c8183f6-35cb-403c-9cfc-1e3bd4801316', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff92941d90>]}
[0m12:09:08.100301 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m12:09:08.100514 [info ] [MainThread]: 
[0m12:09:08.106026 [debug] [Thread-1 (]: Began running node model.movie_warehouse.dim_director
[0m12:09:08.106597 [info ] [Thread-1 (]: 1 of 6 START sql table model `gold_gold`.`dim_director` ........................ [RUN]
[0m12:09:08.106989 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list__gold_gold, now model.movie_warehouse.dim_director)
[0m12:09:08.107286 [debug] [Thread-1 (]: Began compiling node model.movie_warehouse.dim_director
[0m12:09:08.111296 [debug] [Thread-1 (]: Writing injected SQL for node "model.movie_warehouse.dim_director"
[0m12:09:08.111996 [debug] [Thread-1 (]: Began executing node model.movie_warehouse.dim_director
[0m12:09:08.123787 [debug] [Thread-1 (]: Creating new relation dim_director
[0m12:09:08.139917 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_director: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_director"} */

            

    
        create table `gold_gold`.`dim_director`
        
  
        
  engine = MergeTree()
        order by (dir_id)
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

WITH first_dir AS (
    SELECT
        tconst,
        TRIM(splitByChar(',', directors)[1]) AS director_id
    FROM `bronze`.`imdb_title_crew_raw`
    WHERE directors IS NOT NULL AND directors != ''
),
deduped AS (
    SELECT DISTINCT director_id
    FROM first_dir
),
joined AS (
    SELECT
        d.director_id AS dir_id,
        n.primaryName AS dir_name
    FROM deduped d
    LEFT JOIN `bronze`.`imdb_name_basics_raw` n
        ON d.director_id = n.nconst
)
SELECT
    cityHash64(dir_id) AS imdb_dir_name_id,  -- Use hash instead of row_number
    dir_id,
    dir_name,
    today() AS valid_from,
    CAST(NULL AS Nullable(Date)) AS valid_to,
    1 AS is_current  -- Use 1/0 instead of TRUE/FALSE
FROM joined
WHERE dir_id IS NOT NULL
ORDER BY dir_id
          )
        
        ...
[0m12:09:08.147526 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m12:09:08.155590 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_director: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_director"} */

    select name, type from system.columns where table = 'dim_director'
    
      and database = 'gold_gold'
    
    order by position
  ...
[0m12:09:08.159198 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:09:08.161355 [debug] [Thread-1 (]: Writing runtime sql for node "model.movie_warehouse.dim_director"
[0m12:09:08.162190 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_director: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_director"} */

  
    
    
    
        
         


        insert into `gold_gold`.`dim_director`
        ("imdb_dir_name_id", "dir_id", "dir_name", "valid_from", "valid_to", "is_current")

WITH first_dir AS (
    SELECT
        tconst,
        TRIM(splitByChar(',', directors)[1]) AS director_id
    FROM `bronze`.`imdb_title_crew_raw`
    WHERE directors IS NOT NULL AND directors != ''
),
deduped AS (
    SELECT DISTINCT director_id
    FROM first_dir
),
joined AS (
    SELECT
        d.director_id AS dir_id,
        n.primaryName AS dir_name
    FROM deduped d
    LEFT JOIN `bronze`.`imdb_name_basics_raw` n
        ON d.director_id = n.nconst
)
SELECT
    cityHash64(dir_id) AS imdb_dir_name_id,  -- Use hash instead of row_number
    dir_id,
    dir_name,
    today() AS valid_from,
    CAST(NULL AS Nullable(Date)) AS valid_to,
    1 AS is_current  -- Use 1/0 instead of TRUE/FALSE
FROM joined
WHERE dir_id IS NOT NULL
ORDER BY dir_id
  ...
[0m12:09:10.080836 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 1.92 seconds
[0m12:09:10.101941 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0c8183f6-35cb-403c-9cfc-1e3bd4801316', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff4f178650>]}
[0m12:09:10.103067 [info ] [Thread-1 (]: 1 of 6 OK created sql table model `gold_gold`.`dim_director` ................... [[32mOK[0m in 1.99s]
[0m12:09:10.103654 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.dim_director
[0m12:09:10.104136 [debug] [Thread-1 (]: Began running node model.movie_warehouse.dim_genre
[0m12:09:10.104749 [info ] [Thread-1 (]: 2 of 6 START sql table model `gold_gold`.`dim_genre` ........................... [RUN]
[0m12:09:10.105112 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.movie_warehouse.dim_director, now model.movie_warehouse.dim_genre)
[0m12:09:10.105355 [debug] [Thread-1 (]: Began compiling node model.movie_warehouse.dim_genre
[0m12:09:10.108670 [debug] [Thread-1 (]: Writing injected SQL for node "model.movie_warehouse.dim_genre"
[0m12:09:10.109545 [debug] [Thread-1 (]: Began executing node model.movie_warehouse.dim_genre
[0m12:09:10.111668 [debug] [Thread-1 (]: Creating new relation dim_genre
[0m12:09:10.112430 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_genre: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_genre"} */

            

    
        create table `gold_gold`.`dim_genre`
        
  
        
  engine = MergeTree()
        order by (genre_id)
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

WITH parsed_genres AS (
    SELECT
        TRIM(splitByChar(',', genres)[1]) AS first_genre
    FROM `bronze`.`tmdb_raw`
    WHERE genres IS NOT NULL AND genres != ''
)
SELECT
    cityHash64(first_genre) AS genre_id,
    first_genre AS genre_name
FROM parsed_genres
GROUP BY first_genre
ORDER BY first_genre
          )
        
        ...
[0m12:09:10.122730 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m12:09:10.124384 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_genre: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_genre"} */

    select name, type from system.columns where table = 'dim_genre'
    
      and database = 'gold_gold'
    
    order by position
  ...
[0m12:09:10.127186 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:09:10.128222 [debug] [Thread-1 (]: Writing runtime sql for node "model.movie_warehouse.dim_genre"
[0m12:09:10.128788 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_genre: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_genre"} */

  
    
    
    
        
         


        insert into `gold_gold`.`dim_genre`
        ("genre_id", "genre_name")

WITH parsed_genres AS (
    SELECT
        TRIM(splitByChar(',', genres)[1]) AS first_genre
    FROM `bronze`.`tmdb_raw`
    WHERE genres IS NOT NULL AND genres != ''
)
SELECT
    cityHash64(first_genre) AS genre_id,
    first_genre AS genre_name
FROM parsed_genres
GROUP BY first_genre
ORDER BY first_genre
  ...
[0m12:09:10.146048 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m12:09:10.147323 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0c8183f6-35cb-403c-9cfc-1e3bd4801316', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff4e228c90>]}
[0m12:09:10.147671 [info ] [Thread-1 (]: 2 of 6 OK created sql table model `gold_gold`.`dim_genre` ...................... [[32mOK[0m in 0.04s]
[0m12:09:10.147964 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.dim_genre
[0m12:09:10.148217 [debug] [Thread-1 (]: Began running node model.movie_warehouse.dim_movie
[0m12:09:10.148561 [info ] [Thread-1 (]: 3 of 6 START sql table model `gold_gold`.`dim_movie` ........................... [RUN]
[0m12:09:10.148782 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.movie_warehouse.dim_genre, now model.movie_warehouse.dim_movie)
[0m12:09:10.148948 [debug] [Thread-1 (]: Began compiling node model.movie_warehouse.dim_movie
[0m12:09:10.152284 [debug] [Thread-1 (]: Writing injected SQL for node "model.movie_warehouse.dim_movie"
[0m12:09:10.152774 [debug] [Thread-1 (]: Began executing node model.movie_warehouse.dim_movie
[0m12:09:10.153705 [debug] [Thread-1 (]: Creating new relation dim_movie
[0m12:09:10.154222 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_movie: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_movie"} */

            

    
        create table `gold_gold`.`dim_movie`
        
  
        
  engine = MergeTree()
        order by (movie_id)
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            -- ...existing code...


WITH movie_src AS (
    SELECT
        TRIM(title) AS movie_title,
        imdb_id,
        release_date,
        runtime AS movie_runtime,
        original_language AS language
    FROM `bronze`.`tmdb_raw`
    WHERE title IS NOT NULL AND title != ''
)
SELECT
    cityHash64(movie_title) AS movie_id,
    any(imdb_id) AS imdb_id,
    movie_title,
    any(release_date) AS release_date,
    any(movie_runtime) AS movie_runtime,
    any(language) AS language
FROM movie_src
GROUP BY movie_title
ORDER BY movie_title
          )
        
        ...
[0m12:09:10.160596 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m12:09:10.161895 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_movie: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_movie"} */

    select name, type from system.columns where table = 'dim_movie'
    
      and database = 'gold_gold'
    
    order by position
  ...
[0m12:09:10.164008 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:09:10.165387 [debug] [Thread-1 (]: Writing runtime sql for node "model.movie_warehouse.dim_movie"
[0m12:09:10.165939 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_movie: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_movie"} */

  
    
    
    
        
         


        insert into `gold_gold`.`dim_movie`
        ("movie_id", "imdb_id", "movie_title", "release_date", "movie_runtime", "language")-- ...existing code...


WITH movie_src AS (
    SELECT
        TRIM(title) AS movie_title,
        imdb_id,
        release_date,
        runtime AS movie_runtime,
        original_language AS language
    FROM `bronze`.`tmdb_raw`
    WHERE title IS NOT NULL AND title != ''
)
SELECT
    cityHash64(movie_title) AS movie_id,
    any(imdb_id) AS imdb_id,
    movie_title,
    any(release_date) AS release_date,
    any(movie_runtime) AS movie_runtime,
    any(language) AS language
FROM movie_src
GROUP BY movie_title
ORDER BY movie_title
  ...
[0m12:09:10.430479 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.26 seconds
[0m12:09:10.432695 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0c8183f6-35cb-403c-9cfc-1e3bd4801316', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff4e1d1790>]}
[0m12:09:10.433801 [info ] [Thread-1 (]: 3 of 6 OK created sql table model `gold_gold`.`dim_movie` ...................... [[32mOK[0m in 0.28s]
[0m12:09:10.435656 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.dim_movie
[0m12:09:10.437467 [debug] [Thread-1 (]: Began running node model.movie_warehouse.dim_production
[0m12:09:10.438427 [info ] [Thread-1 (]: 4 of 6 START sql table model `gold_gold`.`dim_production` ...................... [RUN]
[0m12:09:10.439662 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.movie_warehouse.dim_movie, now model.movie_warehouse.dim_production)
[0m12:09:10.440454 [debug] [Thread-1 (]: Began compiling node model.movie_warehouse.dim_production
[0m12:09:10.443444 [debug] [Thread-1 (]: Writing injected SQL for node "model.movie_warehouse.dim_production"
[0m12:09:10.445025 [debug] [Thread-1 (]: Began executing node model.movie_warehouse.dim_production
[0m12:09:10.446739 [debug] [Thread-1 (]: Creating new relation dim_production
[0m12:09:10.447657 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_production: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_production"} */

            

    
        create table `gold_gold`.`dim_production`
        
  
        
  engine = MergeTree()
        order by (production_id)
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

WITH first_production AS (
    SELECT
        imdb_id AS movie_id,
        trim(splitByChar(',', production_companies)[1]) AS production_name
    FROM `bronze`.`tmdb_raw`
    WHERE production_companies IS NOT NULL AND production_companies != ''
)

SELECT
    cityHash64(production_name) AS production_id,
    production_name,
    current_date() AS valid_from,
    CAST(NULL AS Nullable(Date)) AS valid_to,
    TRUE AS is_current
FROM (
    SELECT DISTINCT production_name
    FROM first_production
)
WHERE production_name IS NOT NULL
          )
        
        ...
[0m12:09:10.472447 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m12:09:10.477863 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_production: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_production"} */

    select name, type from system.columns where table = 'dim_production'
    
      and database = 'gold_gold'
    
    order by position
  ...
[0m12:09:10.482576 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:09:10.484624 [debug] [Thread-1 (]: Writing runtime sql for node "model.movie_warehouse.dim_production"
[0m12:09:10.485990 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_production: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_production"} */

  
    
    
    
        
         


        insert into `gold_gold`.`dim_production`
        ("production_id", "production_name", "valid_from", "valid_to", "is_current")

WITH first_production AS (
    SELECT
        imdb_id AS movie_id,
        trim(splitByChar(',', production_companies)[1]) AS production_name
    FROM `bronze`.`tmdb_raw`
    WHERE production_companies IS NOT NULL AND production_companies != ''
)

SELECT
    cityHash64(production_name) AS production_id,
    production_name,
    current_date() AS valid_from,
    CAST(NULL AS Nullable(Date)) AS valid_to,
    TRUE AS is_current
FROM (
    SELECT DISTINCT production_name
    FROM first_production
)
WHERE production_name IS NOT NULL
  ...
[0m12:09:10.493626 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m12:09:10.496229 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0c8183f6-35cb-403c-9cfc-1e3bd4801316', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff55a6e290>]}
[0m12:09:10.497628 [info ] [Thread-1 (]: 4 of 6 OK created sql table model `gold_gold`.`dim_production` ................. [[32mOK[0m in 0.06s]
[0m12:09:10.498478 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.dim_production
[0m12:09:10.499226 [debug] [Thread-1 (]: Began running node model.movie_warehouse.dim_release_date
[0m12:09:10.499936 [info ] [Thread-1 (]: 5 of 6 START sql table model `gold_gold`.`dim_release_date` .................... [RUN]
[0m12:09:10.500490 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.movie_warehouse.dim_production, now model.movie_warehouse.dim_release_date)
[0m12:09:10.501118 [debug] [Thread-1 (]: Began compiling node model.movie_warehouse.dim_release_date
[0m12:09:10.505158 [debug] [Thread-1 (]: Writing injected SQL for node "model.movie_warehouse.dim_release_date"
[0m12:09:10.506524 [debug] [Thread-1 (]: Began executing node model.movie_warehouse.dim_release_date
[0m12:09:10.510742 [debug] [Thread-1 (]: Creating new relation dim_release_date
[0m12:09:10.511744 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_release_date: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_release_date"} */

            

    
        create table `gold_gold`.`dim_release_date`
        
  
        
  engine = MergeTree()
        order by (date_id)
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

WITH distinct_dates AS (
    SELECT DISTINCT release_date
    FROM `bronze`.`tmdb_raw`
    WHERE release_date IS NOT NULL
)

SELECT
    cityHash64(release_date)                                    AS date_id,
    release_date                                                AS full_date,
    toYear(release_date)                                        AS year,
    toMonth(release_date)                                       AS month,
    toDayOfMonth(release_date)                                  AS day,
    toISOWeek(release_date)                                     AS week,
    formatDateTime(release_date, '%a')                          AS weekday,
    CASE
        WHEN toMonth(release_date) IN (12,1,2)  THEN 'Winter'
        WHEN toMonth(release_date) IN (3,4,5)   THEN 'Spring'
        WHEN toMonth(release_date) IN (6,7,8)   THEN 'Summer'
        WHEN toMonth(release_date) IN (9,10,11) THEN 'Autumn'
    END                                                         AS season,
    CASE
        WHEN formatDateTime(release_date, '%a') IN ('Saturday','Sunday') THEN 1
        ELSE 0
    END                                                         AS is_weekend,

    /* ---------- holiday tagging ---------- */
    CASE
        WHEN toMonth(release_date)=1  AND toDayOfMonth(release_date)=1  THEN 'New Years Day'
        WHEN toMonth(release_date)=2  AND toDayOfMonth(release_date)=14 THEN 'Valentines Day'
        WHEN toMonth(release_date)=3  AND toDayOfMonth(release_date)=17 THEN 'St. Patricks Day'
        WHEN toMonth(release_date)=4  AND toDayOfMonth(release_date)=1  THEN 'April Fools Day'
        WHEN toMonth(release_date)=4  AND toDayOfMonth(release_date)=22 THEN 'Earth Day'
        WHEN toMonth(release_date)=5  AND toDayOfMonth(release_date)=1  THEN 'May Day'
        WHEN toMonth(release_date)=5  AND toDayOfMonth(release_date)=5  THEN 'Cinco de Mayo'
        WHEN toMonth(release_date)=6  AND toDayOfMonth(release_date) BETWEEN 19 AND 26 THEN 'Midsummer'
        WHEN toMonth(release_date)=7  AND toDayOfMonth(release_date)=4  THEN 'Independence Day'
        WHEN toMonth(release_date)=9  AND toDayOfMonth(release_date) BETWEEN 1 AND 7 
             AND formatDateTime(release_date,'%a')='Monday'             THEN 'Labor Day (US)'
        WHEN toMonth(release_date)=10 AND toDayOfMonth(release_date)=31 THEN 'Halloween'
        WHEN toMonth(release_date)=11 AND formatDateTime(release_date,'%a')='Thursday'
             AND toISOWeek(release_date) >= 47                           THEN 'Thanksgiving'
        WHEN toMonth(release_date)=12 AND toDayOfMonth(release_date)=24 THEN 'Christmas Eve'
        WHEN toMonth(release_date)=12 AND toDayOfMonth(release_date)=25 THEN 'Christmas Day'
        WHEN toMonth(release_date)=12 AND toDayOfMonth(release_date)=31 THEN 'New Years Eve'
        ELSE NULL
    END                                                         AS holiday_name,
    IF(holiday_name IS NOT NULL, 1, 0)                          AS is_holiday,

    /* placeholders for later enhancement */
    CAST(NULL AS Nullable(Int32)) AS days_until_holiday,
    CAST(NULL AS Nullable(Int32)) AS days_after_holiday

FROM distinct_dates
ORDER BY release_date
          )
        
        ...
[0m12:09:10.534017 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m12:09:10.536039 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_release_date: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_release_date"} */

    select name, type from system.columns where table = 'dim_release_date'
    
      and database = 'gold_gold'
    
    order by position
  ...
[0m12:09:10.542864 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m12:09:10.547541 [debug] [Thread-1 (]: Writing runtime sql for node "model.movie_warehouse.dim_release_date"
[0m12:09:10.551038 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_release_date: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_release_date"} */

  
    
    
    
        
         


        insert into `gold_gold`.`dim_release_date`
        ("date_id", "full_date", "year", "month", "day", "week", "weekday", "season", "is_weekend", "holiday_name", "is_holiday", "days_until_holiday", "days_after_holiday")

WITH distinct_dates AS (
    SELECT DISTINCT release_date
    FROM `bronze`.`tmdb_raw`
    WHERE release_date IS NOT NULL
)

SELECT
    cityHash64(release_date)                                    AS date_id,
    release_date                                                AS full_date,
    toYear(release_date)                                        AS year,
    toMonth(release_date)                                       AS month,
    toDayOfMonth(release_date)                                  AS day,
    toISOWeek(release_date)                                     AS week,
    formatDateTime(release_date, '%a')                          AS weekday,
    CASE
        WHEN toMonth(release_date) IN (12,1,2)  THEN 'Winter'
        WHEN toMonth(release_date) IN (3,4,5)   THEN 'Spring'
        WHEN toMonth(release_date) IN (6,7,8)   THEN 'Summer'
        WHEN toMonth(release_date) IN (9,10,11) THEN 'Autumn'
    END                                                         AS season,
    CASE
        WHEN formatDateTime(release_date, '%a') IN ('Saturday','Sunday') THEN 1
        ELSE 0
    END                                                         AS is_weekend,

    /* ---------- holiday tagging ---------- */
    CASE
        WHEN toMonth(release_date)=1  AND toDayOfMonth(release_date)=1  THEN 'New Years Day'
        WHEN toMonth(release_date)=2  AND toDayOfMonth(release_date)=14 THEN 'Valentines Day'
        WHEN toMonth(release_date)=3  AND toDayOfMonth(release_date)=17 THEN 'St. Patricks Day'
        WHEN toMonth(release_date)=4  AND toDayOfMonth(release_date)=1  THEN 'April Fools Day'
        WHEN toMonth(release_date)=4  AND toDayOfMonth(release_date)=22 THEN 'Earth Day'
        WHEN toMonth(release_date)=5  AND toDayOfMonth(release_date)=1  THEN 'May Day'
        WHEN toMonth(release_date)=5  AND toDayOfMonth(release_date)=5  THEN 'Cinco de Mayo'
        WHEN toMonth(release_date)=6  AND toDayOfMonth(release_date) BETWEEN 19 AND 26 THEN 'Midsummer'
        WHEN toMonth(release_date)=7  AND toDayOfMonth(release_date)=4  THEN 'Independence Day'
        WHEN toMonth(release_date)=9  AND toDayOfMonth(release_date) BETWEEN 1 AND 7 
             AND formatDateTime(release_date,'%a')='Monday'             THEN 'Labor Day (US)'
        WHEN toMonth(release_date)=10 AND toDayOfMonth(release_date)=31 THEN 'Halloween'
        WHEN toMonth(release_date)=11 AND formatDateTime(release_date,'%a')='Thursday'
             AND toISOWeek(release_date) >= 47                           THEN 'Thanksgiving'
        WHEN toMonth(release_date)=12 AND toDayOfMonth(release_date)=24 THEN 'Christmas Eve'
        WHEN toMonth(release_date)=12 AND toDayOfMonth(release_date)=25 THEN 'Christmas Day'
        WHEN toMonth(release_date)=12 AND toDayOfMonth(release_date)=31 THEN 'New Years Eve'
        ELSE NULL
    END                                                         AS holiday_name,
    IF(holiday_name IS NOT NULL, 1, 0)                          AS is_holiday,

    /* placeholders for later enhancement */
    CAST(NULL AS Nullable(Int32)) AS days_until_holiday,
    CAST(NULL AS Nullable(Int32)) AS days_after_holiday

FROM distinct_dates
ORDER BY release_date
  ...
[0m12:09:10.592609 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.04 seconds
[0m12:09:10.594090 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0c8183f6-35cb-403c-9cfc-1e3bd4801316', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff4e24ed50>]}
[0m12:09:10.594870 [info ] [Thread-1 (]: 5 of 6 OK created sql table model `gold_gold`.`dim_release_date` ............... [[32mOK[0m in 0.09s]
[0m12:09:10.595825 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.dim_release_date
[0m12:09:10.598664 [debug] [Thread-1 (]: Began running node model.movie_warehouse.fact_movie
[0m12:09:10.599405 [info ] [Thread-1 (]: 6 of 6 START sql table model `gold_gold`.`fact_movie` .......................... [RUN]
[0m12:09:10.599994 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.movie_warehouse.dim_release_date, now model.movie_warehouse.fact_movie)
[0m12:09:10.600377 [debug] [Thread-1 (]: Began compiling node model.movie_warehouse.fact_movie
[0m12:09:10.606967 [debug] [Thread-1 (]: Writing injected SQL for node "model.movie_warehouse.fact_movie"
[0m12:09:10.608037 [debug] [Thread-1 (]: Began executing node model.movie_warehouse.fact_movie
[0m12:09:10.611555 [debug] [Thread-1 (]: Creating new relation fact_movie
[0m12:09:10.612778 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.fact_movie: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.fact_movie"} */

            

    
        create table `gold_gold`.`fact_movie`
        
  
        
  engine = MergeTree()
        order by (fact_id)
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

WITH filtered_tmdb AS (
    SELECT 
        imdb_id,
        title,
        release_date,
        production_companies,
        budget,
        revenue,
        vote_average,
        vote_count,
        runtime,
        genres,
        original_language,
        (vote_average * log(1 + vote_count)) AS movie_popularity
    FROM `bronze`.`tmdb_raw`
),

-- First genre
first_genre AS (
    SELECT
        imdb_id AS movie_id,
        trim(splitByChar(',', genres)[1]) AS genre_name
    FROM filtered_tmdb
),

-- First director
first_director AS (
    SELECT
        t.imdb_id AS movie_id,
        trim(splitByChar(',', c.directors)[1]) AS director_id
    FROM filtered_tmdb t
    LEFT JOIN `bronze`.`imdb_title_crew_raw` c
        ON t.imdb_id = c.tconst
),

-- Join to dim_production to get production_id
movie_production AS (
    SELECT
        t.imdb_id AS movie_id,
        p.production_id
    FROM filtered_tmdb t
    LEFT JOIN `gold_gold`.`dim_production` p
        ON trim(splitByChar(',', t.production_companies)[1]) = p.production_name
),

-- Map genre_name to dim_genre to get genre_id
movie_genre AS (
    SELECT
        fg.movie_id,
        g.genre_id
    FROM first_genre fg
    LEFT JOIN `gold_gold`.`dim_genre` g
        ON fg.genre_name = g.genre_name
),

base AS (
    SELECT
        t.imdb_id                                 AS movie_id,
        d.director_id,
        mg.genre_id,
        mp.production_id,
        dr.date_id                                AS date_id,
        t.vote_average                            AS vote_avg,
        t.vote_count,
        t.revenue,
        t.budget,
        t.movie_popularity,
        toYear(t.release_date)                    AS release_year
    FROM filtered_tmdb t
    LEFT JOIN movie_genre mg       ON mg.movie_id = t.imdb_id
    LEFT JOIN first_director d     ON d.movie_id = t.imdb_id
    LEFT JOIN movie_production mp  ON mp.movie_id = t.imdb_id
    LEFT JOIN `gold_gold`.`dim_release_date` dr
        ON dr.full_date = t.release_date
),

metrics AS (
    SELECT
        b.*,
        b.revenue - lag(b.revenue, 1) OVER (PARTITION BY b.movie_id ORDER BY b.release_year) AS revenue_growth,
        b.movie_popularity - lag(b.movie_popularity, 1) OVER (PARTITION BY b.movie_id ORDER BY b.release_year) AS popularity_change,
        b.vote_avg - lag(b.vote_avg, 1) OVER (PARTITION BY b.movie_id ORDER BY b.release_year) AS vote_avg_change
    FROM base b
)

SELECT
    row_number() OVER (ORDER BY movie_id, date_id, director_id, genre_id) AS fact_id,
    movie_id,
    director_id,
    genre_id,
    production_id,
    date_id,
    vote_avg,
    vote_count,
    revenue,
    budget,
    movie_popularity,
    revenue_growth,
    popularity_change,
    vote_avg_change
FROM metrics
          )
        
        ...
[0m12:09:10.630566 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m12:09:10.632564 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.fact_movie: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.fact_movie"} */

    select name, type from system.columns where table = 'fact_movie'
    
      and database = 'gold_gold'
    
    order by position
  ...
[0m12:09:10.637217 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:09:10.639815 [debug] [Thread-1 (]: Writing runtime sql for node "model.movie_warehouse.fact_movie"
[0m12:09:10.641826 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.fact_movie: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.fact_movie"} */

  
    
    
    
        
         


        insert into `gold_gold`.`fact_movie`
        ("fact_id", "movie_id", "director_id", "genre_id", "production_id", "date_id", "vote_avg", "vote_count", "revenue", "budget", "movie_popularity", "revenue_growth", "popularity_change", "vote_avg_change")

WITH filtered_tmdb AS (
    SELECT 
        imdb_id,
        title,
        release_date,
        production_companies,
        budget,
        revenue,
        vote_average,
        vote_count,
        runtime,
        genres,
        original_language,
        (vote_average * log(1 + vote_count)) AS movie_popularity
    FROM `bronze`.`tmdb_raw`
),

-- First genre
first_genre AS (
    SELECT
        imdb_id AS movie_id,
        trim(splitByChar(',', genres)[1]) AS genre_name
    FROM filtered_tmdb
),

-- First director
first_director AS (
    SELECT
        t.imdb_id AS movie_id,
        trim(splitByChar(',', c.directors)[1]) AS director_id
    FROM filtered_tmdb t
    LEFT JOIN `bronze`.`imdb_title_crew_raw` c
        ON t.imdb_id = c.tconst
),

-- Join to dim_production to get production_id
movie_production AS (
    SELECT
        t.imdb_id AS movie_id,
        p.production_id
    FROM filtered_tmdb t
    LEFT JOIN `gold_gold`.`dim_production` p
        ON trim(splitByChar(',', t.production_companies)[1]) = p.production_name
),

-- Map genre_name to dim_genre to get genre_id
movie_genre AS (
    SELECT
        fg.movie_id,
        g.genre_id
    FROM first_genre fg
    LEFT JOIN `gold_gold`.`dim_genre` g
        ON fg.genre_name = g.genre_name
),

base AS (
    SELECT
        t.imdb_id                                 AS movie_id,
        d.director_id,
        mg.genre_id,
        mp.production_id,
        dr.date_id                                AS date_id,
        t.vote_average                            AS vote_avg,
        t.vote_count,
        t.revenue,
        t.budget,
        t.movie_popularity,
        toYear(t.release_date)                    AS release_year
    FROM filtered_tmdb t
    LEFT JOIN movie_genre mg       ON mg.movie_id = t.imdb_id
    LEFT JOIN first_director d     ON d.movie_id = t.imdb_id
    LEFT JOIN movie_production mp  ON mp.movie_id = t.imdb_id
    LEFT JOIN `gold_gold`.`dim_release_date` dr
        ON dr.full_date = t.release_date
),

metrics AS (
    SELECT
        b.*,
        b.revenue - lag(b.revenue, 1) OVER (PARTITION BY b.movie_id ORDER BY b.release_year) AS revenue_growth,
        b.movie_popularity - lag(b.movie_popularity, 1) OVER (PARTITION BY b.movie_id ORDER BY b.release_year) AS popularity_change,
        b.vote_avg - lag(b.vote_avg, 1) OVER (PARTITION BY b.movie_id ORDER BY b.release_year) AS vote_avg_change
    FROM base b
)

SELECT
    row_number() OVER (ORDER BY movie_id, date_id, director_id, genre_id) AS fact_id,
    movie_id,
    director_id,
    genre_id,
    production_id,
    date_id,
    vote_avg,
    vote_count,
    revenue,
    budget,
    movie_popularity,
    revenue_growth,
    popularity_change,
    vote_avg_change
FROM metrics
  ...
[0m12:09:16.373193 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 5.72 seconds
[0m12:09:16.384030 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0c8183f6-35cb-403c-9cfc-1e3bd4801316', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff4e2985d0>]}
[0m12:09:16.385426 [info ] [Thread-1 (]: 6 of 6 OK created sql table model `gold_gold`.`fact_movie` ..................... [[32mOK[0m in 5.78s]
[0m12:09:16.386417 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.fact_movie
[0m12:09:16.395865 [debug] [MainThread]: Connection 'master' was properly closed.
[0m12:09:16.396731 [debug] [MainThread]: Connection 'model.movie_warehouse.fact_movie' was left open.
[0m12:09:16.397066 [debug] [MainThread]: On model.movie_warehouse.fact_movie: Close
[0m12:09:16.398107 [info ] [MainThread]: 
[0m12:09:16.398614 [info ] [MainThread]: Finished running 6 table models in 0 hours 0 minutes and 8.57 seconds (8.57s).
[0m12:09:16.400017 [debug] [MainThread]: Command end result
[0m12:09:16.440244 [info ] [MainThread]: 
[0m12:09:16.440749 [info ] [MainThread]: [32mCompleted successfully[0m
[0m12:09:16.441017 [info ] [MainThread]: 
[0m12:09:16.441283 [info ] [MainThread]: Done. PASS=6 WARN=0 ERROR=0 SKIP=0 TOTAL=6
[0m12:09:16.444202 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 9.095604, "process_in_blocks": "120", "process_kernel_time": 0.254715, "process_mem_max_rss": "192676", "process_out_blocks": "3486", "process_user_time": 2.009647}
[0m12:09:16.445355 [debug] [MainThread]: Command `dbt run` succeeded at 12:09:16.445264 after 9.10 seconds
[0m12:09:16.445824 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff92d32090>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff97ad1f10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff97ad1e50>]}
[0m12:09:16.446165 [debug] [MainThread]: Flushing usage events
[0m12:09:20.260142 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff9df4d110>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff9df4d190>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff9df4c250>]}


============================== 12:09:20.263819 | 3960962a-44ca-4918-bae6-9a99676c2e6d ==============================
[0m12:09:20.263819 [info ] [MainThread]: Running with dbt=1.8.9
[0m12:09:20.264131 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'version_check': 'True', 'log_path': '/opt/airflow/project_root/dbt/logs', 'profiles_dir': '/opt/airflow/project_root/dbt', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'invocation_command': 'dbt test --project-dir /opt/airflow/project_root/dbt --profiles-dir /opt/airflow/project_root/dbt --select gold', 'log_format': 'default', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m12:09:20.391420 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '3960962a-44ca-4918-bae6-9a99676c2e6d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff9e33fed0>]}
[0m12:09:20.422008 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '3960962a-44ca-4918-bae6-9a99676c2e6d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff9e97b350>]}
[0m12:09:20.422740 [info ] [MainThread]: Registered adapter: clickhouse=1.8.9
[0m12:09:20.467067 [debug] [MainThread]: checksum: 132857a23e9d07220246854f7763165174ce9b737cfc7867629ace4294e520b1, vars: {}, profile: , target: , version: 1.8.9
[0m12:09:20.525130 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m12:09:20.525393 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m12:09:20.528132 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.movie_warehouse.bronze
[0m12:09:20.543792 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '3960962a-44ca-4918-bae6-9a99676c2e6d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff9df8d1d0>]}
[0m12:09:20.602399 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '3960962a-44ca-4918-bae6-9a99676c2e6d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff9d7e7f50>]}
[0m12:09:20.602872 [info ] [MainThread]: Found 6 models, 12 data tests, 4 sources, 477 macros
[0m12:09:20.603234 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '3960962a-44ca-4918-bae6-9a99676c2e6d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff9dd2ca50>]}
[0m12:09:20.604495 [info ] [MainThread]: 
[0m12:09:20.604912 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m12:09:20.607998 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list__gold_gold'
[0m12:09:20.614344 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:09:20.947215 [info ] [ThreadPool]: dbt_clickhouse adapter: Unexpected server exception dropping table
[0m12:09:20.947711 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__gold_gold: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "connection_name": "list__gold_gold"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'gold_gold'
      

  ...
[0m12:09:20.952267 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:09:20.968049 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '3960962a-44ca-4918-bae6-9a99676c2e6d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff9dcaaa10>]}
[0m12:09:20.968578 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m12:09:20.968871 [info ] [MainThread]: 
[0m12:09:20.973610 [debug] [Thread-1 (]: Began running node test.movie_warehouse.not_null_dim_genre_genre_id.9bb76b166c
[0m12:09:20.973911 [info ] [Thread-1 (]: 1 of 12 START test not_null_dim_genre_genre_id ................................. [RUN]
[0m12:09:20.974212 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list__gold_gold, now test.movie_warehouse.not_null_dim_genre_genre_id.9bb76b166c)
[0m12:09:20.974437 [debug] [Thread-1 (]: Began compiling node test.movie_warehouse.not_null_dim_genre_genre_id.9bb76b166c
[0m12:09:20.981204 [debug] [Thread-1 (]: Writing injected SQL for node "test.movie_warehouse.not_null_dim_genre_genre_id.9bb76b166c"
[0m12:09:20.981979 [debug] [Thread-1 (]: Began executing node test.movie_warehouse.not_null_dim_genre_genre_id.9bb76b166c
[0m12:09:20.989665 [debug] [Thread-1 (]: Writing runtime sql for node "test.movie_warehouse.not_null_dim_genre_genre_id.9bb76b166c"
[0m12:09:20.990464 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.movie_warehouse.not_null_dim_genre_genre_id.9bb76b166c: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "test.movie_warehouse.not_null_dim_genre_genre_id.9bb76b166c"} */

    
    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select genre_id
from `gold_gold`.`dim_genre`
where genre_id is null



  
  
    ) dbt_internal_test...
[0m12:09:20.995097 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:09:20.998085 [info ] [Thread-1 (]: 1 of 12 PASS not_null_dim_genre_genre_id ....................................... [[32mPASS[0m in 0.02s]
[0m12:09:20.998686 [debug] [Thread-1 (]: Finished running node test.movie_warehouse.not_null_dim_genre_genre_id.9bb76b166c
[0m12:09:20.999553 [debug] [Thread-1 (]: Began running node test.movie_warehouse.not_null_dim_movie_movie_id.fd05907b20
[0m12:09:21.000049 [info ] [Thread-1 (]: 2 of 12 START test not_null_dim_movie_movie_id ................................. [RUN]
[0m12:09:21.002381 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.movie_warehouse.not_null_dim_genre_genre_id.9bb76b166c, now test.movie_warehouse.not_null_dim_movie_movie_id.fd05907b20)
[0m12:09:21.004489 [debug] [Thread-1 (]: Began compiling node test.movie_warehouse.not_null_dim_movie_movie_id.fd05907b20
[0m12:09:21.009288 [debug] [Thread-1 (]: Writing injected SQL for node "test.movie_warehouse.not_null_dim_movie_movie_id.fd05907b20"
[0m12:09:21.010736 [debug] [Thread-1 (]: Began executing node test.movie_warehouse.not_null_dim_movie_movie_id.fd05907b20
[0m12:09:21.013632 [debug] [Thread-1 (]: Writing runtime sql for node "test.movie_warehouse.not_null_dim_movie_movie_id.fd05907b20"
[0m12:09:21.015106 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.movie_warehouse.not_null_dim_movie_movie_id.fd05907b20: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "test.movie_warehouse.not_null_dim_movie_movie_id.fd05907b20"} */

    
    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select movie_id
from `gold_gold`.`dim_movie`
where movie_id is null



  
  
    ) dbt_internal_test...
[0m12:09:21.020584 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:09:21.023179 [info ] [Thread-1 (]: 2 of 12 PASS not_null_dim_movie_movie_id ....................................... [[32mPASS[0m in 0.02s]
[0m12:09:21.023553 [debug] [Thread-1 (]: Finished running node test.movie_warehouse.not_null_dim_movie_movie_id.fd05907b20
[0m12:09:21.023854 [debug] [Thread-1 (]: Began running node test.movie_warehouse.not_null_dim_production_production_id.7ff384ec2b
[0m12:09:21.024235 [info ] [Thread-1 (]: 3 of 12 START test not_null_dim_production_production_id ....................... [RUN]
[0m12:09:21.024587 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.movie_warehouse.not_null_dim_movie_movie_id.fd05907b20, now test.movie_warehouse.not_null_dim_production_production_id.7ff384ec2b)
[0m12:09:21.025052 [debug] [Thread-1 (]: Began compiling node test.movie_warehouse.not_null_dim_production_production_id.7ff384ec2b
[0m12:09:21.028064 [debug] [Thread-1 (]: Writing injected SQL for node "test.movie_warehouse.not_null_dim_production_production_id.7ff384ec2b"
[0m12:09:21.028838 [debug] [Thread-1 (]: Began executing node test.movie_warehouse.not_null_dim_production_production_id.7ff384ec2b
[0m12:09:21.030582 [debug] [Thread-1 (]: Writing runtime sql for node "test.movie_warehouse.not_null_dim_production_production_id.7ff384ec2b"
[0m12:09:21.031330 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.movie_warehouse.not_null_dim_production_production_id.7ff384ec2b: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "test.movie_warehouse.not_null_dim_production_production_id.7ff384ec2b"} */

    
    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select production_id
from `gold_gold`.`dim_production`
where production_id is null



  
  
    ) dbt_internal_test...
[0m12:09:21.035298 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:09:21.037030 [info ] [Thread-1 (]: 3 of 12 PASS not_null_dim_production_production_id ............................. [[32mPASS[0m in 0.01s]
[0m12:09:21.037381 [debug] [Thread-1 (]: Finished running node test.movie_warehouse.not_null_dim_production_production_id.7ff384ec2b
[0m12:09:21.037706 [debug] [Thread-1 (]: Began running node test.movie_warehouse.not_null_dim_release_date_date_id.f6b8c9c3d5
[0m12:09:21.038826 [info ] [Thread-1 (]: 4 of 12 START test not_null_dim_release_date_date_id ........................... [RUN]
[0m12:09:21.039260 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.movie_warehouse.not_null_dim_production_production_id.7ff384ec2b, now test.movie_warehouse.not_null_dim_release_date_date_id.f6b8c9c3d5)
[0m12:09:21.039544 [debug] [Thread-1 (]: Began compiling node test.movie_warehouse.not_null_dim_release_date_date_id.f6b8c9c3d5
[0m12:09:21.041996 [debug] [Thread-1 (]: Writing injected SQL for node "test.movie_warehouse.not_null_dim_release_date_date_id.f6b8c9c3d5"
[0m12:09:21.043230 [debug] [Thread-1 (]: Began executing node test.movie_warehouse.not_null_dim_release_date_date_id.f6b8c9c3d5
[0m12:09:21.044598 [debug] [Thread-1 (]: Writing runtime sql for node "test.movie_warehouse.not_null_dim_release_date_date_id.f6b8c9c3d5"
[0m12:09:21.045881 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.movie_warehouse.not_null_dim_release_date_date_id.f6b8c9c3d5: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "test.movie_warehouse.not_null_dim_release_date_date_id.f6b8c9c3d5"} */

    
    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select date_id
from `gold_gold`.`dim_release_date`
where date_id is null



  
  
    ) dbt_internal_test...
[0m12:09:21.054902 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m12:09:21.056972 [info ] [Thread-1 (]: 4 of 12 PASS not_null_dim_release_date_date_id ................................. [[32mPASS[0m in 0.02s]
[0m12:09:21.057650 [debug] [Thread-1 (]: Finished running node test.movie_warehouse.not_null_dim_release_date_date_id.f6b8c9c3d5
[0m12:09:21.058272 [debug] [Thread-1 (]: Began running node test.movie_warehouse.not_null_fact_movie_date_id.ca6e5e8ca0
[0m12:09:21.058631 [info ] [Thread-1 (]: 5 of 12 START test not_null_fact_movie_date_id ................................. [RUN]
[0m12:09:21.059418 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.movie_warehouse.not_null_dim_release_date_date_id.f6b8c9c3d5, now test.movie_warehouse.not_null_fact_movie_date_id.ca6e5e8ca0)
[0m12:09:21.059666 [debug] [Thread-1 (]: Began compiling node test.movie_warehouse.not_null_fact_movie_date_id.ca6e5e8ca0
[0m12:09:21.062903 [debug] [Thread-1 (]: Writing injected SQL for node "test.movie_warehouse.not_null_fact_movie_date_id.ca6e5e8ca0"
[0m12:09:21.064409 [debug] [Thread-1 (]: Began executing node test.movie_warehouse.not_null_fact_movie_date_id.ca6e5e8ca0
[0m12:09:21.067055 [debug] [Thread-1 (]: Writing runtime sql for node "test.movie_warehouse.not_null_fact_movie_date_id.ca6e5e8ca0"
[0m12:09:21.068627 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.movie_warehouse.not_null_fact_movie_date_id.ca6e5e8ca0: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "test.movie_warehouse.not_null_fact_movie_date_id.ca6e5e8ca0"} */

    
    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select date_id
from `gold_gold`.`fact_movie`
where date_id is null



  
  
    ) dbt_internal_test...
[0m12:09:21.076805 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m12:09:21.079109 [info ] [Thread-1 (]: 5 of 12 PASS not_null_fact_movie_date_id ....................................... [[32mPASS[0m in 0.02s]
[0m12:09:21.079736 [debug] [Thread-1 (]: Finished running node test.movie_warehouse.not_null_fact_movie_date_id.ca6e5e8ca0
[0m12:09:21.080037 [debug] [Thread-1 (]: Began running node test.movie_warehouse.not_null_fact_movie_fact_id.1f53f01729
[0m12:09:21.080325 [info ] [Thread-1 (]: 6 of 12 START test not_null_fact_movie_fact_id ................................. [RUN]
[0m12:09:21.080653 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.movie_warehouse.not_null_fact_movie_date_id.ca6e5e8ca0, now test.movie_warehouse.not_null_fact_movie_fact_id.1f53f01729)
[0m12:09:21.081016 [debug] [Thread-1 (]: Began compiling node test.movie_warehouse.not_null_fact_movie_fact_id.1f53f01729
[0m12:09:21.083299 [debug] [Thread-1 (]: Writing injected SQL for node "test.movie_warehouse.not_null_fact_movie_fact_id.1f53f01729"
[0m12:09:21.084904 [debug] [Thread-1 (]: Began executing node test.movie_warehouse.not_null_fact_movie_fact_id.1f53f01729
[0m12:09:21.086511 [debug] [Thread-1 (]: Writing runtime sql for node "test.movie_warehouse.not_null_fact_movie_fact_id.1f53f01729"
[0m12:09:21.088247 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.movie_warehouse.not_null_fact_movie_fact_id.1f53f01729: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "test.movie_warehouse.not_null_fact_movie_fact_id.1f53f01729"} */

    
    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select fact_id
from `gold_gold`.`fact_movie`
where fact_id is null



  
  
    ) dbt_internal_test...
[0m12:09:21.092447 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:09:21.093632 [info ] [Thread-1 (]: 6 of 12 PASS not_null_fact_movie_fact_id ....................................... [[32mPASS[0m in 0.01s]
[0m12:09:21.094006 [debug] [Thread-1 (]: Finished running node test.movie_warehouse.not_null_fact_movie_fact_id.1f53f01729
[0m12:09:21.094427 [debug] [Thread-1 (]: Began running node test.movie_warehouse.not_null_fact_movie_movie_id.115d5160ae
[0m12:09:21.095746 [info ] [Thread-1 (]: 7 of 12 START test not_null_fact_movie_movie_id ................................ [RUN]
[0m12:09:21.097216 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.movie_warehouse.not_null_fact_movie_fact_id.1f53f01729, now test.movie_warehouse.not_null_fact_movie_movie_id.115d5160ae)
[0m12:09:21.097942 [debug] [Thread-1 (]: Began compiling node test.movie_warehouse.not_null_fact_movie_movie_id.115d5160ae
[0m12:09:21.101560 [debug] [Thread-1 (]: Writing injected SQL for node "test.movie_warehouse.not_null_fact_movie_movie_id.115d5160ae"
[0m12:09:21.102725 [debug] [Thread-1 (]: Began executing node test.movie_warehouse.not_null_fact_movie_movie_id.115d5160ae
[0m12:09:21.104298 [debug] [Thread-1 (]: Writing runtime sql for node "test.movie_warehouse.not_null_fact_movie_movie_id.115d5160ae"
[0m12:09:21.105015 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.movie_warehouse.not_null_fact_movie_movie_id.115d5160ae: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "test.movie_warehouse.not_null_fact_movie_movie_id.115d5160ae"} */

    
    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select movie_id
from `gold_gold`.`fact_movie`
where movie_id is null



  
  
    ) dbt_internal_test...
[0m12:09:21.109316 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:09:21.110401 [info ] [Thread-1 (]: 7 of 12 PASS not_null_fact_movie_movie_id ...................................... [[32mPASS[0m in 0.01s]
[0m12:09:21.110962 [debug] [Thread-1 (]: Finished running node test.movie_warehouse.not_null_fact_movie_movie_id.115d5160ae
[0m12:09:21.111299 [debug] [Thread-1 (]: Began running node test.movie_warehouse.unique_dim_genre_genre_id.757304f7bc
[0m12:09:21.111703 [info ] [Thread-1 (]: 8 of 12 START test unique_dim_genre_genre_id ................................... [RUN]
[0m12:09:21.112118 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.movie_warehouse.not_null_fact_movie_movie_id.115d5160ae, now test.movie_warehouse.unique_dim_genre_genre_id.757304f7bc)
[0m12:09:21.112301 [debug] [Thread-1 (]: Began compiling node test.movie_warehouse.unique_dim_genre_genre_id.757304f7bc
[0m12:09:21.161006 [debug] [Thread-1 (]: Writing injected SQL for node "test.movie_warehouse.unique_dim_genre_genre_id.757304f7bc"
[0m12:09:21.161843 [debug] [Thread-1 (]: Began executing node test.movie_warehouse.unique_dim_genre_genre_id.757304f7bc
[0m12:09:21.163604 [debug] [Thread-1 (]: Writing runtime sql for node "test.movie_warehouse.unique_dim_genre_genre_id.757304f7bc"
[0m12:09:21.164573 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.movie_warehouse.unique_dim_genre_genre_id.757304f7bc: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "test.movie_warehouse.unique_dim_genre_genre_id.757304f7bc"} */

    
    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    genre_id as unique_field,
    count(*) as n_records

from `gold_gold`.`dim_genre`
where genre_id is not null
group by genre_id
having count(*) > 1



  
  
    ) dbt_internal_test...
[0m12:09:21.172113 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m12:09:21.173450 [info ] [Thread-1 (]: 8 of 12 PASS unique_dim_genre_genre_id ......................................... [[32mPASS[0m in 0.06s]
[0m12:09:21.174038 [debug] [Thread-1 (]: Finished running node test.movie_warehouse.unique_dim_genre_genre_id.757304f7bc
[0m12:09:21.174544 [debug] [Thread-1 (]: Began running node test.movie_warehouse.unique_dim_movie_movie_id.42054933eb
[0m12:09:21.174881 [info ] [Thread-1 (]: 9 of 12 START test unique_dim_movie_movie_id ................................... [RUN]
[0m12:09:21.175295 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.movie_warehouse.unique_dim_genre_genre_id.757304f7bc, now test.movie_warehouse.unique_dim_movie_movie_id.42054933eb)
[0m12:09:21.175631 [debug] [Thread-1 (]: Began compiling node test.movie_warehouse.unique_dim_movie_movie_id.42054933eb
[0m12:09:21.178232 [debug] [Thread-1 (]: Writing injected SQL for node "test.movie_warehouse.unique_dim_movie_movie_id.42054933eb"
[0m12:09:21.178930 [debug] [Thread-1 (]: Began executing node test.movie_warehouse.unique_dim_movie_movie_id.42054933eb
[0m12:09:21.180022 [debug] [Thread-1 (]: Writing runtime sql for node "test.movie_warehouse.unique_dim_movie_movie_id.42054933eb"
[0m12:09:21.180606 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.movie_warehouse.unique_dim_movie_movie_id.42054933eb: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "test.movie_warehouse.unique_dim_movie_movie_id.42054933eb"} */

    
    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    movie_id as unique_field,
    count(*) as n_records

from `gold_gold`.`dim_movie`
where movie_id is not null
group by movie_id
having count(*) > 1



  
  
    ) dbt_internal_test...
[0m12:09:21.223209 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.04 seconds
[0m12:09:21.225998 [info ] [Thread-1 (]: 9 of 12 PASS unique_dim_movie_movie_id ......................................... [[32mPASS[0m in 0.05s]
[0m12:09:21.226603 [debug] [Thread-1 (]: Finished running node test.movie_warehouse.unique_dim_movie_movie_id.42054933eb
[0m12:09:21.227031 [debug] [Thread-1 (]: Began running node test.movie_warehouse.unique_dim_production_production_id.b674858001
[0m12:09:21.227709 [info ] [Thread-1 (]: 10 of 12 START test unique_dim_production_production_id ........................ [RUN]
[0m12:09:21.228893 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.movie_warehouse.unique_dim_movie_movie_id.42054933eb, now test.movie_warehouse.unique_dim_production_production_id.b674858001)
[0m12:09:21.229974 [debug] [Thread-1 (]: Began compiling node test.movie_warehouse.unique_dim_production_production_id.b674858001
[0m12:09:21.234999 [debug] [Thread-1 (]: Writing injected SQL for node "test.movie_warehouse.unique_dim_production_production_id.b674858001"
[0m12:09:21.237007 [debug] [Thread-1 (]: Began executing node test.movie_warehouse.unique_dim_production_production_id.b674858001
[0m12:09:21.239542 [debug] [Thread-1 (]: Writing runtime sql for node "test.movie_warehouse.unique_dim_production_production_id.b674858001"
[0m12:09:21.241457 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.movie_warehouse.unique_dim_production_production_id.b674858001: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "test.movie_warehouse.unique_dim_production_production_id.b674858001"} */

    
    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    production_id as unique_field,
    count(*) as n_records

from `gold_gold`.`dim_production`
where production_id is not null
group by production_id
having count(*) > 1



  
  
    ) dbt_internal_test...
[0m12:09:21.254027 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m12:09:21.256982 [info ] [Thread-1 (]: 10 of 12 PASS unique_dim_production_production_id .............................. [[32mPASS[0m in 0.03s]
[0m12:09:21.257891 [debug] [Thread-1 (]: Finished running node test.movie_warehouse.unique_dim_production_production_id.b674858001
[0m12:09:21.258219 [debug] [Thread-1 (]: Began running node test.movie_warehouse.unique_dim_release_date_date_id.fdf0ed82bf
[0m12:09:21.258842 [info ] [Thread-1 (]: 11 of 12 START test unique_dim_release_date_date_id ............................ [RUN]
[0m12:09:21.260048 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.movie_warehouse.unique_dim_production_production_id.b674858001, now test.movie_warehouse.unique_dim_release_date_date_id.fdf0ed82bf)
[0m12:09:21.260590 [debug] [Thread-1 (]: Began compiling node test.movie_warehouse.unique_dim_release_date_date_id.fdf0ed82bf
[0m12:09:21.263409 [debug] [Thread-1 (]: Writing injected SQL for node "test.movie_warehouse.unique_dim_release_date_date_id.fdf0ed82bf"
[0m12:09:21.264558 [debug] [Thread-1 (]: Began executing node test.movie_warehouse.unique_dim_release_date_date_id.fdf0ed82bf
[0m12:09:21.267096 [debug] [Thread-1 (]: Writing runtime sql for node "test.movie_warehouse.unique_dim_release_date_date_id.fdf0ed82bf"
[0m12:09:21.268298 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.movie_warehouse.unique_dim_release_date_date_id.fdf0ed82bf: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "test.movie_warehouse.unique_dim_release_date_date_id.fdf0ed82bf"} */

    
    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    date_id as unique_field,
    count(*) as n_records

from `gold_gold`.`dim_release_date`
where date_id is not null
group by date_id
having count(*) > 1



  
  
    ) dbt_internal_test...
[0m12:09:21.285539 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m12:09:21.289431 [info ] [Thread-1 (]: 11 of 12 PASS unique_dim_release_date_date_id .................................. [[32mPASS[0m in 0.03s]
[0m12:09:21.290437 [debug] [Thread-1 (]: Finished running node test.movie_warehouse.unique_dim_release_date_date_id.fdf0ed82bf
[0m12:09:21.291031 [debug] [Thread-1 (]: Began running node test.movie_warehouse.unique_fact_movie_fact_id.fbd4f040d2
[0m12:09:21.291547 [info ] [Thread-1 (]: 12 of 12 START test unique_fact_movie_fact_id .................................. [RUN]
[0m12:09:21.291902 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.movie_warehouse.unique_dim_release_date_date_id.fdf0ed82bf, now test.movie_warehouse.unique_fact_movie_fact_id.fbd4f040d2)
[0m12:09:21.292131 [debug] [Thread-1 (]: Began compiling node test.movie_warehouse.unique_fact_movie_fact_id.fbd4f040d2
[0m12:09:21.294070 [debug] [Thread-1 (]: Writing injected SQL for node "test.movie_warehouse.unique_fact_movie_fact_id.fbd4f040d2"
[0m12:09:21.294616 [debug] [Thread-1 (]: Began executing node test.movie_warehouse.unique_fact_movie_fact_id.fbd4f040d2
[0m12:09:21.295582 [debug] [Thread-1 (]: Writing runtime sql for node "test.movie_warehouse.unique_fact_movie_fact_id.fbd4f040d2"
[0m12:09:21.296043 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.movie_warehouse.unique_fact_movie_fact_id.fbd4f040d2: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "test.movie_warehouse.unique_fact_movie_fact_id.fbd4f040d2"} */

    
    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    fact_id as unique_field,
    count(*) as n_records

from `gold_gold`.`fact_movie`
where fact_id is not null
group by fact_id
having count(*) > 1



  
  
    ) dbt_internal_test...
[0m12:09:21.648228 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.35 seconds
[0m12:09:21.649811 [info ] [Thread-1 (]: 12 of 12 PASS unique_fact_movie_fact_id ........................................ [[32mPASS[0m in 0.36s]
[0m12:09:21.650239 [debug] [Thread-1 (]: Finished running node test.movie_warehouse.unique_fact_movie_fact_id.fbd4f040d2
[0m12:09:21.651154 [debug] [MainThread]: Connection 'master' was properly closed.
[0m12:09:21.651424 [debug] [MainThread]: Connection 'test.movie_warehouse.unique_fact_movie_fact_id.fbd4f040d2' was left open.
[0m12:09:21.651620 [debug] [MainThread]: On test.movie_warehouse.unique_fact_movie_fact_id.fbd4f040d2: Close
[0m12:09:21.651899 [info ] [MainThread]: 
[0m12:09:21.652103 [info ] [MainThread]: Finished running 12 data tests in 0 hours 0 minutes and 1.05 seconds (1.05s).
[0m12:09:21.652928 [debug] [MainThread]: Command end result
[0m12:09:21.674890 [info ] [MainThread]: 
[0m12:09:21.675187 [info ] [MainThread]: [32mCompleted successfully[0m
[0m12:09:21.675371 [info ] [MainThread]: 
[0m12:09:21.675556 [info ] [MainThread]: Done. PASS=12 WARN=0 ERROR=0 SKIP=0 TOTAL=12
[0m12:09:21.676284 [debug] [MainThread]: Resource report: {"command_name": "test", "command_success": true, "command_wall_clock_time": 1.4396005, "process_in_blocks": "79824", "process_kernel_time": 0.261928, "process_mem_max_rss": "191348", "process_out_blocks": "2348", "process_user_time": 1.884062}
[0m12:09:21.676612 [debug] [MainThread]: Command `dbt test` succeeded at 12:09:21.676568 after 1.44 seconds
[0m12:09:21.676839 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff9df7f5d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff9df7f550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff7a7075d0>]}
[0m12:09:21.677061 [debug] [MainThread]: Flushing usage events
[0m12:12:55.311447 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff9a7ed410>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff9a90d050>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff9c623410>]}


============================== 12:12:55.315552 | 23b4ae95-287e-41ca-8a5f-7048afc98485 ==============================
[0m12:12:55.315552 [info ] [MainThread]: Running with dbt=1.8.9
[0m12:12:55.315875 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'fail_fast': 'False', 'log_path': '/opt/airflow/project_root/dbt/logs', 'profiles_dir': '/opt/airflow/project_root/dbt', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run --project-dir /opt/airflow/project_root/dbt --profiles-dir /opt/airflow/project_root/dbt --select gold', 'static_parser': 'True', 'introspect': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m12:12:55.430083 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '23b4ae95-287e-41ca-8a5f-7048afc98485', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff9a82d710>]}
[0m12:12:55.448862 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '23b4ae95-287e-41ca-8a5f-7048afc98485', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff9b21b450>]}
[0m12:12:55.449367 [info ] [MainThread]: Registered adapter: clickhouse=1.8.9
[0m12:12:55.497388 [debug] [MainThread]: checksum: 132857a23e9d07220246854f7763165174ce9b737cfc7867629ace4294e520b1, vars: {}, profile: , target: , version: 1.8.9
[0m12:12:55.597681 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m12:12:55.598187 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m12:12:55.602118 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.movie_warehouse.bronze
[0m12:12:55.627381 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '23b4ae95-287e-41ca-8a5f-7048afc98485', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff9a81b9d0>]}
[0m12:12:55.706199 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '23b4ae95-287e-41ca-8a5f-7048afc98485', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff9a5480d0>]}
[0m12:12:55.706700 [info ] [MainThread]: Found 6 models, 12 data tests, 4 sources, 477 macros
[0m12:12:55.707005 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '23b4ae95-287e-41ca-8a5f-7048afc98485', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff9a82d9d0>]}
[0m12:12:55.708106 [info ] [MainThread]: 
[0m12:12:55.708665 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m12:12:55.711992 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m12:12:55.718471 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:12:56.161231 [info ] [ThreadPool]: dbt_clickhouse adapter: Unexpected server exception dropping table
[0m12:12:56.161800 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m12:12:56.167519 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:12:56.186964 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__gold_gold)
[0m12:12:56.190176 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__gold_gold: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "connection_name": "list__gold_gold"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'gold_gold'
      

  ...
[0m12:12:56.202632 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m12:12:56.204380 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '23b4ae95-287e-41ca-8a5f-7048afc98485', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff9a433450>]}
[0m12:12:56.205196 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m12:12:56.205441 [info ] [MainThread]: 
[0m12:12:56.210309 [debug] [Thread-1 (]: Began running node model.movie_warehouse.dim_director
[0m12:12:56.210877 [info ] [Thread-1 (]: 1 of 6 START sql table model `gold_gold`.`dim_director` ........................ [RUN]
[0m12:12:56.211258 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list__gold_gold, now model.movie_warehouse.dim_director)
[0m12:12:56.211485 [debug] [Thread-1 (]: Began compiling node model.movie_warehouse.dim_director
[0m12:12:56.215470 [debug] [Thread-1 (]: Writing injected SQL for node "model.movie_warehouse.dim_director"
[0m12:12:56.216671 [debug] [Thread-1 (]: Began executing node model.movie_warehouse.dim_director
[0m12:12:56.230157 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_director: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_director"} */

    drop table if exists `gold_gold`.`dim_director__dbt_backup` 
  ...
[0m12:12:56.233066 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_director"} */

    drop table if exists `gold_gold`.`dim_director__dbt_backup` 
  
[0m12:12:56.233448 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: macro drop_relation
[0m12:12:56.239169 [debug] [Thread-1 (]: Database Error in model dim_director (models/gold/dim_director.sql)
  :HTTPDriver for http://clickhouse-server:8123 returned response code 500)
   std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/8c9/8c9b38bb-5974-4368-97d1-712fe72b58b0/dim_director__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/gold_gold.dim_director__dbt_backup.2c99c2ef-a08c-480a-8b73-f82e307048ee.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build))
[0m12:12:56.239982 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '23b4ae95-287e-41ca-8a5f-7048afc98485', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff883c71d0>]}
[0m12:12:56.240340 [error] [Thread-1 (]: 1 of 6 ERROR creating sql table model `gold_gold`.`dim_director` ............... [[31mERROR[0m in 0.03s]
[0m12:12:56.240637 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.dim_director
[0m12:12:56.240842 [debug] [Thread-1 (]: Began running node model.movie_warehouse.dim_genre
[0m12:12:56.241377 [info ] [Thread-1 (]: 2 of 6 START sql table model `gold_gold`.`dim_genre` ........................... [RUN]
[0m12:12:56.241626 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.movie_warehouse.dim_director, now model.movie_warehouse.dim_genre)
[0m12:12:56.241822 [debug] [Thread-1 (]: Began compiling node model.movie_warehouse.dim_genre
[0m12:12:56.243659 [debug] [Thread-1 (]: Writing injected SQL for node "model.movie_warehouse.dim_genre"
[0m12:12:56.244298 [debug] [Thread-1 (]: Began executing node model.movie_warehouse.dim_genre
[0m12:12:56.246184 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_genre: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_genre"} */

    drop table if exists `gold_gold`.`dim_genre__dbt_backup` 
  ...
[0m12:12:56.247910 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_genre"} */

    drop table if exists `gold_gold`.`dim_genre__dbt_backup` 
  
[0m12:12:56.248147 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: macro drop_relation
[0m12:12:56.249835 [debug] [Thread-1 (]: Database Error in model dim_genre (models/gold/dim_genre.sql)
  :HTTPDriver for http://clickhouse-server:8123 returned response code 500)
   std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/8c9/8c9b38bb-5974-4368-97d1-712fe72b58b0/dim_genre__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/gold_gold.dim_genre__dbt_backup.2487f1ca-ea22-4281-94ae-ca07070efa81.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build))
[0m12:12:56.250087 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '23b4ae95-287e-41ca-8a5f-7048afc98485', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff773ccf10>]}
[0m12:12:56.250387 [error] [Thread-1 (]: 2 of 6 ERROR creating sql table model `gold_gold`.`dim_genre` .................. [[31mERROR[0m in 0.01s]
[0m12:12:56.250671 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.dim_genre
[0m12:12:56.250911 [debug] [Thread-1 (]: Began running node model.movie_warehouse.dim_movie
[0m12:12:56.251183 [info ] [Thread-1 (]: 3 of 6 START sql table model `gold_gold`.`dim_movie` ........................... [RUN]
[0m12:12:56.251409 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.movie_warehouse.dim_genre, now model.movie_warehouse.dim_movie)
[0m12:12:56.251576 [debug] [Thread-1 (]: Began compiling node model.movie_warehouse.dim_movie
[0m12:12:56.252946 [debug] [Thread-1 (]: Writing injected SQL for node "model.movie_warehouse.dim_movie"
[0m12:12:56.253429 [debug] [Thread-1 (]: Began executing node model.movie_warehouse.dim_movie
[0m12:12:56.256238 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_movie: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_movie"} */

    drop table if exists `gold_gold`.`dim_movie__dbt_backup` 
  ...
[0m12:12:56.258363 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_movie"} */

    drop table if exists `gold_gold`.`dim_movie__dbt_backup` 
  
[0m12:12:56.258592 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: macro drop_relation
[0m12:12:56.260299 [debug] [Thread-1 (]: Database Error in model dim_movie (models/gold/dim_movie.sql)
  :HTTPDriver for http://clickhouse-server:8123 returned response code 500)
   std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/8c9/8c9b38bb-5974-4368-97d1-712fe72b58b0/dim_movie__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/gold_gold.dim_movie__dbt_backup.1916288c-7695-4a93-8987-f314a281fa5f.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build))
[0m12:12:56.260532 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '23b4ae95-287e-41ca-8a5f-7048afc98485', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff7c5e49d0>]}
[0m12:12:56.260843 [error] [Thread-1 (]: 3 of 6 ERROR creating sql table model `gold_gold`.`dim_movie` .................. [[31mERROR[0m in 0.01s]
[0m12:12:56.261104 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.dim_movie
[0m12:12:56.261291 [debug] [Thread-1 (]: Began running node model.movie_warehouse.dim_production
[0m12:12:56.261547 [info ] [Thread-1 (]: 4 of 6 START sql table model `gold_gold`.`dim_production` ...................... [RUN]
[0m12:12:56.261767 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.movie_warehouse.dim_movie, now model.movie_warehouse.dim_production)
[0m12:12:56.261945 [debug] [Thread-1 (]: Began compiling node model.movie_warehouse.dim_production
[0m12:12:56.263345 [debug] [Thread-1 (]: Writing injected SQL for node "model.movie_warehouse.dim_production"
[0m12:12:56.263920 [debug] [Thread-1 (]: Began executing node model.movie_warehouse.dim_production
[0m12:12:56.265785 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_production: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_production"} */

    drop table if exists `gold_gold`.`dim_production__dbt_backup` 
  ...
[0m12:12:56.267208 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_production"} */

    drop table if exists `gold_gold`.`dim_production__dbt_backup` 
  
[0m12:12:56.267413 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: macro drop_relation
[0m12:12:56.269461 [debug] [Thread-1 (]: Database Error in model dim_production (models/gold/dim_production.sql)
  :HTTPDriver for http://clickhouse-server:8123 returned response code 500)
   std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/8c9/8c9b38bb-5974-4368-97d1-712fe72b58b0/dim_production__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/gold_gold.dim_production__dbt_backup.cb69e4e8-058b-48e7-b13a-77549ddf5902.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build))
[0m12:12:56.269812 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '23b4ae95-287e-41ca-8a5f-7048afc98485', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff76e36850>]}
[0m12:12:56.270163 [error] [Thread-1 (]: 4 of 6 ERROR creating sql table model `gold_gold`.`dim_production` ............. [[31mERROR[0m in 0.01s]
[0m12:12:56.270437 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.dim_production
[0m12:12:56.270638 [debug] [Thread-1 (]: Began running node model.movie_warehouse.dim_release_date
[0m12:12:56.270889 [info ] [Thread-1 (]: 5 of 6 START sql table model `gold_gold`.`dim_release_date` .................... [RUN]
[0m12:12:56.271085 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.movie_warehouse.dim_production, now model.movie_warehouse.dim_release_date)
[0m12:12:56.271249 [debug] [Thread-1 (]: Began compiling node model.movie_warehouse.dim_release_date
[0m12:12:56.272775 [debug] [Thread-1 (]: Writing injected SQL for node "model.movie_warehouse.dim_release_date"
[0m12:12:56.273473 [debug] [Thread-1 (]: Began executing node model.movie_warehouse.dim_release_date
[0m12:12:56.275259 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_release_date: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_release_date"} */

    drop table if exists `gold_gold`.`dim_release_date__dbt_backup` 
  ...
[0m12:12:56.276944 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_release_date"} */

    drop table if exists `gold_gold`.`dim_release_date__dbt_backup` 
  
[0m12:12:56.277160 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: macro drop_relation
[0m12:12:56.278745 [debug] [Thread-1 (]: Database Error in model dim_release_date (models/gold/dim_release_date.sql)
  :HTTPDriver for http://clickhouse-server:8123 returned response code 500)
   std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/8c9/8c9b38bb-5974-4368-97d1-712fe72b58b0/dim_release_date__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/gold_gold.dim_release_date__dbt_backup.f2636bd2-27ea-40bb-be87-ff663458e441.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build))
[0m12:12:56.278987 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '23b4ae95-287e-41ca-8a5f-7048afc98485', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff7700c550>]}
[0m12:12:56.279269 [error] [Thread-1 (]: 5 of 6 ERROR creating sql table model `gold_gold`.`dim_release_date` ........... [[31mERROR[0m in 0.01s]
[0m12:12:56.279534 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.dim_release_date
[0m12:12:56.279994 [debug] [Thread-1 (]: Began running node model.movie_warehouse.fact_movie
[0m12:12:56.280191 [info ] [Thread-1 (]: 6 of 6 SKIP relation gold_gold.fact_movie ...................................... [[33mSKIP[0m]
[0m12:12:56.280383 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.fact_movie
[0m12:12:56.280989 [debug] [MainThread]: Connection 'master' was properly closed.
[0m12:12:56.281187 [debug] [MainThread]: Connection 'model.movie_warehouse.dim_release_date' was left open.
[0m12:12:56.281353 [debug] [MainThread]: On model.movie_warehouse.dim_release_date: Close
[0m12:12:56.281572 [info ] [MainThread]: 
[0m12:12:56.281765 [info ] [MainThread]: Finished running 6 table models in 0 hours 0 minutes and 0.57 seconds (0.57s).
[0m12:12:56.282265 [debug] [MainThread]: Command end result
[0m12:12:56.336180 [info ] [MainThread]: 
[0m12:12:56.336470 [info ] [MainThread]: [31mCompleted with 5 errors and 0 warnings:[0m
[0m12:12:56.336737 [info ] [MainThread]: 
[0m12:12:56.336967 [error] [MainThread]:   Database Error in model dim_director (models/gold/dim_director.sql)
  :HTTPDriver for http://clickhouse-server:8123 returned response code 500)
   std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/8c9/8c9b38bb-5974-4368-97d1-712fe72b58b0/dim_director__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/gold_gold.dim_director__dbt_backup.2c99c2ef-a08c-480a-8b73-f82e307048ee.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build))
[0m12:12:56.337132 [info ] [MainThread]: 
[0m12:12:56.337306 [error] [MainThread]:   Database Error in model dim_genre (models/gold/dim_genre.sql)
  :HTTPDriver for http://clickhouse-server:8123 returned response code 500)
   std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/8c9/8c9b38bb-5974-4368-97d1-712fe72b58b0/dim_genre__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/gold_gold.dim_genre__dbt_backup.2487f1ca-ea22-4281-94ae-ca07070efa81.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build))
[0m12:12:56.337461 [info ] [MainThread]: 
[0m12:12:56.337642 [error] [MainThread]:   Database Error in model dim_movie (models/gold/dim_movie.sql)
  :HTTPDriver for http://clickhouse-server:8123 returned response code 500)
   std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/8c9/8c9b38bb-5974-4368-97d1-712fe72b58b0/dim_movie__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/gold_gold.dim_movie__dbt_backup.1916288c-7695-4a93-8987-f314a281fa5f.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build))
[0m12:12:56.337792 [info ] [MainThread]: 
[0m12:12:56.337963 [error] [MainThread]:   Database Error in model dim_production (models/gold/dim_production.sql)
  :HTTPDriver for http://clickhouse-server:8123 returned response code 500)
   std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/8c9/8c9b38bb-5974-4368-97d1-712fe72b58b0/dim_production__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/gold_gold.dim_production__dbt_backup.cb69e4e8-058b-48e7-b13a-77549ddf5902.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build))
[0m12:12:56.338113 [info ] [MainThread]: 
[0m12:12:56.338281 [error] [MainThread]:   Database Error in model dim_release_date (models/gold/dim_release_date.sql)
  :HTTPDriver for http://clickhouse-server:8123 returned response code 500)
   std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/8c9/8c9b38bb-5974-4368-97d1-712fe72b58b0/dim_release_date__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/gold_gold.dim_release_date__dbt_backup.f2636bd2-27ea-40bb-be87-ff663458e441.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build))
[0m12:12:56.338439 [info ] [MainThread]: 
[0m12:12:56.338614 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=5 SKIP=1 TOTAL=6
[0m12:12:56.339089 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 1.0511634, "process_in_blocks": "79016", "process_kernel_time": 0.346884, "process_mem_max_rss": "190256", "process_out_blocks": "2342", "process_user_time": 1.817716}
[0m12:12:56.339363 [debug] [MainThread]: Command `dbt run` failed at 12:12:56.339325 after 1.05 seconds
[0m12:12:56.339559 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff9a7ecb50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff9a7edf90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff9a7ecc50>]}
[0m12:12:56.339744 [debug] [MainThread]: Flushing usage events
[0m12:16:58.012623 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff858ad690>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff858d1ed0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff85adaad0>]}


============================== 12:16:58.017340 | dd246a1b-606d-4f08-86c5-135ce4174431 ==============================
[0m12:16:58.017340 [info ] [MainThread]: Running with dbt=1.8.9
[0m12:16:58.017797 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/project_root/dbt', 'debug': 'False', 'version_check': 'True', 'log_path': '/opt/airflow/project_root/dbt/logs', 'warn_error': 'None', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'static_parser': 'True', 'log_format': 'default', 'target_path': 'None', 'invocation_command': 'dbt run --project-dir /opt/airflow/project_root/dbt --profiles-dir /opt/airflow/project_root/dbt --select gold', 'send_anonymous_usage_stats': 'True'}
[0m12:16:58.096039 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'dd246a1b-606d-4f08-86c5-135ce4174431', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff857dc550>]}
[0m12:16:58.115559 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'dd246a1b-606d-4f08-86c5-135ce4174431', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff862db110>]}
[0m12:16:58.116237 [info ] [MainThread]: Registered adapter: clickhouse=1.8.9
[0m12:16:58.153582 [debug] [MainThread]: checksum: 132857a23e9d07220246854f7763165174ce9b737cfc7867629ace4294e520b1, vars: {}, profile: , target: , version: 1.8.9
[0m12:16:58.208507 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m12:16:58.208781 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m12:16:58.211452 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.movie_warehouse.bronze
[0m12:16:58.230306 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'dd246a1b-606d-4f08-86c5-135ce4174431', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff854de310>]}
[0m12:16:58.285075 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'dd246a1b-606d-4f08-86c5-135ce4174431', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff85416c90>]}
[0m12:16:58.285435 [info ] [MainThread]: Found 6 models, 12 data tests, 4 sources, 477 macros
[0m12:16:58.285662 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'dd246a1b-606d-4f08-86c5-135ce4174431', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff857bc510>]}
[0m12:16:58.286525 [info ] [MainThread]: 
[0m12:16:58.286888 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m12:16:58.289728 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m12:16:58.295280 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:16:58.625876 [info ] [ThreadPool]: dbt_clickhouse adapter: Unexpected server exception dropping table
[0m12:16:58.626358 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m12:16:58.627975 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:16:58.659602 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__gold_gold)
[0m12:16:58.663399 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__gold_gold: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "connection_name": "list__gold_gold"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'gold_gold'
      

  ...
[0m12:16:58.668758 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:16:58.670422 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'dd246a1b-606d-4f08-86c5-135ce4174431', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff63c7b390>]}
[0m12:16:58.670853 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m12:16:58.671101 [info ] [MainThread]: 
[0m12:16:58.677437 [debug] [Thread-1 (]: Began running node model.movie_warehouse.dim_director
[0m12:16:58.677938 [info ] [Thread-1 (]: 1 of 6 START sql table model `gold_gold`.`dim_director` ........................ [RUN]
[0m12:16:58.678265 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list__gold_gold, now model.movie_warehouse.dim_director)
[0m12:16:58.678512 [debug] [Thread-1 (]: Began compiling node model.movie_warehouse.dim_director
[0m12:16:58.682117 [debug] [Thread-1 (]: Writing injected SQL for node "model.movie_warehouse.dim_director"
[0m12:16:58.682896 [debug] [Thread-1 (]: Began executing node model.movie_warehouse.dim_director
[0m12:16:58.691158 [debug] [Thread-1 (]: Creating new relation dim_director
[0m12:16:58.703462 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_director: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_director"} */

            

    
        create table `gold_gold`.`dim_director`
        
  
        
  engine = MergeTree()
        order by (dir_id)
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

WITH first_dir AS (
    SELECT
        tconst,
        TRIM(splitByChar(',', directors)[1]) AS director_id
    FROM `bronze`.`imdb_title_crew_raw`
    WHERE directors IS NOT NULL AND directors != ''
),
deduped AS (
    SELECT DISTINCT director_id
    FROM first_dir
),
joined AS (
    SELECT
        d.director_id AS dir_id,
        n.primaryName AS dir_name
    FROM deduped d
    LEFT JOIN `bronze`.`imdb_name_basics_raw` n
        ON d.director_id = n.nconst
)
SELECT
    cityHash64(dir_id) AS imdb_dir_name_id,  -- Use hash instead of row_number
    dir_id,
    dir_name,
    today() AS valid_from,
    CAST(NULL AS Nullable(Date)) AS valid_to,
    1 AS is_current  -- Use 1/0 instead of TRUE/FALSE
FROM joined
WHERE dir_id IS NOT NULL
ORDER BY dir_id
          )
        
        ...
[0m12:16:58.710576 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m12:16:58.717753 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_director: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_director"} */

    select name, type from system.columns where table = 'dim_director'
    
      and database = 'gold_gold'
    
    order by position
  ...
[0m12:16:58.721084 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:16:58.724729 [debug] [Thread-1 (]: Writing runtime sql for node "model.movie_warehouse.dim_director"
[0m12:16:58.725908 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_director: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_director"} */

  
    
    
    
        
         


        insert into `gold_gold`.`dim_director`
        ("imdb_dir_name_id", "dir_id", "dir_name", "valid_from", "valid_to", "is_current")

WITH first_dir AS (
    SELECT
        tconst,
        TRIM(splitByChar(',', directors)[1]) AS director_id
    FROM `bronze`.`imdb_title_crew_raw`
    WHERE directors IS NOT NULL AND directors != ''
),
deduped AS (
    SELECT DISTINCT director_id
    FROM first_dir
),
joined AS (
    SELECT
        d.director_id AS dir_id,
        n.primaryName AS dir_name
    FROM deduped d
    LEFT JOIN `bronze`.`imdb_name_basics_raw` n
        ON d.director_id = n.nconst
)
SELECT
    cityHash64(dir_id) AS imdb_dir_name_id,  -- Use hash instead of row_number
    dir_id,
    dir_name,
    today() AS valid_from,
    CAST(NULL AS Nullable(Date)) AS valid_to,
    1 AS is_current  -- Use 1/0 instead of TRUE/FALSE
FROM joined
WHERE dir_id IS NOT NULL
ORDER BY dir_id
  ...
[0m12:17:04.541636 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 5.81 seconds
[0m12:17:04.582967 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'dd246a1b-606d-4f08-86c5-135ce4174431', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff85791b50>]}
[0m12:17:04.584996 [info ] [Thread-1 (]: 1 of 6 OK created sql table model `gold_gold`.`dim_director` ................... [[32mOK[0m in 5.90s]
[0m12:17:04.586096 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.dim_director
[0m12:17:04.586868 [debug] [Thread-1 (]: Began running node model.movie_warehouse.dim_genre
[0m12:17:04.588969 [info ] [Thread-1 (]: 2 of 6 START sql table model `gold_gold`.`dim_genre` ........................... [RUN]
[0m12:17:04.589507 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.movie_warehouse.dim_director, now model.movie_warehouse.dim_genre)
[0m12:17:04.589813 [debug] [Thread-1 (]: Began compiling node model.movie_warehouse.dim_genre
[0m12:17:04.595284 [debug] [Thread-1 (]: Writing injected SQL for node "model.movie_warehouse.dim_genre"
[0m12:17:04.596327 [debug] [Thread-1 (]: Began executing node model.movie_warehouse.dim_genre
[0m12:17:04.598022 [debug] [Thread-1 (]: Creating new relation dim_genre
[0m12:17:04.599003 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_genre: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_genre"} */

            

    
        create table `gold_gold`.`dim_genre`
        
  
        
  engine = MergeTree()
        order by (genre_id)
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

WITH parsed_genres AS (
    SELECT
        TRIM(splitByChar(',', genres)[1]) AS first_genre
    FROM `bronze`.`tmdb_raw`
    WHERE genres IS NOT NULL AND genres != ''
)
SELECT
    cityHash64(first_genre) AS genre_id,
    first_genre AS genre_name
FROM parsed_genres
GROUP BY first_genre
ORDER BY first_genre
          )
        
        ...
[0m12:17:04.621103 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m12:17:04.625164 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_genre: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_genre"} */

    select name, type from system.columns where table = 'dim_genre'
    
      and database = 'gold_gold'
    
    order by position
  ...
[0m12:17:04.629668 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:17:04.631343 [debug] [Thread-1 (]: Writing runtime sql for node "model.movie_warehouse.dim_genre"
[0m12:17:04.632311 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_genre: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_genre"} */

  
    
    
    
        
         


        insert into `gold_gold`.`dim_genre`
        ("genre_id", "genre_name")

WITH parsed_genres AS (
    SELECT
        TRIM(splitByChar(',', genres)[1]) AS first_genre
    FROM `bronze`.`tmdb_raw`
    WHERE genres IS NOT NULL AND genres != ''
)
SELECT
    cityHash64(first_genre) AS genre_id,
    first_genre AS genre_name
FROM parsed_genres
GROUP BY first_genre
ORDER BY first_genre
  ...
[0m12:17:04.665670 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.03 seconds
[0m12:17:04.667568 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'dd246a1b-606d-4f08-86c5-135ce4174431', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff879f07d0>]}
[0m12:17:04.668124 [info ] [Thread-1 (]: 2 of 6 OK created sql table model `gold_gold`.`dim_genre` ...................... [[32mOK[0m in 0.08s]
[0m12:17:04.668835 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.dim_genre
[0m12:17:04.669347 [debug] [Thread-1 (]: Began running node model.movie_warehouse.dim_movie
[0m12:17:04.669845 [info ] [Thread-1 (]: 3 of 6 START sql table model `gold_gold`.`dim_movie` ........................... [RUN]
[0m12:17:04.670136 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.movie_warehouse.dim_genre, now model.movie_warehouse.dim_movie)
[0m12:17:04.670323 [debug] [Thread-1 (]: Began compiling node model.movie_warehouse.dim_movie
[0m12:17:04.672938 [debug] [Thread-1 (]: Writing injected SQL for node "model.movie_warehouse.dim_movie"
[0m12:17:04.673861 [debug] [Thread-1 (]: Began executing node model.movie_warehouse.dim_movie
[0m12:17:04.675297 [debug] [Thread-1 (]: Creating new relation dim_movie
[0m12:17:04.676024 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_movie: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_movie"} */

            

    
        create table `gold_gold`.`dim_movie`
        
  
        
  engine = MergeTree()
        order by (movie_id)
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            -- ...existing code...


WITH movie_src AS (
    SELECT
        TRIM(title) AS movie_title,
        imdb_id,
        release_date,
        runtime AS movie_runtime,
        original_language AS language
    FROM `bronze`.`tmdb_raw`
    WHERE title IS NOT NULL AND title != ''
)
SELECT
    cityHash64(movie_title) AS movie_id,
    any(imdb_id) AS imdb_id,
    movie_title,
    any(release_date) AS release_date,
    any(movie_runtime) AS movie_runtime,
    any(language) AS language
FROM movie_src
GROUP BY movie_title
ORDER BY movie_title
          )
        
        ...
[0m12:17:04.684498 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m12:17:04.686738 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_movie: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_movie"} */

    select name, type from system.columns where table = 'dim_movie'
    
      and database = 'gold_gold'
    
    order by position
  ...
[0m12:17:04.689879 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:17:04.691050 [debug] [Thread-1 (]: Writing runtime sql for node "model.movie_warehouse.dim_movie"
[0m12:17:04.691612 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_movie: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_movie"} */

  
    
    
    
        
         


        insert into `gold_gold`.`dim_movie`
        ("movie_id", "imdb_id", "movie_title", "release_date", "movie_runtime", "language")-- ...existing code...


WITH movie_src AS (
    SELECT
        TRIM(title) AS movie_title,
        imdb_id,
        release_date,
        runtime AS movie_runtime,
        original_language AS language
    FROM `bronze`.`tmdb_raw`
    WHERE title IS NOT NULL AND title != ''
)
SELECT
    cityHash64(movie_title) AS movie_id,
    any(imdb_id) AS imdb_id,
    movie_title,
    any(release_date) AS release_date,
    any(movie_runtime) AS movie_runtime,
    any(language) AS language
FROM movie_src
GROUP BY movie_title
ORDER BY movie_title
  ...
[0m12:17:05.154239 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.46 seconds
[0m12:17:05.155925 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'dd246a1b-606d-4f08-86c5-135ce4174431', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff6209d090>]}
[0m12:17:05.156442 [info ] [Thread-1 (]: 3 of 6 OK created sql table model `gold_gold`.`dim_movie` ...................... [[32mOK[0m in 0.49s]
[0m12:17:05.156832 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.dim_movie
[0m12:17:05.157163 [debug] [Thread-1 (]: Began running node model.movie_warehouse.dim_production
[0m12:17:05.157545 [info ] [Thread-1 (]: 4 of 6 START sql table model `gold_gold`.`dim_production` ...................... [RUN]
[0m12:17:05.157881 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.movie_warehouse.dim_movie, now model.movie_warehouse.dim_production)
[0m12:17:05.158115 [debug] [Thread-1 (]: Began compiling node model.movie_warehouse.dim_production
[0m12:17:05.160995 [debug] [Thread-1 (]: Writing injected SQL for node "model.movie_warehouse.dim_production"
[0m12:17:05.162208 [debug] [Thread-1 (]: Began executing node model.movie_warehouse.dim_production
[0m12:17:05.163773 [debug] [Thread-1 (]: Creating new relation dim_production
[0m12:17:05.164481 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_production: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_production"} */

            

    
        create table `gold_gold`.`dim_production`
        
  
        
  engine = MergeTree()
        order by (production_id)
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

WITH first_production AS (
    SELECT
        imdb_id AS movie_id,
        trim(splitByChar(',', production_companies)[1]) AS production_name
    FROM `bronze`.`tmdb_raw`
    WHERE production_companies IS NOT NULL AND production_companies != ''
)

SELECT
    cityHash64(production_name) AS production_id,
    production_name,
    current_date() AS valid_from,
    CAST(NULL AS Nullable(Date)) AS valid_to,
    TRUE AS is_current
FROM (
    SELECT DISTINCT production_name
    FROM first_production
)
WHERE production_name IS NOT NULL
          )
        
        ...
[0m12:17:05.173037 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m12:17:05.175812 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_production: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_production"} */

    select name, type from system.columns where table = 'dim_production'
    
      and database = 'gold_gold'
    
    order by position
  ...
[0m12:17:05.179451 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:17:05.180855 [debug] [Thread-1 (]: Writing runtime sql for node "model.movie_warehouse.dim_production"
[0m12:17:05.181716 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_production: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_production"} */

  
    
    
    
        
         


        insert into `gold_gold`.`dim_production`
        ("production_id", "production_name", "valid_from", "valid_to", "is_current")

WITH first_production AS (
    SELECT
        imdb_id AS movie_id,
        trim(splitByChar(',', production_companies)[1]) AS production_name
    FROM `bronze`.`tmdb_raw`
    WHERE production_companies IS NOT NULL AND production_companies != ''
)

SELECT
    cityHash64(production_name) AS production_id,
    production_name,
    current_date() AS valid_from,
    CAST(NULL AS Nullable(Date)) AS valid_to,
    TRUE AS is_current
FROM (
    SELECT DISTINCT production_name
    FROM first_production
)
WHERE production_name IS NOT NULL
  ...
[0m12:17:05.188738 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m12:17:05.190767 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'dd246a1b-606d-4f08-86c5-135ce4174431', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff62fce790>]}
[0m12:17:05.191230 [info ] [Thread-1 (]: 4 of 6 OK created sql table model `gold_gold`.`dim_production` ................. [[32mOK[0m in 0.03s]
[0m12:17:05.191612 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.dim_production
[0m12:17:05.191880 [debug] [Thread-1 (]: Began running node model.movie_warehouse.dim_release_date
[0m12:17:05.192252 [info ] [Thread-1 (]: 5 of 6 START sql table model `gold_gold`.`dim_release_date` .................... [RUN]
[0m12:17:05.192543 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.movie_warehouse.dim_production, now model.movie_warehouse.dim_release_date)
[0m12:17:05.192749 [debug] [Thread-1 (]: Began compiling node model.movie_warehouse.dim_release_date
[0m12:17:05.194825 [debug] [Thread-1 (]: Writing injected SQL for node "model.movie_warehouse.dim_release_date"
[0m12:17:05.195402 [debug] [Thread-1 (]: Began executing node model.movie_warehouse.dim_release_date
[0m12:17:05.196670 [debug] [Thread-1 (]: Creating new relation dim_release_date
[0m12:17:05.197375 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_release_date: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_release_date"} */

            

    
        create table `gold_gold`.`dim_release_date`
        
  
        
  engine = MergeTree()
        order by (date_id)
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

WITH distinct_dates AS (
    SELECT DISTINCT release_date
    FROM `bronze`.`tmdb_raw`
    WHERE release_date IS NOT NULL
)

SELECT
    cityHash64(release_date)                                    AS date_id,
    release_date                                                AS full_date,
    toYear(release_date)                                        AS year,
    toMonth(release_date)                                       AS month,
    toDayOfMonth(release_date)                                  AS day,
    toISOWeek(release_date)                                     AS week,
    formatDateTime(release_date, '%a')                          AS weekday,
    CASE
        WHEN toMonth(release_date) IN (12,1,2)  THEN 'Winter'
        WHEN toMonth(release_date) IN (3,4,5)   THEN 'Spring'
        WHEN toMonth(release_date) IN (6,7,8)   THEN 'Summer'
        WHEN toMonth(release_date) IN (9,10,11) THEN 'Autumn'
    END                                                         AS season,
    CASE
        WHEN formatDateTime(release_date, '%a') IN ('Saturday','Sunday') THEN 1
        ELSE 0
    END                                                         AS is_weekend,

    /* ---------- holiday tagging ---------- */
    CASE
        WHEN toMonth(release_date)=1  AND toDayOfMonth(release_date)=1  THEN 'New Years Day'
        WHEN toMonth(release_date)=2  AND toDayOfMonth(release_date)=14 THEN 'Valentines Day'
        WHEN toMonth(release_date)=3  AND toDayOfMonth(release_date)=17 THEN 'St. Patricks Day'
        WHEN toMonth(release_date)=4  AND toDayOfMonth(release_date)=1  THEN 'April Fools Day'
        WHEN toMonth(release_date)=4  AND toDayOfMonth(release_date)=22 THEN 'Earth Day'
        WHEN toMonth(release_date)=5  AND toDayOfMonth(release_date)=1  THEN 'May Day'
        WHEN toMonth(release_date)=5  AND toDayOfMonth(release_date)=5  THEN 'Cinco de Mayo'
        WHEN toMonth(release_date)=6  AND toDayOfMonth(release_date) BETWEEN 19 AND 26 THEN 'Midsummer'
        WHEN toMonth(release_date)=7  AND toDayOfMonth(release_date)=4  THEN 'Independence Day'
        WHEN toMonth(release_date)=9  AND toDayOfMonth(release_date) BETWEEN 1 AND 7 
             AND formatDateTime(release_date,'%a')='Monday'             THEN 'Labor Day (US)'
        WHEN toMonth(release_date)=10 AND toDayOfMonth(release_date)=31 THEN 'Halloween'
        WHEN toMonth(release_date)=11 AND formatDateTime(release_date,'%a')='Thursday'
             AND toISOWeek(release_date) >= 47                           THEN 'Thanksgiving'
        WHEN toMonth(release_date)=12 AND toDayOfMonth(release_date)=24 THEN 'Christmas Eve'
        WHEN toMonth(release_date)=12 AND toDayOfMonth(release_date)=25 THEN 'Christmas Day'
        WHEN toMonth(release_date)=12 AND toDayOfMonth(release_date)=31 THEN 'New Years Eve'
        ELSE NULL
    END                                                         AS holiday_name,
    IF(holiday_name IS NOT NULL, 1, 0)                          AS is_holiday,

    /* placeholders for later enhancement */
    CAST(NULL AS Nullable(Int32)) AS days_until_holiday,
    CAST(NULL AS Nullable(Int32)) AS days_after_holiday

FROM distinct_dates
ORDER BY release_date
          )
        
        ...
[0m12:17:05.217990 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m12:17:05.220590 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_release_date: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_release_date"} */

    select name, type from system.columns where table = 'dim_release_date'
    
      and database = 'gold_gold'
    
    order by position
  ...
[0m12:17:05.223628 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:17:05.225099 [debug] [Thread-1 (]: Writing runtime sql for node "model.movie_warehouse.dim_release_date"
[0m12:17:05.225771 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_release_date: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_release_date"} */

  
    
    
    
        
         


        insert into `gold_gold`.`dim_release_date`
        ("date_id", "full_date", "year", "month", "day", "week", "weekday", "season", "is_weekend", "holiday_name", "is_holiday", "days_until_holiday", "days_after_holiday")

WITH distinct_dates AS (
    SELECT DISTINCT release_date
    FROM `bronze`.`tmdb_raw`
    WHERE release_date IS NOT NULL
)

SELECT
    cityHash64(release_date)                                    AS date_id,
    release_date                                                AS full_date,
    toYear(release_date)                                        AS year,
    toMonth(release_date)                                       AS month,
    toDayOfMonth(release_date)                                  AS day,
    toISOWeek(release_date)                                     AS week,
    formatDateTime(release_date, '%a')                          AS weekday,
    CASE
        WHEN toMonth(release_date) IN (12,1,2)  THEN 'Winter'
        WHEN toMonth(release_date) IN (3,4,5)   THEN 'Spring'
        WHEN toMonth(release_date) IN (6,7,8)   THEN 'Summer'
        WHEN toMonth(release_date) IN (9,10,11) THEN 'Autumn'
    END                                                         AS season,
    CASE
        WHEN formatDateTime(release_date, '%a') IN ('Saturday','Sunday') THEN 1
        ELSE 0
    END                                                         AS is_weekend,

    /* ---------- holiday tagging ---------- */
    CASE
        WHEN toMonth(release_date)=1  AND toDayOfMonth(release_date)=1  THEN 'New Years Day'
        WHEN toMonth(release_date)=2  AND toDayOfMonth(release_date)=14 THEN 'Valentines Day'
        WHEN toMonth(release_date)=3  AND toDayOfMonth(release_date)=17 THEN 'St. Patricks Day'
        WHEN toMonth(release_date)=4  AND toDayOfMonth(release_date)=1  THEN 'April Fools Day'
        WHEN toMonth(release_date)=4  AND toDayOfMonth(release_date)=22 THEN 'Earth Day'
        WHEN toMonth(release_date)=5  AND toDayOfMonth(release_date)=1  THEN 'May Day'
        WHEN toMonth(release_date)=5  AND toDayOfMonth(release_date)=5  THEN 'Cinco de Mayo'
        WHEN toMonth(release_date)=6  AND toDayOfMonth(release_date) BETWEEN 19 AND 26 THEN 'Midsummer'
        WHEN toMonth(release_date)=7  AND toDayOfMonth(release_date)=4  THEN 'Independence Day'
        WHEN toMonth(release_date)=9  AND toDayOfMonth(release_date) BETWEEN 1 AND 7 
             AND formatDateTime(release_date,'%a')='Monday'             THEN 'Labor Day (US)'
        WHEN toMonth(release_date)=10 AND toDayOfMonth(release_date)=31 THEN 'Halloween'
        WHEN toMonth(release_date)=11 AND formatDateTime(release_date,'%a')='Thursday'
             AND toISOWeek(release_date) >= 47                           THEN 'Thanksgiving'
        WHEN toMonth(release_date)=12 AND toDayOfMonth(release_date)=24 THEN 'Christmas Eve'
        WHEN toMonth(release_date)=12 AND toDayOfMonth(release_date)=25 THEN 'Christmas Day'
        WHEN toMonth(release_date)=12 AND toDayOfMonth(release_date)=31 THEN 'New Years Eve'
        ELSE NULL
    END                                                         AS holiday_name,
    IF(holiday_name IS NOT NULL, 1, 0)                          AS is_holiday,

    /* placeholders for later enhancement */
    CAST(NULL AS Nullable(Int32)) AS days_until_holiday,
    CAST(NULL AS Nullable(Int32)) AS days_after_holiday

FROM distinct_dates
ORDER BY release_date
  ...
[0m12:17:05.254452 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.03 seconds
[0m12:17:05.255722 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'dd246a1b-606d-4f08-86c5-135ce4174431', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff6885d6d0>]}
[0m12:17:05.256114 [info ] [Thread-1 (]: 5 of 6 OK created sql table model `gold_gold`.`dim_release_date` ............... [[32mOK[0m in 0.06s]
[0m12:17:05.256595 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.dim_release_date
[0m12:17:05.257870 [debug] [Thread-1 (]: Began running node model.movie_warehouse.fact_movie
[0m12:17:05.258127 [info ] [Thread-1 (]: 6 of 6 START sql table model `gold_gold`.`fact_movie` .......................... [RUN]
[0m12:17:05.258345 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.movie_warehouse.dim_release_date, now model.movie_warehouse.fact_movie)
[0m12:17:05.258532 [debug] [Thread-1 (]: Began compiling node model.movie_warehouse.fact_movie
[0m12:17:05.261681 [debug] [Thread-1 (]: Writing injected SQL for node "model.movie_warehouse.fact_movie"
[0m12:17:05.262303 [debug] [Thread-1 (]: Began executing node model.movie_warehouse.fact_movie
[0m12:17:05.431439 [debug] [Thread-1 (]: Creating new relation fact_movie
[0m12:17:05.432716 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.fact_movie: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.fact_movie"} */

            

    
        create table `gold_gold`.`fact_movie`
        
  
        
  engine = MergeTree()
        order by (fact_id)
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

WITH filtered_tmdb AS (
    SELECT 
        imdb_id,
        title,
        release_date,
        production_companies,
        budget,
        revenue,
        vote_average,
        vote_count,
        runtime,
        genres,
        original_language,
        (vote_average * log(1 + vote_count)) AS movie_popularity
    FROM `bronze`.`tmdb_raw`
),

-- First genre
first_genre AS (
    SELECT
        imdb_id AS movie_id,
        trim(splitByChar(',', genres)[1]) AS genre_name
    FROM filtered_tmdb
),

-- First director
first_director AS (
    SELECT
        t.imdb_id AS movie_id,
        trim(splitByChar(',', c.directors)[1]) AS director_id
    FROM filtered_tmdb t
    LEFT JOIN `bronze`.`imdb_title_crew_raw` c
        ON t.imdb_id = c.tconst
),

-- Join to dim_production to get production_id
movie_production AS (
    SELECT
        t.imdb_id AS movie_id,
        p.production_id
    FROM filtered_tmdb t
    LEFT JOIN `gold_gold`.`dim_production` p
        ON trim(splitByChar(',', t.production_companies)[1]) = p.production_name
),

-- Map genre_name to dim_genre to get genre_id
movie_genre AS (
    SELECT
        fg.movie_id,
        g.genre_id
    FROM first_genre fg
    LEFT JOIN `gold_gold`.`dim_genre` g
        ON fg.genre_name = g.genre_name
),

base AS (
    SELECT
        t.imdb_id                                 AS movie_id,
        d.director_id,
        mg.genre_id,
        mp.production_id,
        dr.date_id                                AS date_id,
        t.vote_average                            AS vote_avg,
        t.vote_count,
        t.revenue,
        t.budget,
        t.movie_popularity,
        toYear(t.release_date)                    AS release_year
    FROM filtered_tmdb t
    LEFT JOIN movie_genre mg       ON mg.movie_id = t.imdb_id
    LEFT JOIN first_director d     ON d.movie_id = t.imdb_id
    LEFT JOIN movie_production mp  ON mp.movie_id = t.imdb_id
    LEFT JOIN `gold_gold`.`dim_release_date` dr
        ON dr.full_date = t.release_date
),

metrics AS (
    SELECT
        b.*,
        b.revenue - lag(b.revenue, 1) OVER (PARTITION BY b.movie_id ORDER BY b.release_year) AS revenue_growth,
        b.movie_popularity - lag(b.movie_popularity, 1) OVER (PARTITION BY b.movie_id ORDER BY b.release_year) AS popularity_change,
        b.vote_avg - lag(b.vote_avg, 1) OVER (PARTITION BY b.movie_id ORDER BY b.release_year) AS vote_avg_change
    FROM base b
)

SELECT
    row_number() OVER (ORDER BY movie_id, date_id, director_id, genre_id) AS fact_id,
    movie_id,
    director_id,
    genre_id,
    production_id,
    date_id,
    vote_avg,
    vote_count,
    revenue,
    budget,
    movie_popularity,
    revenue_growth,
    popularity_change,
    vote_avg_change
FROM metrics
          )
        
        ...
[0m12:17:05.450696 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m12:17:05.452798 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.fact_movie: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.fact_movie"} */

    select name, type from system.columns where table = 'fact_movie'
    
      and database = 'gold_gold'
    
    order by position
  ...
[0m12:17:05.456589 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:17:05.459336 [debug] [Thread-1 (]: Writing runtime sql for node "model.movie_warehouse.fact_movie"
[0m12:17:05.460418 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.fact_movie: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.fact_movie"} */

  
    
    
    
        
         


        insert into `gold_gold`.`fact_movie`
        ("fact_id", "movie_id", "director_id", "genre_id", "production_id", "date_id", "vote_avg", "vote_count", "revenue", "budget", "movie_popularity", "revenue_growth", "popularity_change", "vote_avg_change")

WITH filtered_tmdb AS (
    SELECT 
        imdb_id,
        title,
        release_date,
        production_companies,
        budget,
        revenue,
        vote_average,
        vote_count,
        runtime,
        genres,
        original_language,
        (vote_average * log(1 + vote_count)) AS movie_popularity
    FROM `bronze`.`tmdb_raw`
),

-- First genre
first_genre AS (
    SELECT
        imdb_id AS movie_id,
        trim(splitByChar(',', genres)[1]) AS genre_name
    FROM filtered_tmdb
),

-- First director
first_director AS (
    SELECT
        t.imdb_id AS movie_id,
        trim(splitByChar(',', c.directors)[1]) AS director_id
    FROM filtered_tmdb t
    LEFT JOIN `bronze`.`imdb_title_crew_raw` c
        ON t.imdb_id = c.tconst
),

-- Join to dim_production to get production_id
movie_production AS (
    SELECT
        t.imdb_id AS movie_id,
        p.production_id
    FROM filtered_tmdb t
    LEFT JOIN `gold_gold`.`dim_production` p
        ON trim(splitByChar(',', t.production_companies)[1]) = p.production_name
),

-- Map genre_name to dim_genre to get genre_id
movie_genre AS (
    SELECT
        fg.movie_id,
        g.genre_id
    FROM first_genre fg
    LEFT JOIN `gold_gold`.`dim_genre` g
        ON fg.genre_name = g.genre_name
),

base AS (
    SELECT
        t.imdb_id                                 AS movie_id,
        d.director_id,
        mg.genre_id,
        mp.production_id,
        dr.date_id                                AS date_id,
        t.vote_average                            AS vote_avg,
        t.vote_count,
        t.revenue,
        t.budget,
        t.movie_popularity,
        toYear(t.release_date)                    AS release_year
    FROM filtered_tmdb t
    LEFT JOIN movie_genre mg       ON mg.movie_id = t.imdb_id
    LEFT JOIN first_director d     ON d.movie_id = t.imdb_id
    LEFT JOIN movie_production mp  ON mp.movie_id = t.imdb_id
    LEFT JOIN `gold_gold`.`dim_release_date` dr
        ON dr.full_date = t.release_date
),

metrics AS (
    SELECT
        b.*,
        b.revenue - lag(b.revenue, 1) OVER (PARTITION BY b.movie_id ORDER BY b.release_year) AS revenue_growth,
        b.movie_popularity - lag(b.movie_popularity, 1) OVER (PARTITION BY b.movie_id ORDER BY b.release_year) AS popularity_change,
        b.vote_avg - lag(b.vote_avg, 1) OVER (PARTITION BY b.movie_id ORDER BY b.release_year) AS vote_avg_change
    FROM base b
)

SELECT
    row_number() OVER (ORDER BY movie_id, date_id, director_id, genre_id) AS fact_id,
    movie_id,
    director_id,
    genre_id,
    production_id,
    date_id,
    vote_avg,
    vote_count,
    revenue,
    budget,
    movie_popularity,
    revenue_growth,
    popularity_change,
    vote_avg_change
FROM metrics
  ...
[0m12:17:10.208443 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 4.75 seconds
[0m12:17:10.217007 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'dd246a1b-606d-4f08-86c5-135ce4174431', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff61f64cd0>]}
[0m12:17:10.218724 [info ] [Thread-1 (]: 6 of 6 OK created sql table model `gold_gold`.`fact_movie` ..................... [[32mOK[0m in 4.96s]
[0m12:17:10.219685 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.fact_movie
[0m12:17:10.225432 [debug] [MainThread]: Connection 'master' was properly closed.
[0m12:17:10.226001 [debug] [MainThread]: Connection 'model.movie_warehouse.fact_movie' was left open.
[0m12:17:10.226316 [debug] [MainThread]: On model.movie_warehouse.fact_movie: Close
[0m12:17:10.227400 [info ] [MainThread]: 
[0m12:17:10.227817 [info ] [MainThread]: Finished running 6 table models in 0 hours 0 minutes and 11.94 seconds (11.94s).
[0m12:17:10.229315 [debug] [MainThread]: Command end result
[0m12:17:10.264907 [info ] [MainThread]: 
[0m12:17:10.265306 [info ] [MainThread]: [32mCompleted successfully[0m
[0m12:17:10.265499 [info ] [MainThread]: 
[0m12:17:10.265731 [info ] [MainThread]: Done. PASS=6 WARN=0 ERROR=0 SKIP=0 TOTAL=6
[0m12:17:10.268475 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 12.2773695, "process_in_blocks": "58592", "process_kernel_time": 0.347786, "process_mem_max_rss": "189572", "process_out_blocks": "2408", "process_user_time": 2.080652}
[0m12:17:10.269111 [debug] [MainThread]: Command `dbt run` succeeded at 12:17:10.269030 after 12.28 seconds
[0m12:17:10.269638 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8a7a9e10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8a7a8890>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8a7a9fd0>]}
[0m12:17:10.269908 [debug] [MainThread]: Flushing usage events
[0m12:17:13.019145 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8f1dd450>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8f1ddad0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8f1dcb50>]}


============================== 12:17:13.022664 | 85f48430-4bb4-4985-9184-a027e6d639d3 ==============================
[0m12:17:13.022664 [info ] [MainThread]: Running with dbt=1.8.9
[0m12:17:13.022996 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'version_check': 'True', 'log_path': '/opt/airflow/project_root/dbt/logs', 'fail_fast': 'False', 'profiles_dir': '/opt/airflow/project_root/dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'log_format': 'default', 'invocation_command': 'dbt test --project-dir /opt/airflow/project_root/dbt --profiles-dir /opt/airflow/project_root/dbt --select gold', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m12:17:13.136973 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '85f48430-4bb4-4985-9184-a027e6d639d3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8f46ff50>]}
[0m12:17:13.155960 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '85f48430-4bb4-4985-9184-a027e6d639d3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8fc0b510>]}
[0m12:17:13.156700 [info ] [MainThread]: Registered adapter: clickhouse=1.8.9
[0m12:17:13.189587 [debug] [MainThread]: checksum: 132857a23e9d07220246854f7763165174ce9b737cfc7867629ace4294e520b1, vars: {}, profile: , target: , version: 1.8.9
[0m12:17:13.243459 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m12:17:13.243735 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m12:17:13.246330 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.movie_warehouse.bronze
[0m12:17:13.262547 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '85f48430-4bb4-4985-9184-a027e6d639d3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8ef50050>]}
[0m12:17:13.357573 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '85f48430-4bb4-4985-9184-a027e6d639d3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8ea70410>]}
[0m12:17:13.358184 [info ] [MainThread]: Found 6 models, 12 data tests, 4 sources, 477 macros
[0m12:17:13.358596 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '85f48430-4bb4-4985-9184-a027e6d639d3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8ef38a10>]}
[0m12:17:13.360346 [info ] [MainThread]: 
[0m12:17:13.360803 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m12:17:13.363786 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list__gold_gold'
[0m12:17:13.369694 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:17:13.695436 [info ] [ThreadPool]: dbt_clickhouse adapter: Unexpected server exception dropping table
[0m12:17:13.695891 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__gold_gold: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "connection_name": "list__gold_gold"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'gold_gold'
      

  ...
[0m12:17:13.701222 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:17:13.721455 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '85f48430-4bb4-4985-9184-a027e6d639d3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8eec6510>]}
[0m12:17:13.721930 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m12:17:13.722157 [info ] [MainThread]: 
[0m12:17:13.727164 [debug] [Thread-1 (]: Began running node test.movie_warehouse.not_null_dim_genre_genre_id.9bb76b166c
[0m12:17:13.727492 [info ] [Thread-1 (]: 1 of 12 START test not_null_dim_genre_genre_id ................................. [RUN]
[0m12:17:13.727827 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list__gold_gold, now test.movie_warehouse.not_null_dim_genre_genre_id.9bb76b166c)
[0m12:17:13.728055 [debug] [Thread-1 (]: Began compiling node test.movie_warehouse.not_null_dim_genre_genre_id.9bb76b166c
[0m12:17:13.734889 [debug] [Thread-1 (]: Writing injected SQL for node "test.movie_warehouse.not_null_dim_genre_genre_id.9bb76b166c"
[0m12:17:13.735928 [debug] [Thread-1 (]: Began executing node test.movie_warehouse.not_null_dim_genre_genre_id.9bb76b166c
[0m12:17:13.742944 [debug] [Thread-1 (]: Writing runtime sql for node "test.movie_warehouse.not_null_dim_genre_genre_id.9bb76b166c"
[0m12:17:13.743712 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.movie_warehouse.not_null_dim_genre_genre_id.9bb76b166c: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "test.movie_warehouse.not_null_dim_genre_genre_id.9bb76b166c"} */

    
    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select genre_id
from `gold_gold`.`dim_genre`
where genre_id is null



  
  
    ) dbt_internal_test...
[0m12:17:13.749384 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m12:17:13.753362 [info ] [Thread-1 (]: 1 of 12 PASS not_null_dim_genre_genre_id ....................................... [[32mPASS[0m in 0.03s]
[0m12:17:13.754395 [debug] [Thread-1 (]: Finished running node test.movie_warehouse.not_null_dim_genre_genre_id.9bb76b166c
[0m12:17:13.754770 [debug] [Thread-1 (]: Began running node test.movie_warehouse.not_null_dim_movie_movie_id.fd05907b20
[0m12:17:13.755146 [info ] [Thread-1 (]: 2 of 12 START test not_null_dim_movie_movie_id ................................. [RUN]
[0m12:17:13.755478 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.movie_warehouse.not_null_dim_genre_genre_id.9bb76b166c, now test.movie_warehouse.not_null_dim_movie_movie_id.fd05907b20)
[0m12:17:13.755700 [debug] [Thread-1 (]: Began compiling node test.movie_warehouse.not_null_dim_movie_movie_id.fd05907b20
[0m12:17:13.757732 [debug] [Thread-1 (]: Writing injected SQL for node "test.movie_warehouse.not_null_dim_movie_movie_id.fd05907b20"
[0m12:17:13.758547 [debug] [Thread-1 (]: Began executing node test.movie_warehouse.not_null_dim_movie_movie_id.fd05907b20
[0m12:17:13.760453 [debug] [Thread-1 (]: Writing runtime sql for node "test.movie_warehouse.not_null_dim_movie_movie_id.fd05907b20"
[0m12:17:13.760971 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.movie_warehouse.not_null_dim_movie_movie_id.fd05907b20: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "test.movie_warehouse.not_null_dim_movie_movie_id.fd05907b20"} */

    
    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select movie_id
from `gold_gold`.`dim_movie`
where movie_id is null



  
  
    ) dbt_internal_test...
[0m12:17:13.764384 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:17:13.765242 [info ] [Thread-1 (]: 2 of 12 PASS not_null_dim_movie_movie_id ....................................... [[32mPASS[0m in 0.01s]
[0m12:17:13.765527 [debug] [Thread-1 (]: Finished running node test.movie_warehouse.not_null_dim_movie_movie_id.fd05907b20
[0m12:17:13.765773 [debug] [Thread-1 (]: Began running node test.movie_warehouse.not_null_dim_production_production_id.7ff384ec2b
[0m12:17:13.766019 [info ] [Thread-1 (]: 3 of 12 START test not_null_dim_production_production_id ....................... [RUN]
[0m12:17:13.766243 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.movie_warehouse.not_null_dim_movie_movie_id.fd05907b20, now test.movie_warehouse.not_null_dim_production_production_id.7ff384ec2b)
[0m12:17:13.766422 [debug] [Thread-1 (]: Began compiling node test.movie_warehouse.not_null_dim_production_production_id.7ff384ec2b
[0m12:17:13.768242 [debug] [Thread-1 (]: Writing injected SQL for node "test.movie_warehouse.not_null_dim_production_production_id.7ff384ec2b"
[0m12:17:13.768694 [debug] [Thread-1 (]: Began executing node test.movie_warehouse.not_null_dim_production_production_id.7ff384ec2b
[0m12:17:13.769633 [debug] [Thread-1 (]: Writing runtime sql for node "test.movie_warehouse.not_null_dim_production_production_id.7ff384ec2b"
[0m12:17:13.770260 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.movie_warehouse.not_null_dim_production_production_id.7ff384ec2b: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "test.movie_warehouse.not_null_dim_production_production_id.7ff384ec2b"} */

    
    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select production_id
from `gold_gold`.`dim_production`
where production_id is null



  
  
    ) dbt_internal_test...
[0m12:17:13.773186 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:17:13.773976 [info ] [Thread-1 (]: 3 of 12 PASS not_null_dim_production_production_id ............................. [[32mPASS[0m in 0.01s]
[0m12:17:13.774303 [debug] [Thread-1 (]: Finished running node test.movie_warehouse.not_null_dim_production_production_id.7ff384ec2b
[0m12:17:13.774545 [debug] [Thread-1 (]: Began running node test.movie_warehouse.not_null_dim_release_date_date_id.f6b8c9c3d5
[0m12:17:13.774860 [info ] [Thread-1 (]: 4 of 12 START test not_null_dim_release_date_date_id ........................... [RUN]
[0m12:17:13.775356 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.movie_warehouse.not_null_dim_production_production_id.7ff384ec2b, now test.movie_warehouse.not_null_dim_release_date_date_id.f6b8c9c3d5)
[0m12:17:13.775785 [debug] [Thread-1 (]: Began compiling node test.movie_warehouse.not_null_dim_release_date_date_id.f6b8c9c3d5
[0m12:17:13.778532 [debug] [Thread-1 (]: Writing injected SQL for node "test.movie_warehouse.not_null_dim_release_date_date_id.f6b8c9c3d5"
[0m12:17:13.779159 [debug] [Thread-1 (]: Began executing node test.movie_warehouse.not_null_dim_release_date_date_id.f6b8c9c3d5
[0m12:17:13.780317 [debug] [Thread-1 (]: Writing runtime sql for node "test.movie_warehouse.not_null_dim_release_date_date_id.f6b8c9c3d5"
[0m12:17:13.780953 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.movie_warehouse.not_null_dim_release_date_date_id.f6b8c9c3d5: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "test.movie_warehouse.not_null_dim_release_date_date_id.f6b8c9c3d5"} */

    
    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select date_id
from `gold_gold`.`dim_release_date`
where date_id is null



  
  
    ) dbt_internal_test...
[0m12:17:13.786822 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m12:17:13.788389 [info ] [Thread-1 (]: 4 of 12 PASS not_null_dim_release_date_date_id ................................. [[32mPASS[0m in 0.01s]
[0m12:17:13.789064 [debug] [Thread-1 (]: Finished running node test.movie_warehouse.not_null_dim_release_date_date_id.f6b8c9c3d5
[0m12:17:13.789648 [debug] [Thread-1 (]: Began running node test.movie_warehouse.not_null_fact_movie_date_id.ca6e5e8ca0
[0m12:17:13.789934 [info ] [Thread-1 (]: 5 of 12 START test not_null_fact_movie_date_id ................................. [RUN]
[0m12:17:13.790229 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.movie_warehouse.not_null_dim_release_date_date_id.f6b8c9c3d5, now test.movie_warehouse.not_null_fact_movie_date_id.ca6e5e8ca0)
[0m12:17:13.790474 [debug] [Thread-1 (]: Began compiling node test.movie_warehouse.not_null_fact_movie_date_id.ca6e5e8ca0
[0m12:17:13.792814 [debug] [Thread-1 (]: Writing injected SQL for node "test.movie_warehouse.not_null_fact_movie_date_id.ca6e5e8ca0"
[0m12:17:13.793532 [debug] [Thread-1 (]: Began executing node test.movie_warehouse.not_null_fact_movie_date_id.ca6e5e8ca0
[0m12:17:13.794847 [debug] [Thread-1 (]: Writing runtime sql for node "test.movie_warehouse.not_null_fact_movie_date_id.ca6e5e8ca0"
[0m12:17:13.795399 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.movie_warehouse.not_null_fact_movie_date_id.ca6e5e8ca0: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "test.movie_warehouse.not_null_fact_movie_date_id.ca6e5e8ca0"} */

    
    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select date_id
from `gold_gold`.`fact_movie`
where date_id is null



  
  
    ) dbt_internal_test...
[0m12:17:13.799060 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:17:13.800064 [info ] [Thread-1 (]: 5 of 12 PASS not_null_fact_movie_date_id ....................................... [[32mPASS[0m in 0.01s]
[0m12:17:13.800432 [debug] [Thread-1 (]: Finished running node test.movie_warehouse.not_null_fact_movie_date_id.ca6e5e8ca0
[0m12:17:13.800681 [debug] [Thread-1 (]: Began running node test.movie_warehouse.not_null_fact_movie_fact_id.1f53f01729
[0m12:17:13.800927 [info ] [Thread-1 (]: 6 of 12 START test not_null_fact_movie_fact_id ................................. [RUN]
[0m12:17:13.801172 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.movie_warehouse.not_null_fact_movie_date_id.ca6e5e8ca0, now test.movie_warehouse.not_null_fact_movie_fact_id.1f53f01729)
[0m12:17:13.801412 [debug] [Thread-1 (]: Began compiling node test.movie_warehouse.not_null_fact_movie_fact_id.1f53f01729
[0m12:17:13.803554 [debug] [Thread-1 (]: Writing injected SQL for node "test.movie_warehouse.not_null_fact_movie_fact_id.1f53f01729"
[0m12:17:13.804093 [debug] [Thread-1 (]: Began executing node test.movie_warehouse.not_null_fact_movie_fact_id.1f53f01729
[0m12:17:13.805835 [debug] [Thread-1 (]: Writing runtime sql for node "test.movie_warehouse.not_null_fact_movie_fact_id.1f53f01729"
[0m12:17:13.806845 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.movie_warehouse.not_null_fact_movie_fact_id.1f53f01729: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "test.movie_warehouse.not_null_fact_movie_fact_id.1f53f01729"} */

    
    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select fact_id
from `gold_gold`.`fact_movie`
where fact_id is null



  
  
    ) dbt_internal_test...
[0m12:17:13.811603 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:17:13.812604 [info ] [Thread-1 (]: 6 of 12 PASS not_null_fact_movie_fact_id ....................................... [[32mPASS[0m in 0.01s]
[0m12:17:13.812912 [debug] [Thread-1 (]: Finished running node test.movie_warehouse.not_null_fact_movie_fact_id.1f53f01729
[0m12:17:13.813134 [debug] [Thread-1 (]: Began running node test.movie_warehouse.not_null_fact_movie_movie_id.115d5160ae
[0m12:17:13.813355 [info ] [Thread-1 (]: 7 of 12 START test not_null_fact_movie_movie_id ................................ [RUN]
[0m12:17:13.813587 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.movie_warehouse.not_null_fact_movie_fact_id.1f53f01729, now test.movie_warehouse.not_null_fact_movie_movie_id.115d5160ae)
[0m12:17:13.813802 [debug] [Thread-1 (]: Began compiling node test.movie_warehouse.not_null_fact_movie_movie_id.115d5160ae
[0m12:17:13.815859 [debug] [Thread-1 (]: Writing injected SQL for node "test.movie_warehouse.not_null_fact_movie_movie_id.115d5160ae"
[0m12:17:13.816414 [debug] [Thread-1 (]: Began executing node test.movie_warehouse.not_null_fact_movie_movie_id.115d5160ae
[0m12:17:13.817461 [debug] [Thread-1 (]: Writing runtime sql for node "test.movie_warehouse.not_null_fact_movie_movie_id.115d5160ae"
[0m12:17:13.818084 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.movie_warehouse.not_null_fact_movie_movie_id.115d5160ae: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "test.movie_warehouse.not_null_fact_movie_movie_id.115d5160ae"} */

    
    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select movie_id
from `gold_gold`.`fact_movie`
where movie_id is null



  
  
    ) dbt_internal_test...
[0m12:17:13.821119 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:17:13.821923 [info ] [Thread-1 (]: 7 of 12 PASS not_null_fact_movie_movie_id ...................................... [[32mPASS[0m in 0.01s]
[0m12:17:13.822217 [debug] [Thread-1 (]: Finished running node test.movie_warehouse.not_null_fact_movie_movie_id.115d5160ae
[0m12:17:13.822430 [debug] [Thread-1 (]: Began running node test.movie_warehouse.unique_dim_genre_genre_id.757304f7bc
[0m12:17:13.822663 [info ] [Thread-1 (]: 8 of 12 START test unique_dim_genre_genre_id ................................... [RUN]
[0m12:17:13.822872 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.movie_warehouse.not_null_fact_movie_movie_id.115d5160ae, now test.movie_warehouse.unique_dim_genre_genre_id.757304f7bc)
[0m12:17:13.823056 [debug] [Thread-1 (]: Began compiling node test.movie_warehouse.unique_dim_genre_genre_id.757304f7bc
[0m12:17:13.864222 [debug] [Thread-1 (]: Writing injected SQL for node "test.movie_warehouse.unique_dim_genre_genre_id.757304f7bc"
[0m12:17:13.865108 [debug] [Thread-1 (]: Began executing node test.movie_warehouse.unique_dim_genre_genre_id.757304f7bc
[0m12:17:13.866189 [debug] [Thread-1 (]: Writing runtime sql for node "test.movie_warehouse.unique_dim_genre_genre_id.757304f7bc"
[0m12:17:13.866608 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.movie_warehouse.unique_dim_genre_genre_id.757304f7bc: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "test.movie_warehouse.unique_dim_genre_genre_id.757304f7bc"} */

    
    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    genre_id as unique_field,
    count(*) as n_records

from `gold_gold`.`dim_genre`
where genre_id is not null
group by genre_id
having count(*) > 1



  
  
    ) dbt_internal_test...
[0m12:17:13.871319 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:17:13.872162 [info ] [Thread-1 (]: 8 of 12 PASS unique_dim_genre_genre_id ......................................... [[32mPASS[0m in 0.05s]
[0m12:17:13.872448 [debug] [Thread-1 (]: Finished running node test.movie_warehouse.unique_dim_genre_genre_id.757304f7bc
[0m12:17:13.872684 [debug] [Thread-1 (]: Began running node test.movie_warehouse.unique_dim_movie_movie_id.42054933eb
[0m12:17:13.872921 [info ] [Thread-1 (]: 9 of 12 START test unique_dim_movie_movie_id ................................... [RUN]
[0m12:17:13.873157 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.movie_warehouse.unique_dim_genre_genre_id.757304f7bc, now test.movie_warehouse.unique_dim_movie_movie_id.42054933eb)
[0m12:17:13.873334 [debug] [Thread-1 (]: Began compiling node test.movie_warehouse.unique_dim_movie_movie_id.42054933eb
[0m12:17:13.875043 [debug] [Thread-1 (]: Writing injected SQL for node "test.movie_warehouse.unique_dim_movie_movie_id.42054933eb"
[0m12:17:13.875506 [debug] [Thread-1 (]: Began executing node test.movie_warehouse.unique_dim_movie_movie_id.42054933eb
[0m12:17:13.876496 [debug] [Thread-1 (]: Writing runtime sql for node "test.movie_warehouse.unique_dim_movie_movie_id.42054933eb"
[0m12:17:13.876922 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.movie_warehouse.unique_dim_movie_movie_id.42054933eb: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "test.movie_warehouse.unique_dim_movie_movie_id.42054933eb"} */

    
    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    movie_id as unique_field,
    count(*) as n_records

from `gold_gold`.`dim_movie`
where movie_id is not null
group by movie_id
having count(*) > 1



  
  
    ) dbt_internal_test...
[0m12:17:13.901625 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m12:17:13.902608 [info ] [Thread-1 (]: 9 of 12 PASS unique_dim_movie_movie_id ......................................... [[32mPASS[0m in 0.03s]
[0m12:17:13.902932 [debug] [Thread-1 (]: Finished running node test.movie_warehouse.unique_dim_movie_movie_id.42054933eb
[0m12:17:13.903157 [debug] [Thread-1 (]: Began running node test.movie_warehouse.unique_dim_production_production_id.b674858001
[0m12:17:13.903384 [info ] [Thread-1 (]: 10 of 12 START test unique_dim_production_production_id ........................ [RUN]
[0m12:17:13.903632 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.movie_warehouse.unique_dim_movie_movie_id.42054933eb, now test.movie_warehouse.unique_dim_production_production_id.b674858001)
[0m12:17:13.903813 [debug] [Thread-1 (]: Began compiling node test.movie_warehouse.unique_dim_production_production_id.b674858001
[0m12:17:13.905589 [debug] [Thread-1 (]: Writing injected SQL for node "test.movie_warehouse.unique_dim_production_production_id.b674858001"
[0m12:17:13.906058 [debug] [Thread-1 (]: Began executing node test.movie_warehouse.unique_dim_production_production_id.b674858001
[0m12:17:13.907063 [debug] [Thread-1 (]: Writing runtime sql for node "test.movie_warehouse.unique_dim_production_production_id.b674858001"
[0m12:17:13.907493 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.movie_warehouse.unique_dim_production_production_id.b674858001: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "test.movie_warehouse.unique_dim_production_production_id.b674858001"} */

    
    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    production_id as unique_field,
    count(*) as n_records

from `gold_gold`.`dim_production`
where production_id is not null
group by production_id
having count(*) > 1



  
  
    ) dbt_internal_test...
[0m12:17:13.910325 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:17:13.911094 [info ] [Thread-1 (]: 10 of 12 PASS unique_dim_production_production_id .............................. [[32mPASS[0m in 0.01s]
[0m12:17:13.911393 [debug] [Thread-1 (]: Finished running node test.movie_warehouse.unique_dim_production_production_id.b674858001
[0m12:17:13.911595 [debug] [Thread-1 (]: Began running node test.movie_warehouse.unique_dim_release_date_date_id.fdf0ed82bf
[0m12:17:13.911846 [info ] [Thread-1 (]: 11 of 12 START test unique_dim_release_date_date_id ............................ [RUN]
[0m12:17:13.912137 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.movie_warehouse.unique_dim_production_production_id.b674858001, now test.movie_warehouse.unique_dim_release_date_date_id.fdf0ed82bf)
[0m12:17:13.912383 [debug] [Thread-1 (]: Began compiling node test.movie_warehouse.unique_dim_release_date_date_id.fdf0ed82bf
[0m12:17:13.914224 [debug] [Thread-1 (]: Writing injected SQL for node "test.movie_warehouse.unique_dim_release_date_date_id.fdf0ed82bf"
[0m12:17:13.914769 [debug] [Thread-1 (]: Began executing node test.movie_warehouse.unique_dim_release_date_date_id.fdf0ed82bf
[0m12:17:13.915725 [debug] [Thread-1 (]: Writing runtime sql for node "test.movie_warehouse.unique_dim_release_date_date_id.fdf0ed82bf"
[0m12:17:13.916120 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.movie_warehouse.unique_dim_release_date_date_id.fdf0ed82bf: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "test.movie_warehouse.unique_dim_release_date_date_id.fdf0ed82bf"} */

    
    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    date_id as unique_field,
    count(*) as n_records

from `gold_gold`.`dim_release_date`
where date_id is not null
group by date_id
having count(*) > 1



  
  
    ) dbt_internal_test...
[0m12:17:13.927597 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m12:17:13.928629 [info ] [Thread-1 (]: 11 of 12 PASS unique_dim_release_date_date_id .................................. [[32mPASS[0m in 0.02s]
[0m12:17:13.928923 [debug] [Thread-1 (]: Finished running node test.movie_warehouse.unique_dim_release_date_date_id.fdf0ed82bf
[0m12:17:13.929127 [debug] [Thread-1 (]: Began running node test.movie_warehouse.unique_fact_movie_fact_id.fbd4f040d2
[0m12:17:13.929327 [info ] [Thread-1 (]: 12 of 12 START test unique_fact_movie_fact_id .................................. [RUN]
[0m12:17:13.929582 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.movie_warehouse.unique_dim_release_date_date_id.fdf0ed82bf, now test.movie_warehouse.unique_fact_movie_fact_id.fbd4f040d2)
[0m12:17:13.929776 [debug] [Thread-1 (]: Began compiling node test.movie_warehouse.unique_fact_movie_fact_id.fbd4f040d2
[0m12:17:13.931518 [debug] [Thread-1 (]: Writing injected SQL for node "test.movie_warehouse.unique_fact_movie_fact_id.fbd4f040d2"
[0m12:17:13.931961 [debug] [Thread-1 (]: Began executing node test.movie_warehouse.unique_fact_movie_fact_id.fbd4f040d2
[0m12:17:13.932952 [debug] [Thread-1 (]: Writing runtime sql for node "test.movie_warehouse.unique_fact_movie_fact_id.fbd4f040d2"
[0m12:17:13.933405 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.movie_warehouse.unique_fact_movie_fact_id.fbd4f040d2: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "test.movie_warehouse.unique_fact_movie_fact_id.fbd4f040d2"} */

    
    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    fact_id as unique_field,
    count(*) as n_records

from `gold_gold`.`fact_movie`
where fact_id is not null
group by fact_id
having count(*) > 1



  
  
    ) dbt_internal_test...
[0m12:17:14.175561 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.24 seconds
[0m12:17:14.176901 [info ] [Thread-1 (]: 12 of 12 PASS unique_fact_movie_fact_id ........................................ [[32mPASS[0m in 0.25s]
[0m12:17:14.177252 [debug] [Thread-1 (]: Finished running node test.movie_warehouse.unique_fact_movie_fact_id.fbd4f040d2
[0m12:17:14.178245 [debug] [MainThread]: Connection 'master' was properly closed.
[0m12:17:14.178451 [debug] [MainThread]: Connection 'test.movie_warehouse.unique_fact_movie_fact_id.fbd4f040d2' was left open.
[0m12:17:14.178631 [debug] [MainThread]: On test.movie_warehouse.unique_fact_movie_fact_id.fbd4f040d2: Close
[0m12:17:14.178874 [info ] [MainThread]: 
[0m12:17:14.179096 [info ] [MainThread]: Finished running 12 data tests in 0 hours 0 minutes and 0.82 seconds (0.82s).
[0m12:17:14.179873 [debug] [MainThread]: Command end result
[0m12:17:14.200698 [info ] [MainThread]: 
[0m12:17:14.200958 [info ] [MainThread]: [32mCompleted successfully[0m
[0m12:17:14.201163 [info ] [MainThread]: 
[0m12:17:14.201366 [info ] [MainThread]: Done. PASS=12 WARN=0 ERROR=0 SKIP=0 TOTAL=12
[0m12:17:14.201947 [debug] [MainThread]: Resource report: {"command_name": "test", "command_success": true, "command_wall_clock_time": 1.2025244, "process_in_blocks": "63824", "process_kernel_time": 0.213712, "process_mem_max_rss": "191308", "process_out_blocks": "2348", "process_user_time": 1.786023}
[0m12:17:14.202250 [debug] [MainThread]: Command `dbt test` succeeded at 12:17:14.202208 after 1.20 seconds
[0m12:17:14.202458 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff93fa1f10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff93fa1e50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff940da110>]}
[0m12:17:14.202658 [debug] [MainThread]: Flushing usage events
[0m12:47:49.367799 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff89b8d5d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff89b8d790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff89b8cc50>]}


============================== 12:47:49.372556 | e1a49bb8-d71d-47a9-ad58-ff593b1840ec ==============================
[0m12:47:49.372556 [info ] [MainThread]: Running with dbt=1.8.9
[0m12:47:49.372996 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/project_root/dbt', 'fail_fast': 'False', 'warn_error': 'None', 'log_path': '/opt/airflow/project_root/dbt/logs', 'version_check': 'True', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run --project-dir /opt/airflow/project_root/dbt --profiles-dir /opt/airflow/project_root/dbt --select gold', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m12:47:49.453582 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'e1a49bb8-d71d-47a9-ad58-ff593b1840ec', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff89e70c10>]}
[0m12:47:49.482142 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'e1a49bb8-d71d-47a9-ad58-ff593b1840ec', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8a5bb490>]}
[0m12:47:49.483105 [info ] [MainThread]: Registered adapter: clickhouse=1.8.9
[0m12:47:49.540287 [debug] [MainThread]: checksum: 132857a23e9d07220246854f7763165174ce9b737cfc7867629ace4294e520b1, vars: {}, profile: , target: , version: 1.8.9
[0m12:47:49.700232 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m12:47:49.701087 [debug] [MainThread]: Partial parsing: updated file: movie_warehouse://models/gold/dim_production.sql
[0m12:47:49.906027 [warn ] [MainThread]: [[33mWARNING[0m]: Deprecated functionality
The `tests` config has been renamed to `data_tests`. Please see
https://docs.getdbt.com/docs/build/data-tests#new-data_tests-syntax for more
information.
[0m12:47:49.906951 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'deprecation', 'label': 'e1a49bb8-d71d-47a9-ad58-ff593b1840ec', 'property_': 'warn', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8970b890>]}
[0m12:47:49.994230 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.movie_warehouse.bronze
[0m12:47:50.000450 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'e1a49bb8-d71d-47a9-ad58-ff593b1840ec', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff896a29d0>]}
[0m12:47:50.126993 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'e1a49bb8-d71d-47a9-ad58-ff593b1840ec', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff89800f90>]}
[0m12:47:50.127423 [info ] [MainThread]: Found 6 models, 12 data tests, 4 sources, 477 macros
[0m12:47:50.127683 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'e1a49bb8-d71d-47a9-ad58-ff593b1840ec', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff89559850>]}
[0m12:47:50.128822 [info ] [MainThread]: 
[0m12:47:50.129277 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m12:47:50.133079 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m12:47:50.138573 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:47:50.435612 [info ] [ThreadPool]: dbt_clickhouse adapter: Unexpected server exception dropping table
[0m12:47:50.436122 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m12:47:50.439383 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:47:50.517396 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__gold_gold)
[0m12:47:50.520886 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__gold_gold: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "connection_name": "list__gold_gold"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'gold_gold'
      

  ...
[0m12:47:50.527415 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m12:47:50.528827 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'e1a49bb8-d71d-47a9-ad58-ff593b1840ec', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff701699d0>]}
[0m12:47:50.529178 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m12:47:50.529390 [info ] [MainThread]: 
[0m12:47:50.534112 [debug] [Thread-1 (]: Began running node model.movie_warehouse.dim_director
[0m12:47:50.534490 [info ] [Thread-1 (]: 1 of 6 START sql table model `gold_gold`.`dim_director` ........................ [RUN]
[0m12:47:50.534876 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list__gold_gold, now model.movie_warehouse.dim_director)
[0m12:47:50.535135 [debug] [Thread-1 (]: Began compiling node model.movie_warehouse.dim_director
[0m12:47:50.539055 [debug] [Thread-1 (]: Writing injected SQL for node "model.movie_warehouse.dim_director"
[0m12:47:50.540155 [debug] [Thread-1 (]: Began executing node model.movie_warehouse.dim_director
[0m12:47:50.549027 [debug] [Thread-1 (]: Creating new relation dim_director
[0m12:47:50.564082 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_director: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_director"} */

            

    
        create table `gold_gold`.`dim_director`
        
  
        
  engine = MergeTree()
        order by (dir_id)
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

WITH first_dir AS (
    SELECT
        tconst,
        TRIM(splitByChar(',', directors)[1]) AS director_id
    FROM `bronze`.`imdb_title_crew_raw`
    WHERE directors IS NOT NULL AND directors != ''
),
deduped AS (
    SELECT DISTINCT director_id
    FROM first_dir
),
joined AS (
    SELECT
        d.director_id AS dir_id,
        n.primaryName AS dir_name
    FROM deduped d
    LEFT JOIN `bronze`.`imdb_name_basics_raw` n
        ON d.director_id = n.nconst
)
SELECT
    cityHash64(dir_id) AS imdb_dir_name_id,  -- Use hash instead of row_number
    dir_id,
    dir_name,
    today() AS valid_from,
    CAST(NULL AS Nullable(Date)) AS valid_to,
    1 AS is_current  -- Use 1/0 instead of TRUE/FALSE
FROM joined
WHERE dir_id IS NOT NULL
ORDER BY dir_id
          )
        
        ...
[0m12:47:50.575162 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m12:47:50.584286 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_director: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_director"} */

    select name, type from system.columns where table = 'dim_director'
    
      and database = 'gold_gold'
    
    order by position
  ...
[0m12:47:50.589475 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:47:50.591654 [debug] [Thread-1 (]: Writing runtime sql for node "model.movie_warehouse.dim_director"
[0m12:47:50.592652 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_director: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_director"} */

  
    
    
    
        
         


        insert into `gold_gold`.`dim_director`
        ("imdb_dir_name_id", "dir_id", "dir_name", "valid_from", "valid_to", "is_current")

WITH first_dir AS (
    SELECT
        tconst,
        TRIM(splitByChar(',', directors)[1]) AS director_id
    FROM `bronze`.`imdb_title_crew_raw`
    WHERE directors IS NOT NULL AND directors != ''
),
deduped AS (
    SELECT DISTINCT director_id
    FROM first_dir
),
joined AS (
    SELECT
        d.director_id AS dir_id,
        n.primaryName AS dir_name
    FROM deduped d
    LEFT JOIN `bronze`.`imdb_name_basics_raw` n
        ON d.director_id = n.nconst
)
SELECT
    cityHash64(dir_id) AS imdb_dir_name_id,  -- Use hash instead of row_number
    dir_id,
    dir_name,
    today() AS valid_from,
    CAST(NULL AS Nullable(Date)) AS valid_to,
    1 AS is_current  -- Use 1/0 instead of TRUE/FALSE
FROM joined
WHERE dir_id IS NOT NULL
ORDER BY dir_id
  ...
[0m12:47:55.622934 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 5.02 seconds
[0m12:47:55.691056 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e1a49bb8-d71d-47a9-ad58-ff593b1840ec', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff49625810>]}
[0m12:47:55.693528 [info ] [Thread-1 (]: 1 of 6 OK created sql table model `gold_gold`.`dim_director` ................... [[32mOK[0m in 5.15s]
[0m12:47:55.694881 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.dim_director
[0m12:47:55.695883 [debug] [Thread-1 (]: Began running node model.movie_warehouse.dim_genre
[0m12:47:55.696997 [info ] [Thread-1 (]: 2 of 6 START sql table model `gold_gold`.`dim_genre` ........................... [RUN]
[0m12:47:55.697598 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.movie_warehouse.dim_director, now model.movie_warehouse.dim_genre)
[0m12:47:55.697928 [debug] [Thread-1 (]: Began compiling node model.movie_warehouse.dim_genre
[0m12:47:55.703165 [debug] [Thread-1 (]: Writing injected SQL for node "model.movie_warehouse.dim_genre"
[0m12:47:55.704514 [debug] [Thread-1 (]: Began executing node model.movie_warehouse.dim_genre
[0m12:47:55.706436 [debug] [Thread-1 (]: Creating new relation dim_genre
[0m12:47:55.707648 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_genre: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_genre"} */

            

    
        create table `gold_gold`.`dim_genre`
        
  
        
  engine = MergeTree()
        order by (genre_id)
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

WITH parsed_genres AS (
    SELECT
        TRIM(splitByChar(',', genres)[1]) AS first_genre
    FROM `bronze`.`tmdb_raw`
    WHERE genres IS NOT NULL AND genres != ''
)
SELECT
    cityHash64(first_genre) AS genre_id,
    first_genre AS genre_name
FROM parsed_genres
GROUP BY first_genre
ORDER BY first_genre
          )
        
        ...
[0m12:47:55.743642 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.04 seconds
[0m12:47:55.746944 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_genre: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_genre"} */

    select name, type from system.columns where table = 'dim_genre'
    
      and database = 'gold_gold'
    
    order by position
  ...
[0m12:47:55.765326 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m12:47:55.768789 [debug] [Thread-1 (]: Writing runtime sql for node "model.movie_warehouse.dim_genre"
[0m12:47:55.772558 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_genre: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_genre"} */

  
    
    
    
        
         


        insert into `gold_gold`.`dim_genre`
        ("genre_id", "genre_name")

WITH parsed_genres AS (
    SELECT
        TRIM(splitByChar(',', genres)[1]) AS first_genre
    FROM `bronze`.`tmdb_raw`
    WHERE genres IS NOT NULL AND genres != ''
)
SELECT
    cityHash64(first_genre) AS genre_id,
    first_genre AS genre_name
FROM parsed_genres
GROUP BY first_genre
ORDER BY first_genre
  ...
[0m12:47:55.843384 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.07 seconds
[0m12:47:55.847300 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e1a49bb8-d71d-47a9-ad58-ff593b1840ec', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff48fef690>]}
[0m12:47:55.850020 [info ] [Thread-1 (]: 2 of 6 OK created sql table model `gold_gold`.`dim_genre` ...................... [[32mOK[0m in 0.15s]
[0m12:47:55.850874 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.dim_genre
[0m12:47:55.851576 [debug] [Thread-1 (]: Began running node model.movie_warehouse.dim_movie
[0m12:47:55.852407 [info ] [Thread-1 (]: 3 of 6 START sql table model `gold_gold`.`dim_movie` ........................... [RUN]
[0m12:47:55.852887 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.movie_warehouse.dim_genre, now model.movie_warehouse.dim_movie)
[0m12:47:55.853243 [debug] [Thread-1 (]: Began compiling node model.movie_warehouse.dim_movie
[0m12:47:55.859970 [debug] [Thread-1 (]: Writing injected SQL for node "model.movie_warehouse.dim_movie"
[0m12:47:55.861400 [debug] [Thread-1 (]: Began executing node model.movie_warehouse.dim_movie
[0m12:47:55.865485 [debug] [Thread-1 (]: Creating new relation dim_movie
[0m12:47:55.866818 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_movie: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_movie"} */

            

    
        create table `gold_gold`.`dim_movie`
        
  
        
  engine = MergeTree()
        order by (movie_id)
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            -- ...existing code...


WITH movie_src AS (
    SELECT
        TRIM(title) AS movie_title,
        imdb_id,
        release_date,
        runtime AS movie_runtime,
        original_language AS language
    FROM `bronze`.`tmdb_raw`
    WHERE title IS NOT NULL AND title != ''
)
SELECT
    cityHash64(movie_title) AS movie_id,
    any(imdb_id) AS imdb_id,
    movie_title,
    any(release_date) AS release_date,
    any(movie_runtime) AS movie_runtime,
    any(language) AS language
FROM movie_src
GROUP BY movie_title
ORDER BY movie_title
          )
        
        ...
[0m12:47:55.887478 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m12:47:55.892637 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_movie: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_movie"} */

    select name, type from system.columns where table = 'dim_movie'
    
      and database = 'gold_gold'
    
    order by position
  ...
[0m12:47:55.903413 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m12:47:55.911434 [debug] [Thread-1 (]: Writing runtime sql for node "model.movie_warehouse.dim_movie"
[0m12:47:55.917026 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_movie: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_movie"} */

  
    
    
    
        
         


        insert into `gold_gold`.`dim_movie`
        ("movie_id", "imdb_id", "movie_title", "release_date", "movie_runtime", "language")-- ...existing code...


WITH movie_src AS (
    SELECT
        TRIM(title) AS movie_title,
        imdb_id,
        release_date,
        runtime AS movie_runtime,
        original_language AS language
    FROM `bronze`.`tmdb_raw`
    WHERE title IS NOT NULL AND title != ''
)
SELECT
    cityHash64(movie_title) AS movie_id,
    any(imdb_id) AS imdb_id,
    movie_title,
    any(release_date) AS release_date,
    any(movie_runtime) AS movie_runtime,
    any(language) AS language
FROM movie_src
GROUP BY movie_title
ORDER BY movie_title
  ...
[0m12:47:56.549151 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.63 seconds
[0m12:47:56.551806 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e1a49bb8-d71d-47a9-ad58-ff593b1840ec', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff897bc490>]}
[0m12:47:56.552352 [info ] [Thread-1 (]: 3 of 6 OK created sql table model `gold_gold`.`dim_movie` ...................... [[32mOK[0m in 0.70s]
[0m12:47:56.552716 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.dim_movie
[0m12:47:56.553124 [debug] [Thread-1 (]: Began running node model.movie_warehouse.dim_production
[0m12:47:56.553633 [info ] [Thread-1 (]: 4 of 6 START sql table model `gold_gold`.`dim_production` ...................... [RUN]
[0m12:47:56.554033 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.movie_warehouse.dim_movie, now model.movie_warehouse.dim_production)
[0m12:47:56.554247 [debug] [Thread-1 (]: Began compiling node model.movie_warehouse.dim_production
[0m12:47:56.558291 [debug] [Thread-1 (]: Writing injected SQL for node "model.movie_warehouse.dim_production"
[0m12:47:56.561221 [debug] [Thread-1 (]: Began executing node model.movie_warehouse.dim_production
[0m12:47:56.563450 [debug] [Thread-1 (]: Creating new relation dim_production
[0m12:47:56.564565 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_production: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_production"} */

            

    
        create table `gold_gold`.`dim_production`
        
  
        
  engine = MergeTree()
        order by (production_id)
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

WITH production_list AS (
    SELECT
        trim(splitByChar(
            ',',
            replaceRegexpAll(production_companies, '\\[|\\]|\"', '')
        )[1]) AS production_name
    FROM `bronze`.`tmdb_raw`
    WHERE production_companies IS NOT NULL AND production_companies != ''
)

SELECT
    cityHash64(production_name) AS production_id,
    production_name,
    current_date() AS valid_from,
    CAST(NULL AS Nullable(Date)) AS valid_to,
    TRUE AS is_current
FROM (
    SELECT DISTINCT production_name
    FROM production_list
)
WHERE production_name IS NOT NULL AND production_name != ''
          )
        
        ...
[0m12:47:56.591669 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.03 seconds
[0m12:47:56.595420 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_production: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_production"} */

    select name, type from system.columns where table = 'dim_production'
    
      and database = 'gold_gold'
    
    order by position
  ...
[0m12:47:56.607810 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m12:47:56.609975 [debug] [Thread-1 (]: Writing runtime sql for node "model.movie_warehouse.dim_production"
[0m12:47:56.611108 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_production: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_production"} */

  
    
    
    
        
         


        insert into `gold_gold`.`dim_production`
        ("production_id", "production_name", "valid_from", "valid_to", "is_current")

WITH production_list AS (
    SELECT
        trim(splitByChar(
            ',',
            replaceRegexpAll(production_companies, '\\[|\\]|\"', '')
        )[1]) AS production_name
    FROM `bronze`.`tmdb_raw`
    WHERE production_companies IS NOT NULL AND production_companies != ''
)

SELECT
    cityHash64(production_name) AS production_id,
    production_name,
    current_date() AS valid_from,
    CAST(NULL AS Nullable(Date)) AS valid_to,
    TRUE AS is_current
FROM (
    SELECT DISTINCT production_name
    FROM production_list
)
WHERE production_name IS NOT NULL AND production_name != ''
  ...
[0m12:47:56.620166 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m12:47:56.622641 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e1a49bb8-d71d-47a9-ad58-ff593b1840ec', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff70196850>]}
[0m12:47:56.623179 [info ] [Thread-1 (]: 4 of 6 OK created sql table model `gold_gold`.`dim_production` ................. [[32mOK[0m in 0.07s]
[0m12:47:56.623615 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.dim_production
[0m12:47:56.623923 [debug] [Thread-1 (]: Began running node model.movie_warehouse.dim_release_date
[0m12:47:56.624395 [info ] [Thread-1 (]: 5 of 6 START sql table model `gold_gold`.`dim_release_date` .................... [RUN]
[0m12:47:56.624955 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.movie_warehouse.dim_production, now model.movie_warehouse.dim_release_date)
[0m12:47:56.625311 [debug] [Thread-1 (]: Began compiling node model.movie_warehouse.dim_release_date
[0m12:47:56.627940 [debug] [Thread-1 (]: Writing injected SQL for node "model.movie_warehouse.dim_release_date"
[0m12:47:56.628650 [debug] [Thread-1 (]: Began executing node model.movie_warehouse.dim_release_date
[0m12:47:56.630147 [debug] [Thread-1 (]: Creating new relation dim_release_date
[0m12:47:56.631038 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_release_date: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_release_date"} */

            

    
        create table `gold_gold`.`dim_release_date`
        
  
        
  engine = MergeTree()
        order by (date_id)
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

WITH distinct_dates AS (
    SELECT DISTINCT release_date
    FROM `bronze`.`tmdb_raw`
    WHERE release_date IS NOT NULL
)

SELECT
    cityHash64(release_date)                                    AS date_id,
    release_date                                                AS full_date,
    toYear(release_date)                                        AS year,
    toMonth(release_date)                                       AS month,
    toDayOfMonth(release_date)                                  AS day,
    toISOWeek(release_date)                                     AS week,
    formatDateTime(release_date, '%a')                          AS weekday,
    CASE
        WHEN toMonth(release_date) IN (12,1,2)  THEN 'Winter'
        WHEN toMonth(release_date) IN (3,4,5)   THEN 'Spring'
        WHEN toMonth(release_date) IN (6,7,8)   THEN 'Summer'
        WHEN toMonth(release_date) IN (9,10,11) THEN 'Autumn'
    END                                                         AS season,
    CASE
        WHEN formatDateTime(release_date, '%a') IN ('Saturday','Sunday') THEN 1
        ELSE 0
    END                                                         AS is_weekend,

    /* ---------- holiday tagging ---------- */
    CASE
        WHEN toMonth(release_date)=1  AND toDayOfMonth(release_date)=1  THEN 'New Years Day'
        WHEN toMonth(release_date)=2  AND toDayOfMonth(release_date)=14 THEN 'Valentines Day'
        WHEN toMonth(release_date)=3  AND toDayOfMonth(release_date)=17 THEN 'St. Patricks Day'
        WHEN toMonth(release_date)=4  AND toDayOfMonth(release_date)=1  THEN 'April Fools Day'
        WHEN toMonth(release_date)=4  AND toDayOfMonth(release_date)=22 THEN 'Earth Day'
        WHEN toMonth(release_date)=5  AND toDayOfMonth(release_date)=1  THEN 'May Day'
        WHEN toMonth(release_date)=5  AND toDayOfMonth(release_date)=5  THEN 'Cinco de Mayo'
        WHEN toMonth(release_date)=6  AND toDayOfMonth(release_date) BETWEEN 19 AND 26 THEN 'Midsummer'
        WHEN toMonth(release_date)=7  AND toDayOfMonth(release_date)=4  THEN 'Independence Day'
        WHEN toMonth(release_date)=9  AND toDayOfMonth(release_date) BETWEEN 1 AND 7 
             AND formatDateTime(release_date,'%a')='Monday'             THEN 'Labor Day (US)'
        WHEN toMonth(release_date)=10 AND toDayOfMonth(release_date)=31 THEN 'Halloween'
        WHEN toMonth(release_date)=11 AND formatDateTime(release_date,'%a')='Thursday'
             AND toISOWeek(release_date) >= 47                           THEN 'Thanksgiving'
        WHEN toMonth(release_date)=12 AND toDayOfMonth(release_date)=24 THEN 'Christmas Eve'
        WHEN toMonth(release_date)=12 AND toDayOfMonth(release_date)=25 THEN 'Christmas Day'
        WHEN toMonth(release_date)=12 AND toDayOfMonth(release_date)=31 THEN 'New Years Eve'
        ELSE NULL
    END                                                         AS holiday_name,
    IF(holiday_name IS NOT NULL, 1, 0)                          AS is_holiday,

    /* placeholders for later enhancement */
    CAST(NULL AS Nullable(Int32)) AS days_until_holiday,
    CAST(NULL AS Nullable(Int32)) AS days_after_holiday

FROM distinct_dates
ORDER BY release_date
          )
        
        ...
[0m12:47:56.650375 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m12:47:56.653076 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_release_date: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_release_date"} */

    select name, type from system.columns where table = 'dim_release_date'
    
      and database = 'gold_gold'
    
    order by position
  ...
[0m12:47:56.658050 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:47:56.661034 [debug] [Thread-1 (]: Writing runtime sql for node "model.movie_warehouse.dim_release_date"
[0m12:47:56.662622 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_release_date: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_release_date"} */

  
    
    
    
        
         


        insert into `gold_gold`.`dim_release_date`
        ("date_id", "full_date", "year", "month", "day", "week", "weekday", "season", "is_weekend", "holiday_name", "is_holiday", "days_until_holiday", "days_after_holiday")

WITH distinct_dates AS (
    SELECT DISTINCT release_date
    FROM `bronze`.`tmdb_raw`
    WHERE release_date IS NOT NULL
)

SELECT
    cityHash64(release_date)                                    AS date_id,
    release_date                                                AS full_date,
    toYear(release_date)                                        AS year,
    toMonth(release_date)                                       AS month,
    toDayOfMonth(release_date)                                  AS day,
    toISOWeek(release_date)                                     AS week,
    formatDateTime(release_date, '%a')                          AS weekday,
    CASE
        WHEN toMonth(release_date) IN (12,1,2)  THEN 'Winter'
        WHEN toMonth(release_date) IN (3,4,5)   THEN 'Spring'
        WHEN toMonth(release_date) IN (6,7,8)   THEN 'Summer'
        WHEN toMonth(release_date) IN (9,10,11) THEN 'Autumn'
    END                                                         AS season,
    CASE
        WHEN formatDateTime(release_date, '%a') IN ('Saturday','Sunday') THEN 1
        ELSE 0
    END                                                         AS is_weekend,

    /* ---------- holiday tagging ---------- */
    CASE
        WHEN toMonth(release_date)=1  AND toDayOfMonth(release_date)=1  THEN 'New Years Day'
        WHEN toMonth(release_date)=2  AND toDayOfMonth(release_date)=14 THEN 'Valentines Day'
        WHEN toMonth(release_date)=3  AND toDayOfMonth(release_date)=17 THEN 'St. Patricks Day'
        WHEN toMonth(release_date)=4  AND toDayOfMonth(release_date)=1  THEN 'April Fools Day'
        WHEN toMonth(release_date)=4  AND toDayOfMonth(release_date)=22 THEN 'Earth Day'
        WHEN toMonth(release_date)=5  AND toDayOfMonth(release_date)=1  THEN 'May Day'
        WHEN toMonth(release_date)=5  AND toDayOfMonth(release_date)=5  THEN 'Cinco de Mayo'
        WHEN toMonth(release_date)=6  AND toDayOfMonth(release_date) BETWEEN 19 AND 26 THEN 'Midsummer'
        WHEN toMonth(release_date)=7  AND toDayOfMonth(release_date)=4  THEN 'Independence Day'
        WHEN toMonth(release_date)=9  AND toDayOfMonth(release_date) BETWEEN 1 AND 7 
             AND formatDateTime(release_date,'%a')='Monday'             THEN 'Labor Day (US)'
        WHEN toMonth(release_date)=10 AND toDayOfMonth(release_date)=31 THEN 'Halloween'
        WHEN toMonth(release_date)=11 AND formatDateTime(release_date,'%a')='Thursday'
             AND toISOWeek(release_date) >= 47                           THEN 'Thanksgiving'
        WHEN toMonth(release_date)=12 AND toDayOfMonth(release_date)=24 THEN 'Christmas Eve'
        WHEN toMonth(release_date)=12 AND toDayOfMonth(release_date)=25 THEN 'Christmas Day'
        WHEN toMonth(release_date)=12 AND toDayOfMonth(release_date)=31 THEN 'New Years Eve'
        ELSE NULL
    END                                                         AS holiday_name,
    IF(holiday_name IS NOT NULL, 1, 0)                          AS is_holiday,

    /* placeholders for later enhancement */
    CAST(NULL AS Nullable(Int32)) AS days_until_holiday,
    CAST(NULL AS Nullable(Int32)) AS days_after_holiday

FROM distinct_dates
ORDER BY release_date
  ...
[0m12:47:56.732717 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.07 seconds
[0m12:47:56.737439 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e1a49bb8-d71d-47a9-ad58-ff593b1840ec', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff58212310>]}
[0m12:47:56.738505 [info ] [Thread-1 (]: 5 of 6 OK created sql table model `gold_gold`.`dim_release_date` ............... [[32mOK[0m in 0.11s]
[0m12:47:56.739377 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.dim_release_date
[0m12:47:56.742708 [debug] [Thread-1 (]: Began running node model.movie_warehouse.fact_movie
[0m12:47:56.743686 [info ] [Thread-1 (]: 6 of 6 START sql table model `gold_gold`.`fact_movie` .......................... [RUN]
[0m12:47:56.744539 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.movie_warehouse.dim_release_date, now model.movie_warehouse.fact_movie)
[0m12:47:56.745397 [debug] [Thread-1 (]: Began compiling node model.movie_warehouse.fact_movie
[0m12:47:56.755556 [debug] [Thread-1 (]: Writing injected SQL for node "model.movie_warehouse.fact_movie"
[0m12:47:56.758441 [debug] [Thread-1 (]: Began executing node model.movie_warehouse.fact_movie
[0m12:47:56.766411 [debug] [Thread-1 (]: Creating new relation fact_movie
[0m12:47:56.768741 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.fact_movie: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.fact_movie"} */

            

    
        create table `gold_gold`.`fact_movie`
        
  
        
  engine = MergeTree()
        order by (fact_id)
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

WITH filtered_tmdb AS (
    SELECT 
        imdb_id,
        title,
        release_date,
        production_companies,
        budget,
        revenue,
        vote_average,
        vote_count,
        runtime,
        genres,
        original_language,
        (vote_average * log(1 + vote_count)) AS movie_popularity
    FROM `bronze`.`tmdb_raw`
),

-- First genre
first_genre AS (
    SELECT
        imdb_id AS movie_id,
        trim(splitByChar(',', genres)[1]) AS genre_name
    FROM filtered_tmdb
),

-- First director
first_director AS (
    SELECT
        t.imdb_id AS movie_id,
        trim(splitByChar(',', c.directors)[1]) AS director_id
    FROM filtered_tmdb t
    LEFT JOIN `bronze`.`imdb_title_crew_raw` c
        ON t.imdb_id = c.tconst
),

-- Join to dim_production to get production_id
movie_production AS (
    SELECT
        t.imdb_id AS movie_id,
        p.production_id
    FROM filtered_tmdb t
    LEFT JOIN `gold_gold`.`dim_production` p
        ON trim(splitByChar(',', t.production_companies)[1]) = p.production_name
),

-- Map genre_name to dim_genre to get genre_id
movie_genre AS (
    SELECT
        fg.movie_id,
        g.genre_id
    FROM first_genre fg
    LEFT JOIN `gold_gold`.`dim_genre` g
        ON fg.genre_name = g.genre_name
),

base AS (
    SELECT
        t.imdb_id                                 AS movie_id,
        d.director_id,
        mg.genre_id,
        mp.production_id,
        dr.date_id                                AS date_id,
        t.vote_average                            AS vote_avg,
        t.vote_count,
        t.revenue,
        t.budget,
        t.movie_popularity,
        toYear(t.release_date)                    AS release_year
    FROM filtered_tmdb t
    LEFT JOIN movie_genre mg       ON mg.movie_id = t.imdb_id
    LEFT JOIN first_director d     ON d.movie_id = t.imdb_id
    LEFT JOIN movie_production mp  ON mp.movie_id = t.imdb_id
    LEFT JOIN `gold_gold`.`dim_release_date` dr
        ON dr.full_date = t.release_date
),

metrics AS (
    SELECT
        b.*,
        b.revenue - lag(b.revenue, 1) OVER (PARTITION BY b.movie_id ORDER BY b.release_year) AS revenue_growth,
        b.movie_popularity - lag(b.movie_popularity, 1) OVER (PARTITION BY b.movie_id ORDER BY b.release_year) AS popularity_change,
        b.vote_avg - lag(b.vote_avg, 1) OVER (PARTITION BY b.movie_id ORDER BY b.release_year) AS vote_avg_change
    FROM base b
)

SELECT
    row_number() OVER (ORDER BY movie_id, date_id, director_id, genre_id) AS fact_id,
    movie_id,
    director_id,
    genre_id,
    production_id,
    date_id,
    vote_avg,
    vote_count,
    revenue,
    budget,
    movie_popularity,
    revenue_growth,
    popularity_change,
    vote_avg_change
FROM metrics
          )
        
        ...
[0m12:47:56.800085 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.03 seconds
[0m12:47:56.802938 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.fact_movie: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.fact_movie"} */

    select name, type from system.columns where table = 'fact_movie'
    
      and database = 'gold_gold'
    
    order by position
  ...
[0m12:47:56.809248 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m12:47:56.812492 [debug] [Thread-1 (]: Writing runtime sql for node "model.movie_warehouse.fact_movie"
[0m12:47:56.814337 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.fact_movie: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.fact_movie"} */

  
    
    
    
        
         


        insert into `gold_gold`.`fact_movie`
        ("fact_id", "movie_id", "director_id", "genre_id", "production_id", "date_id", "vote_avg", "vote_count", "revenue", "budget", "movie_popularity", "revenue_growth", "popularity_change", "vote_avg_change")

WITH filtered_tmdb AS (
    SELECT 
        imdb_id,
        title,
        release_date,
        production_companies,
        budget,
        revenue,
        vote_average,
        vote_count,
        runtime,
        genres,
        original_language,
        (vote_average * log(1 + vote_count)) AS movie_popularity
    FROM `bronze`.`tmdb_raw`
),

-- First genre
first_genre AS (
    SELECT
        imdb_id AS movie_id,
        trim(splitByChar(',', genres)[1]) AS genre_name
    FROM filtered_tmdb
),

-- First director
first_director AS (
    SELECT
        t.imdb_id AS movie_id,
        trim(splitByChar(',', c.directors)[1]) AS director_id
    FROM filtered_tmdb t
    LEFT JOIN `bronze`.`imdb_title_crew_raw` c
        ON t.imdb_id = c.tconst
),

-- Join to dim_production to get production_id
movie_production AS (
    SELECT
        t.imdb_id AS movie_id,
        p.production_id
    FROM filtered_tmdb t
    LEFT JOIN `gold_gold`.`dim_production` p
        ON trim(splitByChar(',', t.production_companies)[1]) = p.production_name
),

-- Map genre_name to dim_genre to get genre_id
movie_genre AS (
    SELECT
        fg.movie_id,
        g.genre_id
    FROM first_genre fg
    LEFT JOIN `gold_gold`.`dim_genre` g
        ON fg.genre_name = g.genre_name
),

base AS (
    SELECT
        t.imdb_id                                 AS movie_id,
        d.director_id,
        mg.genre_id,
        mp.production_id,
        dr.date_id                                AS date_id,
        t.vote_average                            AS vote_avg,
        t.vote_count,
        t.revenue,
        t.budget,
        t.movie_popularity,
        toYear(t.release_date)                    AS release_year
    FROM filtered_tmdb t
    LEFT JOIN movie_genre mg       ON mg.movie_id = t.imdb_id
    LEFT JOIN first_director d     ON d.movie_id = t.imdb_id
    LEFT JOIN movie_production mp  ON mp.movie_id = t.imdb_id
    LEFT JOIN `gold_gold`.`dim_release_date` dr
        ON dr.full_date = t.release_date
),

metrics AS (
    SELECT
        b.*,
        b.revenue - lag(b.revenue, 1) OVER (PARTITION BY b.movie_id ORDER BY b.release_year) AS revenue_growth,
        b.movie_popularity - lag(b.movie_popularity, 1) OVER (PARTITION BY b.movie_id ORDER BY b.release_year) AS popularity_change,
        b.vote_avg - lag(b.vote_avg, 1) OVER (PARTITION BY b.movie_id ORDER BY b.release_year) AS vote_avg_change
    FROM base b
)

SELECT
    row_number() OVER (ORDER BY movie_id, date_id, director_id, genre_id) AS fact_id,
    movie_id,
    director_id,
    genre_id,
    production_id,
    date_id,
    vote_avg,
    vote_count,
    revenue,
    budget,
    movie_popularity,
    revenue_growth,
    popularity_change,
    vote_avg_change
FROM metrics
  ...
[0m12:48:05.114799 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 8.30 seconds
[0m12:48:05.130939 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e1a49bb8-d71d-47a9-ad58-ff593b1840ec', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff4906bd10>]}
[0m12:48:05.133446 [info ] [Thread-1 (]: 6 of 6 OK created sql table model `gold_gold`.`fact_movie` ..................... [[32mOK[0m in 8.39s]
[0m12:48:05.135592 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.fact_movie
[0m12:48:05.141253 [debug] [MainThread]: Connection 'master' was properly closed.
[0m12:48:05.142045 [debug] [MainThread]: Connection 'model.movie_warehouse.fact_movie' was left open.
[0m12:48:05.142570 [debug] [MainThread]: On model.movie_warehouse.fact_movie: Close
[0m12:48:05.144237 [info ] [MainThread]: 
[0m12:48:05.144832 [info ] [MainThread]: Finished running 6 table models in 0 hours 0 minutes and 15.01 seconds (15.01s).
[0m12:48:05.146784 [debug] [MainThread]: Command end result
[0m12:48:05.231475 [info ] [MainThread]: 
[0m12:48:05.232209 [info ] [MainThread]: [32mCompleted successfully[0m
[0m12:48:05.232648 [info ] [MainThread]: 
[0m12:48:05.233150 [info ] [MainThread]: Done. PASS=6 WARN=0 ERROR=0 SKIP=0 TOTAL=6
[0m12:48:05.237115 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 15.897857, "process_in_blocks": "240", "process_kernel_time": 0.464948, "process_mem_max_rss": "192748", "process_out_blocks": "3488", "process_user_time": 2.880071}
[0m12:48:05.238364 [debug] [MainThread]: Command `dbt run` succeeded at 12:48:05.238234 after 15.90 seconds
[0m12:48:05.239234 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff89bbf5d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff89bbf8d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8e951e50>]}
[0m12:48:05.239733 [debug] [MainThread]: Flushing usage events
[0m12:48:09.686595 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff897ed590>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff89815c90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff897eca10>]}


============================== 12:48:09.697691 | 87c7bee5-456d-4f13-930c-d9fafd0e8368 ==============================
[0m12:48:09.697691 [info ] [MainThread]: Running with dbt=1.8.9
[0m12:48:09.698749 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'debug': 'False', 'log_path': '/opt/airflow/project_root/dbt/logs', 'profiles_dir': '/opt/airflow/project_root/dbt', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'invocation_command': 'dbt test --project-dir /opt/airflow/project_root/dbt --profiles-dir /opt/airflow/project_root/dbt --select gold', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m12:48:10.114079 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '87c7bee5-456d-4f13-930c-d9fafd0e8368', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8984b990>]}
[0m12:48:10.260605 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '87c7bee5-456d-4f13-930c-d9fafd0e8368', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8a21b410>]}
[0m12:48:10.262344 [info ] [MainThread]: Registered adapter: clickhouse=1.8.9
[0m12:48:10.444790 [debug] [MainThread]: checksum: 132857a23e9d07220246854f7763165174ce9b737cfc7867629ace4294e520b1, vars: {}, profile: , target: , version: 1.8.9
[0m12:48:10.734608 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m12:48:10.736396 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m12:48:10.751231 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.movie_warehouse.bronze
[0m12:48:10.828407 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '87c7bee5-456d-4f13-930c-d9fafd0e8368', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff893dfa90>]}
[0m12:48:10.944392 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '87c7bee5-456d-4f13-930c-d9fafd0e8368', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8927dfd0>]}
[0m12:48:10.944849 [info ] [MainThread]: Found 6 models, 12 data tests, 4 sources, 477 macros
[0m12:48:10.945088 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '87c7bee5-456d-4f13-930c-d9fafd0e8368', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff89554410>]}
[0m12:48:10.946412 [info ] [MainThread]: 
[0m12:48:10.946880 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m12:48:10.950327 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list__gold_gold'
[0m12:48:10.957670 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:48:11.251083 [info ] [ThreadPool]: dbt_clickhouse adapter: Unexpected server exception dropping table
[0m12:48:11.252051 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__gold_gold: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "connection_name": "list__gold_gold"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'gold_gold'
      

  ...
[0m12:48:11.263574 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m12:48:11.294672 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '87c7bee5-456d-4f13-930c-d9fafd0e8368', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff89272450>]}
[0m12:48:11.295277 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m12:48:11.295634 [info ] [MainThread]: 
[0m12:48:11.303463 [debug] [Thread-1 (]: Began running node test.movie_warehouse.not_null_dim_genre_genre_id.9bb76b166c
[0m12:48:11.304199 [info ] [Thread-1 (]: 1 of 12 START test not_null_dim_genre_genre_id ................................. [RUN]
[0m12:48:11.304851 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list__gold_gold, now test.movie_warehouse.not_null_dim_genre_genre_id.9bb76b166c)
[0m12:48:11.305575 [debug] [Thread-1 (]: Began compiling node test.movie_warehouse.not_null_dim_genre_genre_id.9bb76b166c
[0m12:48:11.314847 [debug] [Thread-1 (]: Writing injected SQL for node "test.movie_warehouse.not_null_dim_genre_genre_id.9bb76b166c"
[0m12:48:11.316897 [debug] [Thread-1 (]: Began executing node test.movie_warehouse.not_null_dim_genre_genre_id.9bb76b166c
[0m12:48:11.327153 [debug] [Thread-1 (]: Writing runtime sql for node "test.movie_warehouse.not_null_dim_genre_genre_id.9bb76b166c"
[0m12:48:11.328740 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.movie_warehouse.not_null_dim_genre_genre_id.9bb76b166c: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "test.movie_warehouse.not_null_dim_genre_genre_id.9bb76b166c"} */

    
    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select genre_id
from `gold_gold`.`dim_genre`
where genre_id is null



  
  
    ) dbt_internal_test...
[0m12:48:11.335550 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m12:48:11.340266 [info ] [Thread-1 (]: 1 of 12 PASS not_null_dim_genre_genre_id ....................................... [[32mPASS[0m in 0.04s]
[0m12:48:11.340988 [debug] [Thread-1 (]: Finished running node test.movie_warehouse.not_null_dim_genre_genre_id.9bb76b166c
[0m12:48:11.341436 [debug] [Thread-1 (]: Began running node test.movie_warehouse.not_null_dim_movie_movie_id.fd05907b20
[0m12:48:11.342047 [info ] [Thread-1 (]: 2 of 12 START test not_null_dim_movie_movie_id ................................. [RUN]
[0m12:48:11.342554 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.movie_warehouse.not_null_dim_genre_genre_id.9bb76b166c, now test.movie_warehouse.not_null_dim_movie_movie_id.fd05907b20)
[0m12:48:11.342906 [debug] [Thread-1 (]: Began compiling node test.movie_warehouse.not_null_dim_movie_movie_id.fd05907b20
[0m12:48:11.345645 [debug] [Thread-1 (]: Writing injected SQL for node "test.movie_warehouse.not_null_dim_movie_movie_id.fd05907b20"
[0m12:48:11.347191 [debug] [Thread-1 (]: Began executing node test.movie_warehouse.not_null_dim_movie_movie_id.fd05907b20
[0m12:48:11.351212 [debug] [Thread-1 (]: Writing runtime sql for node "test.movie_warehouse.not_null_dim_movie_movie_id.fd05907b20"
[0m12:48:11.353605 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.movie_warehouse.not_null_dim_movie_movie_id.fd05907b20: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "test.movie_warehouse.not_null_dim_movie_movie_id.fd05907b20"} */

    
    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select movie_id
from `gold_gold`.`dim_movie`
where movie_id is null



  
  
    ) dbt_internal_test...
[0m12:48:11.363530 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m12:48:11.365011 [info ] [Thread-1 (]: 2 of 12 PASS not_null_dim_movie_movie_id ....................................... [[32mPASS[0m in 0.02s]
[0m12:48:11.365490 [debug] [Thread-1 (]: Finished running node test.movie_warehouse.not_null_dim_movie_movie_id.fd05907b20
[0m12:48:11.365820 [debug] [Thread-1 (]: Began running node test.movie_warehouse.not_null_dim_production_production_id.7ff384ec2b
[0m12:48:11.366159 [info ] [Thread-1 (]: 3 of 12 START test not_null_dim_production_production_id ....................... [RUN]
[0m12:48:11.366540 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.movie_warehouse.not_null_dim_movie_movie_id.fd05907b20, now test.movie_warehouse.not_null_dim_production_production_id.7ff384ec2b)
[0m12:48:11.366814 [debug] [Thread-1 (]: Began compiling node test.movie_warehouse.not_null_dim_production_production_id.7ff384ec2b
[0m12:48:11.369613 [debug] [Thread-1 (]: Writing injected SQL for node "test.movie_warehouse.not_null_dim_production_production_id.7ff384ec2b"
[0m12:48:11.370267 [debug] [Thread-1 (]: Began executing node test.movie_warehouse.not_null_dim_production_production_id.7ff384ec2b
[0m12:48:11.371467 [debug] [Thread-1 (]: Writing runtime sql for node "test.movie_warehouse.not_null_dim_production_production_id.7ff384ec2b"
[0m12:48:11.372058 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.movie_warehouse.not_null_dim_production_production_id.7ff384ec2b: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "test.movie_warehouse.not_null_dim_production_production_id.7ff384ec2b"} */

    
    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select production_id
from `gold_gold`.`dim_production`
where production_id is null



  
  
    ) dbt_internal_test...
[0m12:48:11.375648 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:48:11.376670 [info ] [Thread-1 (]: 3 of 12 PASS not_null_dim_production_production_id ............................. [[32mPASS[0m in 0.01s]
[0m12:48:11.376989 [debug] [Thread-1 (]: Finished running node test.movie_warehouse.not_null_dim_production_production_id.7ff384ec2b
[0m12:48:11.377247 [debug] [Thread-1 (]: Began running node test.movie_warehouse.not_null_dim_release_date_date_id.f6b8c9c3d5
[0m12:48:11.377500 [info ] [Thread-1 (]: 4 of 12 START test not_null_dim_release_date_date_id ........................... [RUN]
[0m12:48:11.377752 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.movie_warehouse.not_null_dim_production_production_id.7ff384ec2b, now test.movie_warehouse.not_null_dim_release_date_date_id.f6b8c9c3d5)
[0m12:48:11.377956 [debug] [Thread-1 (]: Began compiling node test.movie_warehouse.not_null_dim_release_date_date_id.f6b8c9c3d5
[0m12:48:11.379944 [debug] [Thread-1 (]: Writing injected SQL for node "test.movie_warehouse.not_null_dim_release_date_date_id.f6b8c9c3d5"
[0m12:48:11.380490 [debug] [Thread-1 (]: Began executing node test.movie_warehouse.not_null_dim_release_date_date_id.f6b8c9c3d5
[0m12:48:11.381538 [debug] [Thread-1 (]: Writing runtime sql for node "test.movie_warehouse.not_null_dim_release_date_date_id.f6b8c9c3d5"
[0m12:48:11.382267 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.movie_warehouse.not_null_dim_release_date_date_id.f6b8c9c3d5: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "test.movie_warehouse.not_null_dim_release_date_date_id.f6b8c9c3d5"} */

    
    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select date_id
from `gold_gold`.`dim_release_date`
where date_id is null



  
  
    ) dbt_internal_test...
[0m12:48:11.386453 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:48:11.387434 [info ] [Thread-1 (]: 4 of 12 PASS not_null_dim_release_date_date_id ................................. [[32mPASS[0m in 0.01s]
[0m12:48:11.387739 [debug] [Thread-1 (]: Finished running node test.movie_warehouse.not_null_dim_release_date_date_id.f6b8c9c3d5
[0m12:48:11.387990 [debug] [Thread-1 (]: Began running node test.movie_warehouse.not_null_fact_movie_date_id.ca6e5e8ca0
[0m12:48:11.388235 [info ] [Thread-1 (]: 5 of 12 START test not_null_fact_movie_date_id ................................. [RUN]
[0m12:48:11.388470 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.movie_warehouse.not_null_dim_release_date_date_id.f6b8c9c3d5, now test.movie_warehouse.not_null_fact_movie_date_id.ca6e5e8ca0)
[0m12:48:11.388689 [debug] [Thread-1 (]: Began compiling node test.movie_warehouse.not_null_fact_movie_date_id.ca6e5e8ca0
[0m12:48:11.390766 [debug] [Thread-1 (]: Writing injected SQL for node "test.movie_warehouse.not_null_fact_movie_date_id.ca6e5e8ca0"
[0m12:48:11.391374 [debug] [Thread-1 (]: Began executing node test.movie_warehouse.not_null_fact_movie_date_id.ca6e5e8ca0
[0m12:48:11.392494 [debug] [Thread-1 (]: Writing runtime sql for node "test.movie_warehouse.not_null_fact_movie_date_id.ca6e5e8ca0"
[0m12:48:11.393033 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.movie_warehouse.not_null_fact_movie_date_id.ca6e5e8ca0: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "test.movie_warehouse.not_null_fact_movie_date_id.ca6e5e8ca0"} */

    
    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select date_id
from `gold_gold`.`fact_movie`
where date_id is null



  
  
    ) dbt_internal_test...
[0m12:48:11.397010 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:48:11.398016 [info ] [Thread-1 (]: 5 of 12 PASS not_null_fact_movie_date_id ....................................... [[32mPASS[0m in 0.01s]
[0m12:48:11.398321 [debug] [Thread-1 (]: Finished running node test.movie_warehouse.not_null_fact_movie_date_id.ca6e5e8ca0
[0m12:48:11.398533 [debug] [Thread-1 (]: Began running node test.movie_warehouse.not_null_fact_movie_fact_id.1f53f01729
[0m12:48:11.398748 [info ] [Thread-1 (]: 6 of 12 START test not_null_fact_movie_fact_id ................................. [RUN]
[0m12:48:11.398989 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.movie_warehouse.not_null_fact_movie_date_id.ca6e5e8ca0, now test.movie_warehouse.not_null_fact_movie_fact_id.1f53f01729)
[0m12:48:11.399201 [debug] [Thread-1 (]: Began compiling node test.movie_warehouse.not_null_fact_movie_fact_id.1f53f01729
[0m12:48:11.401084 [debug] [Thread-1 (]: Writing injected SQL for node "test.movie_warehouse.not_null_fact_movie_fact_id.1f53f01729"
[0m12:48:11.401564 [debug] [Thread-1 (]: Began executing node test.movie_warehouse.not_null_fact_movie_fact_id.1f53f01729
[0m12:48:11.402527 [debug] [Thread-1 (]: Writing runtime sql for node "test.movie_warehouse.not_null_fact_movie_fact_id.1f53f01729"
[0m12:48:11.403135 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.movie_warehouse.not_null_fact_movie_fact_id.1f53f01729: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "test.movie_warehouse.not_null_fact_movie_fact_id.1f53f01729"} */

    
    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select fact_id
from `gold_gold`.`fact_movie`
where fact_id is null



  
  
    ) dbt_internal_test...
[0m12:48:11.406698 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:48:11.407642 [info ] [Thread-1 (]: 6 of 12 PASS not_null_fact_movie_fact_id ....................................... [[32mPASS[0m in 0.01s]
[0m12:48:11.407987 [debug] [Thread-1 (]: Finished running node test.movie_warehouse.not_null_fact_movie_fact_id.1f53f01729
[0m12:48:11.408220 [debug] [Thread-1 (]: Began running node test.movie_warehouse.not_null_fact_movie_movie_id.115d5160ae
[0m12:48:11.408442 [info ] [Thread-1 (]: 7 of 12 START test not_null_fact_movie_movie_id ................................ [RUN]
[0m12:48:11.408668 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.movie_warehouse.not_null_fact_movie_fact_id.1f53f01729, now test.movie_warehouse.not_null_fact_movie_movie_id.115d5160ae)
[0m12:48:11.408874 [debug] [Thread-1 (]: Began compiling node test.movie_warehouse.not_null_fact_movie_movie_id.115d5160ae
[0m12:48:11.410835 [debug] [Thread-1 (]: Writing injected SQL for node "test.movie_warehouse.not_null_fact_movie_movie_id.115d5160ae"
[0m12:48:11.411331 [debug] [Thread-1 (]: Began executing node test.movie_warehouse.not_null_fact_movie_movie_id.115d5160ae
[0m12:48:11.412375 [debug] [Thread-1 (]: Writing runtime sql for node "test.movie_warehouse.not_null_fact_movie_movie_id.115d5160ae"
[0m12:48:11.413328 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.movie_warehouse.not_null_fact_movie_movie_id.115d5160ae: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "test.movie_warehouse.not_null_fact_movie_movie_id.115d5160ae"} */

    
    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select movie_id
from `gold_gold`.`fact_movie`
where movie_id is null



  
  
    ) dbt_internal_test...
[0m12:48:11.416846 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:48:11.417882 [info ] [Thread-1 (]: 7 of 12 PASS not_null_fact_movie_movie_id ...................................... [[32mPASS[0m in 0.01s]
[0m12:48:11.418218 [debug] [Thread-1 (]: Finished running node test.movie_warehouse.not_null_fact_movie_movie_id.115d5160ae
[0m12:48:11.418455 [debug] [Thread-1 (]: Began running node test.movie_warehouse.unique_dim_genre_genre_id.757304f7bc
[0m12:48:11.418671 [info ] [Thread-1 (]: 8 of 12 START test unique_dim_genre_genre_id ................................... [RUN]
[0m12:48:11.418894 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.movie_warehouse.not_null_fact_movie_movie_id.115d5160ae, now test.movie_warehouse.unique_dim_genre_genre_id.757304f7bc)
[0m12:48:11.419067 [debug] [Thread-1 (]: Began compiling node test.movie_warehouse.unique_dim_genre_genre_id.757304f7bc
[0m12:48:11.474990 [debug] [Thread-1 (]: Writing injected SQL for node "test.movie_warehouse.unique_dim_genre_genre_id.757304f7bc"
[0m12:48:11.475851 [debug] [Thread-1 (]: Began executing node test.movie_warehouse.unique_dim_genre_genre_id.757304f7bc
[0m12:48:11.476966 [debug] [Thread-1 (]: Writing runtime sql for node "test.movie_warehouse.unique_dim_genre_genre_id.757304f7bc"
[0m12:48:11.477507 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.movie_warehouse.unique_dim_genre_genre_id.757304f7bc: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "test.movie_warehouse.unique_dim_genre_genre_id.757304f7bc"} */

    
    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    genre_id as unique_field,
    count(*) as n_records

from `gold_gold`.`dim_genre`
where genre_id is not null
group by genre_id
having count(*) > 1



  
  
    ) dbt_internal_test...
[0m12:48:11.482603 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:48:11.483584 [info ] [Thread-1 (]: 8 of 12 PASS unique_dim_genre_genre_id ......................................... [[32mPASS[0m in 0.06s]
[0m12:48:11.483889 [debug] [Thread-1 (]: Finished running node test.movie_warehouse.unique_dim_genre_genre_id.757304f7bc
[0m12:48:11.484095 [debug] [Thread-1 (]: Began running node test.movie_warehouse.unique_dim_movie_movie_id.42054933eb
[0m12:48:11.484310 [info ] [Thread-1 (]: 9 of 12 START test unique_dim_movie_movie_id ................................... [RUN]
[0m12:48:11.484521 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.movie_warehouse.unique_dim_genre_genre_id.757304f7bc, now test.movie_warehouse.unique_dim_movie_movie_id.42054933eb)
[0m12:48:11.484686 [debug] [Thread-1 (]: Began compiling node test.movie_warehouse.unique_dim_movie_movie_id.42054933eb
[0m12:48:11.486524 [debug] [Thread-1 (]: Writing injected SQL for node "test.movie_warehouse.unique_dim_movie_movie_id.42054933eb"
[0m12:48:11.487198 [debug] [Thread-1 (]: Began executing node test.movie_warehouse.unique_dim_movie_movie_id.42054933eb
[0m12:48:11.488233 [debug] [Thread-1 (]: Writing runtime sql for node "test.movie_warehouse.unique_dim_movie_movie_id.42054933eb"
[0m12:48:11.488698 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.movie_warehouse.unique_dim_movie_movie_id.42054933eb: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "test.movie_warehouse.unique_dim_movie_movie_id.42054933eb"} */

    
    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    movie_id as unique_field,
    count(*) as n_records

from `gold_gold`.`dim_movie`
where movie_id is not null
group by movie_id
having count(*) > 1



  
  
    ) dbt_internal_test...
[0m12:48:11.522132 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.03 seconds
[0m12:48:11.523579 [info ] [Thread-1 (]: 9 of 12 PASS unique_dim_movie_movie_id ......................................... [[32mPASS[0m in 0.04s]
[0m12:48:11.523999 [debug] [Thread-1 (]: Finished running node test.movie_warehouse.unique_dim_movie_movie_id.42054933eb
[0m12:48:11.524307 [debug] [Thread-1 (]: Began running node test.movie_warehouse.unique_dim_production_production_id.b674858001
[0m12:48:11.524571 [info ] [Thread-1 (]: 10 of 12 START test unique_dim_production_production_id ........................ [RUN]
[0m12:48:11.524848 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.movie_warehouse.unique_dim_movie_movie_id.42054933eb, now test.movie_warehouse.unique_dim_production_production_id.b674858001)
[0m12:48:11.525057 [debug] [Thread-1 (]: Began compiling node test.movie_warehouse.unique_dim_production_production_id.b674858001
[0m12:48:11.527344 [debug] [Thread-1 (]: Writing injected SQL for node "test.movie_warehouse.unique_dim_production_production_id.b674858001"
[0m12:48:11.528195 [debug] [Thread-1 (]: Began executing node test.movie_warehouse.unique_dim_production_production_id.b674858001
[0m12:48:11.529394 [debug] [Thread-1 (]: Writing runtime sql for node "test.movie_warehouse.unique_dim_production_production_id.b674858001"
[0m12:48:11.530123 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.movie_warehouse.unique_dim_production_production_id.b674858001: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "test.movie_warehouse.unique_dim_production_production_id.b674858001"} */

    
    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    production_id as unique_field,
    count(*) as n_records

from `gold_gold`.`dim_production`
where production_id is not null
group by production_id
having count(*) > 1



  
  
    ) dbt_internal_test...
[0m12:48:11.537686 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m12:48:11.539291 [info ] [Thread-1 (]: 10 of 12 PASS unique_dim_production_production_id .............................. [[32mPASS[0m in 0.01s]
[0m12:48:11.539806 [debug] [Thread-1 (]: Finished running node test.movie_warehouse.unique_dim_production_production_id.b674858001
[0m12:48:11.540184 [debug] [Thread-1 (]: Began running node test.movie_warehouse.unique_dim_release_date_date_id.fdf0ed82bf
[0m12:48:11.540617 [info ] [Thread-1 (]: 11 of 12 START test unique_dim_release_date_date_id ............................ [RUN]
[0m12:48:11.541081 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.movie_warehouse.unique_dim_production_production_id.b674858001, now test.movie_warehouse.unique_dim_release_date_date_id.fdf0ed82bf)
[0m12:48:11.541427 [debug] [Thread-1 (]: Began compiling node test.movie_warehouse.unique_dim_release_date_date_id.fdf0ed82bf
[0m12:48:11.544379 [debug] [Thread-1 (]: Writing injected SQL for node "test.movie_warehouse.unique_dim_release_date_date_id.fdf0ed82bf"
[0m12:48:11.545284 [debug] [Thread-1 (]: Began executing node test.movie_warehouse.unique_dim_release_date_date_id.fdf0ed82bf
[0m12:48:11.546623 [debug] [Thread-1 (]: Writing runtime sql for node "test.movie_warehouse.unique_dim_release_date_date_id.fdf0ed82bf"
[0m12:48:11.547273 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.movie_warehouse.unique_dim_release_date_date_id.fdf0ed82bf: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "test.movie_warehouse.unique_dim_release_date_date_id.fdf0ed82bf"} */

    
    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    date_id as unique_field,
    count(*) as n_records

from `gold_gold`.`dim_release_date`
where date_id is not null
group by date_id
having count(*) > 1



  
  
    ) dbt_internal_test...
[0m12:48:11.560016 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m12:48:11.561912 [info ] [Thread-1 (]: 11 of 12 PASS unique_dim_release_date_date_id .................................. [[32mPASS[0m in 0.02s]
[0m12:48:11.562545 [debug] [Thread-1 (]: Finished running node test.movie_warehouse.unique_dim_release_date_date_id.fdf0ed82bf
[0m12:48:11.562931 [debug] [Thread-1 (]: Began running node test.movie_warehouse.unique_fact_movie_fact_id.fbd4f040d2
[0m12:48:11.563239 [info ] [Thread-1 (]: 12 of 12 START test unique_fact_movie_fact_id .................................. [RUN]
[0m12:48:11.563486 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.movie_warehouse.unique_dim_release_date_date_id.fdf0ed82bf, now test.movie_warehouse.unique_fact_movie_fact_id.fbd4f040d2)
[0m12:48:11.563672 [debug] [Thread-1 (]: Began compiling node test.movie_warehouse.unique_fact_movie_fact_id.fbd4f040d2
[0m12:48:11.565608 [debug] [Thread-1 (]: Writing injected SQL for node "test.movie_warehouse.unique_fact_movie_fact_id.fbd4f040d2"
[0m12:48:11.566149 [debug] [Thread-1 (]: Began executing node test.movie_warehouse.unique_fact_movie_fact_id.fbd4f040d2
[0m12:48:11.567116 [debug] [Thread-1 (]: Writing runtime sql for node "test.movie_warehouse.unique_fact_movie_fact_id.fbd4f040d2"
[0m12:48:11.567565 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.movie_warehouse.unique_fact_movie_fact_id.fbd4f040d2: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "test.movie_warehouse.unique_fact_movie_fact_id.fbd4f040d2"} */

    
    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    fact_id as unique_field,
    count(*) as n_records

from `gold_gold`.`fact_movie`
where fact_id is not null
group by fact_id
having count(*) > 1



  
  
    ) dbt_internal_test...
[0m12:48:11.873070 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.31 seconds
[0m12:48:11.875618 [info ] [Thread-1 (]: 12 of 12 PASS unique_fact_movie_fact_id ........................................ [[32mPASS[0m in 0.31s]
[0m12:48:11.876203 [debug] [Thread-1 (]: Finished running node test.movie_warehouse.unique_fact_movie_fact_id.fbd4f040d2
[0m12:48:11.877925 [debug] [MainThread]: Connection 'master' was properly closed.
[0m12:48:11.878217 [debug] [MainThread]: Connection 'test.movie_warehouse.unique_fact_movie_fact_id.fbd4f040d2' was left open.
[0m12:48:11.878520 [debug] [MainThread]: On test.movie_warehouse.unique_fact_movie_fact_id.fbd4f040d2: Close
[0m12:48:11.878960 [info ] [MainThread]: 
[0m12:48:11.879237 [info ] [MainThread]: Finished running 12 data tests in 0 hours 0 minutes and 0.93 seconds (0.93s).
[0m12:48:11.880358 [debug] [MainThread]: Command end result
[0m12:48:11.907330 [info ] [MainThread]: 
[0m12:48:11.907712 [info ] [MainThread]: [32mCompleted successfully[0m
[0m12:48:11.907953 [info ] [MainThread]: 
[0m12:48:11.908211 [info ] [MainThread]: Done. PASS=12 WARN=0 ERROR=0 SKIP=0 TOTAL=12
[0m12:48:11.909470 [debug] [MainThread]: Resource report: {"command_name": "test", "command_success": true, "command_wall_clock_time": 2.3180041, "process_in_blocks": "0", "process_kernel_time": 0.403691, "process_mem_max_rss": "191372", "process_out_blocks": "2348", "process_user_time": 3.143168}
[0m12:48:11.910115 [debug] [MainThread]: Command `dbt test` succeeded at 12:48:11.910001 after 2.32 seconds
[0m12:48:11.910526 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8e6e9e10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8e6e8890>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8e6e9fd0>]}
[0m12:48:11.910853 [debug] [MainThread]: Flushing usage events
