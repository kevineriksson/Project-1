[0m16:34:56.373387 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff7e8e8a50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff7e8e86d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff7e8e8610>]}


============================== 16:34:56.377680 | d143b363-127a-413d-adec-4dbc9c01b45b ==============================
[0m16:34:56.377680 [info ] [MainThread]: Running with dbt=1.8.9
[0m16:34:56.378486 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/home/airflow/.dbt', 'fail_fast': 'False', 'warn_error': 'None', 'log_path': '/opt/airflow/project_root/dbt/logs', 'version_check': 'True', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'introspect': 'True', 'invocation_command': 'dbt clean --project-dir /opt/airflow/project_root/dbt', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m16:34:56.464369 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'd143b363-127a-413d-adec-4dbc9c01b45b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff7e991390>]}
[0m16:34:56.476562 [debug] [MainThread]: Resource report: {"command_name": "clean", "command_success": true, "command_wall_clock_time": 0.12727371, "process_in_blocks": "288", "process_kernel_time": 0.248187, "process_mem_max_rss": "101980", "process_out_blocks": "3", "process_user_time": 0.844653}
[0m16:34:56.476938 [debug] [MainThread]: Command `dbt clean` succeeded at 16:34:56.476883 after 0.13 seconds
[0m16:34:56.477183 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff7ec3d3d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff7e923a10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff7e80b250>]}
[0m16:34:56.477438 [debug] [MainThread]: Flushing usage events
[0m16:35:00.705527 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff7c5b5950>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff7c5a7e90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff7c5eb0d0>]}


============================== 16:35:00.708598 | de1f68e5-9e4a-4f94-90d9-42058c8efb3f ==============================
[0m16:35:00.708598 [info ] [MainThread]: Running with dbt=1.8.9
[0m16:35:00.709067 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'debug': 'False', 'log_path': '/opt/airflow/project_root/dbt/logs', 'version_check': 'True', 'profiles_dir': '/home/airflow/.dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'static_parser': 'True', 'invocation_command': 'dbt deps --project-dir /opt/airflow/project_root/dbt', 'introspect': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m16:35:00.747837 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'de1f68e5-9e4a-4f94-90d9-42058c8efb3f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff7c613310>]}
[0m16:35:00.755929 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m16:35:00.756640 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m16:35:00.757196 [debug] [MainThread]: Resource report: {"command_name": "deps", "command_success": true, "command_wall_clock_time": 0.069538414, "process_in_blocks": "504", "process_kernel_time": 0.138381, "process_mem_max_rss": "102128", "process_out_blocks": "3", "process_user_time": 0.638759}
[0m16:35:00.757532 [debug] [MainThread]: Command `dbt deps` succeeded at 16:35:00.757458 after 0.07 seconds
[0m16:35:00.757788 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff7c5b4510>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff7c5b5cd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff81631d50>]}
[0m16:35:00.758007 [debug] [MainThread]: Flushing usage events
[0m16:35:17.184770 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffab5b0fd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffab5a3290>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffad607090>]}


============================== 16:35:17.188421 | 31e86de9-e025-4cad-912c-40eac4dda1f9 ==============================
[0m16:35:17.188421 [info ] [MainThread]: Running with dbt=1.8.9
[0m16:35:17.188847 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'debug': 'False', 'log_path': '/opt/airflow/project_root/dbt/logs', 'fail_fast': 'False', 'profiles_dir': '/home/airflow/.dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'invocation_command': 'dbt run --project-dir /opt/airflow/project_root/dbt --select gold', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m16:35:17.270316 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '31e86de9-e025-4cad-912c-40eac4dda1f9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffab60f690>]}
[0m16:35:17.294122 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '31e86de9-e025-4cad-912c-40eac4dda1f9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffabfdf090>]}
[0m16:35:17.294692 [info ] [MainThread]: Registered adapter: clickhouse=1.8.9
[0m16:35:17.330079 [debug] [MainThread]: checksum: 132857a23e9d07220246854f7763165174ce9b737cfc7867629ace4294e520b1, vars: {}, profile: , target: , version: 1.8.9
[0m16:35:17.330718 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m16:35:17.331048 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '31e86de9-e025-4cad-912c-40eac4dda1f9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffab47bf10>]}
[0m16:35:17.783605 [warn ] [MainThread]: [[33mWARNING[0m]: Deprecated functionality
The `tests` config has been renamed to `data_tests`. Please see
https://docs.getdbt.com/docs/build/data-tests#new-data_tests-syntax for more
information.
[0m16:35:17.784110 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'deprecation', 'label': '31e86de9-e025-4cad-912c-40eac4dda1f9', 'property_': 'warn', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffab47bbd0>]}
[0m16:35:17.876290 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '31e86de9-e025-4cad-912c-40eac4dda1f9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffab162e10>]}
[0m16:35:17.926348 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '31e86de9-e025-4cad-912c-40eac4dda1f9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffaa9d5e10>]}
[0m16:35:17.926666 [info ] [MainThread]: Found 6 models, 12 data tests, 4 sources, 477 macros
[0m16:35:17.926903 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '31e86de9-e025-4cad-912c-40eac4dda1f9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffaad890d0>]}
[0m16:35:17.927802 [info ] [MainThread]: 
[0m16:35:17.928226 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m16:35:17.931053 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m16:35:17.935719 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:35:18.216663 [info ] [ThreadPool]: dbt_clickhouse adapter: Unexpected server exception dropping table
[0m16:35:18.217053 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m16:35:18.219153 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:35:18.234014 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__gold_gold)
[0m16:35:18.237328 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__gold_gold: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "connection_name": "list__gold_gold"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'gold_gold'
      

  ...
[0m16:35:18.242193 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:35:18.243886 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '31e86de9-e025-4cad-912c-40eac4dda1f9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffab2e4890>]}
[0m16:35:18.244296 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m16:35:18.244672 [info ] [MainThread]: 
[0m16:35:18.252977 [debug] [Thread-1 (]: Began running node model.movie_warehouse.dim_date
[0m16:35:18.253536 [info ] [Thread-1 (]: 1 of 6 START sql table model `gold_gold`.`dim_date` ............................ [RUN]
[0m16:35:18.254123 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list__gold_gold, now model.movie_warehouse.dim_date)
[0m16:35:18.254454 [debug] [Thread-1 (]: Began compiling node model.movie_warehouse.dim_date
[0m16:35:18.259287 [debug] [Thread-1 (]: Writing injected SQL for node "model.movie_warehouse.dim_date"
[0m16:35:18.261034 [debug] [Thread-1 (]: Began executing node model.movie_warehouse.dim_date
[0m16:35:18.283609 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_date: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_date"} */

    drop table if exists `gold_gold`.`dim_date__dbt_backup` 
  ...
[0m16:35:18.286047 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_date"} */

    drop table if exists `gold_gold`.`dim_date__dbt_backup` 
  
[0m16:35:18.286362 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: macro drop_relation
[0m16:35:18.289082 [debug] [Thread-1 (]: Database Error in model dim_date (models/gold/dim_date.sql)
  :HTTPDriver for http://clickhouse-server:8123 returned response code 500)
   std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/d4e/d4e63993-47bf-4aef-b23f-193de2d5c461/dim_date__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/gold_gold.dim_date__dbt_backup.7bb8aee6-d822-474b-b60f-5338e1918023.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build))
[0m16:35:18.289934 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '31e86de9-e025-4cad-912c-40eac4dda1f9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa81c0f10>]}
[0m16:35:18.290348 [error] [Thread-1 (]: 1 of 6 ERROR creating sql table model `gold_gold`.`dim_date` ................... [[31mERROR[0m in 0.04s]
[0m16:35:18.290799 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.dim_date
[0m16:35:18.291142 [debug] [Thread-1 (]: Began running node model.movie_warehouse.dim_director
[0m16:35:18.291832 [info ] [Thread-1 (]: 2 of 6 START sql table model `gold_gold`.`dim_director` ........................ [RUN]
[0m16:35:18.292239 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.movie_warehouse.dim_date, now model.movie_warehouse.dim_director)
[0m16:35:18.292498 [debug] [Thread-1 (]: Began compiling node model.movie_warehouse.dim_director
[0m16:35:18.294329 [debug] [Thread-1 (]: Writing injected SQL for node "model.movie_warehouse.dim_director"
[0m16:35:18.295153 [debug] [Thread-1 (]: Began executing node model.movie_warehouse.dim_director
[0m16:35:18.297389 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_director: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_director"} */

    drop table if exists `gold_gold`.`dim_director__dbt_backup` 
  ...
[0m16:35:18.299631 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_director"} */

    drop table if exists `gold_gold`.`dim_director__dbt_backup` 
  
[0m16:35:18.299920 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: macro drop_relation
[0m16:35:18.301706 [debug] [Thread-1 (]: Database Error in model dim_director (models/gold/dim_director.sql)
  :HTTPDriver for http://clickhouse-server:8123 returned response code 500)
   std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/d4e/d4e63993-47bf-4aef-b23f-193de2d5c461/dim_director__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/gold_gold.dim_director__dbt_backup.ff3ad2c3-e8f6-4b67-ad7e-cb3e6c2800c6.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build))
[0m16:35:18.302028 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '31e86de9-e025-4cad-912c-40eac4dda1f9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffaa9d5510>]}
[0m16:35:18.302391 [error] [Thread-1 (]: 2 of 6 ERROR creating sql table model `gold_gold`.`dim_director` ............... [[31mERROR[0m in 0.01s]
[0m16:35:18.302725 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.dim_director
[0m16:35:18.302988 [debug] [Thread-1 (]: Began running node model.movie_warehouse.dim_genre
[0m16:35:18.303284 [info ] [Thread-1 (]: 3 of 6 START sql table model `gold_gold`.`dim_genre` ........................... [RUN]
[0m16:35:18.303581 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.movie_warehouse.dim_director, now model.movie_warehouse.dim_genre)
[0m16:35:18.303845 [debug] [Thread-1 (]: Began compiling node model.movie_warehouse.dim_genre
[0m16:35:18.305704 [debug] [Thread-1 (]: Writing injected SQL for node "model.movie_warehouse.dim_genre"
[0m16:35:18.306545 [debug] [Thread-1 (]: Began executing node model.movie_warehouse.dim_genre
[0m16:35:18.309843 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_genre: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_genre"} */

    drop table if exists `gold_gold`.`dim_genre__dbt_backup` 
  ...
[0m16:35:18.312210 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_genre"} */

    drop table if exists `gold_gold`.`dim_genre__dbt_backup` 
  
[0m16:35:18.312556 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: macro drop_relation
[0m16:35:18.314368 [debug] [Thread-1 (]: Database Error in model dim_genre (models/gold/dim_genre.sql)
  :HTTPDriver for http://clickhouse-server:8123 returned response code 500)
   std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/d4e/d4e63993-47bf-4aef-b23f-193de2d5c461/dim_genre__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/gold_gold.dim_genre__dbt_backup.b4f34411-0d76-46cf-aad5-326845803a2c.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build))
[0m16:35:18.314705 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '31e86de9-e025-4cad-912c-40eac4dda1f9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffab24b990>]}
[0m16:35:18.315063 [error] [Thread-1 (]: 3 of 6 ERROR creating sql table model `gold_gold`.`dim_genre` .................. [[31mERROR[0m in 0.01s]
[0m16:35:18.315435 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.dim_genre
[0m16:35:18.315805 [debug] [Thread-1 (]: Began running node model.movie_warehouse.dim_movie
[0m16:35:18.316185 [info ] [Thread-1 (]: 4 of 6 START sql table model `gold_gold`.`dim_movie` ........................... [RUN]
[0m16:35:18.316553 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.movie_warehouse.dim_genre, now model.movie_warehouse.dim_movie)
[0m16:35:18.316835 [debug] [Thread-1 (]: Began compiling node model.movie_warehouse.dim_movie
[0m16:35:18.318667 [debug] [Thread-1 (]: Writing injected SQL for node "model.movie_warehouse.dim_movie"
[0m16:35:18.319744 [debug] [Thread-1 (]: Began executing node model.movie_warehouse.dim_movie
[0m16:35:18.322276 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_movie: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_movie"} */

    drop table if exists `gold_gold`.`dim_movie__dbt_backup` 
  ...
[0m16:35:18.324787 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_movie"} */

    drop table if exists `gold_gold`.`dim_movie__dbt_backup` 
  
[0m16:35:18.325067 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: macro drop_relation
[0m16:35:18.326864 [debug] [Thread-1 (]: Database Error in model dim_movie (models/gold/dim_movie.sql)
  :HTTPDriver for http://clickhouse-server:8123 returned response code 500)
   std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/d4e/d4e63993-47bf-4aef-b23f-193de2d5c461/dim_movie__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/gold_gold.dim_movie__dbt_backup.7a08bfc7-bc08-4f37-b9b0-f3fbcc780a4f.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build))
[0m16:35:18.327294 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '31e86de9-e025-4cad-912c-40eac4dda1f9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffab170790>]}
[0m16:35:18.327720 [error] [Thread-1 (]: 4 of 6 ERROR creating sql table model `gold_gold`.`dim_movie` .................. [[31mERROR[0m in 0.01s]
[0m16:35:18.328068 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.dim_movie
[0m16:35:18.328383 [debug] [Thread-1 (]: Began running node model.movie_warehouse.dim_production
[0m16:35:18.328725 [info ] [Thread-1 (]: 5 of 6 START sql table model `gold_gold`.`dim_production` ...................... [RUN]
[0m16:35:18.329070 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.movie_warehouse.dim_movie, now model.movie_warehouse.dim_production)
[0m16:35:18.329301 [debug] [Thread-1 (]: Began compiling node model.movie_warehouse.dim_production
[0m16:35:18.331001 [debug] [Thread-1 (]: Writing injected SQL for node "model.movie_warehouse.dim_production"
[0m16:35:18.331780 [debug] [Thread-1 (]: Began executing node model.movie_warehouse.dim_production
[0m16:35:18.334082 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_production: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_production"} */

    drop table if exists `gold_gold`.`dim_production__dbt_backup` 
  ...
[0m16:35:18.336384 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_production"} */

    drop table if exists `gold_gold`.`dim_production__dbt_backup` 
  
[0m16:35:18.336656 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: macro drop_relation
[0m16:35:18.338485 [debug] [Thread-1 (]: Database Error in model dim_production (models/gold/dim_production.sql)
  :HTTPDriver for http://clickhouse-server:8123 returned response code 500)
   std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/d4e/d4e63993-47bf-4aef-b23f-193de2d5c461/dim_production__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/gold_gold.dim_production__dbt_backup.4a04cf59-0707-478f-beee-8ab8d74e2b03.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build))
[0m16:35:18.338821 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '31e86de9-e025-4cad-912c-40eac4dda1f9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffab063290>]}
[0m16:35:18.339164 [error] [Thread-1 (]: 5 of 6 ERROR creating sql table model `gold_gold`.`dim_production` ............. [[31mERROR[0m in 0.01s]
[0m16:35:18.339545 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.dim_production
[0m16:35:18.340138 [debug] [Thread-1 (]: Began running node model.movie_warehouse.fact_movie
[0m16:35:18.340366 [info ] [Thread-1 (]: 6 of 6 SKIP relation gold_gold.fact_movie ...................................... [[33mSKIP[0m]
[0m16:35:18.340664 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.fact_movie
[0m16:35:18.341417 [debug] [MainThread]: Connection 'master' was properly closed.
[0m16:35:18.341647 [debug] [MainThread]: Connection 'model.movie_warehouse.dim_production' was left open.
[0m16:35:18.341838 [debug] [MainThread]: On model.movie_warehouse.dim_production: Close
[0m16:35:18.342140 [info ] [MainThread]: 
[0m16:35:18.342390 [info ] [MainThread]: Finished running 6 table models in 0 hours 0 minutes and 0.41 seconds (0.41s).
[0m16:35:18.343028 [debug] [MainThread]: Command end result
[0m16:35:18.366215 [info ] [MainThread]: 
[0m16:35:18.366541 [info ] [MainThread]: [31mCompleted with 5 errors and 0 warnings:[0m
[0m16:35:18.366825 [info ] [MainThread]: 
[0m16:35:18.367102 [error] [MainThread]:   Database Error in model dim_date (models/gold/dim_date.sql)
  :HTTPDriver for http://clickhouse-server:8123 returned response code 500)
   std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/d4e/d4e63993-47bf-4aef-b23f-193de2d5c461/dim_date__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/gold_gold.dim_date__dbt_backup.7bb8aee6-d822-474b-b60f-5338e1918023.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build))
[0m16:35:18.367301 [info ] [MainThread]: 
[0m16:35:18.367576 [error] [MainThread]:   Database Error in model dim_director (models/gold/dim_director.sql)
  :HTTPDriver for http://clickhouse-server:8123 returned response code 500)
   std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/d4e/d4e63993-47bf-4aef-b23f-193de2d5c461/dim_director__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/gold_gold.dim_director__dbt_backup.ff3ad2c3-e8f6-4b67-ad7e-cb3e6c2800c6.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build))
[0m16:35:18.367814 [info ] [MainThread]: 
[0m16:35:18.368100 [error] [MainThread]:   Database Error in model dim_genre (models/gold/dim_genre.sql)
  :HTTPDriver for http://clickhouse-server:8123 returned response code 500)
   std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/d4e/d4e63993-47bf-4aef-b23f-193de2d5c461/dim_genre__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/gold_gold.dim_genre__dbt_backup.b4f34411-0d76-46cf-aad5-326845803a2c.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build))
[0m16:35:18.368392 [info ] [MainThread]: 
[0m16:35:18.368694 [error] [MainThread]:   Database Error in model dim_movie (models/gold/dim_movie.sql)
  :HTTPDriver for http://clickhouse-server:8123 returned response code 500)
   std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/d4e/d4e63993-47bf-4aef-b23f-193de2d5c461/dim_movie__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/gold_gold.dim_movie__dbt_backup.7a08bfc7-bc08-4f37-b9b0-f3fbcc780a4f.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build))
[0m16:35:18.368912 [info ] [MainThread]: 
[0m16:35:18.369181 [error] [MainThread]:   Database Error in model dim_production (models/gold/dim_production.sql)
  :HTTPDriver for http://clickhouse-server:8123 returned response code 500)
   std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/d4e/d4e63993-47bf-4aef-b23f-193de2d5c461/dim_production__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/gold_gold.dim_production__dbt_backup.4a04cf59-0707-478f-beee-8ab8d74e2b03.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build))
[0m16:35:18.369430 [info ] [MainThread]: 
[0m16:35:18.369653 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=5 SKIP=1 TOTAL=6
[0m16:35:18.370346 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 1.2040529, "process_in_blocks": "80", "process_kernel_time": 0.312225, "process_mem_max_rss": "193324", "process_out_blocks": "3406", "process_user_time": 2.570558}
[0m16:35:18.370657 [debug] [MainThread]: Command `dbt run` failed at 16:35:18.370610 after 1.20 seconds
[0m16:35:18.370926 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffab60fb10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffab60f650>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb06edb90>]}
[0m16:35:18.371208 [debug] [MainThread]: Flushing usage events
[0m16:40:05.681698 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa2aa7d10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa2a6cb50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa2a67850>]}


============================== 16:40:05.687285 | 24abf910-e44c-4963-a018-f3fcb8d1bc49 ==============================
[0m16:40:05.687285 [info ] [MainThread]: Running with dbt=1.8.9
[0m16:40:05.687815 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'version_check': 'True', 'log_path': '/opt/airflow/project_root/dbt/logs', 'profiles_dir': '/home/airflow/.dbt', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'log_format': 'default', 'invocation_command': 'dbt debug --project-dir /opt/airflow/project_root/dbt', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m16:40:05.692144 [info ] [MainThread]: dbt version: 1.8.9
[0m16:40:05.692523 [info ] [MainThread]: python version: 3.11.8
[0m16:40:05.692758 [info ] [MainThread]: python path: /usr/local/bin/python
[0m16:40:05.692966 [info ] [MainThread]: os info: Linux-6.10.14-linuxkit-aarch64-with-glibc2.36
[0m16:40:05.693183 [info ] [MainThread]: Using profiles dir at /home/airflow/.dbt
[0m16:40:05.693395 [info ] [MainThread]: Using profiles.yml file at /home/airflow/.dbt/profiles.yml
[0m16:40:05.693603 [info ] [MainThread]: Using dbt_project.yml file at /opt/airflow/project_root/dbt/dbt_project.yml
[0m16:40:05.729056 [info ] [MainThread]: Configuration:
[0m16:40:05.732793 [info ] [MainThread]:   profiles.yml file [[31mERROR not found[0m]
[0m16:40:05.734182 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m16:40:05.734472 [info ] [MainThread]: Required dependencies:
[0m16:40:05.734933 [debug] [MainThread]: Executing "git --help"
[0m16:40:05.736821 [info ] [MainThread]:  - git [[31mERROR[0m]

[0m16:40:05.737240 [info ] [MainThread]: Connection test skipped since no profile was found
[0m16:40:05.737615 [info ] [MainThread]: [31m2 checks failed:[0m
[0m16:40:05.738004 [info ] [MainThread]: dbt looked for a profiles.yml file in /home/airflow/.dbt/profiles.yml, but did
not find one. For more information on configuring your profile, consult the
documentation:

https://docs.getdbt.com/docs/configure-your-profile


[0m16:40:05.738279 [info ] [MainThread]: Error from git --help: User does not have permissions for this command: "git"

[0m16:40:05.738962 [debug] [MainThread]: Resource report: {"command_name": "debug", "command_success": false, "command_wall_clock_time": 0.076773085, "process_in_blocks": "1176", "process_kernel_time": 0.097869, "process_mem_max_rss": "102408", "process_out_blocks": "1245", "process_user_time": 0.719038}
[0m16:40:05.739359 [debug] [MainThread]: Command `dbt debug` failed at 16:40:05.739313 after 0.08 seconds
[0m16:40:05.739647 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa2a6e4d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa2c6a990>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa7c0dcd0>]}
[0m16:40:05.740020 [debug] [MainThread]: Flushing usage events
[0m16:40:29.616933 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8e3b42d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8e3a7150>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8e3b4b90>]}


============================== 16:40:29.620244 | 9d1c6a49-d96d-4b11-9b56-4c51cc9c27da ==============================
[0m16:40:29.620244 [info ] [MainThread]: Running with dbt=1.8.9
[0m16:40:29.620591 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'debug': 'False', 'log_path': '/opt/airflow/project_root/dbt/logs', 'profiles_dir': '/home/airflow/.dbt', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'log_format': 'default', 'static_parser': 'True', 'invocation_command': 'dbt debug --project-dir /opt/airflow/project_root/dbt', 'introspect': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m16:40:29.624187 [info ] [MainThread]: dbt version: 1.8.9
[0m16:40:29.624463 [info ] [MainThread]: python version: 3.11.8
[0m16:40:29.624697 [info ] [MainThread]: python path: /usr/local/bin/python
[0m16:40:29.624887 [info ] [MainThread]: os info: Linux-6.10.14-linuxkit-aarch64-with-glibc2.36
[0m16:40:29.625112 [info ] [MainThread]: Using profiles dir at /home/airflow/.dbt
[0m16:40:29.625307 [info ] [MainThread]: Using profiles.yml file at /home/airflow/.dbt/profiles.yml
[0m16:40:29.625473 [info ] [MainThread]: Using dbt_project.yml file at /opt/airflow/project_root/dbt/dbt_project.yml
[0m16:40:29.664378 [info ] [MainThread]: Configuration:
[0m16:40:29.664874 [info ] [MainThread]:   profiles.yml file [[31mERROR not found[0m]
[0m16:40:29.665157 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m16:40:29.665404 [info ] [MainThread]: Required dependencies:
[0m16:40:29.665786 [debug] [MainThread]: Executing "git --help"
[0m16:40:29.666823 [info ] [MainThread]:  - git [[31mERROR[0m]

[0m16:40:29.667481 [info ] [MainThread]: Connection test skipped since no profile was found
[0m16:40:29.667945 [info ] [MainThread]: [31m2 checks failed:[0m
[0m16:40:29.668248 [info ] [MainThread]: dbt looked for a profiles.yml file in /home/airflow/.dbt/profiles.yml, but did
not find one. For more information on configuring your profile, consult the
documentation:

https://docs.getdbt.com/docs/configure-your-profile


[0m16:40:29.668632 [info ] [MainThread]: Error from git --help: User does not have permissions for this command: "git"

[0m16:40:29.669738 [debug] [MainThread]: Resource report: {"command_name": "debug", "command_success": false, "command_wall_clock_time": 0.07018971, "process_in_blocks": "0", "process_kernel_time": 0.176753, "process_mem_max_rss": "102400", "process_out_blocks": "5", "process_user_time": 0.618637}
[0m16:40:29.670297 [debug] [MainThread]: Command `dbt debug` failed at 16:40:29.670245 after 0.07 seconds
[0m16:40:29.670675 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8e416a90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8e3b5f10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8e3f2590>]}
[0m16:40:29.671223 [debug] [MainThread]: Flushing usage events
[0m16:41:15.740978 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb1a666d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb1a65590>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb1a649d0>]}


============================== 16:41:15.744576 | a2169394-9866-48a9-9f38-edae3e6ff20c ==============================
[0m16:41:15.744576 [info ] [MainThread]: Running with dbt=1.8.9
[0m16:41:15.745014 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/project_root/dbt', 'debug': 'False', 'warn_error': 'None', 'log_path': '/opt/airflow/project_root/dbt/logs', 'version_check': 'True', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run --project-dir /opt/airflow/project_root/dbt --profiles-dir /opt/airflow/project_root/dbt --select gold', 'introspect': 'True', 'log_format': 'default', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m16:41:15.816302 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'a2169394-9866-48a9-9f38-edae3e6ff20c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb1a59e50>]}
[0m16:41:15.835567 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'a2169394-9866-48a9-9f38-edae3e6ff20c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb2466f50>]}
[0m16:41:15.836066 [info ] [MainThread]: Registered adapter: clickhouse=1.8.9
[0m16:41:15.867171 [debug] [MainThread]: checksum: 132857a23e9d07220246854f7763165174ce9b737cfc7867629ace4294e520b1, vars: {}, profile: , target: , version: 1.8.9
[0m16:41:15.906066 [info ] [MainThread]: Unable to do partial parsing because profile has changed
[0m16:41:15.906519 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'a2169394-9866-48a9-9f38-edae3e6ff20c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb2e8e3d0>]}
[0m16:41:16.384783 [warn ] [MainThread]: [[33mWARNING[0m]: Deprecated functionality
The `tests` config has been renamed to `data_tests`. Please see
https://docs.getdbt.com/docs/build/data-tests#new-data_tests-syntax for more
information.
[0m16:41:16.385246 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'deprecation', 'label': 'a2169394-9866-48a9-9f38-edae3e6ff20c', 'property_': 'warn', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb1a12810>]}
[0m16:41:16.472364 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'a2169394-9866-48a9-9f38-edae3e6ff20c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb17a7790>]}
[0m16:41:16.533342 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'a2169394-9866-48a9-9f38-edae3e6ff20c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb09cbf10>]}
[0m16:41:16.533691 [info ] [MainThread]: Found 6 models, 12 data tests, 4 sources, 477 macros
[0m16:41:16.533946 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a2169394-9866-48a9-9f38-edae3e6ff20c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb0d7f010>]}
[0m16:41:16.534935 [info ] [MainThread]: 
[0m16:41:16.535336 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m16:41:16.538093 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m16:41:16.542878 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:41:16.784757 [info ] [ThreadPool]: dbt_clickhouse adapter: Unexpected server exception dropping table
[0m16:41:16.785135 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m16:41:16.787153 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:41:16.801628 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now create___gold)
[0m16:41:16.803354 [debug] [ThreadPool]: Creating schema "schema: "_gold"
"
[0m16:41:16.807530 [debug] [ThreadPool]: dbt_clickhouse adapter: On create___gold: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "connection_name": "create___gold"} */
create database if not exists `_gold`
        
  
        
  ...
[0m16:41:16.811403 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:41:16.812831 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create___gold, now list___gold)
[0m16:41:16.815759 [debug] [ThreadPool]: dbt_clickhouse adapter: On list___gold: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "connection_name": "list___gold"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = '_gold'
      

  ...
[0m16:41:16.833370 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m16:41:16.834787 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a2169394-9866-48a9-9f38-edae3e6ff20c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb162df90>]}
[0m16:41:16.835312 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m16:41:16.835623 [info ] [MainThread]: 
[0m16:41:16.840837 [debug] [Thread-1 (]: Began running node model.movie_warehouse.dim_date
[0m16:41:16.841291 [info ] [Thread-1 (]: 1 of 6 START sql table model `_gold`.`dim_date` ................................ [RUN]
[0m16:41:16.841704 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list___gold, now model.movie_warehouse.dim_date)
[0m16:41:16.842012 [debug] [Thread-1 (]: Began compiling node model.movie_warehouse.dim_date
[0m16:41:16.846039 [debug] [Thread-1 (]: Writing injected SQL for node "model.movie_warehouse.dim_date"
[0m16:41:16.846921 [debug] [Thread-1 (]: Began executing node model.movie_warehouse.dim_date
[0m16:41:16.855708 [debug] [Thread-1 (]: Creating new relation dim_date
[0m16:41:16.868132 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_date: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_date"} */

            

    
        create table `_gold`.`dim_date`
        
  
        
  engine = MergeTree()
        order by (date_id)
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

WITH distinct_dates AS (
    SELECT DISTINCT release_date
    FROM `bronze`.`tmdb_raw`
    WHERE release_date IS NOT NULL
)

SELECT
    cityHash64(release_date)                                    AS date_id,
    release_date                                                AS full_date,
    toYear(release_date)                                        AS year,
    toMonth(release_date)                                       AS month,
    toDayOfMonth(release_date)                                  AS day,
    toISOWeek(release_date)                                     AS week,
    formatDateTime(release_date, '%a')                          AS weekday,
    CASE
        WHEN toMonth(release_date) IN (12,1,2)  THEN 'Winter'
        WHEN toMonth(release_date) IN (3,4,5)   THEN 'Spring'
        WHEN toMonth(release_date) IN (6,7,8)   THEN 'Summer'
        WHEN toMonth(release_date) IN (9,10,11) THEN 'Autumn'
    END                                                         AS season,
    CASE
        WHEN formatDateTime(release_date, '%a') IN ('Saturday','Sunday') THEN 1
        ELSE 0
    END                                                         AS is_weekend,

    /* ---------- holiday tagging ---------- */
    CASE
        WHEN toMonth(release_date)=1  AND toDayOfMonth(release_date)=1  THEN 'New Years Day'
        WHEN toMonth(release_date)=2  AND toDayOfMonth(release_date)=14 THEN 'Valentines Day'
        WHEN toMonth(release_date)=3  AND toDayOfMonth(release_date)=17 THEN 'St. Patricks Day'
        WHEN toMonth(release_date)=4  AND toDayOfMonth(release_date)=1  THEN 'April Fools Day'
        WHEN toMonth(release_date)=4  AND toDayOfMonth(release_date)=22 THEN 'Earth Day'
        WHEN toMonth(release_date)=5  AND toDayOfMonth(release_date)=1  THEN 'May Day'
        WHEN toMonth(release_date)=5  AND toDayOfMonth(release_date)=5  THEN 'Cinco de Mayo'
        WHEN toMonth(release_date)=6  AND toDayOfMonth(release_date) BETWEEN 19 AND 26 THEN 'Midsummer'
        WHEN toMonth(release_date)=7  AND toDayOfMonth(release_date)=4  THEN 'Independence Day'
        WHEN toMonth(release_date)=9  AND toDayOfMonth(release_date) BETWEEN 1 AND 7 
             AND formatDateTime(release_date,'%a')='Monday'             THEN 'Labor Day (US)'
        WHEN toMonth(release_date)=10 AND toDayOfMonth(release_date)=31 THEN 'Halloween'
        WHEN toMonth(release_date)=11 AND formatDateTime(release_date,'%a')='Thursday'
             AND toISOWeek(release_date) >= 47                           THEN 'Thanksgiving'
        WHEN toMonth(release_date)=12 AND toDayOfMonth(release_date)=24 THEN 'Christmas Eve'
        WHEN toMonth(release_date)=12 AND toDayOfMonth(release_date)=25 THEN 'Christmas Day'
        WHEN toMonth(release_date)=12 AND toDayOfMonth(release_date)=31 THEN 'New Years Eve'
        ELSE NULL
    END                                                         AS holiday_name,
    IF(holiday_name IS NOT NULL, 1, 0)                          AS is_holiday,

    /* placeholders for later enhancement */
    CAST(NULL AS Nullable(Int32)) AS days_until_holiday,
    CAST(NULL AS Nullable(Int32)) AS days_after_holiday

FROM distinct_dates
ORDER BY release_date
          )
        
        ...
[0m16:41:16.880551 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m16:41:16.887739 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_date: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_date"} */

    select name, type from system.columns where table = 'dim_date'
    
      and database = '_gold'
    
    order by position
  ...
[0m16:41:16.890157 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:41:16.892031 [debug] [Thread-1 (]: Writing runtime sql for node "model.movie_warehouse.dim_date"
[0m16:41:16.893103 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_date: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_date"} */

  
    
    
    
        
         


        insert into `_gold`.`dim_date`
        ("date_id", "full_date", "year", "month", "day", "week", "weekday", "season", "is_weekend", "holiday_name", "is_holiday", "days_until_holiday", "days_after_holiday")

WITH distinct_dates AS (
    SELECT DISTINCT release_date
    FROM `bronze`.`tmdb_raw`
    WHERE release_date IS NOT NULL
)

SELECT
    cityHash64(release_date)                                    AS date_id,
    release_date                                                AS full_date,
    toYear(release_date)                                        AS year,
    toMonth(release_date)                                       AS month,
    toDayOfMonth(release_date)                                  AS day,
    toISOWeek(release_date)                                     AS week,
    formatDateTime(release_date, '%a')                          AS weekday,
    CASE
        WHEN toMonth(release_date) IN (12,1,2)  THEN 'Winter'
        WHEN toMonth(release_date) IN (3,4,5)   THEN 'Spring'
        WHEN toMonth(release_date) IN (6,7,8)   THEN 'Summer'
        WHEN toMonth(release_date) IN (9,10,11) THEN 'Autumn'
    END                                                         AS season,
    CASE
        WHEN formatDateTime(release_date, '%a') IN ('Saturday','Sunday') THEN 1
        ELSE 0
    END                                                         AS is_weekend,

    /* ---------- holiday tagging ---------- */
    CASE
        WHEN toMonth(release_date)=1  AND toDayOfMonth(release_date)=1  THEN 'New Years Day'
        WHEN toMonth(release_date)=2  AND toDayOfMonth(release_date)=14 THEN 'Valentines Day'
        WHEN toMonth(release_date)=3  AND toDayOfMonth(release_date)=17 THEN 'St. Patricks Day'
        WHEN toMonth(release_date)=4  AND toDayOfMonth(release_date)=1  THEN 'April Fools Day'
        WHEN toMonth(release_date)=4  AND toDayOfMonth(release_date)=22 THEN 'Earth Day'
        WHEN toMonth(release_date)=5  AND toDayOfMonth(release_date)=1  THEN 'May Day'
        WHEN toMonth(release_date)=5  AND toDayOfMonth(release_date)=5  THEN 'Cinco de Mayo'
        WHEN toMonth(release_date)=6  AND toDayOfMonth(release_date) BETWEEN 19 AND 26 THEN 'Midsummer'
        WHEN toMonth(release_date)=7  AND toDayOfMonth(release_date)=4  THEN 'Independence Day'
        WHEN toMonth(release_date)=9  AND toDayOfMonth(release_date) BETWEEN 1 AND 7 
             AND formatDateTime(release_date,'%a')='Monday'             THEN 'Labor Day (US)'
        WHEN toMonth(release_date)=10 AND toDayOfMonth(release_date)=31 THEN 'Halloween'
        WHEN toMonth(release_date)=11 AND formatDateTime(release_date,'%a')='Thursday'
             AND toISOWeek(release_date) >= 47                           THEN 'Thanksgiving'
        WHEN toMonth(release_date)=12 AND toDayOfMonth(release_date)=24 THEN 'Christmas Eve'
        WHEN toMonth(release_date)=12 AND toDayOfMonth(release_date)=25 THEN 'Christmas Day'
        WHEN toMonth(release_date)=12 AND toDayOfMonth(release_date)=31 THEN 'New Years Eve'
        ELSE NULL
    END                                                         AS holiday_name,
    IF(holiday_name IS NOT NULL, 1, 0)                          AS is_holiday,

    /* placeholders for later enhancement */
    CAST(NULL AS Nullable(Int32)) AS days_until_holiday,
    CAST(NULL AS Nullable(Int32)) AS days_after_holiday

FROM distinct_dates
ORDER BY release_date
  ...
[0m16:41:16.923420 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.03 seconds
[0m16:41:16.933170 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a2169394-9866-48a9-9f38-edae3e6ff20c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb110a390>]}
[0m16:41:16.933573 [info ] [Thread-1 (]: 1 of 6 OK created sql table model `_gold`.`dim_date` ........................... [[32mOK[0m in 0.09s]
[0m16:41:16.934011 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.dim_date
[0m16:41:16.934352 [debug] [Thread-1 (]: Began running node model.movie_warehouse.dim_director
[0m16:41:16.934677 [info ] [Thread-1 (]: 2 of 6 START sql table model `_gold`.`dim_director` ............................ [RUN]
[0m16:41:16.935009 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.movie_warehouse.dim_date, now model.movie_warehouse.dim_director)
[0m16:41:16.935291 [debug] [Thread-1 (]: Began compiling node model.movie_warehouse.dim_director
[0m16:41:16.936909 [debug] [Thread-1 (]: Writing injected SQL for node "model.movie_warehouse.dim_director"
[0m16:41:16.937589 [debug] [Thread-1 (]: Began executing node model.movie_warehouse.dim_director
[0m16:41:16.938631 [debug] [Thread-1 (]: Creating new relation dim_director
[0m16:41:16.939229 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_director: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_director"} */

            

    
        create table `_gold`.`dim_director`
        
  
        
  engine = MergeTree()
        order by (director_id)
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

WITH first_dir AS (
    SELECT
        tconst,
        TRIM(splitByChar(',', directors)[1]) AS director_id
    FROM `bronze`.`imdb_title_crew_raw`
    WHERE directors IS NOT NULL AND directors != ''
),
deduped AS (
    SELECT DISTINCT director_id
    FROM first_dir
),
joined AS (
    SELECT
        d.director_id,
        n.primaryName AS director_name
    FROM deduped d
    LEFT JOIN `bronze`.`imdb_name_basics_raw` n
        ON d.director_id = n.nconst
)
SELECT
    cityHash64(director_id) AS imdb_dir_name_id,  -- Use hash instead of row_number
    director_id,
    director_name,
    today() AS valid_from,
    CAST(NULL AS Nullable(Date)) AS valid_to,
    1 AS is_current  -- Use 1/0 instead of TRUE/FALSE
FROM joined
WHERE director_id IS NOT NULL
ORDER BY director_id
          )
        
        ...
[0m16:41:16.945644 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m16:41:16.947059 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_director: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_director"} */

    select name, type from system.columns where table = 'dim_director'
    
      and database = '_gold'
    
    order by position
  ...
[0m16:41:16.949229 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:41:16.950062 [debug] [Thread-1 (]: Writing runtime sql for node "model.movie_warehouse.dim_director"
[0m16:41:16.950657 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_director: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_director"} */

  
    
    
    
        
         


        insert into `_gold`.`dim_director`
        ("imdb_dir_name_id", "director_id", "director_name", "valid_from", "valid_to", "is_current")

WITH first_dir AS (
    SELECT
        tconst,
        TRIM(splitByChar(',', directors)[1]) AS director_id
    FROM `bronze`.`imdb_title_crew_raw`
    WHERE directors IS NOT NULL AND directors != ''
),
deduped AS (
    SELECT DISTINCT director_id
    FROM first_dir
),
joined AS (
    SELECT
        d.director_id,
        n.primaryName AS director_name
    FROM deduped d
    LEFT JOIN `bronze`.`imdb_name_basics_raw` n
        ON d.director_id = n.nconst
)
SELECT
    cityHash64(director_id) AS imdb_dir_name_id,  -- Use hash instead of row_number
    director_id,
    director_name,
    today() AS valid_from,
    CAST(NULL AS Nullable(Date)) AS valid_to,
    1 AS is_current  -- Use 1/0 instead of TRUE/FALSE
FROM joined
WHERE director_id IS NOT NULL
ORDER BY director_id
  ...
[0m16:41:18.256236 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 1.30 seconds
[0m16:41:18.261217 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a2169394-9866-48a9-9f38-edae3e6ff20c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb1933410>]}
[0m16:41:18.263942 [info ] [Thread-1 (]: 2 of 6 OK created sql table model `_gold`.`dim_director` ....................... [[32mOK[0m in 1.33s]
[0m16:41:18.264920 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.dim_director
[0m16:41:18.266466 [debug] [Thread-1 (]: Began running node model.movie_warehouse.dim_genre
[0m16:41:18.267063 [info ] [Thread-1 (]: 3 of 6 START sql table model `_gold`.`dim_genre` ............................... [RUN]
[0m16:41:18.267528 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.movie_warehouse.dim_director, now model.movie_warehouse.dim_genre)
[0m16:41:18.267775 [debug] [Thread-1 (]: Began compiling node model.movie_warehouse.dim_genre
[0m16:41:18.271633 [debug] [Thread-1 (]: Writing injected SQL for node "model.movie_warehouse.dim_genre"
[0m16:41:18.272503 [debug] [Thread-1 (]: Began executing node model.movie_warehouse.dim_genre
[0m16:41:18.273951 [debug] [Thread-1 (]: Creating new relation dim_genre
[0m16:41:18.274686 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_genre: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_genre"} */

            

    
        create table `_gold`.`dim_genre`
        
  
        
  engine = MergeTree()
        order by (genre_id)
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

WITH parsed_genres AS (
    SELECT
        TRIM(splitByChar(',', genres)[1]) AS first_genre
    FROM `bronze`.`tmdb_raw`
    WHERE genres IS NOT NULL AND genres != ''
)
SELECT
    cityHash64(first_genre) AS genre_id,
    first_genre AS genre_name
FROM parsed_genres
GROUP BY first_genre
ORDER BY first_genre
          )
        
        ...
[0m16:41:18.285383 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m16:41:18.286927 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_genre: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_genre"} */

    select name, type from system.columns where table = 'dim_genre'
    
      and database = '_gold'
    
    order by position
  ...
[0m16:41:18.289912 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:41:18.290783 [debug] [Thread-1 (]: Writing runtime sql for node "model.movie_warehouse.dim_genre"
[0m16:41:18.291319 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_genre: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_genre"} */

  
    
    
    
        
         


        insert into `_gold`.`dim_genre`
        ("genre_id", "genre_name")

WITH parsed_genres AS (
    SELECT
        TRIM(splitByChar(',', genres)[1]) AS first_genre
    FROM `bronze`.`tmdb_raw`
    WHERE genres IS NOT NULL AND genres != ''
)
SELECT
    cityHash64(first_genre) AS genre_id,
    first_genre AS genre_name
FROM parsed_genres
GROUP BY first_genre
ORDER BY first_genre
  ...
[0m16:41:18.312278 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m16:41:18.313344 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a2169394-9866-48a9-9f38-edae3e6ff20c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff7d1794d0>]}
[0m16:41:18.313697 [info ] [Thread-1 (]: 3 of 6 OK created sql table model `_gold`.`dim_genre` .......................... [[32mOK[0m in 0.05s]
[0m16:41:18.314135 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.dim_genre
[0m16:41:18.314473 [debug] [Thread-1 (]: Began running node model.movie_warehouse.dim_movie
[0m16:41:18.314832 [info ] [Thread-1 (]: 4 of 6 START sql table model `_gold`.`dim_movie` ............................... [RUN]
[0m16:41:18.315151 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.movie_warehouse.dim_genre, now model.movie_warehouse.dim_movie)
[0m16:41:18.315395 [debug] [Thread-1 (]: Began compiling node model.movie_warehouse.dim_movie
[0m16:41:18.317066 [debug] [Thread-1 (]: Writing injected SQL for node "model.movie_warehouse.dim_movie"
[0m16:41:18.317786 [debug] [Thread-1 (]: Began executing node model.movie_warehouse.dim_movie
[0m16:41:18.318813 [debug] [Thread-1 (]: Creating new relation dim_movie
[0m16:41:18.319410 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_movie: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_movie"} */

            

    
        create table `_gold`.`dim_movie`
        
  
        
  engine = MergeTree()
        order by (movie_id)
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

WITH movie_src AS (
    SELECT
        TRIM(title) AS movie_title,
        imdb_id,
        release_date,
        runtime AS movie_runtime,
        original_language AS language
    FROM `bronze`.`tmdb_raw`
    WHERE title IS NOT NULL AND title != ''
)
SELECT
    cityHash64(movie_title) AS movie_id,
    any(imdb_id) AS imdb_id,
    movie_title,
    any(release_date) AS release_date,
    any(movie_runtime) AS movie_runtime,
    any(language) AS language
FROM movie_src
GROUP BY movie_title
ORDER BY movie_title
          )
        
        ...
[0m16:41:18.325659 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m16:41:18.327012 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_movie: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_movie"} */

    select name, type from system.columns where table = 'dim_movie'
    
      and database = '_gold'
    
    order by position
  ...
[0m16:41:18.329220 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:41:18.330153 [debug] [Thread-1 (]: Writing runtime sql for node "model.movie_warehouse.dim_movie"
[0m16:41:18.330709 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_movie: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_movie"} */

  
    
    
    
        
         


        insert into `_gold`.`dim_movie`
        ("movie_id", "imdb_id", "movie_title", "release_date", "movie_runtime", "language")

WITH movie_src AS (
    SELECT
        TRIM(title) AS movie_title,
        imdb_id,
        release_date,
        runtime AS movie_runtime,
        original_language AS language
    FROM `bronze`.`tmdb_raw`
    WHERE title IS NOT NULL AND title != ''
)
SELECT
    cityHash64(movie_title) AS movie_id,
    any(imdb_id) AS imdb_id,
    movie_title,
    any(release_date) AS release_date,
    any(movie_runtime) AS movie_runtime,
    any(language) AS language
FROM movie_src
GROUP BY movie_title
ORDER BY movie_title
  ...
[0m16:41:18.574831 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.24 seconds
[0m16:41:18.576099 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a2169394-9866-48a9-9f38-edae3e6ff20c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb09a08d0>]}
[0m16:41:18.576523 [info ] [Thread-1 (]: 4 of 6 OK created sql table model `_gold`.`dim_movie` .......................... [[32mOK[0m in 0.26s]
[0m16:41:18.576941 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.dim_movie
[0m16:41:18.577329 [debug] [Thread-1 (]: Began running node model.movie_warehouse.dim_production
[0m16:41:18.577682 [info ] [Thread-1 (]: 5 of 6 START sql table model `_gold`.`dim_production` .......................... [RUN]
[0m16:41:18.577980 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.movie_warehouse.dim_movie, now model.movie_warehouse.dim_production)
[0m16:41:18.578239 [debug] [Thread-1 (]: Began compiling node model.movie_warehouse.dim_production
[0m16:41:18.581292 [debug] [Thread-1 (]: Writing injected SQL for node "model.movie_warehouse.dim_production"
[0m16:41:18.582156 [debug] [Thread-1 (]: Began executing node model.movie_warehouse.dim_production
[0m16:41:18.583258 [debug] [Thread-1 (]: Creating new relation dim_production
[0m16:41:18.583874 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_production: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_production"} */

            

    
        create table `_gold`.`dim_production`
        
  
        
  engine = MergeTree()
        order by (production_id)
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

WITH production_list AS (
    SELECT TRIM(splitByChar(',', production_companies)[1]) AS production_name
    FROM `bronze`.`tmdb_raw`
    WHERE production_companies IS NOT NULL AND production_companies != ''
)

SELECT
    cityHash64(production_name) AS production_id,
    production_name,
    current_date() AS valid_from,
    CAST(NULL AS Nullable(Date)) AS valid_to,
    TRUE AS is_current
FROM (
    SELECT DISTINCT production_name
    FROM production_list
)
WHERE production_name IS NOT NULL AND production_name != ''
          )
        
        ...
[0m16:41:18.591106 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m16:41:18.592439 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_production: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_production"} */

    select name, type from system.columns where table = 'dim_production'
    
      and database = '_gold'
    
    order by position
  ...
[0m16:41:18.594859 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:41:18.595810 [debug] [Thread-1 (]: Writing runtime sql for node "model.movie_warehouse.dim_production"
[0m16:41:18.596433 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_production: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_production"} */

  
    
    
    
        
         


        insert into `_gold`.`dim_production`
        ("production_id", "production_name", "valid_from", "valid_to", "is_current")

WITH production_list AS (
    SELECT TRIM(splitByChar(',', production_companies)[1]) AS production_name
    FROM `bronze`.`tmdb_raw`
    WHERE production_companies IS NOT NULL AND production_companies != ''
)

SELECT
    cityHash64(production_name) AS production_id,
    production_name,
    current_date() AS valid_from,
    CAST(NULL AS Nullable(Date)) AS valid_to,
    TRUE AS is_current
FROM (
    SELECT DISTINCT production_name
    FROM production_list
)
WHERE production_name IS NOT NULL AND production_name != ''
  ...
[0m16:41:18.628535 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.03 seconds
[0m16:41:18.629591 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a2169394-9866-48a9-9f38-edae3e6ff20c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff7c7b5210>]}
[0m16:41:18.629988 [info ] [Thread-1 (]: 5 of 6 OK created sql table model `_gold`.`dim_production` ..................... [[32mOK[0m in 0.05s]
[0m16:41:18.630401 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.dim_production
[0m16:41:18.631256 [debug] [Thread-1 (]: Began running node model.movie_warehouse.fact_movie
[0m16:41:18.631545 [info ] [Thread-1 (]: 6 of 6 START sql table model `_gold`.`fact_movie` .............................. [RUN]
[0m16:41:18.631864 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.movie_warehouse.dim_production, now model.movie_warehouse.fact_movie)
[0m16:41:18.632153 [debug] [Thread-1 (]: Began compiling node model.movie_warehouse.fact_movie
[0m16:41:18.634532 [debug] [Thread-1 (]: Writing injected SQL for node "model.movie_warehouse.fact_movie"
[0m16:41:18.635154 [debug] [Thread-1 (]: Began executing node model.movie_warehouse.fact_movie
[0m16:41:18.636255 [debug] [Thread-1 (]: Creating new relation fact_movie
[0m16:41:18.636815 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.fact_movie: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.fact_movie"} */

            

    
        create table `_gold`.`fact_movie`
        
  
        
  engine = MergeTree()
        order by (fact_id)
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

WITH filtered_tmdb AS (
    SELECT 
        imdb_id,
        title,
        release_date,
        production_companies,
        budget,
        revenue,
        vote_average,
        vote_count,
        runtime,
        genres,
        original_language,
        
        (vote_average * log(1 + vote_count)) AS movie_popularity
    FROM `bronze`.`tmdb_raw`
),

-- First genre
first_genre AS (
    SELECT
        imdb_id AS movie_id,
        trim(splitByChar(',', genres)[1]) AS genre_name
    FROM filtered_tmdb
),

-- First director
first_director AS (
    SELECT
        t.imdb_id AS movie_id,
        trim(splitByChar(',', c.directors)[1]) AS director_id
    FROM filtered_tmdb t
    LEFT JOIN `bronze`.`imdb_title_crew_raw` c
        ON t.imdb_id = c.tconst
),

-- Join to dim_production to get production_id
movie_production AS (
    SELECT
        t.imdb_id AS movie_id,
        p.production_id
    FROM filtered_tmdb t
    LEFT JOIN `_gold`.`dim_production` p
        ON trim(splitByChar(',', t.production_companies)[1]) = p.production_name
),

-- Map genre_name to dim_genre to get genre_id
movie_genre AS (
    SELECT
        fg.movie_id,
        g.genre_id
    FROM first_genre fg
    LEFT JOIN `_gold`.`dim_genre` g
        ON fg.genre_name = g.genre_name
),

base AS (
    SELECT
        t.imdb_id                                 AS movie_id,
        d.director_id,
        mg.genre_id,
        mp.production_id,
        dr.date_id                                AS date_id,
        t.vote_average                            AS vote_avg,
        t.vote_count,
        t.revenue,
        t.budget,
        t.movie_popularity,
        toYear(t.release_date)                    AS release_year
    FROM filtered_tmdb t
    LEFT JOIN movie_genre mg       ON mg.movie_id = t.imdb_id
    LEFT JOIN first_director d     ON d.movie_id = t.imdb_id
    LEFT JOIN movie_production mp  ON mp.movie_id = t.imdb_id
    LEFT JOIN `_gold`.`dim_date` dr
        ON dr.full_date = t.release_date
),

metrics AS (
    SELECT
        b.*,
        b.revenue - lag(b.revenue, 1) OVER (PARTITION BY b.movie_id ORDER BY b.release_year) AS revenue_growth,
        b.movie_popularity - lag(b.movie_popularity, 1) OVER (PARTITION BY b.movie_id ORDER BY b.release_year) AS popularity_change,
        b.vote_avg - lag(b.vote_avg, 1) OVER (PARTITION BY b.movie_id ORDER BY b.release_year) AS vote_avg_change
    FROM base b
)

SELECT
    row_number() OVER (ORDER BY movie_id, date_id, director_id, genre_id) AS fact_id,
    movie_id,
    director_id,
    genre_id,
    production_id,
    date_id,
    vote_avg,
    vote_count,
    revenue,
    budget,
    movie_popularity,
    revenue_growth,
    popularity_change,
    vote_avg_change
FROM metrics
          )
        
        ...
[0m16:41:18.650427 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m16:41:18.651914 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.fact_movie: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.fact_movie"} */

    select name, type from system.columns where table = 'fact_movie'
    
      and database = '_gold'
    
    order by position
  ...
[0m16:41:18.654229 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:41:18.655417 [debug] [Thread-1 (]: Writing runtime sql for node "model.movie_warehouse.fact_movie"
[0m16:41:18.656004 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.fact_movie: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.fact_movie"} */

  
    
    
    
        
         


        insert into `_gold`.`fact_movie`
        ("fact_id", "movie_id", "director_id", "genre_id", "production_id", "date_id", "vote_avg", "vote_count", "revenue", "budget", "movie_popularity", "revenue_growth", "popularity_change", "vote_avg_change")

WITH filtered_tmdb AS (
    SELECT 
        imdb_id,
        title,
        release_date,
        production_companies,
        budget,
        revenue,
        vote_average,
        vote_count,
        runtime,
        genres,
        original_language,
        
        (vote_average * log(1 + vote_count)) AS movie_popularity
    FROM `bronze`.`tmdb_raw`
),

-- First genre
first_genre AS (
    SELECT
        imdb_id AS movie_id,
        trim(splitByChar(',', genres)[1]) AS genre_name
    FROM filtered_tmdb
),

-- First director
first_director AS (
    SELECT
        t.imdb_id AS movie_id,
        trim(splitByChar(',', c.directors)[1]) AS director_id
    FROM filtered_tmdb t
    LEFT JOIN `bronze`.`imdb_title_crew_raw` c
        ON t.imdb_id = c.tconst
),

-- Join to dim_production to get production_id
movie_production AS (
    SELECT
        t.imdb_id AS movie_id,
        p.production_id
    FROM filtered_tmdb t
    LEFT JOIN `_gold`.`dim_production` p
        ON trim(splitByChar(',', t.production_companies)[1]) = p.production_name
),

-- Map genre_name to dim_genre to get genre_id
movie_genre AS (
    SELECT
        fg.movie_id,
        g.genre_id
    FROM first_genre fg
    LEFT JOIN `_gold`.`dim_genre` g
        ON fg.genre_name = g.genre_name
),

base AS (
    SELECT
        t.imdb_id                                 AS movie_id,
        d.director_id,
        mg.genre_id,
        mp.production_id,
        dr.date_id                                AS date_id,
        t.vote_average                            AS vote_avg,
        t.vote_count,
        t.revenue,
        t.budget,
        t.movie_popularity,
        toYear(t.release_date)                    AS release_year
    FROM filtered_tmdb t
    LEFT JOIN movie_genre mg       ON mg.movie_id = t.imdb_id
    LEFT JOIN first_director d     ON d.movie_id = t.imdb_id
    LEFT JOIN movie_production mp  ON mp.movie_id = t.imdb_id
    LEFT JOIN `_gold`.`dim_date` dr
        ON dr.full_date = t.release_date
),

metrics AS (
    SELECT
        b.*,
        b.revenue - lag(b.revenue, 1) OVER (PARTITION BY b.movie_id ORDER BY b.release_year) AS revenue_growth,
        b.movie_popularity - lag(b.movie_popularity, 1) OVER (PARTITION BY b.movie_id ORDER BY b.release_year) AS popularity_change,
        b.vote_avg - lag(b.vote_avg, 1) OVER (PARTITION BY b.movie_id ORDER BY b.release_year) AS vote_avg_change
    FROM base b
)

SELECT
    row_number() OVER (ORDER BY movie_id, date_id, director_id, genre_id) AS fact_id,
    movie_id,
    director_id,
    genre_id,
    production_id,
    date_id,
    vote_avg,
    vote_count,
    revenue,
    budget,
    movie_popularity,
    revenue_growth,
    popularity_change,
    vote_avg_change
FROM metrics
  ...
[0m16:41:21.904901 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 3.25 seconds
[0m16:41:21.927327 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a2169394-9866-48a9-9f38-edae3e6ff20c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff7c78f4d0>]}
[0m16:41:21.929234 [info ] [Thread-1 (]: 6 of 6 OK created sql table model `_gold`.`fact_movie` ......................... [[32mOK[0m in 3.28s]
[0m16:41:21.929877 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.fact_movie
[0m16:41:21.933287 [debug] [MainThread]: Connection 'master' was properly closed.
[0m16:41:21.933872 [debug] [MainThread]: Connection 'model.movie_warehouse.fact_movie' was left open.
[0m16:41:21.934142 [debug] [MainThread]: On model.movie_warehouse.fact_movie: Close
[0m16:41:21.935484 [info ] [MainThread]: 
[0m16:41:21.935813 [info ] [MainThread]: Finished running 6 table models in 0 hours 0 minutes and 5.40 seconds (5.40s).
[0m16:41:21.936880 [debug] [MainThread]: Command end result
[0m16:41:21.998256 [info ] [MainThread]: 
[0m16:41:21.999000 [info ] [MainThread]: [32mCompleted successfully[0m
[0m16:41:21.999641 [info ] [MainThread]: 
[0m16:41:22.000304 [info ] [MainThread]: Done. PASS=6 WARN=0 ERROR=0 SKIP=0 TOTAL=6
[0m16:41:22.018318 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 6.295836, "process_in_blocks": "11416", "process_kernel_time": 0.192305, "process_mem_max_rss": "189572", "process_out_blocks": "3473", "process_user_time": 2.554344}
[0m16:41:22.020432 [debug] [MainThread]: Command `dbt run` succeeded at 16:41:22.020309 after 6.30 seconds
[0m16:41:22.022219 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb1ac3850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb1ac3890>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa272dc90>]}
[0m16:41:22.023548 [debug] [MainThread]: Flushing usage events
[0m16:43:59.774047 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffac6855d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffac685010>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffada99290>]}


============================== 16:43:59.781148 | 5b866113-c476-49c3-a407-f4eb5a9b2e58 ==============================
[0m16:43:59.781148 [info ] [MainThread]: Running with dbt=1.8.9
[0m16:43:59.781807 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'version_check': 'True', 'log_path': '/opt/airflow/project_root/dbt/logs', 'profiles_dir': '/opt/airflow/project_root/dbt', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'introspect': 'True', 'invocation_command': 'dbt run --project-dir /opt/airflow/project_root/dbt --profiles-dir /opt/airflow/project_root/dbt --select gold', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m16:43:59.962402 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '5b866113-c476-49c3-a407-f4eb5a9b2e58', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffac67e7d0>]}
[0m16:43:59.984458 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '5b866113-c476-49c3-a407-f4eb5a9b2e58', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffad0bb7d0>]}
[0m16:43:59.985181 [info ] [MainThread]: Registered adapter: clickhouse=1.8.9
[0m16:44:00.028419 [debug] [MainThread]: checksum: 132857a23e9d07220246854f7763165174ce9b737cfc7867629ace4294e520b1, vars: {}, profile: , target: , version: 1.8.9
[0m16:44:00.098173 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m16:44:00.098556 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m16:44:00.119449 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '5b866113-c476-49c3-a407-f4eb5a9b2e58', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffac288550>]}
[0m16:44:00.199771 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '5b866113-c476-49c3-a407-f4eb5a9b2e58', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffac5db910>]}
[0m16:44:00.200318 [info ] [MainThread]: Found 6 models, 12 data tests, 4 sources, 477 macros
[0m16:44:00.200646 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '5b866113-c476-49c3-a407-f4eb5a9b2e58', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffac376bd0>]}
[0m16:44:00.201917 [info ] [MainThread]: 
[0m16:44:00.202414 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m16:44:00.205927 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m16:44:00.212503 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:44:00.578144 [info ] [ThreadPool]: dbt_clickhouse adapter: Unexpected server exception dropping table
[0m16:44:00.578559 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m16:44:00.581449 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:44:00.597440 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list___gold)
[0m16:44:00.600678 [debug] [ThreadPool]: dbt_clickhouse adapter: On list___gold: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "connection_name": "list___gold"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = '_gold'
      

  ...
[0m16:44:00.617303 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m16:44:00.619143 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '5b866113-c476-49c3-a407-f4eb5a9b2e58', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffac747550>]}
[0m16:44:00.619625 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m16:44:00.619984 [info ] [MainThread]: 
[0m16:44:00.625716 [debug] [Thread-1 (]: Began running node model.movie_warehouse.dim_date
[0m16:44:00.626191 [info ] [Thread-1 (]: 1 of 6 START sql table model `_gold`.`dim_date` ................................ [RUN]
[0m16:44:00.626616 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list___gold, now model.movie_warehouse.dim_date)
[0m16:44:00.626922 [debug] [Thread-1 (]: Began compiling node model.movie_warehouse.dim_date
[0m16:44:00.631545 [debug] [Thread-1 (]: Writing injected SQL for node "model.movie_warehouse.dim_date"
[0m16:44:00.633284 [debug] [Thread-1 (]: Began executing node model.movie_warehouse.dim_date
[0m16:44:00.663875 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_date: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_date"} */

            

    
        create table `_gold`.`dim_date__dbt_backup`
        
  
        
  engine = MergeTree()
        order by (date_id)
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

WITH distinct_dates AS (
    SELECT DISTINCT release_date
    FROM `bronze`.`tmdb_raw`
    WHERE release_date IS NOT NULL
)

SELECT
    cityHash64(release_date)                                    AS date_id,
    release_date                                                AS full_date,
    toYear(release_date)                                        AS year,
    toMonth(release_date)                                       AS month,
    toDayOfMonth(release_date)                                  AS day,
    toISOWeek(release_date)                                     AS week,
    formatDateTime(release_date, '%a')                          AS weekday,
    CASE
        WHEN toMonth(release_date) IN (12,1,2)  THEN 'Winter'
        WHEN toMonth(release_date) IN (3,4,5)   THEN 'Spring'
        WHEN toMonth(release_date) IN (6,7,8)   THEN 'Summer'
        WHEN toMonth(release_date) IN (9,10,11) THEN 'Autumn'
    END                                                         AS season,
    CASE
        WHEN formatDateTime(release_date, '%a') IN ('Saturday','Sunday') THEN 1
        ELSE 0
    END                                                         AS is_weekend,

    /* ---------- holiday tagging ---------- */
    CASE
        WHEN toMonth(release_date)=1  AND toDayOfMonth(release_date)=1  THEN 'New Years Day'
        WHEN toMonth(release_date)=2  AND toDayOfMonth(release_date)=14 THEN 'Valentines Day'
        WHEN toMonth(release_date)=3  AND toDayOfMonth(release_date)=17 THEN 'St. Patricks Day'
        WHEN toMonth(release_date)=4  AND toDayOfMonth(release_date)=1  THEN 'April Fools Day'
        WHEN toMonth(release_date)=4  AND toDayOfMonth(release_date)=22 THEN 'Earth Day'
        WHEN toMonth(release_date)=5  AND toDayOfMonth(release_date)=1  THEN 'May Day'
        WHEN toMonth(release_date)=5  AND toDayOfMonth(release_date)=5  THEN 'Cinco de Mayo'
        WHEN toMonth(release_date)=6  AND toDayOfMonth(release_date) BETWEEN 19 AND 26 THEN 'Midsummer'
        WHEN toMonth(release_date)=7  AND toDayOfMonth(release_date)=4  THEN 'Independence Day'
        WHEN toMonth(release_date)=9  AND toDayOfMonth(release_date) BETWEEN 1 AND 7 
             AND formatDateTime(release_date,'%a')='Monday'             THEN 'Labor Day (US)'
        WHEN toMonth(release_date)=10 AND toDayOfMonth(release_date)=31 THEN 'Halloween'
        WHEN toMonth(release_date)=11 AND formatDateTime(release_date,'%a')='Thursday'
             AND toISOWeek(release_date) >= 47                           THEN 'Thanksgiving'
        WHEN toMonth(release_date)=12 AND toDayOfMonth(release_date)=24 THEN 'Christmas Eve'
        WHEN toMonth(release_date)=12 AND toDayOfMonth(release_date)=25 THEN 'Christmas Day'
        WHEN toMonth(release_date)=12 AND toDayOfMonth(release_date)=31 THEN 'New Years Eve'
        ELSE NULL
    END                                                         AS holiday_name,
    IF(holiday_name IS NOT NULL, 1, 0)                          AS is_holiday,

    /* placeholders for later enhancement */
    CAST(NULL AS Nullable(Int32)) AS days_until_holiday,
    CAST(NULL AS Nullable(Int32)) AS days_after_holiday

FROM distinct_dates
ORDER BY release_date
          )
        
        ...
[0m16:44:00.691228 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.03 seconds
[0m16:44:00.701324 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_date: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_date"} */

    select name, type from system.columns where table = 'dim_date__dbt_backup'
    
      and database = '_gold'
    
    order by position
  ...
[0m16:44:00.708149 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m16:44:00.711151 [debug] [Thread-1 (]: Writing runtime sql for node "model.movie_warehouse.dim_date"
[0m16:44:00.712396 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_date: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_date"} */

  
    
    
    
        
         


        insert into `_gold`.`dim_date__dbt_backup`
        ("date_id", "full_date", "year", "month", "day", "week", "weekday", "season", "is_weekend", "holiday_name", "is_holiday", "days_until_holiday", "days_after_holiday")

WITH distinct_dates AS (
    SELECT DISTINCT release_date
    FROM `bronze`.`tmdb_raw`
    WHERE release_date IS NOT NULL
)

SELECT
    cityHash64(release_date)                                    AS date_id,
    release_date                                                AS full_date,
    toYear(release_date)                                        AS year,
    toMonth(release_date)                                       AS month,
    toDayOfMonth(release_date)                                  AS day,
    toISOWeek(release_date)                                     AS week,
    formatDateTime(release_date, '%a')                          AS weekday,
    CASE
        WHEN toMonth(release_date) IN (12,1,2)  THEN 'Winter'
        WHEN toMonth(release_date) IN (3,4,5)   THEN 'Spring'
        WHEN toMonth(release_date) IN (6,7,8)   THEN 'Summer'
        WHEN toMonth(release_date) IN (9,10,11) THEN 'Autumn'
    END                                                         AS season,
    CASE
        WHEN formatDateTime(release_date, '%a') IN ('Saturday','Sunday') THEN 1
        ELSE 0
    END                                                         AS is_weekend,

    /* ---------- holiday tagging ---------- */
    CASE
        WHEN toMonth(release_date)=1  AND toDayOfMonth(release_date)=1  THEN 'New Years Day'
        WHEN toMonth(release_date)=2  AND toDayOfMonth(release_date)=14 THEN 'Valentines Day'
        WHEN toMonth(release_date)=3  AND toDayOfMonth(release_date)=17 THEN 'St. Patricks Day'
        WHEN toMonth(release_date)=4  AND toDayOfMonth(release_date)=1  THEN 'April Fools Day'
        WHEN toMonth(release_date)=4  AND toDayOfMonth(release_date)=22 THEN 'Earth Day'
        WHEN toMonth(release_date)=5  AND toDayOfMonth(release_date)=1  THEN 'May Day'
        WHEN toMonth(release_date)=5  AND toDayOfMonth(release_date)=5  THEN 'Cinco de Mayo'
        WHEN toMonth(release_date)=6  AND toDayOfMonth(release_date) BETWEEN 19 AND 26 THEN 'Midsummer'
        WHEN toMonth(release_date)=7  AND toDayOfMonth(release_date)=4  THEN 'Independence Day'
        WHEN toMonth(release_date)=9  AND toDayOfMonth(release_date) BETWEEN 1 AND 7 
             AND formatDateTime(release_date,'%a')='Monday'             THEN 'Labor Day (US)'
        WHEN toMonth(release_date)=10 AND toDayOfMonth(release_date)=31 THEN 'Halloween'
        WHEN toMonth(release_date)=11 AND formatDateTime(release_date,'%a')='Thursday'
             AND toISOWeek(release_date) >= 47                           THEN 'Thanksgiving'
        WHEN toMonth(release_date)=12 AND toDayOfMonth(release_date)=24 THEN 'Christmas Eve'
        WHEN toMonth(release_date)=12 AND toDayOfMonth(release_date)=25 THEN 'Christmas Day'
        WHEN toMonth(release_date)=12 AND toDayOfMonth(release_date)=31 THEN 'New Years Eve'
        ELSE NULL
    END                                                         AS holiday_name,
    IF(holiday_name IS NOT NULL, 1, 0)                          AS is_holiday,

    /* placeholders for later enhancement */
    CAST(NULL AS Nullable(Int32)) AS days_until_holiday,
    CAST(NULL AS Nullable(Int32)) AS days_after_holiday

FROM distinct_dates
ORDER BY release_date
  ...
[0m16:44:00.758807 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m16:44:00.762408 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_date: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_date"} */
EXCHANGE TABLES `_gold`.`dim_date__dbt_backup` AND `_gold`.`dim_date` 
  
  ...
[0m16:44:00.766678 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:44:00.782615 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_date: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_date"} */

    drop table if exists `_gold`.`dim_date__dbt_backup` 
  ...
[0m16:44:00.785185 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_date"} */

    drop table if exists `_gold`.`dim_date__dbt_backup` 
  
[0m16:44:00.785590 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: macro drop_relation
[0m16:44:00.791172 [debug] [Thread-1 (]: Database Error in model dim_date (models/gold/dim_date.sql)
  :HTTPDriver for http://clickhouse-server:8123 returned response code 500)
   std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/5db/5db6bf74-23a3-44ff-8a65-d72393c86820/dim_date__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/_gold.dim_date__dbt_backup.3ed4ff45-f3b0-4a24-b2bc-b9ef04f8a07b.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build))
  compiled code at target/run/movie_warehouse/models/gold/dim_date.sql
[0m16:44:00.792159 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5b866113-c476-49c3-a407-f4eb5a9b2e58', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff7ec020d0>]}
[0m16:44:00.792605 [error] [Thread-1 (]: 1 of 6 ERROR creating sql table model `_gold`.`dim_date` ....................... [[31mERROR[0m in 0.17s]
[0m16:44:00.793029 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.dim_date
[0m16:44:00.793321 [debug] [Thread-1 (]: Began running node model.movie_warehouse.dim_director
[0m16:44:00.794019 [info ] [Thread-1 (]: 2 of 6 START sql table model `_gold`.`dim_director` ............................ [RUN]
[0m16:44:00.794351 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.movie_warehouse.dim_date, now model.movie_warehouse.dim_director)
[0m16:44:00.794627 [debug] [Thread-1 (]: Began compiling node model.movie_warehouse.dim_director
[0m16:44:00.796970 [debug] [Thread-1 (]: Writing injected SQL for node "model.movie_warehouse.dim_director"
[0m16:44:00.798165 [debug] [Thread-1 (]: Began executing node model.movie_warehouse.dim_director
[0m16:44:00.801404 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_director: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_director"} */

            

    
        create table `_gold`.`dim_director__dbt_backup`
        
  
        
  engine = MergeTree()
        order by (director_id)
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

WITH first_dir AS (
    SELECT
        tconst,
        TRIM(splitByChar(',', directors)[1]) AS director_id
    FROM `bronze`.`imdb_title_crew_raw`
    WHERE directors IS NOT NULL AND directors != ''
),
deduped AS (
    SELECT DISTINCT director_id
    FROM first_dir
),
joined AS (
    SELECT
        d.director_id,
        n.primaryName AS director_name
    FROM deduped d
    LEFT JOIN `bronze`.`imdb_name_basics_raw` n
        ON d.director_id = n.nconst
)
SELECT
    cityHash64(director_id) AS imdb_dir_name_id,  -- Use hash instead of row_number
    director_id,
    director_name,
    today() AS valid_from,
    CAST(NULL AS Nullable(Date)) AS valid_to,
    1 AS is_current  -- Use 1/0 instead of TRUE/FALSE
FROM joined
WHERE director_id IS NOT NULL
ORDER BY director_id
          )
        
        ...
[0m16:44:00.815463 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m16:44:00.817191 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_director: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_director"} */

    select name, type from system.columns where table = 'dim_director__dbt_backup'
    
      and database = '_gold'
    
    order by position
  ...
[0m16:44:00.820666 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:44:00.821992 [debug] [Thread-1 (]: Writing runtime sql for node "model.movie_warehouse.dim_director"
[0m16:44:00.822933 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_director: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_director"} */

  
    
    
    
        
         


        insert into `_gold`.`dim_director__dbt_backup`
        ("imdb_dir_name_id", "director_id", "director_name", "valid_from", "valid_to", "is_current")

WITH first_dir AS (
    SELECT
        tconst,
        TRIM(splitByChar(',', directors)[1]) AS director_id
    FROM `bronze`.`imdb_title_crew_raw`
    WHERE directors IS NOT NULL AND directors != ''
),
deduped AS (
    SELECT DISTINCT director_id
    FROM first_dir
),
joined AS (
    SELECT
        d.director_id,
        n.primaryName AS director_name
    FROM deduped d
    LEFT JOIN `bronze`.`imdb_name_basics_raw` n
        ON d.director_id = n.nconst
)
SELECT
    cityHash64(director_id) AS imdb_dir_name_id,  -- Use hash instead of row_number
    director_id,
    director_name,
    today() AS valid_from,
    CAST(NULL AS Nullable(Date)) AS valid_to,
    1 AS is_current  -- Use 1/0 instead of TRUE/FALSE
FROM joined
WHERE director_id IS NOT NULL
ORDER BY director_id
  ...
[0m16:44:02.123236 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 1.30 seconds
[0m16:44:02.133848 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_director: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_director"} */
EXCHANGE TABLES `_gold`.`dim_director__dbt_backup` AND `_gold`.`dim_director` 
  
  ...
[0m16:44:02.152519 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m16:44:02.159736 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_director: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_director"} */

    drop table if exists `_gold`.`dim_director__dbt_backup` 
  ...
[0m16:44:02.168699 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_director"} */

    drop table if exists `_gold`.`dim_director__dbt_backup` 
  
[0m16:44:02.169798 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: macro drop_relation
[0m16:44:02.174758 [debug] [Thread-1 (]: Database Error in model dim_director (models/gold/dim_director.sql)
  :HTTPDriver for http://clickhouse-server:8123 returned response code 500)
   std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/5db/5db6bf74-23a3-44ff-8a65-d72393c86820/dim_director__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/_gold.dim_director__dbt_backup.f2280a21-2492-41e7-9abb-1bd2bd4ff459.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build))
  compiled code at target/run/movie_warehouse/models/gold/dim_director.sql
[0m16:44:02.175890 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5b866113-c476-49c3-a407-f4eb5a9b2e58', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff7eb47cd0>]}
[0m16:44:02.177905 [error] [Thread-1 (]: 2 of 6 ERROR creating sql table model `_gold`.`dim_director` ................... [[31mERROR[0m in 1.38s]
[0m16:44:02.179181 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.dim_director
[0m16:44:02.180073 [debug] [Thread-1 (]: Began running node model.movie_warehouse.dim_genre
[0m16:44:02.181294 [info ] [Thread-1 (]: 3 of 6 START sql table model `_gold`.`dim_genre` ............................... [RUN]
[0m16:44:02.181790 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.movie_warehouse.dim_director, now model.movie_warehouse.dim_genre)
[0m16:44:02.182105 [debug] [Thread-1 (]: Began compiling node model.movie_warehouse.dim_genre
[0m16:44:02.185697 [debug] [Thread-1 (]: Writing injected SQL for node "model.movie_warehouse.dim_genre"
[0m16:44:02.187407 [debug] [Thread-1 (]: Began executing node model.movie_warehouse.dim_genre
[0m16:44:02.190891 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_genre: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_genre"} */

            

    
        create table `_gold`.`dim_genre__dbt_backup`
        
  
        
  engine = MergeTree()
        order by (genre_id)
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

WITH parsed_genres AS (
    SELECT
        TRIM(splitByChar(',', genres)[1]) AS first_genre
    FROM `bronze`.`tmdb_raw`
    WHERE genres IS NOT NULL AND genres != ''
)
SELECT
    cityHash64(first_genre) AS genre_id,
    first_genre AS genre_name
FROM parsed_genres
GROUP BY first_genre
ORDER BY first_genre
          )
        
        ...
[0m16:44:02.214365 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m16:44:02.218090 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_genre: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_genre"} */

    select name, type from system.columns where table = 'dim_genre__dbt_backup'
    
      and database = '_gold'
    
    order by position
  ...
[0m16:44:02.226535 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m16:44:02.230744 [debug] [Thread-1 (]: Writing runtime sql for node "model.movie_warehouse.dim_genre"
[0m16:44:02.235403 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_genre: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_genre"} */

  
    
    
    
        
         


        insert into `_gold`.`dim_genre__dbt_backup`
        ("genre_id", "genre_name")

WITH parsed_genres AS (
    SELECT
        TRIM(splitByChar(',', genres)[1]) AS first_genre
    FROM `bronze`.`tmdb_raw`
    WHERE genres IS NOT NULL AND genres != ''
)
SELECT
    cityHash64(first_genre) AS genre_id,
    first_genre AS genre_name
FROM parsed_genres
GROUP BY first_genre
ORDER BY first_genre
  ...
[0m16:44:02.303012 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.07 seconds
[0m16:44:02.304952 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_genre: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_genre"} */
EXCHANGE TABLES `_gold`.`dim_genre__dbt_backup` AND `_gold`.`dim_genre` 
  
  ...
[0m16:44:02.311387 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m16:44:02.314907 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_genre: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_genre"} */

    drop table if exists `_gold`.`dim_genre__dbt_backup` 
  ...
[0m16:44:02.320648 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_genre"} */

    drop table if exists `_gold`.`dim_genre__dbt_backup` 
  
[0m16:44:02.321296 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: macro drop_relation
[0m16:44:02.324007 [debug] [Thread-1 (]: Database Error in model dim_genre (models/gold/dim_genre.sql)
  :HTTPDriver for http://clickhouse-server:8123 returned response code 500)
   std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/5db/5db6bf74-23a3-44ff-8a65-d72393c86820/dim_genre__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/_gold.dim_genre__dbt_backup.c243b476-fcc1-44be-bb13-6d29416c7ea5.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build))
  compiled code at target/run/movie_warehouse/models/gold/dim_genre.sql
[0m16:44:02.324678 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5b866113-c476-49c3-a407-f4eb5a9b2e58', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff7ec91fd0>]}
[0m16:44:02.325264 [error] [Thread-1 (]: 3 of 6 ERROR creating sql table model `_gold`.`dim_genre` ...................... [[31mERROR[0m in 0.14s]
[0m16:44:02.325862 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.dim_genre
[0m16:44:02.326291 [debug] [Thread-1 (]: Began running node model.movie_warehouse.dim_movie
[0m16:44:02.327340 [info ] [Thread-1 (]: 4 of 6 START sql table model `_gold`.`dim_movie` ............................... [RUN]
[0m16:44:02.328114 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.movie_warehouse.dim_genre, now model.movie_warehouse.dim_movie)
[0m16:44:02.328669 [debug] [Thread-1 (]: Began compiling node model.movie_warehouse.dim_movie
[0m16:44:02.331950 [debug] [Thread-1 (]: Writing injected SQL for node "model.movie_warehouse.dim_movie"
[0m16:44:02.334160 [debug] [Thread-1 (]: Began executing node model.movie_warehouse.dim_movie
[0m16:44:02.336731 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_movie: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_movie"} */

            

    
        create table `_gold`.`dim_movie__dbt_backup`
        
  
        
  engine = MergeTree()
        order by (movie_id)
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

WITH movie_src AS (
    SELECT
        TRIM(title) AS movie_title,
        imdb_id,
        release_date,
        runtime AS movie_runtime,
        original_language AS language
    FROM `bronze`.`tmdb_raw`
    WHERE title IS NOT NULL AND title != ''
)
SELECT
    cityHash64(movie_title) AS movie_id,
    any(imdb_id) AS imdb_id,
    movie_title,
    any(release_date) AS release_date,
    any(movie_runtime) AS movie_runtime,
    any(language) AS language
FROM movie_src
GROUP BY movie_title
ORDER BY movie_title
          )
        
        ...
[0m16:44:02.352474 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m16:44:02.354577 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_movie: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_movie"} */

    select name, type from system.columns where table = 'dim_movie__dbt_backup'
    
      and database = '_gold'
    
    order by position
  ...
[0m16:44:02.359420 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:44:02.361979 [debug] [Thread-1 (]: Writing runtime sql for node "model.movie_warehouse.dim_movie"
[0m16:44:02.364407 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_movie: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_movie"} */

  
    
    
    
        
         


        insert into `_gold`.`dim_movie__dbt_backup`
        ("movie_id", "imdb_id", "movie_title", "release_date", "movie_runtime", "language")

WITH movie_src AS (
    SELECT
        TRIM(title) AS movie_title,
        imdb_id,
        release_date,
        runtime AS movie_runtime,
        original_language AS language
    FROM `bronze`.`tmdb_raw`
    WHERE title IS NOT NULL AND title != ''
)
SELECT
    cityHash64(movie_title) AS movie_id,
    any(imdb_id) AS imdb_id,
    movie_title,
    any(release_date) AS release_date,
    any(movie_runtime) AS movie_runtime,
    any(language) AS language
FROM movie_src
GROUP BY movie_title
ORDER BY movie_title
  ...
[0m16:44:02.728749 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.36 seconds
[0m16:44:02.729684 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_movie: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_movie"} */
EXCHANGE TABLES `_gold`.`dim_movie__dbt_backup` AND `_gold`.`dim_movie` 
  
  ...
[0m16:44:02.733679 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:44:02.737201 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_movie: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_movie"} */

    drop table if exists `_gold`.`dim_movie__dbt_backup` 
  ...
[0m16:44:02.739528 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_movie"} */

    drop table if exists `_gold`.`dim_movie__dbt_backup` 
  
[0m16:44:02.739881 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: macro drop_relation
[0m16:44:02.819876 [debug] [Thread-1 (]: Database Error in model dim_movie (models/gold/dim_movie.sql)
  :HTTPDriver for http://clickhouse-server:8123 returned response code 500)
   std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/5db/5db6bf74-23a3-44ff-8a65-d72393c86820/dim_movie__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/_gold.dim_movie__dbt_backup.c5bbd6eb-f72a-439d-91b2-d79f6516aa7d.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build))
  compiled code at target/run/movie_warehouse/models/gold/dim_movie.sql
[0m16:44:02.820396 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5b866113-c476-49c3-a407-f4eb5a9b2e58', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff7e115990>]}
[0m16:44:02.820858 [error] [Thread-1 (]: 4 of 6 ERROR creating sql table model `_gold`.`dim_movie` ...................... [[31mERROR[0m in 0.49s]
[0m16:44:02.821335 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.dim_movie
[0m16:44:02.821661 [debug] [Thread-1 (]: Began running node model.movie_warehouse.dim_production
[0m16:44:02.822032 [info ] [Thread-1 (]: 5 of 6 START sql table model `_gold`.`dim_production` .......................... [RUN]
[0m16:44:02.822350 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.movie_warehouse.dim_movie, now model.movie_warehouse.dim_production)
[0m16:44:02.822605 [debug] [Thread-1 (]: Began compiling node model.movie_warehouse.dim_production
[0m16:44:02.824229 [debug] [Thread-1 (]: Writing injected SQL for node "model.movie_warehouse.dim_production"
[0m16:44:02.825212 [debug] [Thread-1 (]: Began executing node model.movie_warehouse.dim_production
[0m16:44:02.826667 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_production: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_production"} */

            

    
        create table `_gold`.`dim_production__dbt_backup`
        
  
        
  engine = MergeTree()
        order by (production_id)
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

WITH production_list AS (
    SELECT TRIM(splitByChar(',', production_companies)[1]) AS production_name
    FROM `bronze`.`tmdb_raw`
    WHERE production_companies IS NOT NULL AND production_companies != ''
)

SELECT
    cityHash64(production_name) AS production_id,
    production_name,
    current_date() AS valid_from,
    CAST(NULL AS Nullable(Date)) AS valid_to,
    TRUE AS is_current
FROM (
    SELECT DISTINCT production_name
    FROM production_list
)
WHERE production_name IS NOT NULL AND production_name != ''
          )
        
        ...
[0m16:44:02.833197 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m16:44:02.834529 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_production: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_production"} */

    select name, type from system.columns where table = 'dim_production__dbt_backup'
    
      and database = '_gold'
    
    order by position
  ...
[0m16:44:02.836968 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:44:02.838077 [debug] [Thread-1 (]: Writing runtime sql for node "model.movie_warehouse.dim_production"
[0m16:44:02.838930 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_production: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_production"} */

  
    
    
    
        
         


        insert into `_gold`.`dim_production__dbt_backup`
        ("production_id", "production_name", "valid_from", "valid_to", "is_current")

WITH production_list AS (
    SELECT TRIM(splitByChar(',', production_companies)[1]) AS production_name
    FROM `bronze`.`tmdb_raw`
    WHERE production_companies IS NOT NULL AND production_companies != ''
)

SELECT
    cityHash64(production_name) AS production_id,
    production_name,
    current_date() AS valid_from,
    CAST(NULL AS Nullable(Date)) AS valid_to,
    TRUE AS is_current
FROM (
    SELECT DISTINCT production_name
    FROM production_list
)
WHERE production_name IS NOT NULL AND production_name != ''
  ...
[0m16:44:02.881200 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.04 seconds
[0m16:44:02.882008 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_production: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_production"} */
EXCHANGE TABLES `_gold`.`dim_production__dbt_backup` AND `_gold`.`dim_production` 
  
  ...
[0m16:44:02.886088 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:44:02.889075 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_production: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_production"} */

    drop table if exists `_gold`.`dim_production__dbt_backup` 
  ...
[0m16:44:02.891732 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_production"} */

    drop table if exists `_gold`.`dim_production__dbt_backup` 
  
[0m16:44:02.892078 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: macro drop_relation
[0m16:44:02.894208 [debug] [Thread-1 (]: Database Error in model dim_production (models/gold/dim_production.sql)
  :HTTPDriver for http://clickhouse-server:8123 returned response code 500)
   std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/5db/5db6bf74-23a3-44ff-8a65-d72393c86820/dim_production__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/_gold.dim_production__dbt_backup.a028aa9a-882c-47d7-98a9-9e2da6df80a7.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build))
  compiled code at target/run/movie_warehouse/models/gold/dim_production.sql
[0m16:44:02.894579 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5b866113-c476-49c3-a407-f4eb5a9b2e58', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffac562210>]}
[0m16:44:02.894985 [error] [Thread-1 (]: 5 of 6 ERROR creating sql table model `_gold`.`dim_production` ................. [[31mERROR[0m in 0.07s]
[0m16:44:02.895371 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.dim_production
[0m16:44:02.895993 [debug] [Thread-1 (]: Began running node model.movie_warehouse.fact_movie
[0m16:44:02.896257 [info ] [Thread-1 (]: 6 of 6 SKIP relation _gold.fact_movie .......................................... [[33mSKIP[0m]
[0m16:44:02.896554 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.fact_movie
[0m16:44:02.897565 [debug] [MainThread]: Connection 'master' was properly closed.
[0m16:44:02.897779 [debug] [MainThread]: Connection 'model.movie_warehouse.dim_production' was left open.
[0m16:44:02.897973 [debug] [MainThread]: On model.movie_warehouse.dim_production: Close
[0m16:44:02.898292 [info ] [MainThread]: 
[0m16:44:02.898539 [info ] [MainThread]: Finished running 6 table models in 0 hours 0 minutes and 2.70 seconds (2.70s).
[0m16:44:02.899133 [debug] [MainThread]: Command end result
[0m16:44:02.920127 [info ] [MainThread]: 
[0m16:44:02.920437 [info ] [MainThread]: [31mCompleted with 5 errors and 0 warnings:[0m
[0m16:44:02.920614 [info ] [MainThread]: 
[0m16:44:02.920827 [error] [MainThread]:   Database Error in model dim_date (models/gold/dim_date.sql)
  :HTTPDriver for http://clickhouse-server:8123 returned response code 500)
   std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/5db/5db6bf74-23a3-44ff-8a65-d72393c86820/dim_date__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/_gold.dim_date__dbt_backup.3ed4ff45-f3b0-4a24-b2bc-b9ef04f8a07b.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build))
  compiled code at target/run/movie_warehouse/models/gold/dim_date.sql
[0m16:44:02.921019 [info ] [MainThread]: 
[0m16:44:02.921229 [error] [MainThread]:   Database Error in model dim_director (models/gold/dim_director.sql)
  :HTTPDriver for http://clickhouse-server:8123 returned response code 500)
   std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/5db/5db6bf74-23a3-44ff-8a65-d72393c86820/dim_director__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/_gold.dim_director__dbt_backup.f2280a21-2492-41e7-9abb-1bd2bd4ff459.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build))
  compiled code at target/run/movie_warehouse/models/gold/dim_director.sql
[0m16:44:02.921409 [info ] [MainThread]: 
[0m16:44:02.921632 [error] [MainThread]:   Database Error in model dim_genre (models/gold/dim_genre.sql)
  :HTTPDriver for http://clickhouse-server:8123 returned response code 500)
   std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/5db/5db6bf74-23a3-44ff-8a65-d72393c86820/dim_genre__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/_gold.dim_genre__dbt_backup.c243b476-fcc1-44be-bb13-6d29416c7ea5.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build))
  compiled code at target/run/movie_warehouse/models/gold/dim_genre.sql
[0m16:44:02.921837 [info ] [MainThread]: 
[0m16:44:02.922028 [error] [MainThread]:   Database Error in model dim_movie (models/gold/dim_movie.sql)
  :HTTPDriver for http://clickhouse-server:8123 returned response code 500)
   std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/5db/5db6bf74-23a3-44ff-8a65-d72393c86820/dim_movie__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/_gold.dim_movie__dbt_backup.c5bbd6eb-f72a-439d-91b2-d79f6516aa7d.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build))
  compiled code at target/run/movie_warehouse/models/gold/dim_movie.sql
[0m16:44:02.922235 [info ] [MainThread]: 
[0m16:44:02.922485 [error] [MainThread]:   Database Error in model dim_production (models/gold/dim_production.sql)
  :HTTPDriver for http://clickhouse-server:8123 returned response code 500)
   std::exception. Code: 1001, type: std::__1::filesystem::filesystem_error, e.what() = filesystem error: in rename: No such file or directory ["/var/lib/clickhouse/store/5db/5db6bf74-23a3-44ff-8a65-d72393c86820/dim_production__dbt_backup.sql"] ["/var/lib/clickhouse/metadata_dropped/_gold.dim_production__dbt_backup.a028aa9a-882c-47d7-98a9-9e2da6df80a7.sql"]
  Cannot print extra info for Poco::Exception (version 25.9.3.48 (official build))
  compiled code at target/run/movie_warehouse/models/gold/dim_production.sql
[0m16:44:02.922682 [info ] [MainThread]: 
[0m16:44:02.922909 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=5 SKIP=1 TOTAL=6
[0m16:44:02.923874 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 3.1946173, "process_in_blocks": "95160", "process_kernel_time": 0.237516, "process_mem_max_rss": "186752", "process_out_blocks": "3851", "process_user_time": 2.479139}
[0m16:44:02.924189 [debug] [MainThread]: Command `dbt run` failed at 16:44:02.924143 after 3.19 seconds
[0m16:44:02.924436 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffac686c10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffac6e0dd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffac6e0ed0>]}
[0m16:44:02.924654 [debug] [MainThread]: Flushing usage events
[0m16:56:31.512463 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa7591c10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa7952ed0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa79532d0>]}


============================== 16:56:31.520031 | 21e80e30-a917-4b01-bed8-9ce7a188d44c ==============================
[0m16:56:31.520031 [info ] [MainThread]: Running with dbt=1.8.9
[0m16:56:31.520497 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/project_root/dbt', 'fail_fast': 'False', 'debug': 'False', 'log_path': '/opt/airflow/project_root/dbt/logs', 'warn_error': 'None', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'invocation_command': 'dbt run --project-dir /opt/airflow/project_root/dbt --profiles-dir /opt/airflow/project_root/dbt --select gold', 'introspect': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m16:56:31.657480 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '21e80e30-a917-4b01-bed8-9ce7a188d44c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa7510050>]}
[0m16:56:31.678341 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '21e80e30-a917-4b01-bed8-9ce7a188d44c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa7fc7750>]}
[0m16:56:31.678990 [info ] [MainThread]: Registered adapter: clickhouse=1.8.9
[0m16:56:31.721088 [debug] [MainThread]: checksum: 132857a23e9d07220246854f7763165174ce9b737cfc7867629ace4294e520b1, vars: {}, profile: , target: , version: 1.8.9
[0m16:56:31.795648 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m16:56:31.796012 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m16:56:31.815267 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '21e80e30-a917-4b01-bed8-9ce7a188d44c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa71e8a50>]}
[0m16:56:31.873875 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '21e80e30-a917-4b01-bed8-9ce7a188d44c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa7269790>]}
[0m16:56:31.874241 [info ] [MainThread]: Found 6 models, 12 data tests, 4 sources, 477 macros
[0m16:56:31.874488 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '21e80e30-a917-4b01-bed8-9ce7a188d44c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa730d150>]}
[0m16:56:31.875373 [info ] [MainThread]: 
[0m16:56:31.875749 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m16:56:31.880271 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m16:56:31.889235 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:56:32.368071 [info ] [ThreadPool]: dbt_clickhouse adapter: Unexpected server exception dropping table
[0m16:56:32.368570 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m16:56:32.375738 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m16:56:32.400848 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list___gold)
[0m16:56:32.404293 [debug] [ThreadPool]: dbt_clickhouse adapter: On list___gold: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "connection_name": "list___gold"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = '_gold'
      

  ...
[0m16:56:32.424997 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m16:56:32.426098 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '21e80e30-a917-4b01-bed8-9ce7a188d44c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa74cc410>]}
[0m16:56:32.427001 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m16:56:32.427249 [info ] [MainThread]: 
[0m16:56:32.432997 [debug] [Thread-1 (]: Began running node model.movie_warehouse.dim_date
[0m16:56:32.433472 [info ] [Thread-1 (]: 1 of 6 START sql table model `_gold`.`dim_date` ................................ [RUN]
[0m16:56:32.433822 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list___gold, now model.movie_warehouse.dim_date)
[0m16:56:32.438185 [debug] [Thread-1 (]: Began compiling node model.movie_warehouse.dim_date
[0m16:56:32.442458 [debug] [Thread-1 (]: Writing injected SQL for node "model.movie_warehouse.dim_date"
[0m16:56:32.444609 [debug] [Thread-1 (]: Began executing node model.movie_warehouse.dim_date
[0m16:56:32.453999 [debug] [Thread-1 (]: Creating new relation dim_date
[0m16:56:32.468333 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_date: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_date"} */

            

    
        create table `_gold`.`dim_date`
        
  
        
  engine = MergeTree()
        order by (date_id)
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

WITH distinct_dates AS (
    SELECT DISTINCT release_date
    FROM `bronze`.`tmdb_raw`
    WHERE release_date IS NOT NULL
)

SELECT
    cityHash64(release_date)                                    AS date_id,
    release_date                                                AS full_date,
    toYear(release_date)                                        AS year,
    toMonth(release_date)                                       AS month,
    toDayOfMonth(release_date)                                  AS day,
    toISOWeek(release_date)                                     AS week,
    formatDateTime(release_date, '%a')                          AS weekday,
    CASE
        WHEN toMonth(release_date) IN (12,1,2)  THEN 'Winter'
        WHEN toMonth(release_date) IN (3,4,5)   THEN 'Spring'
        WHEN toMonth(release_date) IN (6,7,8)   THEN 'Summer'
        WHEN toMonth(release_date) IN (9,10,11) THEN 'Autumn'
    END                                                         AS season,
    CASE
        WHEN formatDateTime(release_date, '%a') IN ('Saturday','Sunday') THEN 1
        ELSE 0
    END                                                         AS is_weekend,

    /* ---------- holiday tagging ---------- */
    CASE
        WHEN toMonth(release_date)=1  AND toDayOfMonth(release_date)=1  THEN 'New Years Day'
        WHEN toMonth(release_date)=2  AND toDayOfMonth(release_date)=14 THEN 'Valentines Day'
        WHEN toMonth(release_date)=3  AND toDayOfMonth(release_date)=17 THEN 'St. Patricks Day'
        WHEN toMonth(release_date)=4  AND toDayOfMonth(release_date)=1  THEN 'April Fools Day'
        WHEN toMonth(release_date)=4  AND toDayOfMonth(release_date)=22 THEN 'Earth Day'
        WHEN toMonth(release_date)=5  AND toDayOfMonth(release_date)=1  THEN 'May Day'
        WHEN toMonth(release_date)=5  AND toDayOfMonth(release_date)=5  THEN 'Cinco de Mayo'
        WHEN toMonth(release_date)=6  AND toDayOfMonth(release_date) BETWEEN 19 AND 26 THEN 'Midsummer'
        WHEN toMonth(release_date)=7  AND toDayOfMonth(release_date)=4  THEN 'Independence Day'
        WHEN toMonth(release_date)=9  AND toDayOfMonth(release_date) BETWEEN 1 AND 7 
             AND formatDateTime(release_date,'%a')='Monday'             THEN 'Labor Day (US)'
        WHEN toMonth(release_date)=10 AND toDayOfMonth(release_date)=31 THEN 'Halloween'
        WHEN toMonth(release_date)=11 AND formatDateTime(release_date,'%a')='Thursday'
             AND toISOWeek(release_date) >= 47                           THEN 'Thanksgiving'
        WHEN toMonth(release_date)=12 AND toDayOfMonth(release_date)=24 THEN 'Christmas Eve'
        WHEN toMonth(release_date)=12 AND toDayOfMonth(release_date)=25 THEN 'Christmas Day'
        WHEN toMonth(release_date)=12 AND toDayOfMonth(release_date)=31 THEN 'New Years Eve'
        ELSE NULL
    END                                                         AS holiday_name,
    IF(holiday_name IS NOT NULL, 1, 0)                          AS is_holiday,

    /* placeholders for later enhancement */
    CAST(NULL AS Nullable(Int32)) AS days_until_holiday,
    CAST(NULL AS Nullable(Int32)) AS days_after_holiday

FROM distinct_dates
ORDER BY release_date
          )
        
        ...
[0m16:56:32.483060 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m16:56:32.490351 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_date: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_date"} */

    select name, type from system.columns where table = 'dim_date'
    
      and database = '_gold'
    
    order by position
  ...
[0m16:56:32.494721 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:56:32.496908 [debug] [Thread-1 (]: Writing runtime sql for node "model.movie_warehouse.dim_date"
[0m16:56:32.497998 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_date: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_date"} */

  
    
    
    
        
         


        insert into `_gold`.`dim_date`
        ("date_id", "full_date", "year", "month", "day", "week", "weekday", "season", "is_weekend", "holiday_name", "is_holiday", "days_until_holiday", "days_after_holiday")

WITH distinct_dates AS (
    SELECT DISTINCT release_date
    FROM `bronze`.`tmdb_raw`
    WHERE release_date IS NOT NULL
)

SELECT
    cityHash64(release_date)                                    AS date_id,
    release_date                                                AS full_date,
    toYear(release_date)                                        AS year,
    toMonth(release_date)                                       AS month,
    toDayOfMonth(release_date)                                  AS day,
    toISOWeek(release_date)                                     AS week,
    formatDateTime(release_date, '%a')                          AS weekday,
    CASE
        WHEN toMonth(release_date) IN (12,1,2)  THEN 'Winter'
        WHEN toMonth(release_date) IN (3,4,5)   THEN 'Spring'
        WHEN toMonth(release_date) IN (6,7,8)   THEN 'Summer'
        WHEN toMonth(release_date) IN (9,10,11) THEN 'Autumn'
    END                                                         AS season,
    CASE
        WHEN formatDateTime(release_date, '%a') IN ('Saturday','Sunday') THEN 1
        ELSE 0
    END                                                         AS is_weekend,

    /* ---------- holiday tagging ---------- */
    CASE
        WHEN toMonth(release_date)=1  AND toDayOfMonth(release_date)=1  THEN 'New Years Day'
        WHEN toMonth(release_date)=2  AND toDayOfMonth(release_date)=14 THEN 'Valentines Day'
        WHEN toMonth(release_date)=3  AND toDayOfMonth(release_date)=17 THEN 'St. Patricks Day'
        WHEN toMonth(release_date)=4  AND toDayOfMonth(release_date)=1  THEN 'April Fools Day'
        WHEN toMonth(release_date)=4  AND toDayOfMonth(release_date)=22 THEN 'Earth Day'
        WHEN toMonth(release_date)=5  AND toDayOfMonth(release_date)=1  THEN 'May Day'
        WHEN toMonth(release_date)=5  AND toDayOfMonth(release_date)=5  THEN 'Cinco de Mayo'
        WHEN toMonth(release_date)=6  AND toDayOfMonth(release_date) BETWEEN 19 AND 26 THEN 'Midsummer'
        WHEN toMonth(release_date)=7  AND toDayOfMonth(release_date)=4  THEN 'Independence Day'
        WHEN toMonth(release_date)=9  AND toDayOfMonth(release_date) BETWEEN 1 AND 7 
             AND formatDateTime(release_date,'%a')='Monday'             THEN 'Labor Day (US)'
        WHEN toMonth(release_date)=10 AND toDayOfMonth(release_date)=31 THEN 'Halloween'
        WHEN toMonth(release_date)=11 AND formatDateTime(release_date,'%a')='Thursday'
             AND toISOWeek(release_date) >= 47                           THEN 'Thanksgiving'
        WHEN toMonth(release_date)=12 AND toDayOfMonth(release_date)=24 THEN 'Christmas Eve'
        WHEN toMonth(release_date)=12 AND toDayOfMonth(release_date)=25 THEN 'Christmas Day'
        WHEN toMonth(release_date)=12 AND toDayOfMonth(release_date)=31 THEN 'New Years Eve'
        ELSE NULL
    END                                                         AS holiday_name,
    IF(holiday_name IS NOT NULL, 1, 0)                          AS is_holiday,

    /* placeholders for later enhancement */
    CAST(NULL AS Nullable(Int32)) AS days_until_holiday,
    CAST(NULL AS Nullable(Int32)) AS days_after_holiday

FROM distinct_dates
ORDER BY release_date
  ...
[0m16:56:32.535803 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.04 seconds
[0m16:56:32.545376 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '21e80e30-a917-4b01-bed8-9ce7a188d44c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff7e379d50>]}
[0m16:56:32.545988 [info ] [Thread-1 (]: 1 of 6 OK created sql table model `_gold`.`dim_date` ........................... [[32mOK[0m in 0.11s]
[0m16:56:32.546364 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.dim_date
[0m16:56:32.546655 [debug] [Thread-1 (]: Began running node model.movie_warehouse.dim_director
[0m16:56:32.547023 [info ] [Thread-1 (]: 2 of 6 START sql table model `_gold`.`dim_director` ............................ [RUN]
[0m16:56:32.547328 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.movie_warehouse.dim_date, now model.movie_warehouse.dim_director)
[0m16:56:32.547586 [debug] [Thread-1 (]: Began compiling node model.movie_warehouse.dim_director
[0m16:56:32.549451 [debug] [Thread-1 (]: Writing injected SQL for node "model.movie_warehouse.dim_director"
[0m16:56:32.550378 [debug] [Thread-1 (]: Began executing node model.movie_warehouse.dim_director
[0m16:56:32.551576 [debug] [Thread-1 (]: Creating new relation dim_director
[0m16:56:32.552280 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_director: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_director"} */

            

    
        create table `_gold`.`dim_director`
        
  
        
  engine = MergeTree()
        order by (director_id)
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

WITH first_dir AS (
    SELECT
        tconst,
        TRIM(splitByChar(',', directors)[1]) AS director_id
    FROM `bronze`.`imdb_title_crew_raw`
    WHERE directors IS NOT NULL AND directors != ''
),
deduped AS (
    SELECT DISTINCT director_id
    FROM first_dir
),
joined AS (
    SELECT
        d.director_id,
        n.primaryName AS director_name
    FROM deduped d
    LEFT JOIN `bronze`.`imdb_name_basics_raw` n
        ON d.director_id = n.nconst
)
SELECT
    cityHash64(director_id) AS imdb_dir_name_id,  -- Use hash instead of row_number
    director_id,
    director_name,
    today() AS valid_from,
    CAST(NULL AS Nullable(Date)) AS valid_to,
    1 AS is_current  -- Use 1/0 instead of TRUE/FALSE
FROM joined
WHERE director_id IS NOT NULL
ORDER BY director_id
          )
        
        ...
[0m16:56:32.560065 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m16:56:32.562394 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_director: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_director"} */

    select name, type from system.columns where table = 'dim_director'
    
      and database = '_gold'
    
    order by position
  ...
[0m16:56:32.565092 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:56:32.566158 [debug] [Thread-1 (]: Writing runtime sql for node "model.movie_warehouse.dim_director"
[0m16:56:32.567034 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_director: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_director"} */

  
    
    
    
        
         


        insert into `_gold`.`dim_director`
        ("imdb_dir_name_id", "director_id", "director_name", "valid_from", "valid_to", "is_current")

WITH first_dir AS (
    SELECT
        tconst,
        TRIM(splitByChar(',', directors)[1]) AS director_id
    FROM `bronze`.`imdb_title_crew_raw`
    WHERE directors IS NOT NULL AND directors != ''
),
deduped AS (
    SELECT DISTINCT director_id
    FROM first_dir
),
joined AS (
    SELECT
        d.director_id,
        n.primaryName AS director_name
    FROM deduped d
    LEFT JOIN `bronze`.`imdb_name_basics_raw` n
        ON d.director_id = n.nconst
)
SELECT
    cityHash64(director_id) AS imdb_dir_name_id,  -- Use hash instead of row_number
    director_id,
    director_name,
    today() AS valid_from,
    CAST(NULL AS Nullable(Date)) AS valid_to,
    1 AS is_current  -- Use 1/0 instead of TRUE/FALSE
FROM joined
WHERE director_id IS NOT NULL
ORDER BY director_id
  ...
[0m16:56:34.758916 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 2.19 seconds
[0m16:56:34.782654 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '21e80e30-a917-4b01-bed8-9ce7a188d44c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff7da0e210>]}
[0m16:56:34.784880 [info ] [Thread-1 (]: 2 of 6 OK created sql table model `_gold`.`dim_director` ....................... [[32mOK[0m in 2.23s]
[0m16:56:34.786879 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.dim_director
[0m16:56:34.787914 [debug] [Thread-1 (]: Began running node model.movie_warehouse.dim_genre
[0m16:56:34.789411 [info ] [Thread-1 (]: 3 of 6 START sql table model `_gold`.`dim_genre` ............................... [RUN]
[0m16:56:34.790218 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.movie_warehouse.dim_director, now model.movie_warehouse.dim_genre)
[0m16:56:34.790655 [debug] [Thread-1 (]: Began compiling node model.movie_warehouse.dim_genre
[0m16:56:34.802346 [debug] [Thread-1 (]: Writing injected SQL for node "model.movie_warehouse.dim_genre"
[0m16:56:34.803974 [debug] [Thread-1 (]: Began executing node model.movie_warehouse.dim_genre
[0m16:56:34.807249 [debug] [Thread-1 (]: Creating new relation dim_genre
[0m16:56:34.808309 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_genre: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_genre"} */

            

    
        create table `_gold`.`dim_genre`
        
  
        
  engine = MergeTree()
        order by (genre_id)
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

WITH parsed_genres AS (
    SELECT
        TRIM(splitByChar(',', genres)[1]) AS first_genre
    FROM `bronze`.`tmdb_raw`
    WHERE genres IS NOT NULL AND genres != ''
)
SELECT
    cityHash64(first_genre) AS genre_id,
    first_genre AS genre_name
FROM parsed_genres
GROUP BY first_genre
ORDER BY first_genre
          )
        
        ...
[0m16:56:34.823683 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m16:56:34.825909 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_genre: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_genre"} */

    select name, type from system.columns where table = 'dim_genre'
    
      and database = '_gold'
    
    order by position
  ...
[0m16:56:34.829211 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:56:34.830386 [debug] [Thread-1 (]: Writing runtime sql for node "model.movie_warehouse.dim_genre"
[0m16:56:34.831320 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_genre: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_genre"} */

  
    
    
    
        
         


        insert into `_gold`.`dim_genre`
        ("genre_id", "genre_name")

WITH parsed_genres AS (
    SELECT
        TRIM(splitByChar(',', genres)[1]) AS first_genre
    FROM `bronze`.`tmdb_raw`
    WHERE genres IS NOT NULL AND genres != ''
)
SELECT
    cityHash64(first_genre) AS genre_id,
    first_genre AS genre_name
FROM parsed_genres
GROUP BY first_genre
ORDER BY first_genre
  ...
[0m16:56:34.860176 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.03 seconds
[0m16:56:34.861579 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '21e80e30-a917-4b01-bed8-9ce7a188d44c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff7da0e190>]}
[0m16:56:34.862039 [info ] [Thread-1 (]: 3 of 6 OK created sql table model `_gold`.`dim_genre` .......................... [[32mOK[0m in 0.07s]
[0m16:56:34.862460 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.dim_genre
[0m16:56:34.862785 [debug] [Thread-1 (]: Began running node model.movie_warehouse.dim_movie
[0m16:56:34.863199 [info ] [Thread-1 (]: 4 of 6 START sql table model `_gold`.`dim_movie` ............................... [RUN]
[0m16:56:34.863483 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.movie_warehouse.dim_genre, now model.movie_warehouse.dim_movie)
[0m16:56:34.863675 [debug] [Thread-1 (]: Began compiling node model.movie_warehouse.dim_movie
[0m16:56:34.865699 [debug] [Thread-1 (]: Writing injected SQL for node "model.movie_warehouse.dim_movie"
[0m16:56:34.866462 [debug] [Thread-1 (]: Began executing node model.movie_warehouse.dim_movie
[0m16:56:34.867836 [debug] [Thread-1 (]: Creating new relation dim_movie
[0m16:56:34.868486 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_movie: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_movie"} */

            

    
        create table `_gold`.`dim_movie`
        
  
        
  engine = MergeTree()
        order by (movie_id)
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

WITH movie_src AS (
    SELECT
        TRIM(title) AS movie_title,
        imdb_id,
        release_date,
        runtime AS movie_runtime,
        original_language AS language
    FROM `bronze`.`tmdb_raw`
    WHERE title IS NOT NULL AND title != ''
)
SELECT
    cityHash64(movie_title) AS movie_id,
    any(imdb_id) AS imdb_id,
    movie_title,
    any(release_date) AS release_date,
    any(movie_runtime) AS movie_runtime,
    any(language) AS language
FROM movie_src
GROUP BY movie_title
ORDER BY movie_title
          )
        
        ...
[0m16:56:34.876109 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m16:56:34.878122 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_movie: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_movie"} */

    select name, type from system.columns where table = 'dim_movie'
    
      and database = '_gold'
    
    order by position
  ...
[0m16:56:34.881942 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:56:34.883236 [debug] [Thread-1 (]: Writing runtime sql for node "model.movie_warehouse.dim_movie"
[0m16:56:34.884125 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_movie: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_movie"} */

  
    
    
    
        
         


        insert into `_gold`.`dim_movie`
        ("movie_id", "imdb_id", "movie_title", "release_date", "movie_runtime", "language")

WITH movie_src AS (
    SELECT
        TRIM(title) AS movie_title,
        imdb_id,
        release_date,
        runtime AS movie_runtime,
        original_language AS language
    FROM `bronze`.`tmdb_raw`
    WHERE title IS NOT NULL AND title != ''
)
SELECT
    cityHash64(movie_title) AS movie_id,
    any(imdb_id) AS imdb_id,
    movie_title,
    any(release_date) AS release_date,
    any(movie_runtime) AS movie_runtime,
    any(language) AS language
FROM movie_src
GROUP BY movie_title
ORDER BY movie_title
  ...
[0m16:56:35.151109 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.27 seconds
[0m16:56:35.152744 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '21e80e30-a917-4b01-bed8-9ce7a188d44c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa748dad0>]}
[0m16:56:35.153299 [info ] [Thread-1 (]: 4 of 6 OK created sql table model `_gold`.`dim_movie` .......................... [[32mOK[0m in 0.29s]
[0m16:56:35.153895 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.dim_movie
[0m16:56:35.154258 [debug] [Thread-1 (]: Began running node model.movie_warehouse.dim_production
[0m16:56:35.154691 [info ] [Thread-1 (]: 5 of 6 START sql table model `_gold`.`dim_production` .......................... [RUN]
[0m16:56:35.154992 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.movie_warehouse.dim_movie, now model.movie_warehouse.dim_production)
[0m16:56:35.155216 [debug] [Thread-1 (]: Began compiling node model.movie_warehouse.dim_production
[0m16:56:35.157518 [debug] [Thread-1 (]: Writing injected SQL for node "model.movie_warehouse.dim_production"
[0m16:56:35.158349 [debug] [Thread-1 (]: Began executing node model.movie_warehouse.dim_production
[0m16:56:35.160364 [debug] [Thread-1 (]: Creating new relation dim_production
[0m16:56:35.161373 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_production: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_production"} */

            

    
        create table `_gold`.`dim_production`
        
  
        
  engine = MergeTree()
        order by (production_id)
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

WITH production_list AS (
    SELECT TRIM(splitByChar(',', production_companies)[1]) AS production_name
    FROM `bronze`.`tmdb_raw`
    WHERE production_companies IS NOT NULL AND production_companies != ''
)

SELECT
    cityHash64(production_name) AS production_id,
    production_name,
    current_date() AS valid_from,
    CAST(NULL AS Nullable(Date)) AS valid_to,
    TRUE AS is_current
FROM (
    SELECT DISTINCT production_name
    FROM production_list
)
WHERE production_name IS NOT NULL AND production_name != ''
          )
        
        ...
[0m16:56:35.170661 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m16:56:35.172923 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_production: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_production"} */

    select name, type from system.columns where table = 'dim_production'
    
      and database = '_gold'
    
    order by position
  ...
[0m16:56:35.176627 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:56:35.178049 [debug] [Thread-1 (]: Writing runtime sql for node "model.movie_warehouse.dim_production"
[0m16:56:35.178951 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_production: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_production"} */

  
    
    
    
        
         


        insert into `_gold`.`dim_production`
        ("production_id", "production_name", "valid_from", "valid_to", "is_current")

WITH production_list AS (
    SELECT TRIM(splitByChar(',', production_companies)[1]) AS production_name
    FROM `bronze`.`tmdb_raw`
    WHERE production_companies IS NOT NULL AND production_companies != ''
)

SELECT
    cityHash64(production_name) AS production_id,
    production_name,
    current_date() AS valid_from,
    CAST(NULL AS Nullable(Date)) AS valid_to,
    TRUE AS is_current
FROM (
    SELECT DISTINCT production_name
    FROM production_list
)
WHERE production_name IS NOT NULL AND production_name != ''
  ...
[0m16:56:35.222316 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.04 seconds
[0m16:56:35.223650 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '21e80e30-a917-4b01-bed8-9ce7a188d44c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa75bcf90>]}
[0m16:56:35.224144 [info ] [Thread-1 (]: 5 of 6 OK created sql table model `_gold`.`dim_production` ..................... [[32mOK[0m in 0.07s]
[0m16:56:35.224721 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.dim_production
[0m16:56:35.226191 [debug] [Thread-1 (]: Began running node model.movie_warehouse.fact_movie
[0m16:56:35.226561 [info ] [Thread-1 (]: 6 of 6 START sql table model `_gold`.`fact_movie` .............................. [RUN]
[0m16:56:35.226862 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.movie_warehouse.dim_production, now model.movie_warehouse.fact_movie)
[0m16:56:35.227092 [debug] [Thread-1 (]: Began compiling node model.movie_warehouse.fact_movie
[0m16:56:35.231101 [debug] [Thread-1 (]: Writing injected SQL for node "model.movie_warehouse.fact_movie"
[0m16:56:35.231903 [debug] [Thread-1 (]: Began executing node model.movie_warehouse.fact_movie
[0m16:56:35.322545 [debug] [Thread-1 (]: Creating new relation fact_movie
[0m16:56:35.323274 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.fact_movie: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.fact_movie"} */

            

    
        create table `_gold`.`fact_movie`
        
  
        
  engine = MergeTree()
        order by (fact_id)
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

WITH filtered_tmdb AS (
    SELECT 
        imdb_id,
        title,
        release_date,
        production_companies,
        budget,
        revenue,
        vote_average,
        vote_count,
        runtime,
        genres,
        original_language,
        
        (vote_average * log(1 + vote_count)) AS movie_popularity
    FROM `bronze`.`tmdb_raw`
),

-- First genre
first_genre AS (
    SELECT
        imdb_id AS movie_id,
        trim(splitByChar(',', genres)[1]) AS genre_name
    FROM filtered_tmdb
),

-- First director
first_director AS (
    SELECT
        t.imdb_id AS movie_id,
        trim(splitByChar(',', c.directors)[1]) AS director_id
    FROM filtered_tmdb t
    LEFT JOIN `bronze`.`imdb_title_crew_raw` c
        ON t.imdb_id = c.tconst
),

-- Join to dim_production to get production_id
movie_production AS (
    SELECT
        t.imdb_id AS movie_id,
        p.production_id
    FROM filtered_tmdb t
    LEFT JOIN `_gold`.`dim_production` p
        ON trim(splitByChar(',', t.production_companies)[1]) = p.production_name
),

-- Map genre_name to dim_genre to get genre_id
movie_genre AS (
    SELECT
        fg.movie_id,
        g.genre_id
    FROM first_genre fg
    LEFT JOIN `_gold`.`dim_genre` g
        ON fg.genre_name = g.genre_name
),

base AS (
    SELECT
        t.imdb_id                                 AS movie_id,
        d.director_id,
        mg.genre_id,
        mp.production_id,
        dr.date_id                                AS date_id,
        t.vote_average                            AS vote_avg,
        t.vote_count,
        t.revenue,
        t.budget,
        t.movie_popularity,
        toYear(t.release_date)                    AS release_year
    FROM filtered_tmdb t
    LEFT JOIN movie_genre mg       ON mg.movie_id = t.imdb_id
    LEFT JOIN first_director d     ON d.movie_id = t.imdb_id
    LEFT JOIN movie_production mp  ON mp.movie_id = t.imdb_id
    LEFT JOIN `_gold`.`dim_date` dr
        ON dr.full_date = t.release_date
),

metrics AS (
    SELECT
        b.*,
        b.revenue - lag(b.revenue, 1) OVER (PARTITION BY b.movie_id ORDER BY b.release_year) AS revenue_growth,
        b.movie_popularity - lag(b.movie_popularity, 1) OVER (PARTITION BY b.movie_id ORDER BY b.release_year) AS popularity_change,
        b.vote_avg - lag(b.vote_avg, 1) OVER (PARTITION BY b.movie_id ORDER BY b.release_year) AS vote_avg_change
    FROM base b
)

SELECT
    row_number() OVER (ORDER BY movie_id, date_id, director_id, genre_id) AS fact_id,
    movie_id,
    director_id,
    genre_id,
    production_id,
    date_id,
    vote_avg,
    vote_count,
    revenue,
    budget,
    movie_popularity,
    revenue_growth,
    popularity_change,
    vote_avg_change
FROM metrics
          )
        
        ...
[0m16:56:35.338363 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m16:56:35.339955 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.fact_movie: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.fact_movie"} */

    select name, type from system.columns where table = 'fact_movie'
    
      and database = '_gold'
    
    order by position
  ...
[0m16:56:35.342670 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:56:35.343967 [debug] [Thread-1 (]: Writing runtime sql for node "model.movie_warehouse.fact_movie"
[0m16:56:35.344620 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.fact_movie: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.fact_movie"} */

  
    
    
    
        
         


        insert into `_gold`.`fact_movie`
        ("fact_id", "movie_id", "director_id", "genre_id", "production_id", "date_id", "vote_avg", "vote_count", "revenue", "budget", "movie_popularity", "revenue_growth", "popularity_change", "vote_avg_change")

WITH filtered_tmdb AS (
    SELECT 
        imdb_id,
        title,
        release_date,
        production_companies,
        budget,
        revenue,
        vote_average,
        vote_count,
        runtime,
        genres,
        original_language,
        
        (vote_average * log(1 + vote_count)) AS movie_popularity
    FROM `bronze`.`tmdb_raw`
),

-- First genre
first_genre AS (
    SELECT
        imdb_id AS movie_id,
        trim(splitByChar(',', genres)[1]) AS genre_name
    FROM filtered_tmdb
),

-- First director
first_director AS (
    SELECT
        t.imdb_id AS movie_id,
        trim(splitByChar(',', c.directors)[1]) AS director_id
    FROM filtered_tmdb t
    LEFT JOIN `bronze`.`imdb_title_crew_raw` c
        ON t.imdb_id = c.tconst
),

-- Join to dim_production to get production_id
movie_production AS (
    SELECT
        t.imdb_id AS movie_id,
        p.production_id
    FROM filtered_tmdb t
    LEFT JOIN `_gold`.`dim_production` p
        ON trim(splitByChar(',', t.production_companies)[1]) = p.production_name
),

-- Map genre_name to dim_genre to get genre_id
movie_genre AS (
    SELECT
        fg.movie_id,
        g.genre_id
    FROM first_genre fg
    LEFT JOIN `_gold`.`dim_genre` g
        ON fg.genre_name = g.genre_name
),

base AS (
    SELECT
        t.imdb_id                                 AS movie_id,
        d.director_id,
        mg.genre_id,
        mp.production_id,
        dr.date_id                                AS date_id,
        t.vote_average                            AS vote_avg,
        t.vote_count,
        t.revenue,
        t.budget,
        t.movie_popularity,
        toYear(t.release_date)                    AS release_year
    FROM filtered_tmdb t
    LEFT JOIN movie_genre mg       ON mg.movie_id = t.imdb_id
    LEFT JOIN first_director d     ON d.movie_id = t.imdb_id
    LEFT JOIN movie_production mp  ON mp.movie_id = t.imdb_id
    LEFT JOIN `_gold`.`dim_date` dr
        ON dr.full_date = t.release_date
),

metrics AS (
    SELECT
        b.*,
        b.revenue - lag(b.revenue, 1) OVER (PARTITION BY b.movie_id ORDER BY b.release_year) AS revenue_growth,
        b.movie_popularity - lag(b.movie_popularity, 1) OVER (PARTITION BY b.movie_id ORDER BY b.release_year) AS popularity_change,
        b.vote_avg - lag(b.vote_avg, 1) OVER (PARTITION BY b.movie_id ORDER BY b.release_year) AS vote_avg_change
    FROM base b
)

SELECT
    row_number() OVER (ORDER BY movie_id, date_id, director_id, genre_id) AS fact_id,
    movie_id,
    director_id,
    genre_id,
    production_id,
    date_id,
    vote_avg,
    vote_count,
    revenue,
    budget,
    movie_popularity,
    revenue_growth,
    popularity_change,
    vote_avg_change
FROM metrics
  ...
[0m16:56:39.570243 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 4.22 seconds
[0m16:56:39.588029 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '21e80e30-a917-4b01-bed8-9ce7a188d44c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff7da7d450>]}
[0m16:56:39.589518 [info ] [Thread-1 (]: 6 of 6 OK created sql table model `_gold`.`fact_movie` ......................... [[32mOK[0m in 4.36s]
[0m16:56:39.590220 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.fact_movie
[0m16:56:39.592904 [debug] [MainThread]: Connection 'master' was properly closed.
[0m16:56:39.594274 [debug] [MainThread]: Connection 'model.movie_warehouse.fact_movie' was left open.
[0m16:56:39.594795 [debug] [MainThread]: On model.movie_warehouse.fact_movie: Close
[0m16:56:39.595454 [info ] [MainThread]: 
[0m16:56:39.595784 [info ] [MainThread]: Finished running 6 table models in 0 hours 0 minutes and 7.72 seconds (7.72s).
[0m16:56:39.596738 [debug] [MainThread]: Command end result
[0m16:56:39.635917 [info ] [MainThread]: 
[0m16:56:39.636329 [info ] [MainThread]: [32mCompleted successfully[0m
[0m16:56:39.636658 [info ] [MainThread]: 
[0m16:56:39.637486 [info ] [MainThread]: Done. PASS=6 WARN=0 ERROR=0 SKIP=0 TOTAL=6
[0m16:56:39.642753 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 8.165612, "process_in_blocks": "119376", "process_kernel_time": 0.28806, "process_mem_max_rss": "189256", "process_out_blocks": "3858", "process_user_time": 2.539536}
[0m16:56:39.645074 [debug] [MainThread]: Command `dbt run` succeeded at 16:56:39.644898 after 8.17 seconds
[0m16:56:39.646316 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffac369f10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffac369e50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffac49e190>]}
[0m16:56:39.647183 [debug] [MainThread]: Flushing usage events
[0m16:56:44.939953 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff85f35fd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff85f67c50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff85f35a90>]}


============================== 16:56:44.944201 | f7ec87a3-972a-4bef-a438-c513a4664bce ==============================
[0m16:56:44.944201 [info ] [MainThread]: Running with dbt=1.8.9
[0m16:56:44.944637 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/project_root/dbt', 'version_check': 'True', 'fail_fast': 'False', 'log_path': '/opt/airflow/project_root/dbt/logs', 'warn_error': 'None', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'log_format': 'default', 'static_parser': 'True', 'introspect': 'True', 'invocation_command': 'dbt test --project-dir /opt/airflow/project_root/dbt --profiles-dir /opt/airflow/project_root/dbt --select gold', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m16:56:45.055112 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'f7ec87a3-972a-4bef-a438-c513a4664bce', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff85ebd7d0>]}
[0m16:56:45.075862 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'f7ec87a3-972a-4bef-a438-c513a4664bce', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff869633d0>]}
[0m16:56:45.076506 [info ] [MainThread]: Registered adapter: clickhouse=1.8.9
[0m16:56:45.113594 [debug] [MainThread]: checksum: 132857a23e9d07220246854f7763165174ce9b737cfc7867629ace4294e520b1, vars: {}, profile: , target: , version: 1.8.9
[0m16:56:45.184863 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m16:56:45.185493 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m16:56:45.223008 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'f7ec87a3-972a-4bef-a438-c513a4664bce', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff85ca8e90>]}
[0m16:56:45.292330 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'f7ec87a3-972a-4bef-a438-c513a4664bce', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff859c8310>]}
[0m16:56:45.292706 [info ] [MainThread]: Found 6 models, 12 data tests, 4 sources, 477 macros
[0m16:56:45.292941 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'f7ec87a3-972a-4bef-a438-c513a4664bce', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff85c8e450>]}
[0m16:56:45.294024 [info ] [MainThread]: 
[0m16:56:45.294422 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m16:56:45.297692 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list___gold'
[0m16:56:45.304356 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:56:45.667625 [info ] [ThreadPool]: dbt_clickhouse adapter: Unexpected server exception dropping table
[0m16:56:45.668127 [debug] [ThreadPool]: dbt_clickhouse adapter: On list___gold: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "connection_name": "list___gold"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = '_gold'
      

  ...
[0m16:56:45.674580 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m16:56:45.693238 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'f7ec87a3-972a-4bef-a438-c513a4664bce', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff85c9ce50>]}
[0m16:56:45.693726 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m16:56:45.694003 [info ] [MainThread]: 
[0m16:56:45.699153 [debug] [Thread-1 (]: Began running node test.movie_warehouse.not_null_dim_date_date_id.3077875806
[0m16:56:45.699577 [info ] [Thread-1 (]: 1 of 12 START test not_null_dim_date_date_id ................................... [RUN]
[0m16:56:45.699889 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list___gold, now test.movie_warehouse.not_null_dim_date_date_id.3077875806)
[0m16:56:45.700113 [debug] [Thread-1 (]: Began compiling node test.movie_warehouse.not_null_dim_date_date_id.3077875806
[0m16:56:45.707911 [debug] [Thread-1 (]: Writing injected SQL for node "test.movie_warehouse.not_null_dim_date_date_id.3077875806"
[0m16:56:45.709038 [debug] [Thread-1 (]: Began executing node test.movie_warehouse.not_null_dim_date_date_id.3077875806
[0m16:56:45.718019 [debug] [Thread-1 (]: Writing runtime sql for node "test.movie_warehouse.not_null_dim_date_date_id.3077875806"
[0m16:56:45.719092 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.movie_warehouse.not_null_dim_date_date_id.3077875806: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "test.movie_warehouse.not_null_dim_date_date_id.3077875806"} */

    
    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select date_id
from `_gold`.`dim_date`
where date_id is null



  
  
    ) dbt_internal_test...
[0m16:56:45.724489 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m16:56:45.727027 [info ] [Thread-1 (]: 1 of 12 PASS not_null_dim_date_date_id ......................................... [[32mPASS[0m in 0.03s]
[0m16:56:45.727525 [debug] [Thread-1 (]: Finished running node test.movie_warehouse.not_null_dim_date_date_id.3077875806
[0m16:56:45.727796 [debug] [Thread-1 (]: Began running node test.movie_warehouse.not_null_dim_genre_genre_id.9bb76b166c
[0m16:56:45.728088 [info ] [Thread-1 (]: 2 of 12 START test not_null_dim_genre_genre_id ................................. [RUN]
[0m16:56:45.728397 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.movie_warehouse.not_null_dim_date_date_id.3077875806, now test.movie_warehouse.not_null_dim_genre_genre_id.9bb76b166c)
[0m16:56:45.728624 [debug] [Thread-1 (]: Began compiling node test.movie_warehouse.not_null_dim_genre_genre_id.9bb76b166c
[0m16:56:45.730797 [debug] [Thread-1 (]: Writing injected SQL for node "test.movie_warehouse.not_null_dim_genre_genre_id.9bb76b166c"
[0m16:56:45.731911 [debug] [Thread-1 (]: Began executing node test.movie_warehouse.not_null_dim_genre_genre_id.9bb76b166c
[0m16:56:45.734212 [debug] [Thread-1 (]: Writing runtime sql for node "test.movie_warehouse.not_null_dim_genre_genre_id.9bb76b166c"
[0m16:56:45.735104 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.movie_warehouse.not_null_dim_genre_genre_id.9bb76b166c: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "test.movie_warehouse.not_null_dim_genre_genre_id.9bb76b166c"} */

    
    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select genre_id
from `_gold`.`dim_genre`
where genre_id is null



  
  
    ) dbt_internal_test...
[0m16:56:45.739405 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:56:45.740453 [info ] [Thread-1 (]: 2 of 12 PASS not_null_dim_genre_genre_id ....................................... [[32mPASS[0m in 0.01s]
[0m16:56:45.740788 [debug] [Thread-1 (]: Finished running node test.movie_warehouse.not_null_dim_genre_genre_id.9bb76b166c
[0m16:56:45.741030 [debug] [Thread-1 (]: Began running node test.movie_warehouse.not_null_dim_movie_movie_id.fd05907b20
[0m16:56:45.741286 [info ] [Thread-1 (]: 3 of 12 START test not_null_dim_movie_movie_id ................................. [RUN]
[0m16:56:45.741546 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.movie_warehouse.not_null_dim_genre_genre_id.9bb76b166c, now test.movie_warehouse.not_null_dim_movie_movie_id.fd05907b20)
[0m16:56:45.741817 [debug] [Thread-1 (]: Began compiling node test.movie_warehouse.not_null_dim_movie_movie_id.fd05907b20
[0m16:56:45.743976 [debug] [Thread-1 (]: Writing injected SQL for node "test.movie_warehouse.not_null_dim_movie_movie_id.fd05907b20"
[0m16:56:45.744874 [debug] [Thread-1 (]: Began executing node test.movie_warehouse.not_null_dim_movie_movie_id.fd05907b20
[0m16:56:45.746016 [debug] [Thread-1 (]: Writing runtime sql for node "test.movie_warehouse.not_null_dim_movie_movie_id.fd05907b20"
[0m16:56:45.746644 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.movie_warehouse.not_null_dim_movie_movie_id.fd05907b20: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "test.movie_warehouse.not_null_dim_movie_movie_id.fd05907b20"} */

    
    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select movie_id
from `_gold`.`dim_movie`
where movie_id is null



  
  
    ) dbt_internal_test...
[0m16:56:45.750783 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:56:45.751940 [info ] [Thread-1 (]: 3 of 12 PASS not_null_dim_movie_movie_id ....................................... [[32mPASS[0m in 0.01s]
[0m16:56:45.752335 [debug] [Thread-1 (]: Finished running node test.movie_warehouse.not_null_dim_movie_movie_id.fd05907b20
[0m16:56:45.752627 [debug] [Thread-1 (]: Began running node test.movie_warehouse.not_null_dim_production_production_id.7ff384ec2b
[0m16:56:45.752900 [info ] [Thread-1 (]: 4 of 12 START test not_null_dim_production_production_id ....................... [RUN]
[0m16:56:45.753185 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.movie_warehouse.not_null_dim_movie_movie_id.fd05907b20, now test.movie_warehouse.not_null_dim_production_production_id.7ff384ec2b)
[0m16:56:45.753406 [debug] [Thread-1 (]: Began compiling node test.movie_warehouse.not_null_dim_production_production_id.7ff384ec2b
[0m16:56:45.755799 [debug] [Thread-1 (]: Writing injected SQL for node "test.movie_warehouse.not_null_dim_production_production_id.7ff384ec2b"
[0m16:56:45.756767 [debug] [Thread-1 (]: Began executing node test.movie_warehouse.not_null_dim_production_production_id.7ff384ec2b
[0m16:56:45.758602 [debug] [Thread-1 (]: Writing runtime sql for node "test.movie_warehouse.not_null_dim_production_production_id.7ff384ec2b"
[0m16:56:45.759561 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.movie_warehouse.not_null_dim_production_production_id.7ff384ec2b: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "test.movie_warehouse.not_null_dim_production_production_id.7ff384ec2b"} */

    
    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select production_id
from `_gold`.`dim_production`
where production_id is null



  
  
    ) dbt_internal_test...
[0m16:56:45.764016 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:56:45.765132 [info ] [Thread-1 (]: 4 of 12 PASS not_null_dim_production_production_id ............................. [[32mPASS[0m in 0.01s]
[0m16:56:45.765511 [debug] [Thread-1 (]: Finished running node test.movie_warehouse.not_null_dim_production_production_id.7ff384ec2b
[0m16:56:45.765766 [debug] [Thread-1 (]: Began running node test.movie_warehouse.not_null_fact_movie_date_id.ca6e5e8ca0
[0m16:56:45.766004 [info ] [Thread-1 (]: 5 of 12 START test not_null_fact_movie_date_id ................................. [RUN]
[0m16:56:45.766238 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.movie_warehouse.not_null_dim_production_production_id.7ff384ec2b, now test.movie_warehouse.not_null_fact_movie_date_id.ca6e5e8ca0)
[0m16:56:45.766424 [debug] [Thread-1 (]: Began compiling node test.movie_warehouse.not_null_fact_movie_date_id.ca6e5e8ca0
[0m16:56:45.768569 [debug] [Thread-1 (]: Writing injected SQL for node "test.movie_warehouse.not_null_fact_movie_date_id.ca6e5e8ca0"
[0m16:56:45.769429 [debug] [Thread-1 (]: Began executing node test.movie_warehouse.not_null_fact_movie_date_id.ca6e5e8ca0
[0m16:56:45.770872 [debug] [Thread-1 (]: Writing runtime sql for node "test.movie_warehouse.not_null_fact_movie_date_id.ca6e5e8ca0"
[0m16:56:45.771693 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.movie_warehouse.not_null_fact_movie_date_id.ca6e5e8ca0: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "test.movie_warehouse.not_null_fact_movie_date_id.ca6e5e8ca0"} */

    
    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select date_id
from `_gold`.`fact_movie`
where date_id is null



  
  
    ) dbt_internal_test...
[0m16:56:45.776380 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:56:45.777596 [info ] [Thread-1 (]: 5 of 12 PASS not_null_fact_movie_date_id ....................................... [[32mPASS[0m in 0.01s]
[0m16:56:45.778035 [debug] [Thread-1 (]: Finished running node test.movie_warehouse.not_null_fact_movie_date_id.ca6e5e8ca0
[0m16:56:45.778345 [debug] [Thread-1 (]: Began running node test.movie_warehouse.not_null_fact_movie_fact_id.1f53f01729
[0m16:56:45.778644 [info ] [Thread-1 (]: 6 of 12 START test not_null_fact_movie_fact_id ................................. [RUN]
[0m16:56:45.778943 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.movie_warehouse.not_null_fact_movie_date_id.ca6e5e8ca0, now test.movie_warehouse.not_null_fact_movie_fact_id.1f53f01729)
[0m16:56:45.779195 [debug] [Thread-1 (]: Began compiling node test.movie_warehouse.not_null_fact_movie_fact_id.1f53f01729
[0m16:56:45.781670 [debug] [Thread-1 (]: Writing injected SQL for node "test.movie_warehouse.not_null_fact_movie_fact_id.1f53f01729"
[0m16:56:45.782548 [debug] [Thread-1 (]: Began executing node test.movie_warehouse.not_null_fact_movie_fact_id.1f53f01729
[0m16:56:45.783980 [debug] [Thread-1 (]: Writing runtime sql for node "test.movie_warehouse.not_null_fact_movie_fact_id.1f53f01729"
[0m16:56:45.784851 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.movie_warehouse.not_null_fact_movie_fact_id.1f53f01729: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "test.movie_warehouse.not_null_fact_movie_fact_id.1f53f01729"} */

    
    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select fact_id
from `_gold`.`fact_movie`
where fact_id is null



  
  
    ) dbt_internal_test...
[0m16:56:45.789193 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:56:45.790489 [info ] [Thread-1 (]: 6 of 12 PASS not_null_fact_movie_fact_id ....................................... [[32mPASS[0m in 0.01s]
[0m16:56:45.790932 [debug] [Thread-1 (]: Finished running node test.movie_warehouse.not_null_fact_movie_fact_id.1f53f01729
[0m16:56:45.791298 [debug] [Thread-1 (]: Began running node test.movie_warehouse.not_null_fact_movie_movie_id.115d5160ae
[0m16:56:45.791603 [info ] [Thread-1 (]: 7 of 12 START test not_null_fact_movie_movie_id ................................ [RUN]
[0m16:56:45.791895 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.movie_warehouse.not_null_fact_movie_fact_id.1f53f01729, now test.movie_warehouse.not_null_fact_movie_movie_id.115d5160ae)
[0m16:56:45.792124 [debug] [Thread-1 (]: Began compiling node test.movie_warehouse.not_null_fact_movie_movie_id.115d5160ae
[0m16:56:45.795740 [debug] [Thread-1 (]: Writing injected SQL for node "test.movie_warehouse.not_null_fact_movie_movie_id.115d5160ae"
[0m16:56:45.800310 [debug] [Thread-1 (]: Began executing node test.movie_warehouse.not_null_fact_movie_movie_id.115d5160ae
[0m16:56:45.801932 [debug] [Thread-1 (]: Writing runtime sql for node "test.movie_warehouse.not_null_fact_movie_movie_id.115d5160ae"
[0m16:56:45.802792 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.movie_warehouse.not_null_fact_movie_movie_id.115d5160ae: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "test.movie_warehouse.not_null_fact_movie_movie_id.115d5160ae"} */

    
    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select movie_id
from `_gold`.`fact_movie`
where movie_id is null



  
  
    ) dbt_internal_test...
[0m16:56:45.807092 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:56:45.808789 [info ] [Thread-1 (]: 7 of 12 PASS not_null_fact_movie_movie_id ...................................... [[32mPASS[0m in 0.02s]
[0m16:56:45.809391 [debug] [Thread-1 (]: Finished running node test.movie_warehouse.not_null_fact_movie_movie_id.115d5160ae
[0m16:56:45.809841 [debug] [Thread-1 (]: Began running node test.movie_warehouse.unique_dim_date_date_id.7286dcb90d
[0m16:56:45.810187 [info ] [Thread-1 (]: 8 of 12 START test unique_dim_date_date_id ..................................... [RUN]
[0m16:56:45.810537 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.movie_warehouse.not_null_fact_movie_movie_id.115d5160ae, now test.movie_warehouse.unique_dim_date_date_id.7286dcb90d)
[0m16:56:45.810790 [debug] [Thread-1 (]: Began compiling node test.movie_warehouse.unique_dim_date_date_id.7286dcb90d
[0m16:56:45.815447 [debug] [Thread-1 (]: Writing injected SQL for node "test.movie_warehouse.unique_dim_date_date_id.7286dcb90d"
[0m16:56:45.816301 [debug] [Thread-1 (]: Began executing node test.movie_warehouse.unique_dim_date_date_id.7286dcb90d
[0m16:56:45.870103 [debug] [Thread-1 (]: Writing runtime sql for node "test.movie_warehouse.unique_dim_date_date_id.7286dcb90d"
[0m16:56:45.871209 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.movie_warehouse.unique_dim_date_date_id.7286dcb90d: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "test.movie_warehouse.unique_dim_date_date_id.7286dcb90d"} */

    
    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    date_id as unique_field,
    count(*) as n_records

from `_gold`.`dim_date`
where date_id is not null
group by date_id
having count(*) > 1



  
  
    ) dbt_internal_test...
[0m16:56:45.889934 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m16:56:45.891315 [info ] [Thread-1 (]: 8 of 12 PASS unique_dim_date_date_id ........................................... [[32mPASS[0m in 0.08s]
[0m16:56:45.891780 [debug] [Thread-1 (]: Finished running node test.movie_warehouse.unique_dim_date_date_id.7286dcb90d
[0m16:56:45.892113 [debug] [Thread-1 (]: Began running node test.movie_warehouse.unique_dim_genre_genre_id.757304f7bc
[0m16:56:45.892398 [info ] [Thread-1 (]: 9 of 12 START test unique_dim_genre_genre_id ................................... [RUN]
[0m16:56:45.892698 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.movie_warehouse.unique_dim_date_date_id.7286dcb90d, now test.movie_warehouse.unique_dim_genre_genre_id.757304f7bc)
[0m16:56:45.892943 [debug] [Thread-1 (]: Began compiling node test.movie_warehouse.unique_dim_genre_genre_id.757304f7bc
[0m16:56:45.895134 [debug] [Thread-1 (]: Writing injected SQL for node "test.movie_warehouse.unique_dim_genre_genre_id.757304f7bc"
[0m16:56:45.895941 [debug] [Thread-1 (]: Began executing node test.movie_warehouse.unique_dim_genre_genre_id.757304f7bc
[0m16:56:45.897301 [debug] [Thread-1 (]: Writing runtime sql for node "test.movie_warehouse.unique_dim_genre_genre_id.757304f7bc"
[0m16:56:45.898019 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.movie_warehouse.unique_dim_genre_genre_id.757304f7bc: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "test.movie_warehouse.unique_dim_genre_genre_id.757304f7bc"} */

    
    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    genre_id as unique_field,
    count(*) as n_records

from `_gold`.`dim_genre`
where genre_id is not null
group by genre_id
having count(*) > 1



  
  
    ) dbt_internal_test...
[0m16:56:45.904060 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m16:56:45.905209 [info ] [Thread-1 (]: 9 of 12 PASS unique_dim_genre_genre_id ......................................... [[32mPASS[0m in 0.01s]
[0m16:56:45.905635 [debug] [Thread-1 (]: Finished running node test.movie_warehouse.unique_dim_genre_genre_id.757304f7bc
[0m16:56:45.905928 [debug] [Thread-1 (]: Began running node test.movie_warehouse.unique_dim_movie_movie_id.42054933eb
[0m16:56:45.906229 [info ] [Thread-1 (]: 10 of 12 START test unique_dim_movie_movie_id .................................. [RUN]
[0m16:56:45.906555 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.movie_warehouse.unique_dim_genre_genre_id.757304f7bc, now test.movie_warehouse.unique_dim_movie_movie_id.42054933eb)
[0m16:56:45.906817 [debug] [Thread-1 (]: Began compiling node test.movie_warehouse.unique_dim_movie_movie_id.42054933eb
[0m16:56:45.909906 [debug] [Thread-1 (]: Writing injected SQL for node "test.movie_warehouse.unique_dim_movie_movie_id.42054933eb"
[0m16:56:45.910759 [debug] [Thread-1 (]: Began executing node test.movie_warehouse.unique_dim_movie_movie_id.42054933eb
[0m16:56:45.912194 [debug] [Thread-1 (]: Writing runtime sql for node "test.movie_warehouse.unique_dim_movie_movie_id.42054933eb"
[0m16:56:45.913276 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.movie_warehouse.unique_dim_movie_movie_id.42054933eb: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "test.movie_warehouse.unique_dim_movie_movie_id.42054933eb"} */

    
    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    movie_id as unique_field,
    count(*) as n_records

from `_gold`.`dim_movie`
where movie_id is not null
group by movie_id
having count(*) > 1



  
  
    ) dbt_internal_test...
[0m16:56:45.972734 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.06 seconds
[0m16:56:45.974655 [info ] [Thread-1 (]: 10 of 12 PASS unique_dim_movie_movie_id ........................................ [[32mPASS[0m in 0.07s]
[0m16:56:45.975119 [debug] [Thread-1 (]: Finished running node test.movie_warehouse.unique_dim_movie_movie_id.42054933eb
[0m16:56:45.975409 [debug] [Thread-1 (]: Began running node test.movie_warehouse.unique_dim_production_production_id.b674858001
[0m16:56:45.975732 [info ] [Thread-1 (]: 11 of 12 START test unique_dim_production_production_id ........................ [RUN]
[0m16:56:45.976075 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.movie_warehouse.unique_dim_movie_movie_id.42054933eb, now test.movie_warehouse.unique_dim_production_production_id.b674858001)
[0m16:56:45.976395 [debug] [Thread-1 (]: Began compiling node test.movie_warehouse.unique_dim_production_production_id.b674858001
[0m16:56:45.978919 [debug] [Thread-1 (]: Writing injected SQL for node "test.movie_warehouse.unique_dim_production_production_id.b674858001"
[0m16:56:45.979951 [debug] [Thread-1 (]: Began executing node test.movie_warehouse.unique_dim_production_production_id.b674858001
[0m16:56:45.981889 [debug] [Thread-1 (]: Writing runtime sql for node "test.movie_warehouse.unique_dim_production_production_id.b674858001"
[0m16:56:45.982788 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.movie_warehouse.unique_dim_production_production_id.b674858001: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "test.movie_warehouse.unique_dim_production_production_id.b674858001"} */

    
    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    production_id as unique_field,
    count(*) as n_records

from `_gold`.`dim_production`
where production_id is not null
group by production_id
having count(*) > 1



  
  
    ) dbt_internal_test...
[0m16:56:45.997462 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m16:56:45.998737 [info ] [Thread-1 (]: 11 of 12 PASS unique_dim_production_production_id .............................. [[32mPASS[0m in 0.02s]
[0m16:56:45.999118 [debug] [Thread-1 (]: Finished running node test.movie_warehouse.unique_dim_production_production_id.b674858001
[0m16:56:45.999490 [debug] [Thread-1 (]: Began running node test.movie_warehouse.unique_fact_movie_fact_id.fbd4f040d2
[0m16:56:46.000011 [info ] [Thread-1 (]: 12 of 12 START test unique_fact_movie_fact_id .................................. [RUN]
[0m16:56:46.000464 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.movie_warehouse.unique_dim_production_production_id.b674858001, now test.movie_warehouse.unique_fact_movie_fact_id.fbd4f040d2)
[0m16:56:46.001029 [debug] [Thread-1 (]: Began compiling node test.movie_warehouse.unique_fact_movie_fact_id.fbd4f040d2
[0m16:56:46.004328 [debug] [Thread-1 (]: Writing injected SQL for node "test.movie_warehouse.unique_fact_movie_fact_id.fbd4f040d2"
[0m16:56:46.005251 [debug] [Thread-1 (]: Began executing node test.movie_warehouse.unique_fact_movie_fact_id.fbd4f040d2
[0m16:56:46.006955 [debug] [Thread-1 (]: Writing runtime sql for node "test.movie_warehouse.unique_fact_movie_fact_id.fbd4f040d2"
[0m16:56:46.008070 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.movie_warehouse.unique_fact_movie_fact_id.fbd4f040d2: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "test.movie_warehouse.unique_fact_movie_fact_id.fbd4f040d2"} */

    
    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    fact_id as unique_field,
    count(*) as n_records

from `_gold`.`fact_movie`
where fact_id is not null
group by fact_id
having count(*) > 1



  
  
    ) dbt_internal_test...
[0m16:56:46.292097 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.28 seconds
[0m16:56:46.294323 [info ] [Thread-1 (]: 12 of 12 PASS unique_fact_movie_fact_id ........................................ [[32mPASS[0m in 0.29s]
[0m16:56:46.294912 [debug] [Thread-1 (]: Finished running node test.movie_warehouse.unique_fact_movie_fact_id.fbd4f040d2
[0m16:56:46.296221 [debug] [MainThread]: Connection 'master' was properly closed.
[0m16:56:46.296529 [debug] [MainThread]: Connection 'test.movie_warehouse.unique_fact_movie_fact_id.fbd4f040d2' was left open.
[0m16:56:46.296759 [debug] [MainThread]: On test.movie_warehouse.unique_fact_movie_fact_id.fbd4f040d2: Close
[0m16:56:46.297092 [info ] [MainThread]: 
[0m16:56:46.297416 [info ] [MainThread]: Finished running 12 data tests in 0 hours 0 minutes and 1.00 seconds (1.00s).
[0m16:56:46.298427 [debug] [MainThread]: Command end result
[0m16:56:46.321916 [info ] [MainThread]: 
[0m16:56:46.322278 [info ] [MainThread]: [32mCompleted successfully[0m
[0m16:56:46.322507 [info ] [MainThread]: 
[0m16:56:46.322758 [info ] [MainThread]: Done. PASS=12 WARN=0 ERROR=0 SKIP=0 TOTAL=12
[0m16:56:46.323783 [debug] [MainThread]: Resource report: {"command_name": "test", "command_success": true, "command_wall_clock_time": 1.407645, "process_in_blocks": "84400", "process_kernel_time": 0.256778, "process_mem_max_rss": "190112", "process_out_blocks": "2342", "process_user_time": 2.478741}
[0m16:56:46.324166 [debug] [MainThread]: Command `dbt test` succeeded at 16:56:46.324097 after 1.41 seconds
[0m16:56:46.324493 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff85f67bd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff85f93750>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff7e7f8d10>]}
[0m16:56:46.324743 [debug] [MainThread]: Flushing usage events
[0m12:05:46.620358 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff9366d8d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff93a7c650>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff936a56d0>]}


============================== 12:05:46.624556 | a7f08408-21fc-4de3-8f5d-7b565422e16b ==============================
[0m12:05:46.624556 [info ] [MainThread]: Running with dbt=1.8.9
[0m12:05:46.624918 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'profiles_dir': '/opt/airflow/project_root/dbt', 'log_path': '/opt/airflow/project_root/dbt/logs', 'version_check': 'True', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'introspect': 'True', 'invocation_command': 'dbt run --project-dir /opt/airflow/project_root/dbt --profiles-dir /opt/airflow/project_root/dbt --select gold', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m12:05:46.753737 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'a7f08408-21fc-4de3-8f5d-7b565422e16b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff935fbdd0>]}
[0m12:05:46.773283 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'a7f08408-21fc-4de3-8f5d-7b565422e16b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff9406b9d0>]}
[0m12:05:46.773847 [info ] [MainThread]: Registered adapter: clickhouse=1.8.9
[0m12:05:46.810752 [debug] [MainThread]: checksum: 132857a23e9d07220246854f7763165174ce9b737cfc7867629ace4294e520b1, vars: {}, profile: , target: , version: 1.8.9
[0m12:05:46.850227 [info ] [MainThread]: Unable to do partial parsing because profile has changed
[0m12:05:46.850619 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m12:05:46.850902 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'a7f08408-21fc-4de3-8f5d-7b565422e16b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff94a9ec10>]}
[0m12:05:47.311137 [warn ] [MainThread]: [[33mWARNING[0m]: Deprecated functionality
The `tests` config has been renamed to `data_tests`. Please see
https://docs.getdbt.com/docs/build/data-tests#new-data_tests-syntax for more
information.
[0m12:05:47.311541 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'deprecation', 'label': 'a7f08408-21fc-4de3-8f5d-7b565422e16b', 'property_': 'warn', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff92d17650>]}
[0m12:05:47.397185 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'a7f08408-21fc-4de3-8f5d-7b565422e16b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff92963890>]}
[0m12:05:47.466473 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'a7f08408-21fc-4de3-8f5d-7b565422e16b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff925d3f90>]}
[0m12:05:47.467374 [info ] [MainThread]: Found 6 models, 12 data tests, 4 sources, 477 macros
[0m12:05:47.467949 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a7f08408-21fc-4de3-8f5d-7b565422e16b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff929bbc10>]}
[0m12:05:47.470277 [info ] [MainThread]: 
[0m12:05:47.471094 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m12:05:47.474023 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m12:05:47.479025 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:05:47.822950 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m12:05:47.824242 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:05:47.843863 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__gold)
[0m12:05:47.846913 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__gold: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "connection_name": "list__gold"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'gold'
      

  ...
[0m12:05:47.865928 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m12:05:47.867465 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a7f08408-21fc-4de3-8f5d-7b565422e16b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff90171a50>]}
[0m12:05:47.867908 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m12:05:47.868204 [info ] [MainThread]: 
[0m12:05:47.875473 [debug] [Thread-1 (]: Began running node model.movie_warehouse.dim_date
[0m12:05:47.876012 [info ] [Thread-1 (]: 1 of 6 START sql table model `gold`.`dim_date` ................................. [RUN]
[0m12:05:47.876384 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list__gold, now model.movie_warehouse.dim_date)
[0m12:05:47.876737 [debug] [Thread-1 (]: Began compiling node model.movie_warehouse.dim_date
[0m12:05:47.884819 [debug] [Thread-1 (]: Writing injected SQL for node "model.movie_warehouse.dim_date"
[0m12:05:47.886564 [debug] [Thread-1 (]: Began executing node model.movie_warehouse.dim_date
[0m12:05:47.896431 [debug] [Thread-1 (]: Creating new relation dim_date
[0m12:05:47.910382 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_date: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_date"} */

            

    
        create table `gold`.`dim_date`
        
  
        
  engine = MergeTree()
        order by (date_id)
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

WITH distinct_dates AS (
    SELECT DISTINCT release_date
    FROM `bronze`.`tmdb_raw`
    WHERE release_date IS NOT NULL
)

SELECT
    cityHash64(release_date)                                    AS date_id,
    release_date                                                AS full_date,
    toYear(release_date)                                        AS year,
    toMonth(release_date)                                       AS month,
    toDayOfMonth(release_date)                                  AS day,
    toISOWeek(release_date)                                     AS week,
    formatDateTime(release_date, '%a')                          AS weekday,
    CASE
        WHEN toMonth(release_date) IN (12,1,2)  THEN 'Winter'
        WHEN toMonth(release_date) IN (3,4,5)   THEN 'Spring'
        WHEN toMonth(release_date) IN (6,7,8)   THEN 'Summer'
        WHEN toMonth(release_date) IN (9,10,11) THEN 'Autumn'
    END                                                         AS season,
    CASE
        WHEN formatDateTime(release_date, '%a') IN ('Saturday','Sunday') THEN 1
        ELSE 0
    END                                                         AS is_weekend,

    /* ---------- holiday tagging ---------- */
    CASE
        WHEN toMonth(release_date)=1  AND toDayOfMonth(release_date)=1  THEN 'New Years Day'
        WHEN toMonth(release_date)=2  AND toDayOfMonth(release_date)=14 THEN 'Valentines Day'
        WHEN toMonth(release_date)=3  AND toDayOfMonth(release_date)=17 THEN 'St. Patricks Day'
        WHEN toMonth(release_date)=4  AND toDayOfMonth(release_date)=1  THEN 'April Fools Day'
        WHEN toMonth(release_date)=4  AND toDayOfMonth(release_date)=22 THEN 'Earth Day'
        WHEN toMonth(release_date)=5  AND toDayOfMonth(release_date)=1  THEN 'May Day'
        WHEN toMonth(release_date)=5  AND toDayOfMonth(release_date)=5  THEN 'Cinco de Mayo'
        WHEN toMonth(release_date)=6  AND toDayOfMonth(release_date) BETWEEN 19 AND 26 THEN 'Midsummer'
        WHEN toMonth(release_date)=7  AND toDayOfMonth(release_date)=4  THEN 'Independence Day'
        WHEN toMonth(release_date)=9  AND toDayOfMonth(release_date) BETWEEN 1 AND 7 
             AND formatDateTime(release_date,'%a')='Monday'             THEN 'Labor Day (US)'
        WHEN toMonth(release_date)=10 AND toDayOfMonth(release_date)=31 THEN 'Halloween'
        WHEN toMonth(release_date)=11 AND formatDateTime(release_date,'%a')='Thursday'
             AND toISOWeek(release_date) >= 47                           THEN 'Thanksgiving'
        WHEN toMonth(release_date)=12 AND toDayOfMonth(release_date)=24 THEN 'Christmas Eve'
        WHEN toMonth(release_date)=12 AND toDayOfMonth(release_date)=25 THEN 'Christmas Day'
        WHEN toMonth(release_date)=12 AND toDayOfMonth(release_date)=31 THEN 'New Years Eve'
        ELSE NULL
    END                                                         AS holiday_name,
    IF(holiday_name IS NOT NULL, 1, 0)                          AS is_holiday,

    /* placeholders for later enhancement */
    CAST(NULL AS Nullable(Int32)) AS days_until_holiday,
    CAST(NULL AS Nullable(Int32)) AS days_after_holiday

FROM distinct_dates
ORDER BY release_date
          )
        
        ...
[0m12:05:47.923241 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m12:05:47.930131 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_date: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_date"} */

    select name, type from system.columns where table = 'dim_date'
    
      and database = 'gold'
    
    order by position
  ...
[0m12:05:47.932036 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:05:47.934003 [debug] [Thread-1 (]: Writing runtime sql for node "model.movie_warehouse.dim_date"
[0m12:05:47.935119 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_date: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_date"} */

  
    
    
    
        
         


        insert into `gold`.`dim_date`
        ("date_id", "full_date", "year", "month", "day", "week", "weekday", "season", "is_weekend", "holiday_name", "is_holiday", "days_until_holiday", "days_after_holiday")

WITH distinct_dates AS (
    SELECT DISTINCT release_date
    FROM `bronze`.`tmdb_raw`
    WHERE release_date IS NOT NULL
)

SELECT
    cityHash64(release_date)                                    AS date_id,
    release_date                                                AS full_date,
    toYear(release_date)                                        AS year,
    toMonth(release_date)                                       AS month,
    toDayOfMonth(release_date)                                  AS day,
    toISOWeek(release_date)                                     AS week,
    formatDateTime(release_date, '%a')                          AS weekday,
    CASE
        WHEN toMonth(release_date) IN (12,1,2)  THEN 'Winter'
        WHEN toMonth(release_date) IN (3,4,5)   THEN 'Spring'
        WHEN toMonth(release_date) IN (6,7,8)   THEN 'Summer'
        WHEN toMonth(release_date) IN (9,10,11) THEN 'Autumn'
    END                                                         AS season,
    CASE
        WHEN formatDateTime(release_date, '%a') IN ('Saturday','Sunday') THEN 1
        ELSE 0
    END                                                         AS is_weekend,

    /* ---------- holiday tagging ---------- */
    CASE
        WHEN toMonth(release_date)=1  AND toDayOfMonth(release_date)=1  THEN 'New Years Day'
        WHEN toMonth(release_date)=2  AND toDayOfMonth(release_date)=14 THEN 'Valentines Day'
        WHEN toMonth(release_date)=3  AND toDayOfMonth(release_date)=17 THEN 'St. Patricks Day'
        WHEN toMonth(release_date)=4  AND toDayOfMonth(release_date)=1  THEN 'April Fools Day'
        WHEN toMonth(release_date)=4  AND toDayOfMonth(release_date)=22 THEN 'Earth Day'
        WHEN toMonth(release_date)=5  AND toDayOfMonth(release_date)=1  THEN 'May Day'
        WHEN toMonth(release_date)=5  AND toDayOfMonth(release_date)=5  THEN 'Cinco de Mayo'
        WHEN toMonth(release_date)=6  AND toDayOfMonth(release_date) BETWEEN 19 AND 26 THEN 'Midsummer'
        WHEN toMonth(release_date)=7  AND toDayOfMonth(release_date)=4  THEN 'Independence Day'
        WHEN toMonth(release_date)=9  AND toDayOfMonth(release_date) BETWEEN 1 AND 7 
             AND formatDateTime(release_date,'%a')='Monday'             THEN 'Labor Day (US)'
        WHEN toMonth(release_date)=10 AND toDayOfMonth(release_date)=31 THEN 'Halloween'
        WHEN toMonth(release_date)=11 AND formatDateTime(release_date,'%a')='Thursday'
             AND toISOWeek(release_date) >= 47                           THEN 'Thanksgiving'
        WHEN toMonth(release_date)=12 AND toDayOfMonth(release_date)=24 THEN 'Christmas Eve'
        WHEN toMonth(release_date)=12 AND toDayOfMonth(release_date)=25 THEN 'Christmas Day'
        WHEN toMonth(release_date)=12 AND toDayOfMonth(release_date)=31 THEN 'New Years Eve'
        ELSE NULL
    END                                                         AS holiday_name,
    IF(holiday_name IS NOT NULL, 1, 0)                          AS is_holiday,

    /* placeholders for later enhancement */
    CAST(NULL AS Nullable(Int32)) AS days_until_holiday,
    CAST(NULL AS Nullable(Int32)) AS days_after_holiday

FROM distinct_dates
ORDER BY release_date
  ...
[0m12:05:47.956355 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m12:05:47.965785 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a7f08408-21fc-4de3-8f5d-7b565422e16b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff5daebc50>]}
[0m12:05:47.966325 [info ] [Thread-1 (]: 1 of 6 OK created sql table model `gold`.`dim_date` ............................ [[32mOK[0m in 0.09s]
[0m12:05:47.966678 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.dim_date
[0m12:05:47.966940 [debug] [Thread-1 (]: Began running node model.movie_warehouse.dim_director
[0m12:05:47.967300 [info ] [Thread-1 (]: 2 of 6 START sql table model `gold`.`dim_director` ............................. [RUN]
[0m12:05:47.967588 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.movie_warehouse.dim_date, now model.movie_warehouse.dim_director)
[0m12:05:47.967790 [debug] [Thread-1 (]: Began compiling node model.movie_warehouse.dim_director
[0m12:05:47.970579 [debug] [Thread-1 (]: Writing injected SQL for node "model.movie_warehouse.dim_director"
[0m12:05:47.971611 [debug] [Thread-1 (]: Began executing node model.movie_warehouse.dim_director
[0m12:05:47.973212 [debug] [Thread-1 (]: Creating new relation dim_director
[0m12:05:47.973929 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_director: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_director"} */

            

    
        create table `gold`.`dim_director`
        
  
        
  engine = MergeTree()
        order by (director_id)
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

WITH first_dir AS (
    SELECT
        tconst,
        TRIM(splitByChar(',', directors)[1]) AS director_id
    FROM `bronze`.`imdb_title_crew_raw`
    WHERE directors IS NOT NULL AND directors != ''
),
deduped AS (
    SELECT DISTINCT director_id
    FROM first_dir
),
joined AS (
    SELECT
        d.director_id,
        n.primaryName AS director_name
    FROM deduped d
    LEFT JOIN `bronze`.`imdb_name_basics_raw` n
        ON d.director_id = n.nconst
)
SELECT
    cityHash64(director_id) AS imdb_dir_name_id,  -- Use hash instead of row_number
    director_id,
    director_name,
    today() AS valid_from,
    CAST(NULL AS Nullable(Date)) AS valid_to,
    1 AS is_current  -- Use 1/0 instead of TRUE/FALSE
FROM joined
WHERE director_id IS NOT NULL
ORDER BY director_id
          )
        
        ...
[0m12:05:47.979897 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m12:05:47.981418 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_director: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_director"} */

    select name, type from system.columns where table = 'dim_director'
    
      and database = 'gold'
    
    order by position
  ...
[0m12:05:47.983279 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:05:47.984201 [debug] [Thread-1 (]: Writing runtime sql for node "model.movie_warehouse.dim_director"
[0m12:05:47.985095 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_director: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_director"} */

  
    
    
    
        
         


        insert into `gold`.`dim_director`
        ("imdb_dir_name_id", "director_id", "director_name", "valid_from", "valid_to", "is_current")

WITH first_dir AS (
    SELECT
        tconst,
        TRIM(splitByChar(',', directors)[1]) AS director_id
    FROM `bronze`.`imdb_title_crew_raw`
    WHERE directors IS NOT NULL AND directors != ''
),
deduped AS (
    SELECT DISTINCT director_id
    FROM first_dir
),
joined AS (
    SELECT
        d.director_id,
        n.primaryName AS director_name
    FROM deduped d
    LEFT JOIN `bronze`.`imdb_name_basics_raw` n
        ON d.director_id = n.nconst
)
SELECT
    cityHash64(director_id) AS imdb_dir_name_id,  -- Use hash instead of row_number
    director_id,
    director_name,
    today() AS valid_from,
    CAST(NULL AS Nullable(Date)) AS valid_to,
    1 AS is_current  -- Use 1/0 instead of TRUE/FALSE
FROM joined
WHERE director_id IS NOT NULL
ORDER BY director_id
  ...
[0m12:05:49.956889 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 1.97 seconds
[0m12:05:49.966079 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a7f08408-21fc-4de3-8f5d-7b565422e16b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff5cd502d0>]}
[0m12:05:49.969121 [info ] [Thread-1 (]: 2 of 6 OK created sql table model `gold`.`dim_director` ........................ [[32mOK[0m in 2.00s]
[0m12:05:49.970138 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.dim_director
[0m12:05:49.970773 [debug] [Thread-1 (]: Began running node model.movie_warehouse.dim_genre
[0m12:05:49.971469 [info ] [Thread-1 (]: 3 of 6 START sql table model `gold`.`dim_genre` ................................ [RUN]
[0m12:05:49.971918 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.movie_warehouse.dim_director, now model.movie_warehouse.dim_genre)
[0m12:05:49.972257 [debug] [Thread-1 (]: Began compiling node model.movie_warehouse.dim_genre
[0m12:05:49.986600 [debug] [Thread-1 (]: Writing injected SQL for node "model.movie_warehouse.dim_genre"
[0m12:05:49.987941 [debug] [Thread-1 (]: Began executing node model.movie_warehouse.dim_genre
[0m12:05:49.989707 [debug] [Thread-1 (]: Creating new relation dim_genre
[0m12:05:49.990750 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_genre: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_genre"} */

            

    
        create table `gold`.`dim_genre`
        
  
        
  engine = MergeTree()
        order by (genre_id)
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

WITH parsed_genres AS (
    SELECT
        TRIM(splitByChar(',', genres)[1]) AS first_genre
    FROM `bronze`.`tmdb_raw`
    WHERE genres IS NOT NULL AND genres != ''
)
SELECT
    cityHash64(first_genre) AS genre_id,
    first_genre AS genre_name
FROM parsed_genres
GROUP BY first_genre
ORDER BY first_genre
          )
        
        ...
[0m12:05:50.007135 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m12:05:50.009203 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_genre: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_genre"} */

    select name, type from system.columns where table = 'dim_genre'
    
      and database = 'gold'
    
    order by position
  ...
[0m12:05:50.011892 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:05:50.013083 [debug] [Thread-1 (]: Writing runtime sql for node "model.movie_warehouse.dim_genre"
[0m12:05:50.014366 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_genre: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_genre"} */

  
    
    
    
        
         


        insert into `gold`.`dim_genre`
        ("genre_id", "genre_name")

WITH parsed_genres AS (
    SELECT
        TRIM(splitByChar(',', genres)[1]) AS first_genre
    FROM `bronze`.`tmdb_raw`
    WHERE genres IS NOT NULL AND genres != ''
)
SELECT
    cityHash64(first_genre) AS genre_id,
    first_genre AS genre_name
FROM parsed_genres
GROUP BY first_genre
ORDER BY first_genre
  ...
[0m12:05:50.037756 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m12:05:50.038875 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a7f08408-21fc-4de3-8f5d-7b565422e16b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff5da52d90>]}
[0m12:05:50.039303 [info ] [Thread-1 (]: 3 of 6 OK created sql table model `gold`.`dim_genre` ........................... [[32mOK[0m in 0.07s]
[0m12:05:50.039647 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.dim_genre
[0m12:05:50.039904 [debug] [Thread-1 (]: Began running node model.movie_warehouse.dim_movie
[0m12:05:50.040281 [info ] [Thread-1 (]: 4 of 6 START sql table model `gold`.`dim_movie` ................................ [RUN]
[0m12:05:50.040524 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.movie_warehouse.dim_genre, now model.movie_warehouse.dim_movie)
[0m12:05:50.040751 [debug] [Thread-1 (]: Began compiling node model.movie_warehouse.dim_movie
[0m12:05:50.042558 [debug] [Thread-1 (]: Writing injected SQL for node "model.movie_warehouse.dim_movie"
[0m12:05:50.043174 [debug] [Thread-1 (]: Began executing node model.movie_warehouse.dim_movie
[0m12:05:50.044390 [debug] [Thread-1 (]: Creating new relation dim_movie
[0m12:05:50.044951 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_movie: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_movie"} */

            

    
        create table `gold`.`dim_movie`
        
  
        
  engine = MergeTree()
        order by (movie_id)
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

WITH movie_src AS (
    SELECT
        TRIM(title) AS movie_title,
        imdb_id,
        release_date,
        runtime AS movie_runtime,
        original_language AS language
    FROM `bronze`.`tmdb_raw`
    WHERE title IS NOT NULL AND title != ''
)
SELECT
    cityHash64(movie_title) AS movie_id,
    any(imdb_id) AS imdb_id,
    movie_title,
    any(release_date) AS release_date,
    any(movie_runtime) AS movie_runtime,
    any(language) AS language
FROM movie_src
GROUP BY movie_title
ORDER BY movie_title
          )
        
        ...
[0m12:05:50.050572 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m12:05:50.051999 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_movie: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_movie"} */

    select name, type from system.columns where table = 'dim_movie'
    
      and database = 'gold'
    
    order by position
  ...
[0m12:05:50.053647 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:05:50.054737 [debug] [Thread-1 (]: Writing runtime sql for node "model.movie_warehouse.dim_movie"
[0m12:05:50.055636 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_movie: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_movie"} */

  
    
    
    
        
         


        insert into `gold`.`dim_movie`
        ("movie_id", "imdb_id", "movie_title", "release_date", "movie_runtime", "language")

WITH movie_src AS (
    SELECT
        TRIM(title) AS movie_title,
        imdb_id,
        release_date,
        runtime AS movie_runtime,
        original_language AS language
    FROM `bronze`.`tmdb_raw`
    WHERE title IS NOT NULL AND title != ''
)
SELECT
    cityHash64(movie_title) AS movie_id,
    any(imdb_id) AS imdb_id,
    movie_title,
    any(release_date) AS release_date,
    any(movie_runtime) AS movie_runtime,
    any(language) AS language
FROM movie_src
GROUP BY movie_title
ORDER BY movie_title
  ...
[0m12:05:50.155344 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.10 seconds
[0m12:05:50.156666 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a7f08408-21fc-4de3-8f5d-7b565422e16b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff5cdc3f90>]}
[0m12:05:50.157103 [info ] [Thread-1 (]: 4 of 6 OK created sql table model `gold`.`dim_movie` ........................... [[32mOK[0m in 0.12s]
[0m12:05:50.157547 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.dim_movie
[0m12:05:50.157858 [debug] [Thread-1 (]: Began running node model.movie_warehouse.dim_production
[0m12:05:50.158262 [info ] [Thread-1 (]: 5 of 6 START sql table model `gold`.`dim_production` ........................... [RUN]
[0m12:05:50.158552 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.movie_warehouse.dim_movie, now model.movie_warehouse.dim_production)
[0m12:05:50.158868 [debug] [Thread-1 (]: Began compiling node model.movie_warehouse.dim_production
[0m12:05:50.160709 [debug] [Thread-1 (]: Writing injected SQL for node "model.movie_warehouse.dim_production"
[0m12:05:50.161722 [debug] [Thread-1 (]: Began executing node model.movie_warehouse.dim_production
[0m12:05:50.164693 [debug] [Thread-1 (]: Creating new relation dim_production
[0m12:05:50.165389 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_production: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_production"} */

            

    
        create table `gold`.`dim_production`
        
  
        
  engine = MergeTree()
        order by (production_id)
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

WITH production_list AS (
    SELECT TRIM(splitByChar(',', production_companies)[1]) AS production_name
    FROM `bronze`.`tmdb_raw`
    WHERE production_companies IS NOT NULL AND production_companies != ''
)

SELECT
    cityHash64(production_name) AS production_id,
    production_name,
    current_date() AS valid_from,
    CAST(NULL AS Nullable(Date)) AS valid_to,
    TRUE AS is_current
FROM (
    SELECT DISTINCT production_name
    FROM production_list
)
WHERE production_name IS NOT NULL AND production_name != ''
          )
        
        ...
[0m12:05:50.170999 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m12:05:50.172322 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_production: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_production"} */

    select name, type from system.columns where table = 'dim_production'
    
      and database = 'gold'
    
    order by position
  ...
[0m12:05:50.174141 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:05:50.175060 [debug] [Thread-1 (]: Writing runtime sql for node "model.movie_warehouse.dim_production"
[0m12:05:50.176002 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.dim_production: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.dim_production"} */

  
    
    
    
        
         


        insert into `gold`.`dim_production`
        ("production_id", "production_name", "valid_from", "valid_to", "is_current")

WITH production_list AS (
    SELECT TRIM(splitByChar(',', production_companies)[1]) AS production_name
    FROM `bronze`.`tmdb_raw`
    WHERE production_companies IS NOT NULL AND production_companies != ''
)

SELECT
    cityHash64(production_name) AS production_id,
    production_name,
    current_date() AS valid_from,
    CAST(NULL AS Nullable(Date)) AS valid_to,
    TRUE AS is_current
FROM (
    SELECT DISTINCT production_name
    FROM production_list
)
WHERE production_name IS NOT NULL AND production_name != ''
  ...
[0m12:05:50.200980 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m12:05:50.202127 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a7f08408-21fc-4de3-8f5d-7b565422e16b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff5cdc2c50>]}
[0m12:05:50.202576 [info ] [Thread-1 (]: 5 of 6 OK created sql table model `gold`.`dim_production` ...................... [[32mOK[0m in 0.04s]
[0m12:05:50.202958 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.dim_production
[0m12:05:50.204358 [debug] [Thread-1 (]: Began running node model.movie_warehouse.fact_movie_performance
[0m12:05:50.204678 [info ] [Thread-1 (]: 6 of 6 START sql table model `gold`.`fact_movie_performance` ................... [RUN]
[0m12:05:50.205048 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.movie_warehouse.dim_production, now model.movie_warehouse.fact_movie_performance)
[0m12:05:50.205293 [debug] [Thread-1 (]: Began compiling node model.movie_warehouse.fact_movie_performance
[0m12:05:50.207864 [debug] [Thread-1 (]: Writing injected SQL for node "model.movie_warehouse.fact_movie_performance"
[0m12:05:50.208788 [debug] [Thread-1 (]: Began executing node model.movie_warehouse.fact_movie_performance
[0m12:05:50.209921 [debug] [Thread-1 (]: Creating new relation fact_movie_performance
[0m12:05:50.210611 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.fact_movie_performance: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.fact_movie_performance"} */

            

    
        create table `gold`.`fact_movie_performance`
        
  
        
  engine = MergeTree()
        order by (fact_id)
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

WITH filtered_tmdb AS (
    SELECT 
        imdb_id,
        title,
        release_date,
        production_companies,
        budget,
        revenue,
        vote_average,
        vote_count,
        runtime,
        genres,
        original_language,
        
        (vote_average * log(1 + vote_count)) AS movie_popularity
    FROM `bronze`.`tmdb_raw`
),

-- First genre
first_genre AS (
    SELECT
        imdb_id AS movie_id,
        trim(splitByChar(',', genres)[1]) AS genre_name
    FROM filtered_tmdb
),

-- First director
first_director AS (
    SELECT
        t.imdb_id AS movie_id,
        trim(splitByChar(',', c.directors)[1]) AS director_id
    FROM filtered_tmdb t
    LEFT JOIN `bronze`.`imdb_title_crew_raw` c
        ON t.imdb_id = c.tconst
),

-- Join to dim_production to get production_id
movie_production AS (
    SELECT
        t.imdb_id AS movie_id,
        p.production_id
    FROM filtered_tmdb t
    LEFT JOIN `gold`.`dim_production` p
        ON trim(splitByChar(',', t.production_companies)[1]) = p.production_name
),

-- Map genre_name to dim_genre to get genre_id
movie_genre AS (
    SELECT
        fg.movie_id,
        g.genre_id
    FROM first_genre fg
    LEFT JOIN `gold`.`dim_genre` g
        ON fg.genre_name = g.genre_name
),

base AS (
    SELECT
        t.imdb_id,
        d.director_id,
        mg.genre_id,
        mp.production_id,
        dr.date_id                                AS date_id,
        t.vote_average                            AS vote_avg,
        t.vote_count,
        t.title,
        t.revenue,
        t.budget,
        t.movie_popularity,
        toYear(t.release_date)                    AS release_year
    FROM filtered_tmdb t
    LEFT JOIN movie_genre mg       ON mg.movie_id = t.imdb_id
    LEFT JOIN first_director d     ON d.movie_id = t.imdb_id
    LEFT JOIN movie_production mp  ON mp.movie_id = t.imdb_id
    LEFT JOIN `gold`.`dim_date` dr
        ON dr.full_date = t.release_date
),

metrics AS (
    SELECT
        b.*,
        b.revenue - lag(b.revenue, 1) OVER (PARTITION BY b.imdb_id ORDER BY b.release_year) AS revenue_growth,
        b.movie_popularity - lag(b.movie_popularity, 1) OVER (PARTITION BY b.imdb_id ORDER BY b.release_year) AS popularity_change,
        b.vote_avg - lag(b.vote_avg, 1) OVER (PARTITION BY b.imdb_id ORDER BY b.release_year) AS vote_avg_change
    FROM base b
)

SELECT
    row_number() OVER (ORDER BY imdb_id, date_id, director_id, genre_id) AS fact_id,
    cityHash64(TRIM(title)) AS movie_id,
    imdb_id,
    director_id,
    genre_id,
    production_id,
    date_id,
    vote_avg,
    vote_count,
    revenue,
    budget,
    movie_popularity,
    revenue_growth,
    popularity_change,
    vote_avg_change
FROM metrics
          )
        
        ...
[0m12:05:50.223935 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m12:05:50.225440 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.fact_movie_performance: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.fact_movie_performance"} */

    select name, type from system.columns where table = 'fact_movie_performance'
    
      and database = 'gold'
    
    order by position
  ...
[0m12:05:50.227069 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:05:50.228328 [debug] [Thread-1 (]: Writing runtime sql for node "model.movie_warehouse.fact_movie_performance"
[0m12:05:50.229251 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.movie_warehouse.fact_movie_performance: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "model.movie_warehouse.fact_movie_performance"} */

  
    
    
    
        
         


        insert into `gold`.`fact_movie_performance`
        ("fact_id", "movie_id", "imdb_id", "director_id", "genre_id", "production_id", "date_id", "vote_avg", "vote_count", "revenue", "budget", "movie_popularity", "revenue_growth", "popularity_change", "vote_avg_change")

WITH filtered_tmdb AS (
    SELECT 
        imdb_id,
        title,
        release_date,
        production_companies,
        budget,
        revenue,
        vote_average,
        vote_count,
        runtime,
        genres,
        original_language,
        
        (vote_average * log(1 + vote_count)) AS movie_popularity
    FROM `bronze`.`tmdb_raw`
),

-- First genre
first_genre AS (
    SELECT
        imdb_id AS movie_id,
        trim(splitByChar(',', genres)[1]) AS genre_name
    FROM filtered_tmdb
),

-- First director
first_director AS (
    SELECT
        t.imdb_id AS movie_id,
        trim(splitByChar(',', c.directors)[1]) AS director_id
    FROM filtered_tmdb t
    LEFT JOIN `bronze`.`imdb_title_crew_raw` c
        ON t.imdb_id = c.tconst
),

-- Join to dim_production to get production_id
movie_production AS (
    SELECT
        t.imdb_id AS movie_id,
        p.production_id
    FROM filtered_tmdb t
    LEFT JOIN `gold`.`dim_production` p
        ON trim(splitByChar(',', t.production_companies)[1]) = p.production_name
),

-- Map genre_name to dim_genre to get genre_id
movie_genre AS (
    SELECT
        fg.movie_id,
        g.genre_id
    FROM first_genre fg
    LEFT JOIN `gold`.`dim_genre` g
        ON fg.genre_name = g.genre_name
),

base AS (
    SELECT
        t.imdb_id,
        d.director_id,
        mg.genre_id,
        mp.production_id,
        dr.date_id                                AS date_id,
        t.vote_average                            AS vote_avg,
        t.vote_count,
        t.title,
        t.revenue,
        t.budget,
        t.movie_popularity,
        toYear(t.release_date)                    AS release_year
    FROM filtered_tmdb t
    LEFT JOIN movie_genre mg       ON mg.movie_id = t.imdb_id
    LEFT JOIN first_director d     ON d.movie_id = t.imdb_id
    LEFT JOIN movie_production mp  ON mp.movie_id = t.imdb_id
    LEFT JOIN `gold`.`dim_date` dr
        ON dr.full_date = t.release_date
),

metrics AS (
    SELECT
        b.*,
        b.revenue - lag(b.revenue, 1) OVER (PARTITION BY b.imdb_id ORDER BY b.release_year) AS revenue_growth,
        b.movie_popularity - lag(b.movie_popularity, 1) OVER (PARTITION BY b.imdb_id ORDER BY b.release_year) AS popularity_change,
        b.vote_avg - lag(b.vote_avg, 1) OVER (PARTITION BY b.imdb_id ORDER BY b.release_year) AS vote_avg_change
    FROM base b
)

SELECT
    row_number() OVER (ORDER BY imdb_id, date_id, director_id, genre_id) AS fact_id,
    cityHash64(TRIM(title)) AS movie_id,
    imdb_id,
    director_id,
    genre_id,
    production_id,
    date_id,
    vote_avg,
    vote_count,
    revenue,
    budget,
    movie_popularity,
    revenue_growth,
    popularity_change,
    vote_avg_change
FROM metrics
  ...
[0m12:05:50.518335 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.29 seconds
[0m12:05:50.520732 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a7f08408-21fc-4de3-8f5d-7b565422e16b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff5cdb4610>]}
[0m12:05:50.521744 [info ] [Thread-1 (]: 6 of 6 OK created sql table model `gold`.`fact_movie_performance` .............. [[32mOK[0m in 0.32s]
[0m12:05:50.522422 [debug] [Thread-1 (]: Finished running node model.movie_warehouse.fact_movie_performance
[0m12:05:50.524304 [debug] [MainThread]: Connection 'master' was properly closed.
[0m12:05:50.524679 [debug] [MainThread]: Connection 'model.movie_warehouse.fact_movie_performance' was left open.
[0m12:05:50.524973 [debug] [MainThread]: On model.movie_warehouse.fact_movie_performance: Close
[0m12:05:50.525753 [info ] [MainThread]: 
[0m12:05:50.526151 [info ] [MainThread]: Finished running 6 table models in 0 hours 0 minutes and 3.05 seconds (3.05s).
[0m12:05:50.526943 [debug] [MainThread]: Command end result
[0m12:05:50.556716 [info ] [MainThread]: 
[0m12:05:50.557111 [info ] [MainThread]: [32mCompleted successfully[0m
[0m12:05:50.557354 [info ] [MainThread]: 
[0m12:05:50.557628 [info ] [MainThread]: Done. PASS=6 WARN=0 ERROR=0 SKIP=0 TOTAL=6
[0m12:05:50.560956 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 3.9754238, "process_in_blocks": "117592", "process_kernel_time": 0.320362, "process_mem_max_rss": "195560", "process_out_blocks": "4932", "process_user_time": 2.739099}
[0m12:05:50.561565 [debug] [MainThread]: Command `dbt run` succeeded at 12:05:50.561494 after 3.98 seconds
[0m12:05:50.561972 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff983b5d10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff5cd2aa10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff984ed8d0>]}
[0m12:05:50.562204 [debug] [MainThread]: Flushing usage events
[0m12:05:53.355831 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff9dab0c10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff9dab1150>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff9dab0dd0>]}


============================== 12:05:53.359048 | 7dcb3faf-0582-44a1-a30d-aa72c37735fc ==============================
[0m12:05:53.359048 [info ] [MainThread]: Running with dbt=1.8.9
[0m12:05:53.359387 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/project_root/dbt', 'debug': 'False', 'fail_fast': 'False', 'log_path': '/opt/airflow/project_root/dbt/logs', 'warn_error': 'None', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'invocation_command': 'dbt test --project-dir /opt/airflow/project_root/dbt --profiles-dir /opt/airflow/project_root/dbt --select gold', 'static_parser': 'True', 'introspect': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m12:05:53.427607 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '7dcb3faf-0582-44a1-a30d-aa72c37735fc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff9dd94b10>]}
[0m12:05:53.446329 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '7dcb3faf-0582-44a1-a30d-aa72c37735fc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff9e4df190>]}
[0m12:05:53.446757 [info ] [MainThread]: Registered adapter: clickhouse=1.8.9
[0m12:05:53.478974 [debug] [MainThread]: checksum: 132857a23e9d07220246854f7763165174ce9b737cfc7867629ace4294e520b1, vars: {}, profile: , target: , version: 1.8.9
[0m12:05:53.529052 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m12:05:53.529362 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m12:05:53.547279 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '7dcb3faf-0582-44a1-a30d-aa72c37735fc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff9d6f6ad0>]}
[0m12:05:53.601109 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '7dcb3faf-0582-44a1-a30d-aa72c37735fc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff9d54d9d0>]}
[0m12:05:53.601462 [info ] [MainThread]: Found 6 models, 12 data tests, 4 sources, 477 macros
[0m12:05:53.601681 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '7dcb3faf-0582-44a1-a30d-aa72c37735fc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff9d79b390>]}
[0m12:05:53.602619 [info ] [MainThread]: 
[0m12:05:53.602974 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m12:05:53.605693 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list__gold'
[0m12:05:53.611519 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:05:53.830266 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__gold: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "connection_name": "list__gold"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'gold'
      

  ...
[0m12:05:53.833754 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:05:53.847267 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '7dcb3faf-0582-44a1-a30d-aa72c37735fc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff7467da90>]}
[0m12:05:53.847701 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m12:05:53.848215 [info ] [MainThread]: 
[0m12:05:53.853678 [debug] [Thread-1 (]: Began running node test.movie_warehouse.not_null_dim_date_date_id.3077875806
[0m12:05:53.854095 [info ] [Thread-1 (]: 1 of 12 START test not_null_dim_date_date_id ................................... [RUN]
[0m12:05:53.854491 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list__gold, now test.movie_warehouse.not_null_dim_date_date_id.3077875806)
[0m12:05:53.854788 [debug] [Thread-1 (]: Began compiling node test.movie_warehouse.not_null_dim_date_date_id.3077875806
[0m12:05:53.861776 [debug] [Thread-1 (]: Writing injected SQL for node "test.movie_warehouse.not_null_dim_date_date_id.3077875806"
[0m12:05:53.863430 [debug] [Thread-1 (]: Began executing node test.movie_warehouse.not_null_dim_date_date_id.3077875806
[0m12:05:53.870883 [debug] [Thread-1 (]: Writing runtime sql for node "test.movie_warehouse.not_null_dim_date_date_id.3077875806"
[0m12:05:53.871917 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.movie_warehouse.not_null_dim_date_date_id.3077875806: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "test.movie_warehouse.not_null_dim_date_date_id.3077875806"} */

    
    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select date_id
from `gold`.`dim_date`
where date_id is null



  
  
    ) dbt_internal_test...
[0m12:05:53.876709 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:05:53.879030 [info ] [Thread-1 (]: 1 of 12 PASS not_null_dim_date_date_id ......................................... [[32mPASS[0m in 0.02s]
[0m12:05:53.879400 [debug] [Thread-1 (]: Finished running node test.movie_warehouse.not_null_dim_date_date_id.3077875806
[0m12:05:53.879676 [debug] [Thread-1 (]: Began running node test.movie_warehouse.not_null_dim_genre_genre_id.9bb76b166c
[0m12:05:53.879942 [info ] [Thread-1 (]: 2 of 12 START test not_null_dim_genre_genre_id ................................. [RUN]
[0m12:05:53.880217 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.movie_warehouse.not_null_dim_date_date_id.3077875806, now test.movie_warehouse.not_null_dim_genre_genre_id.9bb76b166c)
[0m12:05:53.880429 [debug] [Thread-1 (]: Began compiling node test.movie_warehouse.not_null_dim_genre_genre_id.9bb76b166c
[0m12:05:53.882327 [debug] [Thread-1 (]: Writing injected SQL for node "test.movie_warehouse.not_null_dim_genre_genre_id.9bb76b166c"
[0m12:05:53.882889 [debug] [Thread-1 (]: Began executing node test.movie_warehouse.not_null_dim_genre_genre_id.9bb76b166c
[0m12:05:53.884565 [debug] [Thread-1 (]: Writing runtime sql for node "test.movie_warehouse.not_null_dim_genre_genre_id.9bb76b166c"
[0m12:05:53.885107 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.movie_warehouse.not_null_dim_genre_genre_id.9bb76b166c: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "test.movie_warehouse.not_null_dim_genre_genre_id.9bb76b166c"} */

    
    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select genre_id
from `gold`.`dim_genre`
where genre_id is null



  
  
    ) dbt_internal_test...
[0m12:05:53.887595 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:05:53.888490 [info ] [Thread-1 (]: 2 of 12 PASS not_null_dim_genre_genre_id ....................................... [[32mPASS[0m in 0.01s]
[0m12:05:53.888796 [debug] [Thread-1 (]: Finished running node test.movie_warehouse.not_null_dim_genre_genre_id.9bb76b166c
[0m12:05:53.889026 [debug] [Thread-1 (]: Began running node test.movie_warehouse.not_null_dim_movie_movie_id.fd05907b20
[0m12:05:53.889247 [info ] [Thread-1 (]: 3 of 12 START test not_null_dim_movie_movie_id ................................. [RUN]
[0m12:05:53.889472 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.movie_warehouse.not_null_dim_genre_genre_id.9bb76b166c, now test.movie_warehouse.not_null_dim_movie_movie_id.fd05907b20)
[0m12:05:53.889705 [debug] [Thread-1 (]: Began compiling node test.movie_warehouse.not_null_dim_movie_movie_id.fd05907b20
[0m12:05:53.891635 [debug] [Thread-1 (]: Writing injected SQL for node "test.movie_warehouse.not_null_dim_movie_movie_id.fd05907b20"
[0m12:05:53.892244 [debug] [Thread-1 (]: Began executing node test.movie_warehouse.not_null_dim_movie_movie_id.fd05907b20
[0m12:05:53.893314 [debug] [Thread-1 (]: Writing runtime sql for node "test.movie_warehouse.not_null_dim_movie_movie_id.fd05907b20"
[0m12:05:53.893916 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.movie_warehouse.not_null_dim_movie_movie_id.fd05907b20: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "test.movie_warehouse.not_null_dim_movie_movie_id.fd05907b20"} */

    
    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select movie_id
from `gold`.`dim_movie`
where movie_id is null



  
  
    ) dbt_internal_test...
[0m12:05:53.896603 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:05:53.897578 [info ] [Thread-1 (]: 3 of 12 PASS not_null_dim_movie_movie_id ....................................... [[32mPASS[0m in 0.01s]
[0m12:05:53.897900 [debug] [Thread-1 (]: Finished running node test.movie_warehouse.not_null_dim_movie_movie_id.fd05907b20
[0m12:05:53.898171 [debug] [Thread-1 (]: Began running node test.movie_warehouse.not_null_dim_production_production_id.7ff384ec2b
[0m12:05:53.898401 [info ] [Thread-1 (]: 4 of 12 START test not_null_dim_production_production_id ....................... [RUN]
[0m12:05:53.898624 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.movie_warehouse.not_null_dim_movie_movie_id.fd05907b20, now test.movie_warehouse.not_null_dim_production_production_id.7ff384ec2b)
[0m12:05:53.898805 [debug] [Thread-1 (]: Began compiling node test.movie_warehouse.not_null_dim_production_production_id.7ff384ec2b
[0m12:05:53.900658 [debug] [Thread-1 (]: Writing injected SQL for node "test.movie_warehouse.not_null_dim_production_production_id.7ff384ec2b"
[0m12:05:53.901264 [debug] [Thread-1 (]: Began executing node test.movie_warehouse.not_null_dim_production_production_id.7ff384ec2b
[0m12:05:53.902322 [debug] [Thread-1 (]: Writing runtime sql for node "test.movie_warehouse.not_null_dim_production_production_id.7ff384ec2b"
[0m12:05:53.902871 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.movie_warehouse.not_null_dim_production_production_id.7ff384ec2b: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "test.movie_warehouse.not_null_dim_production_production_id.7ff384ec2b"} */

    
    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select production_id
from `gold`.`dim_production`
where production_id is null



  
  
    ) dbt_internal_test...
[0m12:05:53.905601 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:05:53.907558 [info ] [Thread-1 (]: 4 of 12 PASS not_null_dim_production_production_id ............................. [[32mPASS[0m in 0.01s]
[0m12:05:53.908626 [debug] [Thread-1 (]: Finished running node test.movie_warehouse.not_null_dim_production_production_id.7ff384ec2b
[0m12:05:53.909347 [debug] [Thread-1 (]: Began running node test.movie_warehouse.not_null_fact_movie_performance_date_id.1563eff3c1
[0m12:05:53.910102 [info ] [Thread-1 (]: 5 of 12 START test not_null_fact_movie_performance_date_id ..................... [RUN]
[0m12:05:53.910844 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.movie_warehouse.not_null_dim_production_production_id.7ff384ec2b, now test.movie_warehouse.not_null_fact_movie_performance_date_id.1563eff3c1)
[0m12:05:53.911350 [debug] [Thread-1 (]: Began compiling node test.movie_warehouse.not_null_fact_movie_performance_date_id.1563eff3c1
[0m12:05:53.913612 [debug] [Thread-1 (]: Writing injected SQL for node "test.movie_warehouse.not_null_fact_movie_performance_date_id.1563eff3c1"
[0m12:05:53.915608 [debug] [Thread-1 (]: Began executing node test.movie_warehouse.not_null_fact_movie_performance_date_id.1563eff3c1
[0m12:05:53.916912 [debug] [Thread-1 (]: Writing runtime sql for node "test.movie_warehouse.not_null_fact_movie_performance_date_id.1563eff3c1"
[0m12:05:53.917571 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.movie_warehouse.not_null_fact_movie_performance_date_id.1563eff3c1: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "test.movie_warehouse.not_null_fact_movie_performance_date_id.1563eff3c1"} */

    
    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select date_id
from `gold`.`fact_movie_performance`
where date_id is null



  
  
    ) dbt_internal_test...
[0m12:05:53.920202 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:05:53.921096 [info ] [Thread-1 (]: 5 of 12 PASS not_null_fact_movie_performance_date_id ........................... [[32mPASS[0m in 0.01s]
[0m12:05:53.921393 [debug] [Thread-1 (]: Finished running node test.movie_warehouse.not_null_fact_movie_performance_date_id.1563eff3c1
[0m12:05:53.921640 [debug] [Thread-1 (]: Began running node test.movie_warehouse.not_null_fact_movie_performance_fact_id.7c496e1169
[0m12:05:53.921850 [info ] [Thread-1 (]: 6 of 12 START test not_null_fact_movie_performance_fact_id ..................... [RUN]
[0m12:05:53.922083 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.movie_warehouse.not_null_fact_movie_performance_date_id.1563eff3c1, now test.movie_warehouse.not_null_fact_movie_performance_fact_id.7c496e1169)
[0m12:05:53.922259 [debug] [Thread-1 (]: Began compiling node test.movie_warehouse.not_null_fact_movie_performance_fact_id.7c496e1169
[0m12:05:53.924017 [debug] [Thread-1 (]: Writing injected SQL for node "test.movie_warehouse.not_null_fact_movie_performance_fact_id.7c496e1169"
[0m12:05:53.924634 [debug] [Thread-1 (]: Began executing node test.movie_warehouse.not_null_fact_movie_performance_fact_id.7c496e1169
[0m12:05:53.925659 [debug] [Thread-1 (]: Writing runtime sql for node "test.movie_warehouse.not_null_fact_movie_performance_fact_id.7c496e1169"
[0m12:05:53.926246 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.movie_warehouse.not_null_fact_movie_performance_fact_id.7c496e1169: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "test.movie_warehouse.not_null_fact_movie_performance_fact_id.7c496e1169"} */

    
    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select fact_id
from `gold`.`fact_movie_performance`
where fact_id is null



  
  
    ) dbt_internal_test...
[0m12:05:53.928795 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:05:53.929661 [info ] [Thread-1 (]: 6 of 12 PASS not_null_fact_movie_performance_fact_id ........................... [[32mPASS[0m in 0.01s]
[0m12:05:53.929959 [debug] [Thread-1 (]: Finished running node test.movie_warehouse.not_null_fact_movie_performance_fact_id.7c496e1169
[0m12:05:53.930181 [debug] [Thread-1 (]: Began running node test.movie_warehouse.not_null_fact_movie_performance_movie_id.7f2724a0c4
[0m12:05:53.930390 [info ] [Thread-1 (]: 7 of 12 START test not_null_fact_movie_performance_movie_id .................... [RUN]
[0m12:05:53.930597 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.movie_warehouse.not_null_fact_movie_performance_fact_id.7c496e1169, now test.movie_warehouse.not_null_fact_movie_performance_movie_id.7f2724a0c4)
[0m12:05:53.930770 [debug] [Thread-1 (]: Began compiling node test.movie_warehouse.not_null_fact_movie_performance_movie_id.7f2724a0c4
[0m12:05:53.932586 [debug] [Thread-1 (]: Writing injected SQL for node "test.movie_warehouse.not_null_fact_movie_performance_movie_id.7f2724a0c4"
[0m12:05:53.933522 [debug] [Thread-1 (]: Began executing node test.movie_warehouse.not_null_fact_movie_performance_movie_id.7f2724a0c4
[0m12:05:53.934477 [debug] [Thread-1 (]: Writing runtime sql for node "test.movie_warehouse.not_null_fact_movie_performance_movie_id.7f2724a0c4"
[0m12:05:53.935112 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.movie_warehouse.not_null_fact_movie_performance_movie_id.7f2724a0c4: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "test.movie_warehouse.not_null_fact_movie_performance_movie_id.7f2724a0c4"} */

    
    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select movie_id
from `gold`.`fact_movie_performance`
where movie_id is null



  
  
    ) dbt_internal_test...
[0m12:05:53.937261 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:05:53.938135 [info ] [Thread-1 (]: 7 of 12 PASS not_null_fact_movie_performance_movie_id .......................... [[32mPASS[0m in 0.01s]
[0m12:05:53.938494 [debug] [Thread-1 (]: Finished running node test.movie_warehouse.not_null_fact_movie_performance_movie_id.7f2724a0c4
[0m12:05:53.938709 [debug] [Thread-1 (]: Began running node test.movie_warehouse.unique_dim_date_date_id.7286dcb90d
[0m12:05:53.938915 [info ] [Thread-1 (]: 8 of 12 START test unique_dim_date_date_id ..................................... [RUN]
[0m12:05:53.939136 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.movie_warehouse.not_null_fact_movie_performance_movie_id.7f2724a0c4, now test.movie_warehouse.unique_dim_date_date_id.7286dcb90d)
[0m12:05:53.939313 [debug] [Thread-1 (]: Began compiling node test.movie_warehouse.unique_dim_date_date_id.7286dcb90d
[0m12:05:53.942777 [debug] [Thread-1 (]: Writing injected SQL for node "test.movie_warehouse.unique_dim_date_date_id.7286dcb90d"
[0m12:05:53.943395 [debug] [Thread-1 (]: Began executing node test.movie_warehouse.unique_dim_date_date_id.7286dcb90d
[0m12:05:53.976593 [debug] [Thread-1 (]: Writing runtime sql for node "test.movie_warehouse.unique_dim_date_date_id.7286dcb90d"
[0m12:05:53.977487 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.movie_warehouse.unique_dim_date_date_id.7286dcb90d: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "test.movie_warehouse.unique_dim_date_date_id.7286dcb90d"} */

    
    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    date_id as unique_field,
    count(*) as n_records

from `gold`.`dim_date`
where date_id is not null
group by date_id
having count(*) > 1



  
  
    ) dbt_internal_test...
[0m12:05:53.983186 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m12:05:53.984066 [info ] [Thread-1 (]: 8 of 12 PASS unique_dim_date_date_id ........................................... [[32mPASS[0m in 0.04s]
[0m12:05:53.984384 [debug] [Thread-1 (]: Finished running node test.movie_warehouse.unique_dim_date_date_id.7286dcb90d
[0m12:05:53.984644 [debug] [Thread-1 (]: Began running node test.movie_warehouse.unique_dim_genre_genre_id.757304f7bc
[0m12:05:53.984905 [info ] [Thread-1 (]: 9 of 12 START test unique_dim_genre_genre_id ................................... [RUN]
[0m12:05:53.985134 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.movie_warehouse.unique_dim_date_date_id.7286dcb90d, now test.movie_warehouse.unique_dim_genre_genre_id.757304f7bc)
[0m12:05:53.985314 [debug] [Thread-1 (]: Began compiling node test.movie_warehouse.unique_dim_genre_genre_id.757304f7bc
[0m12:05:53.986975 [debug] [Thread-1 (]: Writing injected SQL for node "test.movie_warehouse.unique_dim_genre_genre_id.757304f7bc"
[0m12:05:53.987471 [debug] [Thread-1 (]: Began executing node test.movie_warehouse.unique_dim_genre_genre_id.757304f7bc
[0m12:05:53.988433 [debug] [Thread-1 (]: Writing runtime sql for node "test.movie_warehouse.unique_dim_genre_genre_id.757304f7bc"
[0m12:05:53.988909 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.movie_warehouse.unique_dim_genre_genre_id.757304f7bc: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "test.movie_warehouse.unique_dim_genre_genre_id.757304f7bc"} */

    
    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    genre_id as unique_field,
    count(*) as n_records

from `gold`.`dim_genre`
where genre_id is not null
group by genre_id
having count(*) > 1



  
  
    ) dbt_internal_test...
[0m12:05:53.991515 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:05:53.992286 [info ] [Thread-1 (]: 9 of 12 PASS unique_dim_genre_genre_id ......................................... [[32mPASS[0m in 0.01s]
[0m12:05:53.992577 [debug] [Thread-1 (]: Finished running node test.movie_warehouse.unique_dim_genre_genre_id.757304f7bc
[0m12:05:53.992800 [debug] [Thread-1 (]: Began running node test.movie_warehouse.unique_dim_movie_movie_id.42054933eb
[0m12:05:53.993001 [info ] [Thread-1 (]: 10 of 12 START test unique_dim_movie_movie_id .................................. [RUN]
[0m12:05:53.993242 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.movie_warehouse.unique_dim_genre_genre_id.757304f7bc, now test.movie_warehouse.unique_dim_movie_movie_id.42054933eb)
[0m12:05:53.993434 [debug] [Thread-1 (]: Began compiling node test.movie_warehouse.unique_dim_movie_movie_id.42054933eb
[0m12:05:53.995137 [debug] [Thread-1 (]: Writing injected SQL for node "test.movie_warehouse.unique_dim_movie_movie_id.42054933eb"
[0m12:05:53.995659 [debug] [Thread-1 (]: Began executing node test.movie_warehouse.unique_dim_movie_movie_id.42054933eb
[0m12:05:53.996632 [debug] [Thread-1 (]: Writing runtime sql for node "test.movie_warehouse.unique_dim_movie_movie_id.42054933eb"
[0m12:05:53.997090 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.movie_warehouse.unique_dim_movie_movie_id.42054933eb: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "test.movie_warehouse.unique_dim_movie_movie_id.42054933eb"} */

    
    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    movie_id as unique_field,
    count(*) as n_records

from `gold`.`dim_movie`
where movie_id is not null
group by movie_id
having count(*) > 1



  
  
    ) dbt_internal_test...
[0m12:05:54.009500 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m12:05:54.010431 [info ] [Thread-1 (]: 10 of 12 PASS unique_dim_movie_movie_id ........................................ [[32mPASS[0m in 0.02s]
[0m12:05:54.010730 [debug] [Thread-1 (]: Finished running node test.movie_warehouse.unique_dim_movie_movie_id.42054933eb
[0m12:05:54.010936 [debug] [Thread-1 (]: Began running node test.movie_warehouse.unique_dim_production_production_id.b674858001
[0m12:05:54.011152 [info ] [Thread-1 (]: 11 of 12 START test unique_dim_production_production_id ........................ [RUN]
[0m12:05:54.011359 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.movie_warehouse.unique_dim_movie_movie_id.42054933eb, now test.movie_warehouse.unique_dim_production_production_id.b674858001)
[0m12:05:54.011568 [debug] [Thread-1 (]: Began compiling node test.movie_warehouse.unique_dim_production_production_id.b674858001
[0m12:05:54.013365 [debug] [Thread-1 (]: Writing injected SQL for node "test.movie_warehouse.unique_dim_production_production_id.b674858001"
[0m12:05:54.013947 [debug] [Thread-1 (]: Began executing node test.movie_warehouse.unique_dim_production_production_id.b674858001
[0m12:05:54.014935 [debug] [Thread-1 (]: Writing runtime sql for node "test.movie_warehouse.unique_dim_production_production_id.b674858001"
[0m12:05:54.015523 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.movie_warehouse.unique_dim_production_production_id.b674858001: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "test.movie_warehouse.unique_dim_production_production_id.b674858001"} */

    
    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    production_id as unique_field,
    count(*) as n_records

from `gold`.`dim_production`
where production_id is not null
group by production_id
having count(*) > 1



  
  
    ) dbt_internal_test...
[0m12:05:54.021470 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m12:05:54.022330 [info ] [Thread-1 (]: 11 of 12 PASS unique_dim_production_production_id .............................. [[32mPASS[0m in 0.01s]
[0m12:05:54.022620 [debug] [Thread-1 (]: Finished running node test.movie_warehouse.unique_dim_production_production_id.b674858001
[0m12:05:54.022830 [debug] [Thread-1 (]: Began running node test.movie_warehouse.unique_fact_movie_performance_fact_id.65b692b055
[0m12:05:54.023063 [info ] [Thread-1 (]: 12 of 12 START test unique_fact_movie_performance_fact_id ...................... [RUN]
[0m12:05:54.023285 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.movie_warehouse.unique_dim_production_production_id.b674858001, now test.movie_warehouse.unique_fact_movie_performance_fact_id.65b692b055)
[0m12:05:54.023460 [debug] [Thread-1 (]: Began compiling node test.movie_warehouse.unique_fact_movie_performance_fact_id.65b692b055
[0m12:05:54.025227 [debug] [Thread-1 (]: Writing injected SQL for node "test.movie_warehouse.unique_fact_movie_performance_fact_id.65b692b055"
[0m12:05:54.026004 [debug] [Thread-1 (]: Began executing node test.movie_warehouse.unique_fact_movie_performance_fact_id.65b692b055
[0m12:05:54.027055 [debug] [Thread-1 (]: Writing runtime sql for node "test.movie_warehouse.unique_fact_movie_performance_fact_id.65b692b055"
[0m12:05:54.028062 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.movie_warehouse.unique_fact_movie_performance_fact_id.65b692b055: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "movie_clickhouse", "target_name": "dev", "node_id": "test.movie_warehouse.unique_fact_movie_performance_fact_id.65b692b055"} */

    
    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    fact_id as unique_field,
    count(*) as n_records

from `gold`.`fact_movie_performance`
where fact_id is not null
group by fact_id
having count(*) > 1



  
  
    ) dbt_internal_test...
[0m12:05:54.044662 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m12:05:54.045591 [info ] [Thread-1 (]: 12 of 12 PASS unique_fact_movie_performance_fact_id ............................ [[32mPASS[0m in 0.02s]
[0m12:05:54.045906 [debug] [Thread-1 (]: Finished running node test.movie_warehouse.unique_fact_movie_performance_fact_id.65b692b055
[0m12:05:54.046756 [debug] [MainThread]: Connection 'master' was properly closed.
[0m12:05:54.046988 [debug] [MainThread]: Connection 'test.movie_warehouse.unique_fact_movie_performance_fact_id.65b692b055' was left open.
[0m12:05:54.047235 [debug] [MainThread]: On test.movie_warehouse.unique_fact_movie_performance_fact_id.65b692b055: Close
[0m12:05:54.047477 [info ] [MainThread]: 
[0m12:05:54.047683 [info ] [MainThread]: Finished running 12 data tests in 0 hours 0 minutes and 0.44 seconds (0.44s).
[0m12:05:54.048452 [debug] [MainThread]: Command end result
[0m12:05:54.067391 [info ] [MainThread]: 
[0m12:05:54.067682 [info ] [MainThread]: [32mCompleted successfully[0m
[0m12:05:54.067882 [info ] [MainThread]: 
[0m12:05:54.068062 [info ] [MainThread]: Done. PASS=12 WARN=0 ERROR=0 SKIP=0 TOTAL=12
[0m12:05:54.068527 [debug] [MainThread]: Resource report: {"command_name": "test", "command_success": true, "command_wall_clock_time": 0.7362106, "process_in_blocks": "1944", "process_kernel_time": 0.222795, "process_mem_max_rss": "192956", "process_out_blocks": "2346", "process_user_time": 2.067382}
[0m12:05:54.068791 [debug] [MainThread]: Command `dbt test` succeeded at 12:05:54.068754 after 0.74 seconds
[0m12:05:54.068985 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff74453f10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa28eddd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa28edc10>]}
[0m12:05:54.069190 [debug] [MainThread]: Flushing usage events
